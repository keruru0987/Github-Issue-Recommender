,html_url,number,labels,state,created_at,pull_request,title,body
0,https://github.com/RaRe-Technologies/gensim/issues/1564,1564,[],closed,2017-09-04 18:49:00+00:00,,Cannot get weights from get_embedding_layer ,"So basically i am training a doc2vec model. I came across something called get_embedding_layer in KeyedVectors class which returns a embedding layer. But I am unable to retrieve the weights for this layer. 
The following is my code:
```
text_corpora = [[""hi how are you""],[""I am all good""],[""We are all good""]]
sentences = [TaggedDocument(words= text_corpora[0][0].split(),tags = ['1']),TaggedDocument(words= text_corpora[1][0].split(),tags = ['2']),TaggedDocument(words= text_corpora[2][0].split(),tags = ['3'])]
model = Doc2Vec(size = 200, window = 300, min_count = 1, workers = 4)
model.build_vocab(sentences)

model.train(sentences,total_examples=model.corpus_count,epochs=model.iter)
```
`model.wv.get_embedding_layer().get_weights()`  should give me the embeddings but its returning an empty array.
` Is model.wv.syn0` a way to retrieve the weights and initialize in the embedding layer in keras ?


Also please say whether this is the correct way to train the model."
1,https://github.com/RaRe-Technologies/gensim/issues/1566,1566,[],closed,2017-09-05 06:24:27+00:00,,LDA multicore using high amount of system cpu. upto 30 million kernel context per second,"48 core, 256 GB machine. no iops recorded.
also checked with strace a very large number of sched_yield() = 0"
2,https://github.com/RaRe-Technologies/gensim/issues/1575,1575,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2017-09-07 23:15:52+00:00,,Add preprocessing in summarize function to remove newlines in the middle of sentences,"#### Description
The `summarize` function depends on the text having at least 10 sentences as measured by `clean_text_by_sentences`.  If the text is shorter than that then the summarization fails in an undocumented way. Moreover  `clean_text_by_sentences` cannot handle properly a text with new lines
at the middle of a sentence. I suggest a preprocessing step to purge those.

I'm currently using this to workaround this bug
```
import re
text = re.sub(r'\n|\r|\t', ' ', text)
text = re.sub(r'\s+', ' ', text)
```

#### Versions
- Python 3.6.2 (default, Jul 17 2017, 16:44:45)
[GCC 4.2.1 Compatible Apple LLVM 8.1.0 (clang-802.0.42)]
- NumPy 1.13.0
- SciPy 0.19.1
- gensim 2.3.0
- FAST_VERSION 0"
3,https://github.com/RaRe-Technologies/gensim/issues/1576,1576,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 708430967, 'node_id': 'MDU6TGFiZWw3MDg0MzA5Njc=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/performance', 'name': 'performance', 'color': 'd93f0b', 'default': False, 'description': 'Issue related to performance (in HW meaning)'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}]",open,2017-09-08 13:33:00+00:00,,Check what's the reason to use double-precision in topic models,"Our TMs return vectors with double-precision `float64`, it looks like very suspicious, because `float32` is enough for all. Need to check, what's a reason of this behavior and what's a concrete method.

The first step - look at [this line in the test](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/test/basetmtests.py#L51), after it - collect all TMs, that depends on this tests and check, where and why `float64` happened.

Result - detailed description (where and why), and fixing this behavior after discussion (if needed)"
4,https://github.com/RaRe-Technologies/gensim/issues/1578,1578,[],closed,2017-09-08 16:53:14+00:00,,Doc2Vec Segmentation Fault Windows and Linux,"I've tried this basic code on both Linux and Windows.  I'm trying to do some online training and it seems like after a couple passes it throws a seg fault.

Code to recreate problem.
````
from gensim.models.doc2vec import Doc2Vec, LabeledSentence, TaggedDocument


sentences = [('food', 'I like to eat broccoli and bananas.'),
             ('food', 'I ate a banana and spinach smoothie for breakfast.'),
             ('animals', 'Chinchillas and kittens are cute.'),
             ('animals', 'My sister adopted a kitten yesterday.'),
             ('animals', 'Look at this cute hamster munching on a piece of broccoli.')]

convSentences = []
for s in sentences:
    convSentences.append(LabeledSentence(tags=[s[0]], words = s[1].split()))

model = Doc2Vec(size=300, window=8, min_count=1, workers=1)

print(""Pass 1:"")
model.build_vocab([convSentences[0]])
model.train([convSentences[0]], total_examples=model.corpus_count)

print(""Pass 2:"")
model.build_vocab([convSentences[1]], update=True)
model.train([convSentences[1]], total_examples=model.corpus_count)

print(""Pass 3:"")
model.build_vocab([convSentences[2]], update=True)
model.train([convSentences[2]], total_examples=model.corpus_count)

print(""Pass 4:"")
model.build_vocab([convSentences[3]], update=True)
model.train([convSentences[3]], total_examples=model.corpus_count)

print(""Pass 5:"")
model.build_vocab([convSentences[4]], update=True)
model.train([convSentences[4]], total_examples=model.corpus_count)
````

Here's the output running in Windows Idle.  Python 3.5.2

```
Warning (from warnings module):
  File ""C:\Python35\lib\site-packages\gensim\utils.py"", line 855
    warnings.warn(""detected Windows; aliasing chunkize to chunkize_serial"")
UserWarning: detected Windows; aliasing chunkize to chunkize_serial
Pass 1:
Pass 2:
Pass 3:
```

Passes 1-3 go quick, then a long pause and Linux throws a segmentation fault, Windows throws an unspecified error."
5,https://github.com/RaRe-Technologies/gensim/issues/1581,1581,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 575779925, 'node_id': 'MDU6TGFiZWw1NzU3Nzk5MjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/breaks%20backward-compatibility', 'name': 'breaks backward-compatibility', 'color': 'e96f1b', 'default': False, 'description': 'Change breaks backward compatibility'}, {'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",open,2017-09-10 11:15:14+00:00,,Add __init__ method in FastText,"Issue #1514 

[FastText](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/wrappers/fasttext.py#L138)  can't make default initializer. only make using `train` or `load_fasttext_format` methods( `train` method calls `load_fasttext_format` )
And input text is only received from the file.

So, If in `__init__` method receiving from python string, will be able to use it more efficiently and not be confused with the FastText constructor( In [Fasttext API](https://radimrehurek.com/gensim/models/wrappers/fasttext.html), It looks like it can be used as a constructor. because base by Word2Vec).

`def __init__(self, ft_path, corpus_text, output_file=None, model='cbow', size=100, alpha=0.025, window=5, min_count=5,
              word_ngrams=1, loss='ns', sample=1e-3, negative=5, iter=5, min_n=3, max_n=6, sorted_vocab=1, threads=12):`
How about like above method? These method arguments follow `train` but `corpus_file` changed to `corpus_text`"
6,https://github.com/RaRe-Technologies/gensim/issues/1583,1583,"[{'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 575779925, 'node_id': 'MDU6TGFiZWw1NzU3Nzk5MjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/breaks%20backward-compatibility', 'name': 'breaks backward-compatibility', 'color': 'e96f1b', 'default': False, 'description': 'Change breaks backward compatibility'}]",open,2017-09-11 13:40:36+00:00,,Move unstable/experimental models to distinct subpackage,"Now we have many models/corpses in `gensim.models.*`, but not all of this is very useful/popular/stable/fast.


For this reason, we should split this into distinct packages

How it looks now: `gensim.corpora.*` and `gensim.models.*`
How it should looks in future: distinct subpackage + copy part of tree structure: `gensim.experimental.corpora.*` and  `gensim.experimental.models.*`


What's candidates for moving to experimental: `ATModel`, `HDP`, `LdaSeq`, all wrappers (maybe, need to discussed it).
Also, maybe move `ucicorpus`, `sharedcorpus`, `indexcorpus` and `csvcorpus` too (or remove, need additional discussion)










"
7,https://github.com/RaRe-Technologies/gensim/issues/1584,1584,"[{'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 575779925, 'node_id': 'MDU6TGFiZWw1NzU3Nzk5MjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/breaks%20backward-compatibility', 'name': 'breaks backward-compatibility', 'color': 'e96f1b', 'default': False, 'description': 'Change breaks backward compatibility'}]",open,2017-09-11 14:38:53+00:00,,Remove/refactor useless subpackages,"In gensim, we have many sub-packages, but several of this should be a part of another subpackage, another part is broken/useless and should be removed.

Candidates:
- [x] `/examples` - Old broken code + confused users with name, should be removed.
- [x] ~`/parsing` - Not relevant for gensim (all of this already implemented in NLTK/etc.), should be removed (but before, need to check that this isn't used).~
- [x]  `/scripts` - Many scripts for Wikipedia + symlinks + some conversions + w2v_standalone. Need to look into all wiki scripts and understand why this needed, remove all that no needed (w2v_standalone too).
- [ ] ~`/summarization` - need to refactor code and create one model, no need distinct subpackage for this.~
- [x] ~`/topic_coherence` - same as `summarization`~
- [x] `nose.py` - unused runner for nose, should be removed.






"
8,https://github.com/RaRe-Technologies/gensim/issues/1585,1585,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2017-09-11 14:48:38+00:00,,Initial investigation/refactoring for gensim.corpora and gensim.similarities,"Tasks:

1.Go into gensim.similarities and understand what's needed/not needed, maybe refactor a little if needed.
2. In corpora, we have many corpuses and many problems with interfaces, need to go into and refactor this code.

About corpora - we have many classes (each for concrete format), maybe it will be a good idea to merge all to one wrapper `Corpus` class, with parameter, for example:

Now
```
corpus_mallet = MalletCorpus(""/path/to/filename"", metadata=True)
corpus_simple = TextCorpus(input=""/path/to/folder"", metadata=False)
```

In my proposal
```
corpus_mallet = Corpus(""/path/to/filename"", metadata=True, type=""mallet"")
corpus_simple = Corpus(""/path/to/filename"", metadata=True, type=""text"")
```

For the one hand, this simplifies the code, no need to find a concrete class, need to change only one parameter. For the other hand, this class has a lot of responsibility, it's not a good pattern."
9,https://github.com/RaRe-Technologies/gensim/issues/1586,1586,[],closed,2017-09-12 03:13:19+00:00,,Building Vector for a sentence in doc2vec from an untrained data set,"I do have a dataset (corpus size = 6 million).

Environment And Package Version:
`Linux-3.10.0-327.18.2.el7.x86_64-x86_64-with-redhat-7.2-Maipo`
`Python 3.6.0 |Anaconda 4.3.1 (64-bit)| (default, Dec 23 2016, 12:22:00) `
`[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]`
`NumPy 1.13.1`
`SciPy 0.19.1`
`gensim 2.3.0`
`FAST_VERSION 1`

I have trained the Doc2Vec model using below steps and parameters:
Step 1: Preprocessing:
Change to lower case

Step 2: Preparing the Tagged Document.

`docs = []`
`docs = [TaggedDocument(words = desc.split(),tags=[df['UNQ_ID'].ix[idx]]) for idx,desc in` `enumerate(df['DOCUMENT'].values)]`


Step 3: Model Training.

`iteration = 150`
`model = gensim.models.Doc2Vec(size=300, window=8, min_count=5, workers=8,   iter=iteration)`
`model.build_vocab(docs)`
`model.train(docs, total_examples=model.corpus_count, epochs=model.iter)`


Step 4: Save the Model.

`model.save(SAVE_NAME)`


Step 5: Find Similarity:

`UNIQUE_ID='XXX'`
`sims = mod.docvecs.most_similar(UNIQUE_ID, topn=5)`


For existing trained documents, the similarity score is above 0.8 on the average. This is good as per my use case.

There are cases. when new untrained documents are encountered.
Those scenarios, give below error:
TypeError: '<' not supported between instances of 'str' and 'int'

I tried using infec_vector() using below steps and parameters.


`UNIQUE_ID='XXX'`
`try:`
`            sims = mod.docvecs.most_similar(UNIQUE_ID, topn=5)`
`            print(""EXECUTING REGULAR mod.docvecs.most_similar"")`
`except:`
`            token = df.loc[df['UNQ_ID']==UNIQUE_ID].DOCUMENT`
`            token = token.str.split()`
`            mod.random.seed(0)`
`            new_vector = mod.infer_vector(token, steps=150)`
`            sims = mod.docvecs.most_similar([new_vector], topn=5) `
`            print(""EXECUTING infer_vector mod.docvecs.most_similar"")`
`sims`


But the similarity score is very less; for the inferred vectors.

Please let know, is there any way through which we can better logical similarity score for untrained documents.

Or other way around, how can we do real time training for Untrained documents.

Googling Around: I got below link: 
[https://stackoverflow.com/questions/32796485/building-vector-for-a-sentence-in-doc2vec-from-an-untrained-data-set?rq=1]
But in latest Gensim version (Gensim 2.3.0), we need to build_vocab before train. In real time, build_vocab for entire data set, will take more time.

`Note:`
Fixed the non-deterministic behaviour of infer_vector() using this link:
https://github.com/RaRe-Technologies/gensim/issues/447"
10,https://github.com/RaRe-Technologies/gensim/issues/1587,1587,[],closed,2017-09-13 11:35:53+00:00,,Gensim reached 5k stars on github!,"Hooray! :bomb: :fire: Gensim reached 5k stars ⭐️ .

Many thanks to our contributors, you are the best!

As a token of appreciation, we're sending a little gift to our contributors (T-shirts, mugs and other things).

**What's needed to receive the gift?**

1. You must be a contributor (at least 1 merged PR to Gensim, Smart-open or Sqlitedict)

2. Write an email to `opensource@rare-technologies.com` with the subject ""Gensim 5k*"". In the email body please include:
    - A link to your Github account
    - A link to your contribution (PR)
    - Your preferred T-shirt size
    - Your postal address

Here's an **incomplete** list of people who qualify. If I missed you - don't worry, if you are a contributor - send us an email too!

CC: @tmylk @chinmayapancholi13 @gojomo @cscorley @sotte @sebastien-j @parulsethi @mattilyra @bhargavvader @fbarrios @ziky90 @olavurmortensen @mataddy @prakhar2b @markroxor @dsquareindia @larsmans @hyhan @davechallis @dedan @temerick @jayantj @erbas @phdowling @droudy @quole @macks22 @KCzar @josephcc @hajicj @vlejd @mfcabrera @fedelopez77 @svenkreiss @jesterhazy @Arttii @alekol @tpsatish95 @isohyt @anmolgulati @souravsingh @shubhvachher @buma @luispedro @Tiepies @lechatpito @aneesh-joshi @charliejharrison @metalaman @akutuzov


"
11,https://github.com/RaRe-Technologies/gensim/issues/1588,1588,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}, {'id': 708430967, 'node_id': 'MDU6TGFiZWw3MDg0MzA5Njc=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/performance', 'name': 'performance', 'color': 'd93f0b', 'default': False, 'description': 'Issue related to performance (in HW meaning)'}]",open,2017-09-16 09:04:16+00:00,,LDA multicore stuck after a few passes,"after running properly for a 10 passes the process is stuck.
48core : 194GB , 6.7 million documents, 57,000 tokens
    num_topics = 64
    chunksize = 10000
    passes = 20
    iterations = 100
**logs stopped printing at ----**
_2017-09-15 20:10:40,745 INFO 140583487252288 PROGRESS: pass 11, dispatched chunk #147 = documents up to #1480000/6748579, outstanding queue size 109
2017-09-15 20:10:40,932 INFO 140583487252288 PROGRESS: pass 11, dispatched chunk #148 = documents up to #1490000/6748579, outstanding queue size 110
2017-09-15 20:10:41,173 INFO 140583487252288 PROGRESS: pass 11, dispatched chunk #149 = documents up to #1500000/6748579, outstanding queue size 111
2017-09-15 20:10:41,410 DEBUG 140583487252288 9924/10000 documents converged within 100 iterations
2017-09-15 20:10:41,550 INFO 140583487252288 PROGRESS: pass 11, dispatched chunk #150 = documents up to #1510000/6748579, outstanding queue size 112
2017-09-15 20:10:41,680 DEBUG 140583487252288 processed chunk, queuing the result
2017-09-15 20:10:41,955 DEBUG 140583487252288 result put
2017-09-15 20:10:41,956 DEBUG 140583487252288 getting a new job
2017-09-15 20:10:45,384 DEBUG 140554940122880 worker process entering E-step loop
2017-09-15 20:10:45,404 DEBUG 140554940122880 getting a new job
2017-09-15 20:10:49,148 DEBUG 140554940122880 worker process entering E-step loop
2017-09-15 20:10:49,195 DEBUG 140554940122880 getting a new job
2017-09-15 20:10:49,441 DEBUG 140583487252288 9920/10000 documents converged within 100 iterations
2017-09-15 20:10:49,630 DEBUG 140583487252288 processed chunk, queuing the result
2017-09-15 20:10:49,830 DEBUG 140583487252288 result put
2017-09-15 20:10:49,831 DEBUG 140583487252288 getting a new job
2017-09-15 20:10:51,158 DEBUG 140583487252288 9925/10000 documents converged within 100 iterations
2017-09-15 20:10:51,322 DEBUG 140583487252288 processed chunk, queuing the result
2017-09-15 20:10:51,344 DEBUG 140583487252288 result put
2017-09-15 20:10:51,345 DEBUG 140583487252288 getting a new job
2017-09-15 20:10:52,413 DEBUG 140583487252288 9925/10000 documents converged within 100 iterations
2017-09-15 20:10:52,597 DEBUG 140583487252288 processed chunk, queuing the result
2017-09-15 20:10:52,640 DEBUG 140554940122880 worker process entering E-step loop
2017-09-15 20:10:52,642 DEBUG 140554940122880 getting a new job
2017-09-15 20:10:53,889 DEBUG 140583487252288 result put
2017-09-15 20:10:53,891 DEBUG 140583487252288 getting a new job
2017-09-15 20:10:54,895 DEBUG 140583487252288 9934/10000 documents converged within 100 iterations
2017-09-15 20:10:55,026 DEBUG 140583487252288 processed chunk, queuing the result
2017-09-15 20:10:55,054 DEBUG 140583487252288 result put
2017-09-15 20:10:55,201 DEBUG 140583487252288 getting a new job
2017-09-15 20:10:57,169 DEBUG 140554940122880 worker process entering E-step loop
2017-09-15 20:10:57,177 DEBUG 140554940122880 getting a new job
2017-09-15 20:11:01,548 DEBUG 140554940122880 worker process entering E-step loop
2017-09-15 20:11:02,448 DEBUG 140554940122880 getting a new job
2017-09-15 20:11:13,901 DEBUG 140554940122880 worker process entering E-step loop
2017-09-15 20:11:13,905 DEBUG 140554940122880 getting a new job
2017-09-15 20:11:17,107 DEBUG 140554940122880 worker process entering E-step loop
2017-09-15 20:11:17,123 DEBUG 140554940122880 getting a new job
2017-09-15 20:11:21,198 DEBUG 140554940122880 worker process entering E-step loop
2017-09-15 20:11:21,201 DEBUG 140554940122880 getting a new job
2017-09-15 20:12:19,365 DEBUG 140583487252288 processing chunk #49 of 10000 documents
2017-09-15 20:12:19,372 DEBUG 140583487252288 performing inference on a chunk of 10000 documents
2017-09-15 20:13:02,963 DEBUG 140583487252288 9938/10000 documents converged within 100 iterations
2017-09-15 20:13:03,053 DEBUG 140583487252288 processed chunk, queuing the result
2017-09-15 20:13:03,058 DEBUG 140583487252288 result put
2017-09-15 20:13:03,058 DEBUG 140583487252288 getting a new job_

**the strace of master process is full of --- poll([{fd=6, events=POLLIN}], 1, 0)     = 0 (Timeout)**
----

**with a little activity n between. ------ like below**

_poll([{fd=6, events=POLLIN}], 1, 0)     = 0 (Timeout)
futex(0x8fffc4, FUTEX_WAKE_OP_PRIVATE, 1, 1, 0x8fffc0, {FUTEX_OP_SET, 0, FUTEX_OP_CMP_GT, 1}) = 1
futex(0x8fff80, FUTEX_WAKE_PRIVATE, 1)  = 1
poll([{fd=6, events=POLLIN}], 1, 0)     = 0 (Timeout)
futex(0x8fffc4, FUTEX_WAIT_BITSET_PRIVATE|FUTEX_CLOCK_REALTIME, 3905250003, {1505552174, 730881000}, ffffffff) = 0
futex(0x8fff80, FUTEX_WAKE_PRIVATE, 1)  = 0
futex(0x8fffc0, FUTEX_WAKE_PRIVATE, 1)  = 1
futex(0x8fffc4, FUTEX_WAIT_BITSET_PRIVATE|FUTEX_CLOCK_REALTIME, 3905250005, {1505552174, 730998000}, ffffffff) = -1 EAGAIN (Resource temporarily unavailable)
futex(0x8fff80, FUTEX_WAKE_PRIVATE, 1)  = 0
futex(0x8fffc0, FUTEX_WAKE_PRIVATE, 1)  = 1
futex(0x8fffc4, FUTEX_WAIT_BITSET_PRIVATE|FUTEX_CLOCK_REALTIME, 3905250007, {1505552174, 731179000}, ffffffff) = -1 EAGAIN (Resource temporarily unavailable)
futex(0x8fff80, FUTEX_WAKE_PRIVATE, 1)  = 0
futex(0x8fffc0, FUTEX_WAKE_PRIVATE, 1)  = 1
futex(0x8fffc4, FUTEX_WAIT_BITSET_PRIVATE|FUTEX_CLOCK_REALTIME, 3905250009, {1505552174, 731287000}, ffffffff) = -1 EAGAIN (Resource temporarily unavailable)
futex(0x8fff80, FUTEX_WAKE_PRIVATE, 1)  = 0
futex(0x8fffc4, FUTEX_WAKE_OP_PRIVATE, 1, 1, 0x8fffc0, {FUTEX_OP_SET, 0, FUTEX_OP_CMP_GT, 1}) = 1
futex(0x8fffc4, FUTEX_WAKE_OP_PRIVATE, 1, 1, 0x8fffc0, {FUTEX_OP_SET, 0, FUTEX_OP_CMP_GT, 1}) = 1
futex(0x8fff80, FUTEX_WAKE_PRIVATE, 1)  = 1
poll([{fd=6, events=POLLIN}], 1, 0)     = 0 (Timeout)
futex(0x8fffc4, FUTEX_WAKE_OP_PRIVATE, 1, 1, 0x8fffc0, {FUTEX_OP_SET, 0, FUTEX_OP_CMP_GT, 1}) = 1
futex(0x8fff80, FUTEX_WAKE_PRIVATE, 1)  = 1
futex(0x8fffc4, FUTEX_WAIT_BITSET_PRIVATE|FUTEX_CLOCK_REALTIME, 3905250017, {1505552174, 731764000}, ffffffff) = -1 EAGAIN (Resource temporarily unavailable)
futex(0x8fff80, FUTEX_WAKE_PRIVATE, 1)  = 0
futex(0x8fffc0, FUTEX_WAKE_PRIVATE, 1)  = 1
futex(0x8fffc4, FUTEX_WAIT_BITSET_PRIVATE|FUTEX_CLOCK_REALTIME, 3905250019, {1505552174, 731798000}, ffffffff) = -1 EAGAIN (Resource temporarily unavailable)
futex(0x8fff80, FUTEX_WAKE_PRIVATE, 1)  = 0
futex(0x8fffc4, FUTEX_WAKE_OP_PRIVATE, 1, 1, 0x8fffc0, {FUTEX_OP_SET, 0, FUTEX_OP_CMP_GT, 1}) = 1
poll([{fd=6, events=POLLIN}], 1, 0)     = 0 (Timeout)
futex(0x8fffc4, FUTEX_WAKE_OP_PRIVATE, 1, 1, 0x8fffc0, {FUTEX_OP_SET, 0, FUTEX_OP_CMP_GT, 1}) = 1
futex(0x8fff80, FUTEX_WAKE_PRIVATE, 1)  = 1
futex(0x8fffc4, FUTEX_WAIT_BITSET_PRIVATE|FUTEX_CLOCK_REALTIME, 3905250025, {1505552174, 732150000}, ffffffff) = -1 EAGAIN (Resource temporarily unavailable)
futex(0x8fff80, FUTEX_WAKE_PRIVATE, 1)  = 0
futex(0x8fffc0, FUTEX_WAKE_PRIVATE, 1)  = 1
futex(0x8fffc4, FUTEX_WAIT_BITSET_PRIVATE|FUTEX_CLOCK_REALTIME, 3905250027, {1505552174, 732184000}, ffffffff) = -1 EAGAIN (Resource temporarily unavailable)
futex(0x8fff80, FUTEX_WAKE_PRIVATE, 1)  = 0
futex(0x8fffc0, FUTEX_WAKE_PRIVATE, 1)  = 1
futex(0x8fffc4, FUTEX_WAIT_BITSET_PRIVATE|FUTEX_CLOCK_REALTIME, 3905250029, {1505552174, 732269000}, ffffffff) = -1 EAGAIN (Resource temporarily unavailable)
futex(0x8fff80, FUTEX_WAKE_PRIVATE, 1)  = 0
futex(0x8fffc0, FUTEX_WAKE_PRIVATE, 1)  = 1
futex(0x8fffc4, FUTEX_WAIT_BITSET_PRIVATE|FUTEX_CLOCK_REALTIME, 3905250031, {1505552174, 732372000}, ffffffff) = -1 EAGAIN (Resource temporarily unavailable)
futex(0x8fff80, FUTEX_WAKE_PRIVATE, 1)  = 0
futex(0x8fffc4, FUTEX_WAKE_OP_PRIVATE, 1, 1, 0x8fffc0, {FUTEX_OP_SET, 0, FUTEX_OP_CMP_GT, 1}) = 1
futex(0x8fff80, FUTEX_WAKE_PRIVATE, 1)  = 1
poll([{fd=6, events=POLLIN}], 1, 0)     = 0 (Timeout)
poll([{fd=6, events=POLLIN}], 1, 0)     = 0 (Timeout)_


----- **mater process is taking 100% of cpu on one core, all the other process are not taking any cpu.
there is still 5GB free ram on the system.** "
12,https://github.com/RaRe-Technologies/gensim/issues/1589,1589,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2017-09-16 17:44:54+00:00,,Problem using bound function in Author Topic model!!,"Hi
I am trying to use author topic model. When I used bound function to evaluate my model I received this error in python:
```
Traceback (most recent call last):
  File ""C:\Users\Sara\Desktop\E-COM\Final Project\Working on data\at_clustering.py"", line 161, in <module>
    test_corpus = test_corpus, test_d2a = test_doc2author, test_a2d = test_author2doc, limit = 25)
  File ""C:\Users\Sara\Desktop\E-COM\Final Project\Working on data\at_clustering.py"", line 70, in evaluate_k
    pr = np.exp2(-model.bound(test_corpus, doc2author=test_d2a, author2doc=test_a2d)/number_of_words)
  File ""C:\Python27\lib\site-packages\gensim\models\atmodel.py"", line 835, in bound
    phinorm = self.compute_phinorm(ids, authors_d, expElogtheta[authors_d, :], expElogbeta[:, ids])
IndexError: arrays used as indices must be of integer (or boolean) type
```
 I think the problem is `` expElogbeta[:, ids] `` because this is not acceptable in python!

Please test bound function and fix source code.
Thanks
"
13,https://github.com/RaRe-Technologies/gensim/issues/1591,1591,[],closed,2017-09-18 07:53:51+00:00,,lda returns TypeError: only integer scalar arrays can be converted to a scalar index,"hello
i am working on urdu language and want to do topic modeling in it.i followed this link  https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/lda_training_tips.ipynb but i am getting type error. 
Traceback (most recent call last):
  File ""main.py"", line 88, in <module>
    top_topics = lda.top_topics(corpus, num_words=5)
  File ""/home/aziya/.local/lib/python3.5/site-packages/gensim/models/ldamodel.py"", line 880, in top_topics
    for l in top_words[:m_index - 1]:
TypeError: only integer scalar arrays can be converted to a scalar index

i even tried it by reducing num of words to 5.this is my code.kindly help me by guiding me where i am doing something wrong.as i am new in gensim and lda. "
14,https://github.com/RaRe-Technologies/gensim/issues/1592,1592,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}, {'id': 708430967, 'node_id': 'MDU6TGFiZWw3MDg0MzA5Njc=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/performance', 'name': 'performance', 'color': 'd93f0b', 'default': False, 'description': 'Issue related to performance (in HW meaning)'}]",open,2017-09-18 14:15:29+00:00,,lda multicore not scaling into large number of cores,"I believe it is due to the primary process being unable to keep up with both filling up the  queues and also merging the result. 

Will it not work better if we split the queue filling part of the code into the a separate process. 
If there are separate processes for queue filling and result queue processing. i dont see any issue. 

Note: i am sure it is not a IO issue as i dont see any IO load on using iostat and iotop

Or may be I should be usig some other corpus format which takes less time to deserialize. ??

Any guidance will help. thanks in advance"
15,https://github.com/RaRe-Technologies/gensim/issues/1595,1595,[],closed,2017-09-20 05:03:13+00:00,,Can not load LineSentencePath ,"`sentences =  gensim.models.word2vec.LineSentencePath('/apsarapangu/disk3/yanan/')`

I try to specify the path to read the files under it. There are many files in the path as sentences.
But it comes that `'module' object has no attribute 'LineSentencePath'`.
What's wrong with it ?
Any example code about how to read huge files as sentences ? "
16,https://github.com/RaRe-Technologies/gensim/issues/1596,1596,[],closed,2017-09-20 13:50:48+00:00,,gensim support GPU programming?,"Dear,

gensim support GPU programming? 
I tried to import gensim and using model.lsi, it seems it does not support GPU programming.

"
17,https://github.com/RaRe-Technologies/gensim/issues/1597,1597,[],closed,2017-09-23 16:45:02+00:00,,Error when most_important_docs in summarizer.py is None,"```python
In [0]: gensim.__version__
Out [0]: '2.3.0'
```
Description:
I was working on a set of Chinese sentences. And when I call the function `gensim.summarization.summarize()`.The Error below was occurred: 
``` python
  File ""/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/gensim/summarization/summarizer.py"", line 215, in summarize
    extracted_sentences = _extract_important_sentences(sentences, corpus, most_important_docs, word_count)
  File ""/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/gensim/summarization/summarizer.py"", line 114, in _extract_important_sentences
    important_sentences = _get_important_sentences(sentences, corpus, important_docs)
  File ""/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/gensim/summarization/summarizer.py"", line 89, in _get_important_sentences
    return [sentences_by_corpus[tuple(important_doc)] for important_doc in important_docs]
TypeError: 'NoneType' object is not iterable
```
It seems that the important_doc is None, and NoneType cannot be iterated. 
Well, I didn't learn so much of TextRank Algorithm, and I am trying to go on to work. Maybe someone can tell what is happening? 

PS: Sorry that I could not afford the test case I was using, for it is full of Chinese name. (If someone ask me privately, maybe i could.) Anyway, there is a bug in it. For some reason the `most_important_docs` at line 212, `summarizer.py` is `None`. This situation should be handled properly. I suppose that summarize() should return None or raise some other Error for debugging when `most_important_docs` is `None`. Or even better, optimize the implementation of TextRank Algorithm, which is fully out of my ability for now... 
``` python
>>> s = '`a string full of different Chinese name, with the number of more than 1 thousand.`'
>>> import gensim.summarization as gsum
>>> gsum.summarize(s)
```
"
18,https://github.com/RaRe-Technologies/gensim/issues/1600,1600,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2017-09-26 11:18:39+00:00,,Only take forward window step of a sentence for Word2vec,"According to Word2vec doc, the parameter window is the maximum distance between the current and predicted word within a sentence, it will take backward and forward distance around a word as a context, 
but how can I only take the forward distance, add a patch? 
"
19,https://github.com/RaRe-Technologies/gensim/issues/1601,1601,[],closed,2017-09-28 10:34:40+00:00,,Word2Vec RAM error when vector size is large,"I'm using word2vec model on MacBook with 16GB of RAM. The input text is 45GB in h5df. 

When the vector size is 50. It runs successfully. When the vector size is 100, it prints

>2017-09-28 14:52:30,736 : INFO : PROGRESS: at 0.29% examples, 42940 words/s, in_qsize 0, out_qsize 0
>Killed: 9 

How can I solve this error?

"
20,https://github.com/RaRe-Technologies/gensim/issues/1602,1602,[],closed,2017-09-28 18:13:06+00:00,,DTM tutorial steps extracted all the same topics for all timestamps,"Hi,

   I've tried following the DTM tutorial almost line by line to extract topics from a corpus.  Using scikit-learn, I can see that there are distinct topics in the corpus, and also that the topics change as a function of time.  However, dtm doesn't seem to produce anything that makes sense.

    Here is my 4-member list of documents:

      documents = [[u'worth', u'deli', u'month', u'enjoy', u'bacon', u'second', u'street', u'even', u'new',u'ever', u'told', u'met', u'daughter', u'brought', u'spoke', u'would', u'asset', u'type', u'tell', u'phone', u'hold', u'room', u'work', u'fresher', u'give', u'household', u'want', u'keep', u'bag', u'end', u'thing', u'travel', u'hot', u'lay', u'third', u'alka', u'greet', u'green', u'enter', u'order', u'wine', u'better', u'easier', u'bread', u'meat', u'went', u'forgot', u'laid', u'got', u'free', u'local', u'tilapia', u'shopper', u'top', u'took', u'hadnt', u'matter', u'mind', u'manner', u'seen', u'seem', u'brandon', u'blue', u'though', u'regular', u'stood', u'make', u'layout', u'aldi', u'stop', u'watermelon', u'twice', u'bad', u'respond', u'best', u'said', u'away', u'yogurt', u'never', u'fault', u'tone', u'speak', u'bathroom', u'beef', u'much', u'save', u'n', u'dept', u'near', u'neat', u'gave', u'sushi', u'cant', u'im', u'ie', u'hand', u'butter', u'kept', u'contact', u'left', u'previous', u'spread', u'gift', u'cooler', u'right', u'old', u'deal', u'ice', u'discount', u'super', u'dinner', u'wrap', u'way', u'head', u'offer', u'upset', u'drive', u'check', u'floor', u'tie', u'smell', u'kroger', u'longer', u'loyal', u'time', u'mile', u'milk', u'anyway', u'item', u'team', u'guy', u'pork', u'sign', u'cost', u'patient', u'clerk', u'along', u'wait', u'box', u'shift', u'love', u'extra', u'prefer', u'market', u'visit', u'live', u'creamer', u'checkout', u'today', u'cashier', u'car', u'product', u'may', u'date', u'man', u'talk', u'still', u'thank', u'main', u'non', u'within', u'name', u'receipt', u'happen', u'correct', u'cart', u'california', u'card', u'care', u'place', u'think', u'frequent', u'first', u'one', u'long', u'ring', u'open', u'tomorrow', u'size', u'checker', u'wide', u'raincheck', u'nicer', u'say', u'saw', u'take', u'sure', u'price', u'knew', u'paid', u'seafood', u'later', u'sale', u'senior', u'shop', u'show', u'bright', u'ground', u'slow', u'enough', u'get', u'seldom', u'husband', u'across', u'sacker', u'come', u'restroom', u'pop', u'mark', u'ive', u'everyday', u'pay', u'trip', u'week', u'assist', u'fruit', u'without', u'reward', u'money', u'young', u'rest', u'speed', u'except', u'real', u'around', u'read', u'world', u'tend', u'either', u'perfer', u'highest', u'wheat', u'ok', u'act', u'road', u'coupon', u'strip', u'area', u'start', u'low', u'heb', u'regard', u'toilet', u'certain', u'incorrect', u'personnel', u'event', u'poor', u'wife', u'missouri', u'follow', u'smile', u'fav', u'fat', u'ticket', u'list', u'small', u'neighborhood', u'andor', u'past', u'section', u'prior', u'amount', u'pick', u'put', u'eye', u'two', u'particular', u'town', u'none', u'del', u'scan', u'gallon', u'huge', u'okay', u'rude', u'short', u'egg', u'help', u'paper', u'might', u'good', u'return', u'food', u'found', u'hard', u'expect', u'beyond', u'health', u'print', u'friday', u'guess', u'pleasant', u'quick', u'reason', u'ask', u'major', u'dont', u'feel', u'number', u'done', u'gourmet', u'least', u'store', u'relationship', u'park', u'kind', u'wasnt', u'sell', u'self', u'jonmark', u'reach', u'plan', u'clear', u'part', u'clean', u'fine', u'find', u'express', u'cheaper', u'cold', u'x', u'see', u'close', u'grocer', u'sold', u'water', u'last', u'mega', u'whole', u'point', u'ran', u'pm', u'citizen', u'understand', u'demand', u'look', u'frozen', u'bill', u'smart', u'error', u'higher', u'walmart', u'lower', u'person', u'cut', u'also', u'eager', u'easter', u'complaint', u'big', u'bit', u'like', u'lost', u'often', u'back', u'understood', u'run', u'question', u'fast', u'doubt', u'line', u'us', u'nice', u'lane', u'e', u'came', u'fresh', u'hello', u'code', u'go', u'sent', u'download', u'cell', u'let', u'great', u'larger', u'survey', u'app', u'use', u'next', u'sore', u'didnt', u'high', u'friendlier', u'instead', u'stand', u'watch', u'light', u'counter', u'move', u'lb', u'front', u'day', u'stock', u'special', u'red', u'que', u'could', u'david', u'lot', u'shelf', u'bother', u'need', u'pharmacist', u'request', u'hi', u'fact', u'bring', u'keyera', u'chicken', u'staff', u'fuel', u'familiar', u'closer', u'neither', u'bought', u'job', u'instant', u'etc', u'comment', u'gone', u'walk', u'commend', u'ad', u'treat', u'vanilla', u'ill', u'almost', u'began', u'cream', u'upon', u'center', u'well', u'thought', u'rush', u'less', u'half', u'match', u'know', u'desk', u'helpful', u'soft', u'church', u'home', u'although', u'justin', u'buy', u'brand', u'bagger', u'made', u'whether', u'wish', u'smooth', u'cake', u'problem'], [u'four', u'deli', u'enjoy', u'second', u'street', u'even', u'new', u'ever', u'told', u'met', u'cart', u'daughter', u'credit', u'brought', u'total', u'spoke', u'would', u'call', u'asset', u'recommend', u'tell', u'warm', u'must', u'room', u'work', u'give', u'want', u'end', u'turn', u'far', u'hot', u'mess', u'earlier', u'wrong', u'lot', u'greet', u'green', u'fan', u'order', u'wine', u'better', u'mgmt', u'bread', u'meat', u'roast', u'went', u'side', u'saturday', u'got', u'free', u'rang', u'shopper', u'top', u'listen', u'took', u'esta', u'ran', u'mind', u'ginger', u'manner', u'seen', u'seem', u'blue', u'regular', u'dog', u'came', u'layout', u'explain', u'aldi', u'stop', u'watermelon', u'bag', u'bad', u'steak', u'steam', u'best', u'said', u'away', u'muy', u'bien', u'yogurt', u'never', u'theresa', u'speak', u'much', u'life', u'xxx', u'worker', u'near', u'neat', u'k', u'cant', u'im', u'id', u'suggest', u'make', u'rain', u'hand', u'butter', u'kept', u'game', u'left', u'save', u'apart', u'gift', u'right', u'old', u'deal', u'ice', u'corn', u'discount', u'super', u'afternoon', u'way', u'head', u'offer', u'true', u'fort', u'later', u'drive', u'mold', u'trip', u'floor', u'na', u'til', u'roll', u'felt', u'weekend', u'phone', u'loyal', u'time', u'mile', u'milk', u'brown', u'level', u'item', u'team', u'quick', u'guy', u'round', u'pork', u'sign', u'cost', u'appear', u'clerk', u'address', u'along', u'wait', u'love', u'extra', u'prefer', u'visit', u'live', u'thru', u'checkout', u'today', u'cashier', u'car', u'soup', u'freezer', u'alway', u'product', u'may', u'floral', u'man', u'basket', u'talk', u'cold', u'still', u'mail', u'main', u'half', u'son', u'wont', u'name', u'en', u'receipt', u'year', u'girl', u'es', u'correct', u'card', u'care', u'thing', u'place', u'think', u'frequent', u'first', u'one', u'long', u'ring', u'open', u'size', u'given', u'plastic', u'checker', u'wide', u'pre', u'raincheck', u'say', u'saw', u'take', u'sure', u'price', u'knew', u'paid', u'seafood', u'sale', u'senior', u'shop', u'shot', u'slow', u'behind', u'get', u'husband', u'concern', u'across', u'sacker', u'come', u'por', u'squash', u'case', u'ive', u'restroom', u'pay', u'check', u'week', u'assist', u'fruit', u'without', u'reward', u'comment', u'outdoor', u'money', u'rest', u'brianna', u'rose', u'except', u'around', u'either', u'satisfecha', u'tube', u'broken', u'found', u'throw', u'ok', u'area', u'hey', u'start', u'low', u'heb', u'enough', u'younger', u'longer', u'asst', u'gone', u'ad', u'certain', u'personnel', u'event', u'poor', u'missouri', u'month', u'tx', u'program', u'smile', u'fall', u'list', u'small', u'neighborhood', u'past', u'pass', u'stood', u'section', u'full', u'reason', u'prior', u'amount', u'pick', u'ask', u'select', u'eye', u'two', u'particular', u'none', u'hour', u'learn', u'clutter', u'prompt', u'scan', u'huge', u'rather', u'rude', u'soda', u'reflect', u'short', u'began', u'help', u'soon', u'paper', u'late', u'friendliest', u'might', u'good', u'return', u'food', u'bigger', u'fish', u'hard', u'expect', u'todo', u'friday', u'guess', u'pleasant', u'dont', u'feel', u'number', u'interact', u'least', u'storm', u'store', u'option', u'deshawn', u'kind', u'toward', u'wasnt', u'self', u'also', u'part', u'cereal', u'fine', u'find', u'access', u'express', u'cheaper', u'breast', u'set', u'see', u'bare', u'sea', u'close', u'sold', u'water', u'last', u'mega', u'whole', u'load', u'point', u'sweet', u'throughout', u'due', u'pm', u'gal', u'understand', u'look', u'frozen', u'bill', u'pack', u'pound', u'kroger', u'belong', u'tiljuanna', u'higher', u'walmart', u'older', u'spent', u'person', u'spend', u'cut', u'eager', u'app', u'complaint', u'big', u'redeem', u'bit', u'often', u'back', u'pet', u'though', u'per', u'run', u'bc', u'within', u'question', u'fast', u'line', u'us', u'nice', u'clean', u'lane', u'e', u'fresh', u'hello', u'go', u'young', u'lower', u'sent', u'booth', u'download', u'cell', u'chose', u'let', u'great', u'larger', u'survey', u'opinion', u'use', u'next', u'meet', u'didnt', u'high', u'bend', u'six', u'instead', u'stock', u'farm', u'watch', u'ronald', u'counter', u'houston', u'move', u'perfect', u'lo', u'coupon', u'weber', u'front', u'day', u'red', u'que', u'could', u'put', u'keep', u'sack', u'fair', u'system', u'shelf', u'need', u'gluten', u'pharmacist', u'face', u'fact', u'bring', u'chicken', u'staff', u'fuel', u'local', u'hope', u'familiar', u'rush', u'werent', u'twice', u'stuff', u'state', u'bought', u'job', u'thank', u'etc', u'co', u'walk', u'cent', u'vanilla', u'ripe', u'almost', u'cream', u'difficult', u'upon', u'center', u'well', u'thought', u'usual', u'less', u'bell', u'add', u'citizen', u'match', u'know', u'desk', u'like', u'dept', u'page', u'home', u'although', u'justin', u'three', u'scanner', u'buy', u'brand', u'bagger', u'eat', u'made', u'wish', u'problem', u'threw', u'special', u'sick', u'stay'], [u'four', u'hate', u'restock', u'worth', u'deli', u'frozen', u'enjoy', u'almond', u'bacon', u'second', u'street', u'ill', u'even', u'new', u'ever', u'told', u'men', u'met', u'brought', u'spoke', u'would', u'call', u'type', u'tell', u'hurt', u'phone', u'must', u'word', u'room', u'work', u'ms', u'mr', u'fresher', u'give', u'want', u'end', u'turn', u'hot', u'mess', u'earlier', u'wrong', u'greet', u'order', u'feedback', u'oven', u'better', u'easier', u'interrupt', u'one', u'bank', u'bread', u'meat', u'went', u'side', u'forgot', u'got', u'free', u'rang', u'shopper', u'top', u'took', u'esta', u'ran', u'raw', u'manner', u'seen', u'seem', u'though', u'regular', u'came', u'teresa', u'layout', u'explain', u'stop', u'bar', u'bad', u'best', u'said', u'away', u'gentleman', u'yogurt', u'never', u'speak', u'beef', u'three', u'beer', u'much', u'dept', u'near', u'neat', u'cant', u'im', u'id', u'suggest', u'make', u'split', u'hand', u'butter', u'kept', u'left', u'yet', u'previous', u'ham', u'save', u'gave', u'night', u'sacker', u'right', u'old', u'deal', u'bottom', u'ice', u'discount', u'dinner', u'wan', u'wal', u'gift', u'way', u'head', u'true', u'sale', u'face', u'check', u'floor', u'na', u'smell', u'roll', u'felt', u'diet', u'younger', u'faster', u'loyal', u'fact', u'time', u'mild', u'milk', u'row', u'item', u'quick', u'guy', u'round', u'pork', u'sign', u'run', u'clerk', u'slow', u'wait', u'box', u'bob', u'love', u'extra', u'prefer', u'super', u'visit', u'live', u'today', u'cashier', u'car', u'soup', u'kym', u'sunday', u'product', u'may', u'date', u'man', u'basket', u'talk', u'cold', u'still', u'group', u'thank', u'mail', u'gel', u'non', u'half', u'son', u'name', u'rock', u'pizza', u'el', u'receipt', u'es', u'correct', u'cart', u'card', u'care', u'thing', u'place', u'think', u'frequent', u'first', u'fast', u'ring', u'open', u'size', u'plastic', u'checker', u'wide', u'bag', u'say', u'saw', u'tshey', u'greek', u'note', u'take', u'green', u'sure', u'normal', u'price', u'paid', u'seafood', u'senior', u'shop', u'shot', u'bright', u'label', u'enough', u'get', u'across', u'come', u'por', u'turkey', u'mark', u'mart', u'case', u'ive', u'clutter', u'buyl', u'pay', u'trip', u'week', u'without', u'money', u'flavor', u'except', u'around', u'read', u'traffic', u'either', u'satisfecha', u'tube', u'wheat', u'broken', u'found', u'comparison', u'act', u'road', u'coupon', u'area', u'start', u'low', u'heb', u'expect', u'toilet', u'certain', u'file', u'fill', u'incorrect', u'personnel', u'event', u'trash', u'u', u'missouri', u'lack', u'dollar', u'month', u'tx', u'program', u'smile', u'woman', u'far', u'fat', u'list', u'small', u'neighborhood', u'andor', u'past', u'stood', u'section', u'public', u'movement', u'full', u'theresa', u'search', u'ahead', u'amount', u'pick', u'select', u'eye', u'two', u'taken', u'diamond', u'particular', u'none', u'hour', u'prompt', u'scan', u'accept', u'huge', u'rather', u'sandwich', u'okay', u'rude', u'short', u'egg', u'help', u'soon', u'paper', u'might', u'good', u'return', u'food', u'weight', u'fish', u'hard', u'finish', u'beyond', u'todo', u'shipment', u'friday', u'pleasant', u'reason', u'put', u'teach', u'fruit', u'dont', u'feel', u'number', u'smaller', u'done', u'miss', u'interact', u'least', u'station', u'jed', u'store', u'part', u'kind', u'cleaner', u'wasnt', u'self', u'reach', u'clean', u'fine', u'find', u'express', u'cheaper', u'silk', u'courteous', u'see', u'close', u'sold', u'water', u'last', u'mega', u'whole', u'point', u'sweet', u'throughout', u'belt', u'due', u'pm', u'look', u'pack', u'kroger', u'higher', u'walmart', u'lower', u'older', u'spent', u'person', u'spend', u'patel', u'cut', u'big', u'bit', u'often', u'back', u'pet', u'patient', u'within', u'question', u'long', u'line', u'checkout', u'us', u'nice', u'competitor', u'ago', u'lane', u'inout', u'fresh', u'hello', u'go', u'young', u'sent', u'cell', u'rotten', u'let', u'great', u'larger', u'survey', u'app', u'use', u'next', u'salad', u'didnt', u'kassidi', u'process', u'high', u'friendlier', u'instead', u'stand', u'counter', u'move', u'meatseafood', u'perfect', u'la', u'willing', u'holiday', u'front', u'day', u'stock', u'special', u'que', u'could', u'ask', u'keep', u'sack', u'floral', u'lot', u'shelf', u'bother', u'neel', u'need', u'mix', u'pharmacist', u'bring', u'chicken', u'longer', u'staff', u'jar', u'fuel', u'hope', u'familiar', u'rush', u'werent', u'stuff', u'grab', u'salmon', u'closer', u'state', u'bought', u'job', u'etc', u'comment', u'gone', u'walk', u'respect', u'ad', u'decent', u'treat', u'almost', u'cream', u'drink', u'center', u'well', u'thought', u'usual', u'less', u'bell', u'match', u'know', u'desk', u'like', u'soft', u'italian', u'home', u'avoid', u'although', u'buy', u'gluten', u'brand', u'hi', u'bagger', u'eat', u'also', u'made', u'wish', u'cake', u'problem', u'display', u'girl'], [u'worth', u'deli', u'school', u'enjoy', u'bacon', u'second', u'street', u'even', u'new', u'ever', u'told', u'never', u'credit', u'brought', u'total', u'spoke', u'would', u'call', u'type', u'tell', u'oscar', u'phone', u'hold', u'must', u'room', u'work', u'ms', u'give', u'want', u'end', u'thing', u'greet', u'order', u'better', u'easier', u'bread', u'meat', u'went', u'got', u'free', u'small', u'rang', u'shopper', u'listen', u'took', u'manner', u'seen', u'seem', u'though', u'regular', u'came', u'teresa', u'layout', u'earn', u'bag', u'bad', u'best', u'said', u'away', u'gentleman', u'yogurt', u'speak', u'bathroom', u'beef', u'three', u'much', u'life', u'worker', u'meyer', u'n', u'dept', u'near', u'neat', u'cant', u'im', u'make', u'rain', u'hand', u'butter', u'kept', u'contact', u'left', u'yet', u'save', u'gave', u'gift', u'night', u'right', u'old', u'deal', u'ice', u'corn', u'discount', u'super', u'dinner', u'nixon', u'son', u'wal', u'way', u'war', u'head', u'offer', u'true', u'sale', u'door', u'download', u'check', u'na', u'nd', u'til', u'felt', u'diet', u'longer', u'loyal', u'time', u'mile', u'milk', u'veg', u'brown', u'cool', u'item', u'quick', u'yall', u'pork', u'cost', u'appear', u'current', u'clerk', u'water', u'wait', u'love', u'extra', u'prefer', u'visit', u'live', u'thru', u'checkout', u'today', u'cashier', u'effort', u'car', u'product', u'may', u'floral', u'man', u'basket', u'still', u'thank', u'non', u'name', u'receipt', u'year', u'space', u'cart', u'card', u'place', u'think', u'first', u'one', u'long', u'ring', u'open', u'checker', u'wide', u'coconut', u'raincheck', u'sad', u'say', u'saw', u'take', u'sure', u'price', u'knew', u'seafood', u'later', u'drive', u'senior', u'shop', u'show', u'bright', u'corner', u'ground', u'slow', u'enough', u'black', u'get', u'behind', u'across', u'come', u'turkey', u'case', u'ive', u'etc', u'pay', u'trip', u'week', u'finish', u'assist', u'fruit', u'without', u'reward', u'comment', u'money', u'flavor', u'real', u'around', u'isiss', u'either', u'found', u'ok', u'stand', u'luck', u'road', u'mart', u'area', u'start', u'low', u'heb', u'regard', u'taylor', u'ad', u'cream', u'peak', u'wife', u'missouri', u'month', u'children', u'program', u'th', u'smile', u'woman', u'far', u'list', u'yasmin', u'neighborhood', u'tea', u'cash', u'past', u'pass', u'section', u'full', u'theresa', u'pick', u'put', u'eye', u'two', u'diamond', u'dion', u'particular', u'glad', u'none', u'learn', u'accept', u'huge', u'rather', u'okay', u'rude', u'short', u'help', u'paper', u'might', u'good', u'food', u'pregnant', u'fish', u'hard', u'expect', u'beyond', u'event', u'hill', u'friday', u'pleasant', u'reason', u'ask', u'dont', u'feel', u'number', u'least', u'store', u'park', u'part', u'kind', u'toward', u'wasnt', u'sell', u'self', u'lit', u'also', u'reach', u'clear', u'mylnn', u'clean', u'gold', u'fine', u'find', u'express', u'see', u'close', u'sold', u'last', u'mega', u'whole', u'bell', u'sweet', u'church', u'belt', u'due', u'pm', u'look', u'frozen', u'budget', u'pack', u'kroger', u'higher', u'walmart', u'lower', u'person', u'five', u'patel', u'easter', u'big', u'bit', u'often', u'back', u'run', u'question', u'fast', u'line', u'us', u'nice', u'helpful', u'lane', u'e', u'fresh', u'hello', u'go', u'young', u'access', u'let', u'great', u'larger', u'survey', u'app', u'use', u'next', u'sort', u'salad', u'meet', u'didnt', u'high', u'instead', u'toddler', u'stock', u'stop', u'counter', u'move', u'bunch', u'perfect', u'lb', u'coupon', u'front', u'day', u'circular', u'lentil', u'special', u'could', u'keep', u'date', u'accent', u'lot', u'shelf', u'need', u'pharmacist', u'upset', u'fact', u'chicken', u'staff', u'fuel', u'local', u'hope', u'familiar', u'werent', u'closer', u'bought', u'job', u'walk', u'scanner', u'main', u'ripe', u'almost', u'upon', u'center', u'well', u'thought', u'usual', u'less', u'obtain', u'citizen', u'know', u'like', u'onion', u'home', u'buy', u'brand', u'bagger', u'made', u'wish', u'cake', u'problem', u'threw', u'display', u'monday']]

   Then I do:

     class DTMcorpus(corpora.textcorpus.TextCorpus):

         def get_texts(self):
             return self.input

       def __len__(self):
            return len(self.input)

    corpus = DTMcorpus(documents)
    time_seq = [2,2]

 and 

    model = DtmModel(dtm_path, corpus, time_seq, num_topics=10,
                  id2word=corpus.dictionary, initialize_lda=True)

 everything seems to run ok, so finally I print out the first 3 topics from the first time slice:

    topics1 = model.show_topic(topicid=0, time=0, num_words=10)
    topics2 = model.show_topic(topicid=1,time=0,num_words=10)
    topics3 = model.show_topic(topicid=2,time=0,num_words=10)

which gives me

    ([(0.0013106159895150723, u'per'),
    (0.0013106159895150723, u'access'),
    (0.0013106159895150723, u'saturday'),
    (0.0013106159895150723, u'es'),
    (0.0013106159895150723, u'concern'),
    (0.0013106159895150723, u'throughout'),
    (0.0013106159895150723, u'appear'),
    (0.0013106159895150723, u'pet'),
    (0.0013106159895150723, u'tube'),
    (0.0013106159895150723, u'muy')],
    [(0.0013106159895150723, u'per'),
    (0.0013106159895150723, u'access'),
    (0.0013106159895150723, u'saturday'),
    (0.0013106159895150723, u'es'),
    (0.0013106159895150723, u'concern'),
    (0.0013106159895150723, u'throughout'),
    (0.0013106159895150723, u'appear'),
    (0.0013106159895150723, u'pet'),
    (0.0013106159895150723, u'tube'),
    (0.0013106159895150723, u'muy')],
    [(0.0013106159895150717, u'per'),
    (0.0013106159895150717, u'access'),
    (0.0013106159895150717, u'saturday'),
    (0.0013106159895150717, u'es'),
    (0.0013106159895150717, u'concern'),
    (0.0013106159895150717, u'throughout'),
    (0.0013106159895150717, u'appear'),
    (0.0013106159895150717, u'pet'),
    (0.0013106159895150717, u'tube'),
    (0.0013106159895150717, u'muy')])   

  I also get the exact same topics for any other time slice. 
   
   Could you please help.   Thank you!




"
21,https://github.com/RaRe-Technologies/gensim/issues/1604,1604,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2017-10-02 10:38:52+00:00,,Fix irrelevant wiki pages,"We have several pages in wiki part, but a huge part of the information is outdated. Need to fix it.

- Word2Vec & Doc2Vec Wishlist - outdated, need to remove
- Home - useless, need to remove
- Developer page - need to update for current state
- GSOC 2017 project ideas - mark as archive (GSOC 2017 was finished)
- Student Projects / Ideas & Feature proposals - merge this to one & remove unrelevant & add info about what's already implement
- Recipes & FAQ - Need to refactor from start
- Roadmap - outdated, need to write new
"
22,https://github.com/RaRe-Technologies/gensim/issues/1609,1609,[],closed,2017-10-03 18:36:00+00:00,,How do you avoid Garbage in garbage out?,"How do you plan out your program that uses gensim? Which questions do you ask yourself to tokenize properly and get usable results? How do you avoid Garbage in garbage out?
"
23,https://github.com/RaRe-Technologies/gensim/issues/1610,1610,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2017-10-04 13:04:33+00:00,,"Add ""DOI badge"" to gensim","Gensim's DOI is `10.13140/2.1.2393.1847`; the badge link should lead to https://www.researchgate.net/publication/255820377_Software_Framework_for_Topic_Modelling_with_Large_Corpora?channel=doi&linkId=0c960528f6404db272000000&showFulltext=true

(I saw this badge in https://github.com/tqdm/tqdm via #451 ; the goal is to promote more citations)"
24,https://github.com/RaRe-Technologies/gensim/issues/1611,1611,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",open,2017-10-04 15:45:13+00:00,,There is no load with file handle,"Through ```utils.SaveLoad```, some classes (like Corups) offer saving with a filename or a file-like object (*fname_or_handle*). However, the corresponding load method only allows filenames, making it more cumbersome to work with in case one uses a non-standard file system.

If this feature (adding the ability to load from file-like object) is desirable, I'd be happy to send a PR."
25,https://github.com/RaRe-Technologies/gensim/issues/1613,1613,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2017-10-05 11:57:54+00:00,,Add tools for run all basic operations for repository,"General ""one-line"" tools for run test/docs/etc is very useful for all developers, for this reason, we need to implement this functionality. Possible tools: `make` or `fabric` (or maybe something better?)

**attention**: for all actions firstly we must create clean virtual enviroment

What's need to implement:
- [x] tool test (with options full/default, where full - with all wrappers, need to install it if needed)
- [x] tool pep8 (check all python code with pep8)
- [x] tool docs (build documentation)
- [x] tool docs upload (build + upload to site)
- [x] another things (for release only, like download wheels + upload to pypi)

After it, need to make several changes in repo
- [x] Update developer guide (add new commands + describe current release process more detailed)
- [x] Update CI (use same things for Travis, for appveyor too if possible)
"
26,https://github.com/RaRe-Technologies/gensim/issues/1614,1614,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2017-10-06 03:23:32+00:00,,gensim import is very slow,"#### Description
Gensim import works very long if you'll have installed Keras+TF, report from [maillist](https://groups.google.com/forum/#!msg/gensim/HY90TZiBiAA/td4fsmwFBgAJ)

#### Steps/Code/Corpus to Reproduce
```
import gensim
```

#### Expected Results
Fast import (less than 0.5 sec) without any `stdout`

#### Actual Results
Slow import (more that 1 sec) + `Using TensorFlow backend.`

"
27,https://github.com/RaRe-Technologies/gensim/issues/1617,1617,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}]",closed,2017-10-10 04:05:44+00:00,,Under utilization of CPU cores when running Word2Vec,"#### Description
I am training a word2vec model with a preprocessed wiki corpus(~8GB) on a dedicated Softlayer cloud instance with the following system configuration:
`56 cores x 2.0GHz, 128GB RAM, 100GB(SAN), Ubuntu Linux 16.04 LST Minimal Install (64 bit).`
I run the code in a docker with **56 workers**. While I can see 56 processes(in training phase), the aggregated CPU utilization is around **1100%**. Screenshots of CPU utilization of each process can be seen below.
Why is total CPU utilization not around 5600%? Is this behavior expected? Am I missing something trivial?

#### Steps/Code/Corpus to Reproduce
Link to gensim [code](https://github.com/manneshiva/benchmark-word2vec-frameworks/blob/master/nn_frameworks/gensim/gensim_word2vec.py)
Link to [Dockerfile](https://github.com/manneshiva/benchmark-word2vec-frameworks/blob/master/Dockerfile-cpu-tfsource)

#### Expected Results
Total CPU utilization > 1100%. Should be around 5600%. 

#### Actual Results
Link to [INFO logs](https://gist.github.com/manneshiva/c4b7fd200507664fa3145b591be17be7).

`top -H -p <PID>`
![top](https://user-images.githubusercontent.com/26998249/31368736-300b7624-ad9d-11e7-9c38-4876e8d679af.png)

`htop`
![selection_006](https://user-images.githubusercontent.com/26998249/31368794-828f3714-ad9d-11e7-8a58-bafe552b3fae.jpg)

#### Versions
Linux-4.10.0-21-generic-x86_64-with-Ubuntu-16.04-xenial
('Python', '2.7.12 (default, Nov 19 2016, 06:48:10) \n[GCC 5.4.0 20160609]')
('NumPy', '1.13.1')
('SciPy', '0.19.1')
('gensim', '2.1.0')
('FAST_VERSION', 1)


"
28,https://github.com/RaRe-Technologies/gensim/issues/1623,1623,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}]",closed,2017-10-11 06:03:13+00:00,,"Potential unification/optimization/simplification/enhancement refactor of *2Vec & related algorithms (FastText, Sent2Vec, FastSent, etc)","Word2Vec, Doc2Vec, FastText, FastSent (#612), Sent2Vec (#1376), 'Doc2VecWithCorruption' (#1159) and others are variants on the same core technique. They should share more code, and perhaps even be implemented as alternate parameter-choices on the same refactored core functions.

A big refactoring (including from-scratch API design) could potentially offer some or all of the following:

1. sharing more code between different modes (SG/CBOW/DBOW/DM/FastText-classification/other), by discovering the ways they're parameterized variants of a shared process

2. making other creative variations possible, even if just experimentally (different kinds of context-windows, dropout strategies, alternate learning-optimizations like AdaGrad/etc, re-weightings of individual examples/vectors, separate input/output vocabularies, 'bloom embeddings', more kinds of 'inference', etc)

3. making it easier to use non-natural-language datasets, perhaps by providing ability to supply examples in an interim (raw-int-indexes) format (other than string tokens), and example transformer/caching classes that turn either texts or other corpuses into the right format

4. eliminating the hard-to-maintain dual-path pure-Python & Cython implementations - perhaps by going to something like Numba-only, or removing the (performance-non-competitive) pure-Python paths whenever Cython code is clean enough

5. avoiding common user errors & sources of confusion - by renaming parameters/methods, updating defaults, separating logically distinct steps into independent code/classes – then providing updated demo notebooks showing the new modes of operation

6. throughput optimizations, including getting away from the 'master single-corpus-reader thread', or using processes rather than threads if that's the only way to avoid GIL contention bottlenecks

7. separating vocabulary-management into explicitly different classes/objects, for more control/customization, perhaps including closer integration with new n-gram (phrasing) options

"
29,https://github.com/RaRe-Technologies/gensim/issues/1624,1624,[],closed,2017-10-11 07:17:17+00:00,,Evaluation of existing Poincaré embedding implementations,"Implementations
- https://github.com/TatsuyaShirakawa/poincare-embedding
- https://github.com/nishnik/poincare_embeddings

Data sets
- [WordNet](https://wordnet.princeton.edu/wordnet/download/)
  - The version used for training/evaluation is prepared with this [script](https://github.com/TatsuyaShirakawa/poincare-embedding/blob/master/scripts/create_wordnet_noun_hierarchy.py) from the c++ poincare embedding repository 
- [HyperLex](http://people.ds.cam.ac.uk/iv250/hyperlex.html)
- scientific collaboration social networks
  - [AstroPh](https://snap.stanford.edu/data/ca-AstroPh.html)
  - [CondMat](https://snap.stanford.edu/data/ca-CondMat.html)
  - [GrQc](https://snap.stanford.edu/data/ca-GrQc.html)
  - [HepPh](https://snap.stanford.edu/data/ca-HepPh.html)

Evaluation experiments
- WordNet reconstruction
- WordNet link prediction
- link prediction in social networks
- lexical entailment on HyperLex & WordNet (for training)

Deliverables
- Jupyter notebook
  - evaluation code
  - evaluation results
  - summary

Requirements
- runnable notebook with minimal necessary dependencies
- ideally, as part of the setup
  - datasets are downloaded
  - implementations are downloaded and installed
- notebook easy to read, concise (no long printouts)
- clean code (PEP8, DRY)"
30,https://github.com/RaRe-Technologies/gensim/issues/1626,1626,[],closed,2017-10-12 05:58:56+00:00,,Why is this required?,"I just curious with the gensim code, then i little bit reading the source, but i dont really understand why is  [this expression](https://github.com/RaRe-Technologies/gensim/blob/351bdeff8e4e013d7cea7828b95cb216d215734d/gensim/models/tfidfmodel.py#L156) required? while [this line](https://github.com/RaRe-Technologies/gensim/blob/351bdeff8e4e013d7cea7828b95cb216d215734d/gensim/models/tfidfmodel.py#L154) exists, because (IMHO) however advanced the compiler is [this line](https://github.com/RaRe-Technologies/gensim/blob/351bdeff8e4e013d7cea7828b95cb216d215734d/gensim/models/tfidfmodel.py#L154) will never be executed"
31,https://github.com/RaRe-Technologies/gensim/issues/1627,1627,"[{'id': 175986, 'node_id': 'MDU6TGFiZWwxNzU5ODY=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/testing', 'name': 'testing', 'color': '444444', 'default': False, 'description': 'Issue related with testing (code, documentation, etc)'}, {'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}]",closed,2017-10-12 09:21:16+00:00,,Inconsistent AppVeyor wheels and MacPython automatization,"When we release gensim, we need to build wheels for different platforms (win and mac), for now, we have 2 problems

1. AppVeyor loads fresh wheel to storage **always** (after each build, not only for release), for this reason, we'll have incorrect wheels in storage after any PR (that's isn't critical, because of all wheels on PyPI), but that's not good. Also, I need to disable AppVeyor when I release (and stop non-release builds), that's critical.
Fix - push wheels in storage **if and only if** when we build **tag** commit in the **master** branch.

2. Need to clone/replace/check twice for [MacPython](https://travis-ci.org/MacPython/gensim-wheels) (first - for **HEAD** commit in dev, second - for **tag** commit in master). Need to automatize this process (at least the first part). 
Fix - maybe we should run a script through webhook or something else.


"
32,https://github.com/RaRe-Technologies/gensim/issues/1628,1628,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}]",open,2017-10-12 20:54:35+00:00,,Investigate Geometric Topic Modelling ,"A new method has been cited here for calculating topics using convex optimization- [https://arxiv.org/abs/1710.02952](https://arxiv.org/abs/1710.02952)

The paper shows that the method is slightly better performing than LDA with collapsed Gibbs sampling and SVI sampling.

It would be nice to integrate this into Gensim if we can validate the results."
33,https://github.com/RaRe-Technologies/gensim/issues/1629,1629,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 175642, 'node_id': 'MDU6TGFiZWwxNzU2NDI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/wishlist', 'name': 'wishlist', 'color': 'd7e102', 'default': False, 'description': 'Feature request'}, {'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}]",open,2017-10-13 06:40:17+00:00,,Trans-gram,"Feature request for cross-lingual embedding

**Maillist thread**: https://groups.google.com/forum/#!topic/gensim/zksGwKHnIUA
**Paper**:  http://aclweb.org/anthology/D15-1131
**Abstract**: *Trans-gram*, a simple and computationally-efficient method to simultaneously learn and align wordembeddings for a variety of languages, using only monolingual data and a smaller set of sentence-aligned data. We use our new method to compute aligned wordembeddings for twenty-one languages using English as a pivot language. We show that some linguistic features are aligned across languages for which we do not have aligned data, even though those properties do not exist in the pivot language. We also achieve state of the art results on standard cross-lingual text classification and word translation tasks."
34,https://github.com/RaRe-Technologies/gensim/issues/1630,1630,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}]",open,2017-10-13 08:46:49+00:00,,Adding topic modeling methods based on word embeddings,"Could be a real plus value to add another type of topic modeling which use word embeddings as prior. For example, these also have public codes: [https://rajarshd.github.io/papers/acl2015.pdf](https://rajarshd.github.io/papers/acl2015.pdf) [https://arxiv.org/abs/1606.02979](https://arxiv.org/abs/1606.02979)"
35,https://github.com/RaRe-Technologies/gensim/issues/1634,1634,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2017-10-18 00:48:09+00:00,,TextCorpus doesn't provide a way to convert document text to indices as needed for say DL NLP models,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
TextCorpus doesn't provide a way to convert text in a document to indices per the dictionary as needed for say Deep Learning NLP models. TextCorpus uses Dictionary objects `doc2bow` function which is great for most ML models but for DL models where we need sequential indices for text its not usable in most cases.
#### Steps/Code/Corpus to Reproduce

sample.txt
```
hello how are you ?
i am good
```

code:
```
from gensim.corpora.textcorpus import TextCorpus

some_file_name = ""sample.txt""
some_dictionary = {
    '<UNK>': 0,
    'how': 1,
    'hello': 2,
    'hi': 3,
    'are': 4,
    'you': 5,
    '?': 6,
    'good': 7
}

gensim_dictionary = Dictionary()
gensim_dictionary.token2id = some_dictionary

txt_corpus = TextCorpus(input=some_file_name, dictionary=gensim_dictionary, token_filters=[])

for text in txt_corpus:
    print list(text)
```


#### Expected Results
Some way to simply convert the corpus to indices per the token2id dict object in Dictionary class, also adding in option to provide an unknown token id which replaces all unknown tokens.
So either adding a `doc2idx()` in `TextCorpus` or integrating that in `Dictionary` class along with `doc2bow()`
[2, 1, 4, 5, 6]
[0, 0, 7]

#### Actual Results
[(1, 1), (2, 1), (4, 1), (5, 1), (6, 1)]
[(7, 1)]

#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->
Darwin-16.4.0-x86_64-i386-64bit
('Python', '2.7.12 |Anaconda custom (x86_64)| (default, Jul  2 2016, 17:43:17) \n[GCC 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)]')
('NumPy', '1.13.1')
('SciPy', '0.19.1')
<!-- Thanks for contributing! -->

"
36,https://github.com/RaRe-Technologies/gensim/issues/1635,1635,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2017-10-18 21:39:38+00:00,,Scoring function in Phrases model is hardcoded,"The [Phrases model](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/phrases.py) is based on word counting and bigram counting and it can process sentences by a given scoring function, which can be supplied via the construtor of `Phrases` (the parameter `scoring`). However, the field for scoring function is used only in the `export_phrases` method. Have a look here: 
https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/phrases.py#L269
and here:
https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/phrases.py#L284

```
count_a = float(vocab[word_a])
count_b = float(vocab[word_b])
count_ab = float(vocab[bigram_word])
score = scoring_function(count_a, count_b, count_ab)
```

However, in the `__getitem__` method, the scoring uses the default scoring always https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/phrases.py#L334 :
```
pa = float(vocab[word_a])
pb = float(vocab[word_b])
pab = float(vocab[bigram_word])
score = (pab - min_count) / pa / pb * len(vocab)
```

This looks like a bug to me (we are always using the default scoring, even if we explicitly stated npmi in the constructor). Is it okay if I open a pull request fixing this one?"
37,https://github.com/RaRe-Technologies/gensim/issues/1637,1637,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2017-10-19 14:08:43+00:00,,FastText wrapper returns inconsistent dtypes,"#### Description
`gensim.models.wrappers.FastText` returns inconsistent dtypes.

#### Steps/Code/Corpus to Reproduce
```python
from gensim.models.wrappers import FastText
embeds = FastText.load_fasttext_format(...)
```
For an existing word:
```python
embeds['the'].dtype == dtype('float32')
```
For an ""imputed"" word (missing from the vocabulary). The word embedding is computed as the sum of embedding for n-grams:

```python
embeds['ttttt'].dtype == dtype('float64')
```

The problem in `models/wrappers/fasttext.py::FastTextKeyedVectors.word_vec`. In the case of a missing word, the zero vector is initialised to be a 64-bit float array to which a bunch of 32-bit embeddings are added to. 

#### Versions
Linux-4.4.0-97-generic-x86_64-with-Ubuntu-16.04-xenial
Python 3.5.2 (default, Nov 17 2016, 17:05:23)
[GCC 5.4.0 20160609]
NumPy 1.13.3
SciPy 0.19.1
gensim 3.0.1
FAST_VERSION 1
"
38,https://github.com/RaRe-Technologies/gensim/issues/1641,1641,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2017-10-21 13:18:42+00:00,,Quick-start possible duplicate,"#### Description
Quick-start tutorial possible duplicated: [One](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim%20Quick%20Start.ipynb), [Two](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/gensim%20Quick%20Start.ipynb). 

Second is in tutorials folder and has links from [main](https://github.com/RaRe-Technologies/gensim) page and [tutorials](https://github.com/RaRe-Technologies/gensim/blob/develop/tutorials.md#tutorials) page. Since first one is in the root and also has few more -- instructions how to install gensim and to work with Jupyter notebooks. Both notebooks are equal except 'how to' introduction. It doesn't looks very confusing. Nevertheless there's no link to first one, it appears in list of files only."
39,https://github.com/RaRe-Technologies/gensim/issues/1642,1642,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2017-10-22 17:40:41+00:00,,fastText models from 2.3.0 can't be loaded in 3.0.0,"#### Description
I do have a compatibility issue with fastText and version 3.0.0. In version 2.3.0, I used the fastText C++ wrapper to train a model based on the code available at that time from 
https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/FastText_Tutorial.ipynb

This code works in **2.3.0**
```
from gensim.models.wrappers.fasttext import FastText as FT_wrapper
model = FT_wrapper.load(model_path)
if key in model:
    character_embedding = model[key]
```

In **3.0.0** it fails due to
>     File ""scripts/foo.py"", line 43, in reduce_fasttext_embedding
>     character_embedding = model[key]
>   File ""/usr/local/lib/python3.5/dist-packages/gensim/models/word2vec.py"", line 1345, in __getitem__
>     return self.wv.__getitem__(words)
>   File ""/usr/local/lib/python3.5/dist-packages/gensim/models/keyedvectors.py"", line 602, in __getitem__
>     return self.word_vec(words)
>   File ""/usr/local/lib/python3.5/dist-packages/gensim/models/wrappers/fasttext.py"", line 94, in word_vec
>     word_vec = np.zeros(self.syn0_ngrams.shape[1])
> AttributeError: 'FastTextKeyedVectors' object has no attribute 'syn0_ngrams'

#### Expected Results
I expected the model from 2.3.0 to be loadable in 3.0.0. I was able to get my code working by downgrading to 2.3.0. I made some evaluations with trained models and I'd be happy to still use these models. Otherwise, I'm stuck at gensim 2.3.0

@menshikh-iv
I guess this has something to do with this commit https://github.com/RaRe-Technologies/gensim/commit/6e511565c1721636cfd14f88df3a08e124e14364#diff-cd6e655ec64f5b3927aa96ce5d006207 and split **'syn0_all' into 'syn0_vocab' and 'syn0_ngrams'**. I'm guessing that models trained with 2.3.0 aren't compatible with version 3. Is it possible that the load method checks whether the model was trained in 2.3.0, loads the 2.3.0 method, and internally makes the same split?




"
40,https://github.com/RaRe-Technologies/gensim/issues/1644,1644,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2017-10-23 10:06:55+00:00,,Fix list of ignored problems for flake8,"Now we using `--ignore=E501,E731,E12,W503,E402` parameters for `flake8`, we can be more ""strict"" and reduce list of ""ignored"" checks

What this checks means (full list [here](http://pep8.readthedocs.io/en/latest/intro.html#error-codes))

| Code | Message | Action (from us)|
|---------|--------------|---------|
|E501|line too long (>80 characters)| remove (but need track size with adequate limit, like 120)|
|E731|do not assign a lambda expression, use a def| remove |
|W503|line break occurred before a binary operator| - |
|E402|module level import not at top of file | remove |
|E12| Many checks ... | remove (need to think about E121, E123, E126) |


Related #1636 

"
41,https://github.com/RaRe-Technologies/gensim/issues/1646,1646,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2017-10-23 18:46:03+00:00,,Fix Regex Deprecation Warnings in Python 3,"#### Description

When I import gensim in Python 3, I get a lot of deprecation warnings like

```
DeprecationWarning: invalid escape sequence \[
  RE_P2 = re.compile(""(\n\[\[[a-z][a-z][\w-]*:[^:\]]+\]\])+$"", re.UNICODE)
```

which is a 2 to 3 issue which I believe can be fixed by adding a raw flag before the string.

#### Steps/Code/Corpus to Reproduce

On Python 3...

```
import gensim
```

Observe the warnings.

#### Expected Results

No deprecation warnings.

#### Actual Results

Deprecation warnings.

#### Versions

Python 3.6.3, gensim 3.0.0
"
42,https://github.com/RaRe-Technologies/gensim/issues/1651,1651,"[{'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2017-10-25 14:18:55+00:00,,Mutable vector returned by KeyedVectors.word_vector,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
TODO: change commented example
<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce
<!--
Example:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->

Method `KeyedVectors.word_vector` returned ""mutable"" vector if we call `model['anywords']` (for `model[['anywords']]` works correctly because [vstack make a copy.](https://github.com/RaRe-Technologies/gensim/blob/269028975e0db48e37e01edfb54e66018db7b61b/gensim/models/keyedvectors.py#L600)

Simple example

```python
from gensim.models import KeyedVectors

model = KeyedVectors.load_word2vec_format('path/to/model')
vector = model['word_from_model']
assert ~np.allclose(vector, np.zeros(vector.shape))  # check that our vector isn't zero
vector *= 0.

assert ~np.allclose(model['word_from_model'], np.zeros(vector.shape))  # failed, because now model['word_from_model'] is zero vector

```



#### Expected Results
assert passed

#### Actual Results
assert failed

#### What needs to fix
Add `arr.setflags(write=False)`  in [word_vec](https://github.com/RaRe-Technologies/gensim/blob/269028975e0db48e37e01edfb54e66018db7b61b/gensim/models/keyedvectors.py#L266)
"
43,https://github.com/RaRe-Technologies/gensim/issues/1654,1654,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 708430967, 'node_id': 'MDU6TGFiZWw3MDg0MzA5Njc=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/performance', 'name': 'performance', 'color': 'd93f0b', 'default': False, 'description': 'Issue related to performance (in HW meaning)'}]",open,2017-10-25 20:32:50+00:00,,Use Bounter for approx frequency counting,"Multiple models in gensim do a full corpus scan as their first step, to get the frequencies / counts of tokens, bigrams etc: word2vec, doc2vec, tfidf, phrases, make_wiki...

This step can require a lot of memory and be slow, because it's typically not parallelized.

Replace all such scanning by [Bounter](https://github.com/RaRe-Technologies/bounter). Let users specify how much memory they want to dedicate in an optional parameter, with some sane default like ""1 GB"" or ""0.25 * total RAM"" or something.

This is also a good place to revisit which algorithms need only the `counts['abc']` functionality, versus full `keys()`/`items()` iteration. The current implementations of counting in gensim are probably unnecessarily demanding (use key iteration), because there's no difference for dict or Counter as they support both operations.

But there is a significant difference for Bounter: counts-only is more efficient than counts-and-iteration. So unless a counting algorithm in gensim *really needs* the keys, we should rewrite it using only `bounter(need_iteration=False)`."
44,https://github.com/RaRe-Technologies/gensim/issues/1657,1657,[],closed,2017-10-26 11:36:12+00:00,,word2vec.score returns  negative values,"Hi, I've just trained a word2vec model on a Chinese corpus and the function _score_ seems to not work. It always returns a negative value given a sentence. Is this a bug or it just can't deal with such a  corpus? 
Thanks in advance!

"
45,https://github.com/RaRe-Technologies/gensim/issues/1659,1659,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2017-10-28 07:09:10+00:00,,model_trimmed_post_training not set on `load()`ed older models,"As seen at: https://stackoverflow.com/questions/46985320/gensim-word2vec-online-training-attributeerror-word2vec-object-has-no-att/46987193#46987193

User received an error because `model_trimmed_post_training` was not present on a model. 

Either `load()` should impute this when missing, or some less-clunky way of tracking stripped-down model state be used, perhaps by testing for actual available properties, rather than adding another flag to be maintained. "
46,https://github.com/RaRe-Technologies/gensim/issues/1663,1663,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2017-10-30 15:39:13+00:00,,Turn off support of Google Style docstrings,"**All docstrings should be refactored first**

To prevent contributors from using Google Style docstrings, we need to set

`napoleon_google_docstring = False`,

[like explained here](https://samnicholls.net/2016/06/15/how-to-sphinx-readthedocs/)."
47,https://github.com/RaRe-Technologies/gensim/issues/1664,1664,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2017-10-30 15:57:10+00:00,,Refactor API reference gensim.parsing,"**Check this PR for the soon-to-be-deprecated modules:** #1618 

Documented submodules:

- [x] `__init__.py`
- [x] `porter.py`
- [x] `preprocessing.py`"
48,https://github.com/RaRe-Technologies/gensim/issues/1665,1665,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2017-10-30 16:10:40+00:00,,Refactor API reference gensim.scripts,"**Check this PR for the soon-to-be-deprecated modules:** #1618 

Documented submodules:

- [ ] `__init__.py`
- [x] `glove2word2vec.py`
-  ~~`make_wiki.py`~~
-  ~~`make_wiki_lemma.py`~~
-  ~~`make_wiki_online.py`~~
-  ~~`make_wiki_online_lemma.py`~~
-  ~~`make_wiki_online_nodebug.py`~~
- [ ] `make_wikicorpus.py`
- [x] `word2vec2tensor.py`
- [x] `word2vec_standalone.py`
- [x] `segment_wiki.py`"
49,https://github.com/RaRe-Technologies/gensim/issues/1666,1666,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2017-10-30 16:12:46+00:00,,Refactor API reference gensim.similarities,"**Check this PR for the soon-to-be-deprecated modules:** #1618 

Documented submodules:

- [ ] `__init__.py`
- [x] `docsim.py`
- [x] `index.py`"
50,https://github.com/RaRe-Technologies/gensim/issues/1667,1667,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",closed,2017-10-30 16:15:17+00:00,,Refactor API reference gensim.sklearn_api,"**Check this PR for the soon-to-be-deprecated modules:** #1618 

Documented submodules:

- [ ] `__init__.py`
- [x] `atmodel.py`
- [x] `d2vmodel.py`
- [x] `hdp.py`
- [x] `ldamodel.py`
- [x] `ldaseqmodel.py`
- [x] `lsimodel.py`
- [x] `phrases.py`
- [x] `rpmodel.py`
- [x] `text2bow.py`
- [x] `tfidf.py`
- [x] `w2vmodel.py`"
51,https://github.com/RaRe-Technologies/gensim/issues/1668,1668,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2017-10-30 16:27:00+00:00,,Refactor API reference gensim.summarization,"**Check this PR for the soon-to-be-deprecated modules:** #1618 

Documented submodules:

- [x] `__init__.py`
- [x] `bm25.py`
- [x] `commons.py`
- [x] `graph.py`
- [x] `keywords.py`
- [x] `pagerank_weighted.py`
- [x] `summarizer.py`
- [x] `syntactic_unit.py`
- [x] `textcleaner.py`"
52,https://github.com/RaRe-Technologies/gensim/issues/1669,1669,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2017-10-30 16:33:15+00:00,,Refactor API reference gensim.topic_coherence,"**Check this PR for the soon-to-be-deprecated modules:** #1618 

Documented submodules:

- [ ] `__init__.py`
- [x] `aggregation.py`
- [x] `direct_confirmation_measure.py`
- [x] `indirect_confirmation_measure.py`
- [x] `probability_estimation.py`
- [x] `segmentation.py`
- [x] `text_analysis.py`"
53,https://github.com/RaRe-Technologies/gensim/issues/1670,1670,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2017-10-30 16:56:25+00:00,,Refactor API reference gensim.models.wrappers,"**Check this PR for the soon-to-be-deprecated modules:** #1618 

Documented submodules:

- [ ] `__init__.py`
- [x] `dtmmodel.py`
- [x] `fasttext.py`
- [x] `ldamallet.py`
- [x] `ldavowpalwabbit.py`
- [x] `varembed.py`
- [x] `wordrank.py`"
54,https://github.com/RaRe-Technologies/gensim/issues/1671,1671,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2017-10-30 16:58:33+00:00,,Refactor API reference gensim.corpora,"**Check this PR for the soon-to-be-deprecated modules:** #1618 

Documented submodules:

- [ ] `__init__.py`
- [x] `bleicorpus.py`
- [x] `csvcorpus.py`
- [x] `dictionary.py`
- [x] `hashdictionary.py`
- [x] `indexedcorpus.py`
- [x] `lowcorpus.py`
- [x] `malletcorpus.py`
- [x] `mmcorpus.py`
- [ ] ~~`shared_corpus.py`~~
- [x] `svmlightcorpus.py`
- [x] `textcorpus.py`
- [x] `ucicorpus.py`
- [x] `wikicorpus.py`"
55,https://github.com/RaRe-Technologies/gensim/issues/1676,1676,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2017-10-31 18:31:14+00:00,,Bug in sklearn_api.hdp and in sklearn_api.ldamodel,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
The new `sklearn_api.hdp` (and also `ldamodel`) modules and/or their combination with `matutils.Sparse2Corpus` yield the wrong results when fitting models from sklearn vectorizers or other sklearn-styled sparse matrices, since they are stored in CSR format. This error might occur in other sklearn_api classes, too.

I believe that either the default value of Sparse2Corpus constructor's `documents_columns` parameter should be changed:

```python
class Sparse2Corpus(object):
    """"""
    Convert a matrix in scipy.sparse format into a streaming gensim corpus.
    This is the mirror function to `corpus2csc`.
    """"""

    # Change this to def __init__(self, sparse, documents_columns=False) ?
    def __init__(self, sparse, documents_columns=True):
        if documents_columns:
            self.sparse = sparse.tocsc()
        else:
            self.sparse = sparse.tocsr().T  # make sure shape[1]=number of docs (needed in len())
```

or the following call should include that `documents_columns=False`:

```python
# Same happens in lda model
class HdpTransformer(TransformerMixin, BaseEstimator):
    ...
    def fit(self, X, y=None):
        """"""
        Fit the model according to the given training data.
        Calls gensim.models.HdpModel
        """"""
        if sparse.issparse(X):
            corpus = matutils.Sparse2Corpus(X) # Change to matutils.Sparse2Corpus(X, False) ?
        ...
```


<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce

Example: The number of processed documents corresponds to the number of features.

```python
from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import CountVectorizer
from gensim.sklearn_api.hdp import HdpTransformer

# Small dataset configuration
ngs = fetch_20newsgroups()
samples = ngs.data[:100]

# Simple count vectorization
vectorizer = CountVectorizer()
# x is a sparse matrix
x = vectorizer.fit_transform(samples)
print(""%d documents, %d features"" % x.shape) # 100 documents, 6547 features

inv_vocab = {v: k for k, v in vectorizer.vocabulary_.items()}

# Train a HDP
hdp_transformer = HdpTransformer(inv_vocab)
hdp_transformer.fit(x)

# Should be 100 but got 6547
print(""Processed documents %d"" % hdp_transformer.gensim_model.m_num_docs_processed) # 6547
```

#### Expected Results
We should expect that the hdp gensim model had processed the 100 documents in samples.
```python
print(""%d documents, %d features"" % x.shape)
# 100 documents, 6547 features
```

#### Actual Results
HDP processed 6547 documents
```python
print(""Processed documents: %d"" % hdp_transformer.gensim_model.m_num_docs_processed)
# Processed documents: 6547
```

#### Workaround, for the record
To make it work correctly, the sparse matrix `x` should be transposed.
```python
vectorizer = CountVectorizer()
x = vectorizer.fit_transform(samples)
inv_vocab = {v: k for k, v in vectorizer.vocabulary_.items()}

hdp_transformer = HdpTransformer(inv_vocab)
hdp_transformer.fit(x.T)
```

#### Versions
```
Windows-8.1-6.3.9600
('Python', '2.7.13 |Anaconda custom (64-bit)| (default, Dec 19 2016, 13:29:36) [MSC v.1500 64 bit (AMD64)]')
('NumPy', '1.12.1')
('SciPy', '1.0.0')
('gensim', '3.0.1')
('FAST_VERSION', 0)
```

"
56,https://github.com/RaRe-Technologies/gensim/issues/1680,1680,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}]",open,2017-11-01 07:06:17+00:00,,assert left > 0 failing in models.LdaMulticore with large chunksize,"#### Description
I am getting an assertionError when running models.LdaMulticore with large values for chunksize



#### Steps/Code/Corpus to Reproduce
Run the following code on the [gutenberg corpus](https://drive.google.com/file/d/0B2MmJrCi88c3MklYaGw0SzB5dms/view?usp=sharing) (2GB zipped download from google drive)

Dictionary is attached
[dictionary.zip](https://github.com/RaRe-Technologies/gensim/files/1433354/dictionary.zip)


```
import gensim.corpora.dictionary as gsdict
from gensim import corpora, models
import logging

logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)

my_dictionary = gsdict.Dictionary.load('clean_vcompact_dictionary.pickle')

my_LD_corpus = corpora.MmCorpus(""E:/Clean_Corpus/Full_Corpus_LD.mm"")

if __name__ == ""__main__"":
    LDA_model = models.LdaMulticore(my_LD_corpus,num_topics=2000,id2word=my_dictionary,workers=2,
                                    chunksize=10000,decay=1.0,iterations=500,eta=0.01)
    LDA_model.save(""repro.pickle"")
```


#### Expected Results
LDA model is trained

#### Actual Results

assert left >0 fails.  Trace below:
```
C:\Winpython\WinPython-64bit-3.5.4.0Qt5\python-3.5.4.amd64\lib\site-packages\gensim\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial
  warnings.warn(""detected Windows; aliasing chunkize to chunkize_serial"")
2017-11-01 00:16:07,433 : INFO : loading Dictionary object from clean_vcompact_dictionary.pickle
2017-11-01 00:16:07,464 : INFO : loaded clean_vcompact_dictionary.pickle
2017-11-01 00:16:07,909 : INFO : loaded corpus index from E:/Clean_Corpus/Full_Corpus_LD.mm.index
2017-11-01 00:16:07,909 : INFO : initializing corpus reader from E:/Clean_Corpus/Full_Corpus_LD.mm
2017-11-01 00:16:07,909 : INFO : accepted corpus with 3443509 documents, 66457 features, 612903679 non-zero entries
2017-11-01 00:16:07,912 : INFO : using symmetric alpha at 0.0005
2017-11-01 00:16:07,914 : INFO : using serial LDA version on this node
2017-11-01 00:28:16,241 : INFO : running online LDA training, 2000 topics, 1 passes over the supplied corpus of 3443509 documents, updating every 20000 documents, evaluating every ~200000 documents, iterating 500x with a convergence threshold of 0.001000
2017-11-01 00:28:16,246 : INFO : training LDA model using 2 processes
C:\Winpython\WinPython-64bit-3.5.4.0Qt5\python-3.5.4.amd64\lib\site-packages\gensim\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial
  warnings.warn(""detected Windows; aliasing chunkize to chunkize_serial"")
C:\Winpython\WinPython-64bit-3.5.4.0Qt5\python-3.5.4.amd64\lib\site-packages\gensim\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial
  warnings.warn(""detected Windows; aliasing chunkize to chunkize_serial"")
2017-11-01 00:28:17,035 : INFO : loading Dictionary object from clean_vcompact_dictionary.pickle
2017-11-01 00:28:17,036 : INFO : loading Dictionary object from clean_vcompact_dictionary.pickle
2017-11-01 00:28:17,070 : INFO : loaded clean_vcompact_dictionary.pickle
2017-11-01 00:28:17,079 : INFO : loaded clean_vcompact_dictionary.pickle
2017-11-01 00:28:17,606 : INFO : loaded corpus index from E:/Clean_Corpus/Full_Corpus_LD.mm.index
2017-11-01 00:28:17,606 : INFO : initializing corpus reader from E:/Clean_Corpus/Full_Corpus_LD.mm
2017-11-01 00:28:17,607 : INFO : accepted corpus with 3443509 documents, 66457 features, 612903679 non-zero entries
2017-11-01 00:28:17,621 : INFO : loaded corpus index from E:/Clean_Corpus/Full_Corpus_LD.mm.index
2017-11-01 00:28:17,621 : INFO : initializing corpus reader from E:/Clean_Corpus/Full_Corpus_LD.mm
2017-11-01 00:28:17,621 : INFO : accepted corpus with 3443509 documents, 66457 features, 612903679 non-zero entries
2017-11-01 00:28:19,786 : INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #10000/3443509, outstanding queue size 1
Process SpawnPoolWorker-1:
Process SpawnPoolWorker-2:
Traceback (most recent call last):
  File ""C:\Winpython\WinPython-64bit-3.5.4.0Qt5\python-3.5.4.amd64\lib\multiprocessing\process.py"", line 252, in _bootstrap
    self.run()
  File ""C:\Winpython\WinPython-64bit-3.5.4.0Qt5\python-3.5.4.amd64\lib\multiprocessing\process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Winpython\WinPython-64bit-3.5.4.0Qt5\python-3.5.4.amd64\lib\multiprocessing\pool.py"", line 103, in worker
    initializer(*initargs)
  File ""C:\Winpython\WinPython-64bit-3.5.4.0Qt5\python-3.5.4.amd64\lib\site-packages\gensim\models\ldamulticore.py"", line 279, in worker_e_step
    chunk_no, chunk, worker_lda = input_queue.get()
  File ""C:\Winpython\WinPython-64bit-3.5.4.0Qt5\python-3.5.4.amd64\lib\multiprocessing\queues.py"", line 94, in get
    res = self._recv_bytes()
  File ""C:\Winpython\WinPython-64bit-3.5.4.0Qt5\python-3.5.4.amd64\lib\multiprocessing\connection.py"", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File ""C:\Winpython\WinPython-64bit-3.5.4.0Qt5\python-3.5.4.amd64\lib\multiprocessing\connection.py"", line 318, in _recv_bytes
    return self._get_more_data(ov, maxsize)
  File ""C:\Winpython\WinPython-64bit-3.5.4.0Qt5\python-3.5.4.amd64\lib\multiprocessing\connection.py"", line 337, in _get_more_data
    assert left > 0
AssertionError
```

#### Versions
Windows-10-10.0.14393-SP0
Python 3.5.4 (v3.5.4:3f56838, Aug  8 2017, 02:17:05) [MSC v.1900 64 bit (AMD64)]
NumPy 1.13.3
SciPy 1.0.0
C:\Winpython\WinPython-64bit-3.5.4.0Qt5\python-3.5.4.amd64\lib\site-packages\gensim\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial
  warnings.warn(""detected Windows; aliasing chunkize to chunkize_serial"")
gensim 3.0.1
FAST_VERSION 0


<!-- Thanks for contributing! -->

"
57,https://github.com/RaRe-Technologies/gensim/issues/1682,1682,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2017-11-01 17:06:58+00:00,,`datatype` parameter in `load_word2vec_format` doesn't work as expected,"#### Description
Using `datatype=np.float64` in a `KeyedVectors.load_word2vec_call` doesn't work as expected, the loaded floats seem to lose precision. The datatype for `syn0` is still `float64` though, so it seems that they are cast to float32 first while loading, then cast to float64 when creating the array.

#### Steps/Code/Corpus to Reproduce
Using this file - 
[test.kv.txt](https://github.com/RaRe-Technologies/gensim/files/1434953/test.kv.txt)

```python
from gensim.models.keyedvectors import KeyedVectors
import numpy as np

kv = KeyedVectors.load_word2vec_format('test.kv.txt', datatype=np.float64)
print(kv['horse.n.01'][0] == -0.0008546282343595379)
# False
print(kv['horse.n.01'].dtype)
# float64
```
#### Expected Results
```python
print(kv['horse.n.01'][0] == -0.0008546282343595379)
# True
```
#### Actual Results
```python
print(kv['horse.n.01'][0] == -0.0008546282343595379)
# False
```

Looking at the code and making a quick hack [here](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/keyedvectors.py#L253), changing..
```
word, weights = parts[0], [REAL(x) for x in parts[1:]]
```
to..
```
word, weights = parts[0], [datatype(x) for x in parts[1:]]
```
..leads to the correct result. However, I imagine there are other cases to be covered as well."
58,https://github.com/RaRe-Technologies/gensim/issues/1683,1683,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2017-11-01 18:28:08+00:00,,model/coherencemodel.py issue - no single core mode,"#### Description
**model/coherencemodel.py** can not be used in single core mode.

#### Steps/Code/Corpus to Reproduce
**line 218**
`self.processes = processes if processes > 1 else max(1, mp.cpu_count() - 1)`

#### Expected Results
If I choose processes parameter = 1 for TopicCoherence, self.processes should be 1, too.

#### Actual Results
If I choose processes parameter = 1 for TopicCoherence, self.processes is mp.cpu_count() - 1. In my case self.processes = 3.

#### Solution
**line 218**
`self.processes = processes if processes >= 1 else max(1, mp.cpu_count() - 1)`

#### Versions
Windows-10-10.0.14393-SP0
Python 3.5.2 |Enthought, Inc. (x86_64)| (default, Mar  2 2017, 16:37:47) [MSC v.1900 64 bit (AMD64)]
NumPy 1.13.3
SciPy 1.0.0
gensim 3.0.1
FAST_VERSION 0

"
59,https://github.com/RaRe-Technologies/gensim/issues/1687,1687,[],closed,2017-11-02 13:06:33+00:00,,rethink multiprocessing,"#### Description
I've noticed gensim uses num_cores() - 1 processes for multiprocessing. 
As far as I know from java programming a process doesn't consume any cpu cycles when it is in waiting mode. So when I start 4 processes on a machine which has 4 cores and the main process is waiting for the other processes (process.join() in python?), your machine should be able to parallelize 4 tasks in 4 processes. 

I am not sure about it, because I am no expert in synchronization and multiprocessing - but I can tell you my observations. When I use 3 processes on a machine with 4 cores, cpu usage is roughly at 80 percent. Actually when I use 4 processes on the same machine, cpu usage is exactly at 100 percent.

You should make your own benchmarks, but maybe gensim could effectively use more resources as it is currently doing."
60,https://github.com/RaRe-Technologies/gensim/issues/1691,1691,[],closed,2017-11-03 12:00:22+00:00,,any2unicode in utils.py,"As `any2unicode` cannot handle floats, I changed it to 

```
def any2unicode(text, encoding='utf8', errors='strict'):
    """"""Convert a string (bytestring in `encoding` or unicode) or float, to unicode.""""""
    if isinstance(text, unicode):
        return text
    if isinstance(text, float):
        return unicode(bytearray(struct.pack(""f"", text)), encoding, errors=errors)
    else:
        return unicode(text, encoding, errors=errors)
```"
61,https://github.com/RaRe-Technologies/gensim/issues/1692,1692,[],closed,2017-11-03 18:55:38+00:00,,Overflow Error in LDA,"I report this issue due to an issue from `shorttext`: https://github.com/stephenhky/PyShortTextCategorization/issues/28

When on iPython, on enters

```
import shorttext
trainclassdict = shorttext.data.nihreports(sample_size=None)
topicmodeler = shorttext.generators.LDAModeler()
topicmodeler.train(trainclassdict, 128)
```

If the keras backend was TensorFlow, the following message appears:

```
Error message:
/lib/python2.7/site-packages/gensim/models/ldamodel.py:535: RuntimeWarning: overflow encountered in exp2
perwordbound, np.exp2(-perwordbound), len(chunk), corpus_words
```

But there is no warning for Theano.

However, this line is not really running the inferrence, but logging the perplexity in the step. And this calculation should have nothing to do with keras. Why does it matter if one is using TensorFlow or Theano?

https://github.com/RaRe-Technologies/gensim/blob/c583b28ff3039d18feff70cc2f1e518ad2c03f42/gensim/models/ldamodel.py#L535"
62,https://github.com/RaRe-Technologies/gensim/issues/1697,1697,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",open,2017-11-07 08:40:29+00:00,,New binary corpus format,"Based on https://github.com/RaRe-Technologies/gensim/pull/1679#issuecomment-341686324

New corpus in binary format:
- Store each document as sequence of (feature_id, feature_weight) pairs as (`uint32`, `float32`) = 8 bytes.
- (optional) possibility of indexing/slicing (some kind of ""offsets"")
- Written in Python/Cython/C, any combinations
- As variant: https://github.com/RaRe-Technologies/gensim/issues/1697#issuecomment-369507427

Should be significantly faster by reading/writing than classic `MmCorpus`, benchmark results is very important in this case.



"
63,https://github.com/RaRe-Technologies/gensim/issues/1698,1698,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2017-11-07 08:46:48+00:00,,Reduce size of gensim distrib,"For the current moment, gensim distribution is very heavy (>60Mb for `.tar.gz`). Need to significantly reduce this value, for example, remove notebooks from tar.gz and so on.

**How to produce `tar.gz`**
`python setup.py sdist`

**How to control content in `tar.gz`**
Change [MANIFEST.in](https://github.com/RaRe-Technologies/gensim/blob/develop/MANIFEST.in)"
64,https://github.com/RaRe-Technologies/gensim/issues/1701,1701,[],closed,2017-11-08 07:47:32+00:00,,Doc2Vec training hangs,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description

Hi, I tried training a model, with 
```
from gensim.models import Doc2Vec

model = Doc2Vec(min_count=1, window=10, size=100, sample=1e-4, negative=5, workers=7)
model.build_vocab(tagged_docs)
model.train(tagged_docs, total_examples=model.corpus_count, epochs=10)
```
but I'm getting the following exception (after which Python hangs):

<!--
Example:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->

#### Actual Results
<!-- Example: Actual shape of (100,5). 

Please paste or specifically describe the actual output or traceback. -->
```
01:03:25 PM INFO gensim.models.doc2vec:collecting all words and their counts
01:03:25 PM INFO gensim.models.doc2vec:PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
01:03:26 PM INFO gensim.models.doc2vec:PROGRESS: at example #10000, processed 3433858 words (6104765/s), 76029 word types, 10000 tags
01:03:26 PM INFO gensim.models.doc2vec:PROGRESS: at example #20000, processed 6635183 words (5692429/s), 103582 word types, 20000 tags
01:03:27 PM INFO gensim.models.doc2vec:PROGRESS: at example #30000, processed 10021476 words (5520268/s), 126018 word types, 30000 tags
01:03:28 PM INFO gensim.models.doc2vec:PROGRESS: at example #40000, processed 13649301 words (5489036/s), 145348 word types, 40000 tags
01:03:28 PM INFO gensim.models.doc2vec:collected 157200 word types and 47050 unique tags from a corpus of 47050 examples and 16232493 words
01:03:28 PM INFO gensim.models.word2vec:Loading a fresh vocabulary
01:03:29 PM INFO gensim.models.word2vec:min_count=1 retains 157200 unique words (100% of original 157200, drops 0)
01:03:29 PM INFO gensim.models.word2vec:min_count=1 leaves 16232493 word corpus (100% of original 16232493, drops 0)
01:03:29 PM INFO gensim.models.word2vec:deleting the raw counts dictionary of 157200 items
01:03:29 PM INFO gensim.models.word2vec:sample=0.0001 downsamples 686 most-common words
01:03:29 PM INFO gensim.models.word2vec:downsampling leaves estimated 13004737 word corpus (80.1% of prior 16232493)
01:03:29 PM INFO gensim.models.word2vec:estimated required memory for 157200 words and 100 dimensions: 223180000 bytes
01:03:30 PM INFO gensim.models.word2vec:resetting layer weights
01:03:31 PM INFO gensim.models.word2vec:training model with 7 workers on 157200 vocabulary and 100 features, using sg=0 hs=0 sample=0.0001 negative=5 window=10
Exception in thread Thread-8:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 810, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 763, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/tarun/.local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 884, in job_producer
    for sent_idx, sentence in enumerate(sentences):
  File ""/home/tarun/.local/lib/python2.7/site-packages/gensim/utils.py"", line 692, in __iter__
    for document in self.corpus:
TypeError: 'NoneType' object is not iterable
```
#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->
('Python', '2.7.6 (default, Oct 26 2016, 20:30:19) \n[GCC 4.8.4]')
('NumPy', '1.13.1')
('SciPy', '0.19.1')
('gensim', '2.3.0')
('cython', '0.27.3')


<!-- Thanks for contributing! -->
Thanks for the help in advance.
"
65,https://github.com/RaRe-Technologies/gensim/issues/1706,1706,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2017-11-10 21:31:24+00:00,,Missplaced logging,"Running the `segment_wiki.py` scripts prints:

```bash
$ time python -m gensim.scripts.segment_wiki -f /data_hdd/wiki/enwiki-latest-pages-articles.xml.bz2 -o /data_hdd/wiki/enwiki-latest.json.gz

No handlers could be found for logger ""gensim.models.doc2vec""

2017-11-10 22:21:25,334 : MainProcess : INFO : running /home/radim/workspace/gensim/gensim/scripts/segment_wiki.py -f /data_hdd/wiki/enwiki-latest-pages-articles.xml.bz2 -o /data_hdd/wiki/enwiki-latest.json.gz
2017-11-10 22:24:40,174 : MainProcess : INFO : Processed #100000 articles
```

which is a bug. The doc2vec module should not log anything on import -- it should behave the same as word2vec, or any other gensim module."
66,https://github.com/RaRe-Technologies/gensim/issues/1710,1710,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2017-11-12 13:16:24+00:00,,segment_wiki doesn't extract only plain text,"The `segment_wiki.py` script doesn't filter formatting properly. Its plain text output contains rubbish like `{| class=\""wikitable\"" style=\""text-align: center`, for example in the article `Academy Award for Best Production Design`, but also others.

This is contrary to the stated mission of the script."
67,https://github.com/RaRe-Technologies/gensim/issues/1711,1711,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}]",open,2017-11-12 13:20:30+00:00,,segment_wiki doesn't handle links properly,"According to @menshikh-iv , segment_wiki will convert the external link `[http://www.example.org/ link text]` to ` ` (nothing).

This will lead to incorrect extraction: `[http://www.example.org/ This article] talks about such issues.` will become plain text `talks about this issues.`, which is not good / expected behaviour.

I see two possible resolutions (controlled by a CLI switch?):

1. keep only the anchor text: `This article talks about such issues.`
2. keep the anchor text, and add the URL after it: `This article http://www.example.org/ talks about such issues`
"
68,https://github.com/RaRe-Technologies/gensim/issues/1712,1712,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2017-11-13 08:26:54+00:00,,Add interlinks to segment_wiki,"### Idea
[Users ask about this feature](https://twitter.com/TheShubhanshu/status/929493213689335808), this is really useful to have [interlinks](https://en.wikipedia.org/wiki/Help:Link) in the dump to construct the graph of articles or use relation between articles in any way.

### What's need to implement
Add field `""section_interlinks"" (list of str)` that contains a list of article titles referenced by this section. 
"
69,https://github.com/RaRe-Technologies/gensim/issues/1713,1713,"[{'id': 175986, 'node_id': 'MDU6TGFiZWwxNzU5ODY=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/testing', 'name': 'testing', 'color': '444444', 'default': False, 'description': 'Issue related with testing (code, documentation, etc)'}, {'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}]",closed,2017-11-13 20:21:11+00:00,,Try to use buildkite,"I'm very annoyed by reason of not automated ""release pipeline"", need to make a lot of manual work, I want to try [buildkite](https://buildkite.com/), killer feature - support for all OS.

If we'll use single CI for all OS/Python versions and release in ""one-click"", this simplify process significantly and make possible to release often without pain.
"
70,https://github.com/RaRe-Technologies/gensim/issues/1716,1716,[],closed,2017-11-14 14:09:46+00:00,,model.syn0norm[0] TypeError: 'NoneType' object is not subscriptable,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
Error while extracting normalized vectors from syn0norm
model.syn0norm[0] TypeError: 'NoneType' object is not subscriptable

#### Steps/Code/Corpus to Reproduce

```
import gensim

model = gensim.models.KeyedVectors.load_word2vec_format(config.GOOGLE_WORD2VEC_MODEL, binary=True)
print(model.syn0norm[0])
```


#### Expected Results
the first vectors in the syn0norm

#### Actual Results
model.syn0norm[0] TypeError: 'NoneType' object is not subscriptable


#### Versions
Darwin-17.0.0-x86_64-i386-64bit
Python 3.5.4 |Continuum Analytics, Inc.| (default, Aug 14 2017, 12:43:10) 
[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]
NumPy 1.13.3
SciPy 1.0.0
gensim 2.3.0
FAST_VERSION 1


<!-- Thanks for contributing! -->

"
71,https://github.com/RaRe-Technologies/gensim/issues/1717,1717,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}]",open,2017-11-14 14:56:41+00:00,,Add more datasets/models to gensim-data,"The next gensim release will contain a new [data/model storage feature](https://github.com/RaRe-Technologies/gensim/issues/1453). For this reason, we want to add models/datasets to make life of our users simpler :cat2:. The data repository is https://github.com/RaRe-Technologies/gensim-data.

This issue unites all previous issues about datasets/model list: https://github.com/RaRe-Technologies/gensim/issues/1453, https://github.com/RaRe-Technologies/gensim/issues/717, https://github.com/RaRe-Technologies/gensim/issues/746.

If you want to help - follow the instructions from https://github.com/RaRe-Technologies/gensim-data#want-to-add-a-new-corpus-or-model

If you want to see what models are already available - look to https://github.com/RaRe-Technologies/gensim-data#available-data

What will be nice to add:

- [ ] All datasets used in `docs/notebooks` + update notebooks (using new API)
- [ ] Trained models available in gensim (HARD), typically small model (toy example, only english) and big model (based on Wikipedia) with different languages (en, de, ru, es)
- [ ] Word vectors ([english](http://vectors.nlpl.eu/repository/) and [russian](http://rusvectores.org/en/models/)), thanks @akutuzov 
- [ ] [NSF Research Award Abstracts 1990-2003](https://archive.ics.uci.edu/ml/datasets/NSF+Research+Award+Abstracts+1990-2003), thanks @macks22 
- [ ] [Reuters-21578 Text Categorization Collection](https://archive.ics.uci.edu/ml/datasets/Reuters-21578+Text+Categorization+Collection)
- [ ] [Reuters Corpus Volume I (RCV1) v2](http://www.jmlr.org/papers/volume5/lewis04a/lyrl2004_rcv1v2_README.htm)
- [ ]  [WebKB](http://www.cs.umb.edu/~smimarog/textmining/datasets/) -- [original here](http://www.cs.cmu.edu/~webkb/)
- [ ]  [USPTO Patent Grant Full Text subsets](https://www.google.com/googlebooks/uspto-patents-grants-text.html)
- [ ] PubMed corpus, thanks @piskvorky 
- [ ] USPTO patents
"
72,https://github.com/RaRe-Technologies/gensim/issues/1718,1718,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2017-11-15 18:28:16+00:00,,Bug in bm25 implementation.,"In line 52 of bm25.py the variable `self.corpus_size` should be replaced by `len(document)`.

https://github.com/RaRe-Technologies/gensim/blob/82c394a9085d583e8a75c2bb32ecd37cf61236f0/gensim/summarization/bm25.py#L52"
73,https://github.com/RaRe-Technologies/gensim/issues/1719,1719,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2017-11-15 19:25:10+00:00,,Overlapping phrases,"#### Description
See below, but the most common phrase is not being detected as a bigram by `Phrases`.

#### Steps/Code/Corpus to Reproduce
```
s = ['i went to toys r us',
     'we are at babies r us',
     'where is babies r us',
     'do you mean toys r us']
s = [_.split() for _ in s]

phrases = Phrases(s, min_count=1, threshold=2)
list(phrases.export_phrases(s))
```
#### Actual Results
```
# [(b'toys r', 3.625),
#  (b'babies r', 3.625),
#  (b'babies r', 3.625),
#  (b'toys r', 3.625)]
```

#### Expected Results
Given that the phrase ""r us"" is the most common in the sentences, I would expect that this would be a common extracted phrase. There is mention in #794 that there is intent to avoid overlapping bigrams. Depending on the use case, overlapping bigrams may not be a problem if all of them pass the specified threshold. Maybe consider an overlapping_phrases flag? 

#### Versions
Windows-7-6.1.7601-SP1
Python 3.6.1 |Anaconda custom (64-bit)| (default, May 11 2017, 13:25:24) [MSC v.1900 64 bit (AMD64)]
NumPy 1.13.3
SciPy 1.0.0
gensim 2.3.0
FAST_VERSION 0


"
74,https://github.com/RaRe-Technologies/gensim/issues/1722,1722,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2017-11-17 11:29:56+00:00,,matutils.unitvec returns vector with different dtype from input vector,"#### Description
`matutils.unitvec` can return a unitvector of a different dtype from the input vector if the input dtype isn't `np.float`.
#### Steps/Code/Corpus to Reproduce
```python
from gensim import matutils
import numpy as np

input_vector = np.random.uniform(size=(100,)).astype(np.float32)
print(input_vector.dtype)
>>> float32

unit_vector = matutils.unitvec(input_vector) 
print(unit_vector.dtype)
>>> float64
```

This seems like mostly an internally used method, so it's probably not super-important but it does lead to some surprises while developing."
75,https://github.com/RaRe-Technologies/gensim/issues/1724,1724,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}]",open,2017-11-18 08:10:22+00:00,,Feature Request: YARN Support,"Support for submitting a gensim job using YARN. Currently to submit a LDA distributed job, it requires setting up it's own server/client setup. Would be very useful to be able to run a simple command to do this were YARN handles the machine acquisition and gensim can talk to YARN to figure out machine information and spawn its processes.

EDIT: I meant LDA. Check [comment](https://github.com/RaRe-Technologies/gensim/issues/1724#issuecomment-345672519)"
76,https://github.com/RaRe-Technologies/gensim/issues/1725,1725,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 175986, 'node_id': 'MDU6TGFiZWwxNzU5ODY=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/testing', 'name': 'testing', 'color': '444444', 'default': False, 'description': 'Issue related with testing (code, documentation, etc)'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2017-11-18 15:02:05+00:00,,Add button for documentation check,"Scikit-learn developers are using [neat userscript](http://scikit-learn.org/stable/developers/tips.html#viewing-the-rendered-html-documentation-for-a-pull-request) to view documentation of a given PR. I think it would be nice for Gensim to have something like that too.

![image](https://user-images.githubusercontent.com/3992246/32981685-a326c82c-cc9a-11e7-9f08-c818247afe0d.png)"
77,https://github.com/RaRe-Technologies/gensim/issues/1731,1731,"[{'id': 175986, 'node_id': 'MDU6TGFiZWwxNzU5ODY=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/testing', 'name': 'testing', 'color': '444444', 'default': False, 'description': 'Issue related with testing (code, documentation, etc)'}, {'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}]",closed,2017-11-21 13:04:54+00:00,,Setup wheel-build repository,"It's very useful to have wheels for all platforms because it allows avoiding many problems with compilation.
Right now, we build windows x64 wheels in [gensim](https://github.com/RaRe-Technologies/gensim) and MacOSX wheels in [gensim-wheels](https://github.com/MacPython/gensim-wheels).

Distinct repo looks like the best solution because for wheel building & testing we need some untrivial CI configurations and this action needs a lot of time (we don't want to have very slow CI in the current repo).

Also, this allows making release process easier (build all wheels by one commit/command), centralized testing of wheels.

What's need to make
- [x] Linux wheels
  - [x]  (2.7, 3.5, 3.6) X (x32, x64)
  - [x] Rackpace
  - [x] Notifications


- [x] Windows wheels
  - [x] (2.7, 3.5, 3.6) X (x32, x64)
  - [x] Rackpace
  - [x] Notifications


- [x] MacOSx wheels 
  - [x] (2.7, 3.5, 3.6)
  - [x] Rackpace
  - [x] Notifications


- [ ] (Optional) Cron jobs (for everyday build)


Related links:
- https://github.com/MacPython/scikit-learn-wheels
- https://github.com/matthew-brett/multibuild
- https://twitter.com/menshikh_iv/status/931917735554109440
"
78,https://github.com/RaRe-Technologies/gensim/issues/1732,1732,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2017-11-21 16:58:13+00:00,,Process case for dictionary id mismatch in LsiModel (instead of break the interpreter),"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
Attempting to train LSI models in online mode results in a segmentation fault. 
<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce
<!--
Example:
-->
```
import logging
logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.DEBUG)
from gensim import models

corpus = [[(0, 1.0), (1, 1.0), (2, 1.0)],
          [(2, 1.0), (3, 1.0), (4, 1.0), (5, 1.0), (6, 1.0), (8, 1.0)],
          [(1, 1.0), (3, 1.0), (4, 1.0), (7, 1.0)],
          [(0, 1.0), (4, 2.0), (7, 1.0)],
           [(3, 1.0), (5, 1.0), (6, 1.0)],
           [(9, 1.0)],
           [(9, 1.0), (10, 1.0)],
           [(9, 1.0), (10, 1.0), (11, 1.0)],
           [(8, 1.0), (10, 1.0), (11, 1.0)]]

lsi2 = models.lsimodel.LsiModel(corpus[:5], num_topics=5)
lsi2.add_documents(corpus[5:])
```

#### Expected Results
<!-- Example: Expected shape of (100,2).-->
That model is trained successfully and gives the same topics as if full corpus was input in one go.

#### Actual Results
<!-- Example: Actual shape of (100,5). 

Please paste or specifically describe the actual output or traceback. -->

Crashes when documents are added in the stochastic_svd function of matutils.py. Output is:

```
2017-11-21 16:50:24,213 : DEBUG : Fast version of gensim.models.doc2vec is being used
2017-11-21 16:50:24,219 : INFO : 'pattern' package not found; tag filters are not available for English
2017-11-21 16:50:24,220 : WARNING : no word id mapping provided; initializing from corpus, assuming identity
2017-11-21 16:50:24,220 : INFO : using serial LSI version on this node
2017-11-21 16:50:24,220 : INFO : updating model with new documents
2017-11-21 16:50:24,220 : INFO : preparing a new chunk of documents
2017-11-21 16:50:24,220 : DEBUG : converting corpus to csc format
2017-11-21 16:50:24,220 : INFO : using 100 extra samples and 2 power iterations
2017-11-21 16:50:24,220 : INFO : 1st phase: constructing (9, 105) action matrix
2017-11-21 16:50:24,220 : INFO : orthonormalizing (9, 105) action matrix
2017-11-21 16:50:24,220 : DEBUG : computing QR of (9, 105) dense matrix
2017-11-21 16:50:24,221 : DEBUG : running 2 power iterations
2017-11-21 16:50:24,221 : DEBUG : computing QR of (9, 9) dense matrix
2017-11-21 16:50:24,221 : DEBUG : computing QR of (9, 9) dense matrix
2017-11-21 16:50:24,221 : INFO : 2nd phase: running dense svd on (9, 5) matrix
2017-11-21 16:50:24,221 : INFO : computing the final decomposition
2017-11-21 16:50:24,221 : INFO : keeping 5 factors (discarding 0.000% of energy spectrum)
2017-11-21 16:50:24,222 : INFO : processed documents up to #5
2017-11-21 16:50:24,222 : INFO : topic #0(3.333): 0.650*""4"" + 0.405*""3"" + 0.305*""7"" + 0.264*""5"" + 0.264*""6"" + 0.240*""2"" + 0.225*""0"" + 0.200*""1"" + 0.180*""8""
2017-11-21 16:50:24,222 : INFO : topic #1(2.363): 0.448*""6"" + 0.448*""5"" + -0.390*""4"" + -0.356*""7"" + 0.350*""3"" + -0.309*""0"" + 0.225*""8"" + 0.174*""2"" + -0.148*""1""
2017-11-21 16:50:24,222 : INFO : topic #2(1.644): 0.594*""2"" + 0.557*""1"" + 0.413*""0"" + -0.337*""4"" + -0.187*""7"" + -0.091*""3"" + -0.070*""6"" + -0.070*""5"" + 0.016*""8""
2017-11-21 16:50:24,222 : INFO : topic #3(1.365): 0.562*""1"" + 0.503*""3"" + -0.324*""0"" + 0.297*""7"" + -0.293*""2"" + -0.263*""8"" + -0.261*""4"" + -0.088*""6"" + -0.088*""5""
2017-11-21 16:50:24,222 : INFO : topic #4(0.858): -0.583*""0"" + 0.555*""8"" + -0.323*""5"" + -0.323*""6"" + 0.322*""2"" + 0.177*""4"" + 0.089*""1"" + -0.028*""7"" + -0.001*""3""
2017-11-21 16:50:24,222 : INFO : updating model with new documents
2017-11-21 16:50:24,222 : INFO : preparing a new chunk of documents
2017-11-21 16:50:24,222 : DEBUG : converting corpus to csc format
2017-11-21 16:50:24,222 : INFO : using 100 extra samples and 2 power iterations
2017-11-21 16:50:24,222 : INFO : 1st phase: constructing (9, 105) action matrix
2017-11-21 16:50:24,222 : INFO : orthonormalizing (9, 105) action matrix
*** Error in `python': double free or corruption (!prev): 0x0000000001785490 ***
```

Full backtrace output found at https://gist.github.com/nmoran/09a13599156e56d6b40a0e7627642e7a

#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->
Linux-4.4.0-97-generic-x86_64-with-Ubuntu-16.04-xenial
('Python', '2.7.12 (default, Nov 19 2016, 06:48:10) \n[GCC 5.4.0 20160609]')
('NumPy', '1.13.3')
('SciPy', '1.0.0')
('gensim', '3.1.0')
('FAST_VERSION', 1)

<!-- Thanks for contributing! -->

"
79,https://github.com/RaRe-Technologies/gensim/issues/1735,1735,[],closed,2017-11-22 05:26:22+00:00,,Doc2Vec most_similar not ranking docs proprerly,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

#### Description
I am on a task to rank a bunch of documents (1000~2000) against set of keyphrases (n grams) associated with given subject.
These are the steps being taken:

1. Extracted keyphrases for all the candidate documents.
2. Trained Gensim's Doc2Vec with list of keyphrases generated at step 1. Each doc has 20-30 keyphrases (2 - 4 grams each)
3. Inferred the target keyphrase vector (for the subject) using the model. Calculate most similar

Upon checking the resultant documents, I find that none of the key phrases from the subject were found in the top documents. Ironically, some of the documents, (which my another frequentist match approach algorithm) find most relevant are ranked negatively by doc2vec.

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Steps/Code/Corpus to Reproduce

Example:
```
documents = []
for item in resultTextData:
    keyphrases = item[""meta_keyphrases""].lower().split("","")
       
    id = []
    id.append(str(item[""text_id""]))
    documents.append(TaggedDocument(keyphrases,id))

model = Doc2Vec(size=50, window=8, min_count=5, workers=4, dm=0, negative=0,iter=100)
model.build_vocab(documents)
model.train(documents, total_examples=model.corpus_count,epochs=model.iter)

#inference
kp = model.infer_vector(targetDocument)
# sims = model.docvecs.most_similar([kp],topn=1150)  # gives you top 10 document tags and their cosine similarity
sims = model.docvecs.most_similar(positive=[model.infer_vector(targetDocument)])  # gives you top 10 document tags and their cosine similarity
print ""sims"", sims
```

"
80,https://github.com/RaRe-Technologies/gensim/issues/1737,1737,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}]",open,2017-11-23 08:29:44+00:00,,"Confusing ""TypeError: '<' not supported between … 'str' and 'int'"" when doc-tag not present for `most_similar()`","I am facing an issue while using the model.docvecs.most_similar() function.
gensim: 2.3.0
Python 3.6.0
Error message: '<' not supported between instances of 'str' and 'int'

My code follows:
```python
def vectorize_doc2vec():
    sentence1 = 'Dogo is a dog'
    sentence2 = 'dog is a pet'
    sentence3 = 'pets are cool'
    sentence={sentence1:'j1', sentence2:'j2', sentence3:'j3'}
    
    sentences = LabeledLineSentence(sentence)
    
    model = Doc2Vec(min_count=1, window=10, size=100, sample=1e-4, negative=5, workers=8)
    model.build_vocab(sentences.to_array())
    
    model.train(sentences.sentences_perm(), total_examples=model.corpus_count, epochs=10)
    
    print(model.docvecs.most_similar('dog', topn=1))
```

The class LabeledLineSentence is as follows:

```python
class LabeledLineSentence(object):
    def __init__(self, sources):
        self.sources = sources
        
        flipped = {}
        
        # make sure that keys are unique
        for key, value in sources.items():
            if value not in flipped:
                flipped[value] = [key]
            else:
                raise Exception('Non-unique prefix encountered')
    
    def __iter__(self):
        for description, id in self.sources.items():
            yield LabeledSentence(description, id)

    def to_array(self):
        self.sentences = []
        for description, id in self.sources.items():
            self.sentences.append(LabeledSentence(description, id))
        return self.sentences
    
    def sentences_perm(self):
        shuffle(self.sentences)
        return self.sentences
```

Error StackTrace:
```
INFO:gensim.models.doc2vec:collecting all words and their counts
WARNING:gensim.models.doc2vec:Each 'words' should be a list of words (usually unicode strings).First 'words' here is instead plain <class 'str'>.
INFO:gensim.models.doc2vec:PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
INFO:gensim.models.doc2vec:collected 14 word types and 4 unique tags from a corpus of 3 examples and 38 words
INFO:gensim.models.word2vec:Loading a fresh vocabulary
INFO:gensim.models.word2vec:min_count=1 retains 14 unique words (100% of original 14, drops 0)
INFO:gensim.models.word2vec:min_count=1 leaves 38 word corpus (100% of original 38, drops 0)
INFO:gensim.models.word2vec:deleting the raw counts dictionary of 14 items
INFO:gensim.models.word2vec:sample=0.0001 downsamples 14 most-common words
INFO:gensim.models.word2vec:downsampling leaves estimated 1 word corpus (3.7% of prior 38)
INFO:gensim.models.word2vec:estimated required memory for 14 words and 100 dimensions: 20600 bytes
INFO:gensim.models.word2vec:resetting layer weights
INFO:gensim.models.word2vec:training model with 8 workers on 14 vocabulary and 100 features, using sg=0 hs=0 sample=0.0001 negative=5 window=10
INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads
INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads
INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads
INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads
INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads
INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads
INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads
INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads
INFO:gensim.models.word2vec:training on 380 raw words (77 effective words) took 0.0s, 3374 effective words/s
WARNING:gensim.models.word2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay
INFO:gensim.models.doc2vec:precomputing L2-norms of doc weight vectors
Traceback (most recent call last):

File """", line 17, in #
 vectorize_doc2vec()
File """", line 14, in vectorize_doc2vec
print(model.docvecs.most_similar('dog', topn=1))

File ""C:\Users\humblebee\AppData\Local\Continuum\Anaconda3\lib\site-packages\gensim\models\doc2vec.py"", line 461, in most_similar
elif doc in self.doctags or doc < self.count:

TypeError: '<' not supported between instances of 'str' and 'int' # #
```

#1586 "
81,https://github.com/RaRe-Technologies/gensim/issues/1740,1740,[],closed,2017-11-26 19:33:16+00:00,,Travis timeout of tests,"Currently, Travis times out due to the max time limit for the jobs. The time out error can be seen here- https://travis-ci.org/RaRe-Technologies/gensim/jobs/307547006

I suggest adding ``travis_wait`` to increase the max time limit."
82,https://github.com/RaRe-Technologies/gensim/issues/1743,1743,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2017-11-28 20:01:41+00:00,,`save/load_word2vec_format` fails for `FastText` models,"#### Description
Saving and loading using `save_word2vec_format` and `load_word2vec_format` fails for both native FastText models and models loaded using the wrapper.
#### Steps/Code/Corpus to Reproduce
Example:
```python
from gensim.models import fasttext as ft
from gensim.models.wrappers import fasttext as ft_wrapper
from gensim.models.word2vec import Text8Corpus

corpus = Text8Corpus('gensim/test/test_data/lee_background.cor')
native_model = ft.FastText()
native_model.build_vocab(corpus)

print(native_model.wv.most_similar('wars'))
>>> # prints results

print(native_model.wv['wars'])
>>> # prints results

native_model.wv.save_word2vec_format('test.wv')
wv = ft_wrapper.FastTextKeyedVectors.load_word2vec_format('test.wv')
```

```
print(wv.most_similar('wars'))

---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-5-43e12f136081> in <module>()
----> 1 print(wv.most_similar('wars'))

~/Projects/gensim/gensim/gensim/models/keyedvectors.py in most_similar(self, positive, negative, topn, restrict_vocab, indexer)
    318             negative = []
    319 
--> 320         self.init_sims()
    321 
    322         if isinstance(positive, string_types) and not negative:

~/Projects/gensim/gensim/gensim/models/wrappers/fasttext.py in init_sims(self, replace)
    125             else:
    126                 self.syn0_ngrams_norm = \
--> 127                     (self.syn0_ngrams / sqrt((self.syn0_ngrams ** 2).sum(-1))[..., newaxis]).astype(REAL)
    128 
    129     def __contains__(self, word):

TypeError: unsupported operand type(s) for ** or pow(): 'NoneType' and 'int'
```

```
print(wv['wars'])

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-6-ce05f767b013> in <module>()
----> 1 print(wv['wars'])

~/Projects/gensim/gensim/gensim/models/keyedvectors.py in __getitem__(self, words)
    601         if isinstance(words, string_types):
    602             # allow calls like trained_model['office'], as a shorthand for trained_model[['office']]
--> 603             return self.word_vec(words)
    604 
    605         return vstack([self.word_vec(word) for word in words])

~/Projects/gensim/gensim/gensim/models/wrappers/fasttext.py in word_vec(self, word, use_norm)
     91             return super(FastTextKeyedVectors, self).word_vec(word, use_norm)
     92         else:
---> 93             word_vec = np.zeros(self.syn0_ngrams.shape[1], dtype=np.float32)
     94             ngrams = compute_ngrams(word, self.min_n, self.max_n)
     95             ngrams = [ng for ng in ngrams if ng in self.ngrams]

AttributeError: 'NoneType' object has no attribute 'shape'
```

From a quick glance, it looks like this resulted from the changes made to `FastTextKeyedVectors` during the native implementation of `FastText` where two different matrices - `syn0_vocab` and `syn0_ngrams` were created.
Although, I'm not sure `save_word2vec_format` is even suitable for `FastText` seeing as how the ngram vectors aren't stored to disk."
83,https://github.com/RaRe-Technologies/gensim/issues/1746,1746,[],closed,2017-11-30 10:02:16+00:00,,total_vec don't exists,"I wanted to save the most important vectors or similar words, but I tried to cut the length of the embeddings using `model.save_word2vec_format('try.c.w2v', total_vec=10000)` but it says total_vec doesn't exists, but it's in the [documentation](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.KeyedVectors.save_word2vec_format). "
84,https://github.com/RaRe-Technologies/gensim/issues/1747,1747,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2017-11-30 11:04:04+00:00,,Update show_topics method from Mallet wrapper,Need to update https://github.com/RaRe-Technologies/gensim/blob/3.1.0/gensim/models/wrappers/ldamallet.py#L250 (replace `num_words` to `topn`) to prevent warning (report comes from https://groups.google.com/forum/#!topic/gensim/r3YIaqPRmzU)
85,https://github.com/RaRe-Technologies/gensim/issues/1748,1748,[],closed,2017-12-01 10:46:32+00:00,,Parameter `work` does not seem to end up being used in `train_document_dbow()`,"https://github.com/RaRe-Technologies/gensim/blob/b6234e7d90ffe9aeda7fab4b39c484381d7c5930/gensim/models/doc2vec.py#L769

By just eyeballing the code, it seems that in this particular function call (and the similar function calls below it), the value passed in `work` is not used inside `train_document_dbow()`. I'm not saying I think it should be used, but if it is not used, perhaps it is cleaner not to pass it in the first place."
86,https://github.com/RaRe-Technologies/gensim/issues/1751,1751,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}]",closed,2017-12-02 21:34:58+00:00,,Gensim 3.1.0 Phrase loader incompatible with older models due to introduction of common_terms,"I have a Phrases model that was computed using Gensim 2.2.0 but because of changes in 3.1.0 (I believe), I cannot load it anymore. This is the error I get:

```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<timed exec> in <module>()

~/Stuff/Sources/anaconda3/envs/nlp/lib/python3.6/site-packages/gensim/models/phrases.py in __init__(self, phrases_model)
    546         self.delimiter = phrases_model.delimiter
    547         self.scoring = phrases_model.scoring
--> 548         self.common_terms = phrases_model.common_terms
    549         corpus = self.pseudocorpus(phrases_model)
    550         self.phrasegrams = {}

AttributeError: 'Phrases' object has no attribute 'common_terms'
```

Cheers!"
87,https://github.com/RaRe-Technologies/gensim/issues/1752,1752,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2017-12-03 22:15:05+00:00,,Incorrect learning of word vectors during online training using `FastText` native implementation,"#### Description
A bug in Fasttext native implementation causes `syn0` to be equal to `syn0_vocab` at the end of training. This causes incorrect learning of vectors during online training.

#### Steps/Code/Corpus to Reproduce

```
from gensim.models.word2vec import LineSentence
from gensim.models.fasttext import FastText as FT_gensim
import os
import gensim

data_dir = '{}'.format(os.sep).join([gensim.__path__[0], 'test', 'test_data']) + os.sep
data_file = '{}lee_background.cor'.format(data_dir)
sentences = LineSentence(data_file)

model = FT_gensim(sg=1, hs=0,window=2, negative=5, iter=1)
model.build_vocab(sentences)
model.train(sentences, total_examples=model.corpus_count, epochs=model.iter)

print (model.wv.syn0 == model.wv.syn0_vocab).all()
```
#### Expected Results
`False`

#### Actual Results
`True`

#### Versions
Linux-4.10.0-40-generic-x86_64-with-Ubuntu-16.04-xenial
('Python', '2.7.12 (default, Nov 19 2016, 06:48:10) \n[GCC 5.4.0 20160609]')
('NumPy', '1.13.3')
('SciPy', '1.0.0')
('gensim', '3.1.0')
('FAST_VERSION', 1)


"
88,https://github.com/RaRe-Technologies/gensim/issues/1753,1753,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",closed,2017-12-04 05:35:34+00:00,,Add explicit deprecation warnings for outdated stuff,"Need to add explicit deprecation warnings for all outdated stuff.
Docstrings isn't good enough for this situation.


What should contain the warning:
- What's an alternative (if exists), i.e. ""Call X instead of DEPRECATED_Y""
- When this function will be removed (concrete version, for example, 4.0.0)


related message https://github.com/RaRe-Technologies/gensim/issues/1746#issuecomment-348680651

"
89,https://github.com/RaRe-Technologies/gensim/issues/1759,1759,[],closed,2017-12-04 20:26:00+00:00,,Updating vocab of a `FastText` model results in change in `dtype` of `model.wv.syn0_vocab`,"#### Description
Updating vocabulary causes an unintended change in the `dtype` of `model.wv.syn0_vocab` from `float32` to `float64`. The primary cause of this issue is the `float64` type `numpy` array returned by `numpy.random.uniform` which when `vstack`ed with a `float32` numpy array casues the change in dtype. This also produces unpredictable segmentation faults in Cython implementation -- #1742.

#### Steps/Code/Corpus to Reproduce
```
from gensim.models.word2vec import LineSentence
from gensim.models.fasttext import FastText as FT_gensim
from gensim.test.utils import common_texts as sentences

new_sentences = [
    ['computer', 'artificial', 'intelligence'],
    ['artificial', 'trees'],
    ['human', 'intelligence'],
    ['artificial', 'graph'],
    ['intelligence'],
    ['artificial', 'intelligence', 'system']
]

model = FT_gensim(size=10, min_count=1)
model.build_vocab(sentences)
print model.wv.syn0_vocab.dtype

model.build_vocab(new_sentences, update=True)
print model.wv.syn0_vocab.dtype
```
#### Expected Results
```
float32
float32
```

#### Actual Results
```
float32
float64
```
#### Versions
Linux-4.10.0-40-generic-x86_64-with-Ubuntu-16.04-xenial
('Python', '2.7.12 (default, Nov 19 2016, 06:48:10) \n[GCC 5.4.0 20160609]')
('NumPy', '1.13.3')
('SciPy', '1.0.0')
('gensim', '3.1.0')
('FAST_VERSION', 1)
"
90,https://github.com/RaRe-Technologies/gensim/issues/1762,1762,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2017-12-05 10:09:42+00:00,,ipython notebook starts ipython3 kernel also when choosing python2 Kernel,"#### Description
ipython notebook starts ipython3 kernel also when choosing python2 Kernel

#### Steps/Code/Corpus to Reproduce
Example:
1. Build a docker and login to it.
2. Open a new jupyter notebook with python2 kernel
3. Try running code that is only suitable to python2 syntax like: 
```
print 1
```

4. On Ubuntu you can also run:
```    
ps -ef | grep jupyter
```
and verify the new notebook was started with ipython3 kernel

#### Expected Results
The new notebook will be ran with ipython2 kernel

#### Actual Results
The new notebook will be ran with ipython2 kernel

### Cause:
Both Kernels has the same command - _python_ as the first _argv_ parameter:
```
root@273133a334a2:/# cat /usr/local/share/jupyter/kernels/python3/kernel.json
{
 ""argv"": [
  ""python"",
  ""-m"",
  ""ipykernel_launcher"",
  ""-f"",
  ""{connection_file}""
 ],
 ""display_name"": ""Python 3"",
 ""language"": ""python""
}root@273133a334a2:/# cat /usr/local/share/jupyter/kernels/python2/kernel.json
{
 ""display_name"": ""Python 2"",
 ""language"": ""python"",
 ""argv"": [
  ""python"",
  ""-m"",
  ""ipykernel_launcher"",
  ""-f"",
  ""{connection_file}""
 ]
}
```

### Solution
Running the following commands (as described [here](https://github.com/jupyter/notebook/issues/2563)):
```
root@273133a334a2:/# ipython2 kernel install
Installed kernelspec python2 in /usr/local/share/jupyter/kernels/python2
root@273133a334a2:/# ipython3 kernel install
Installed kernelspec python3 in /usr/local/share/jupyter/kernels/python3
```
 Fixes the issue:
```
root@273133a334a2:/# cat /usr/local/share/jupyter/kernels/python2/kernel.json
{
 ""display_name"": ""Python 2"",
 ""language"": ""python"",
 ""argv"": [
  ""/usr/bin/python"",
  ""-m"",
  ""ipykernel_launcher"",
  ""-f"",
  ""{connection_file}""
 ]
}root@273133a334a2:/# cat /usr/local/share/jupyter/kernels/python3/kernel.json
{
 ""argv"": [
  ""/usr/bin/python3"",
  ""-m"",
  ""ipykernel_launcher"",
  ""-f"",
  ""{connection_file}""
 ],
 ""display_name"": ""Python 3"",
 ""language"": ""python""
}
```

### Actions Required:
Add the following lines to the Dockerfile:
```
RUN ipython2 kernel install
RUN ipython3 kernel install
```
I'll submit a Pull request containing these changes soon
"
91,https://github.com/RaRe-Technologies/gensim/issues/1765,1765,[],closed,2017-12-06 18:47:45+00:00,,Bucket Argument in fasttext not working as expected ?,"Hi, For the fasttext native from gensim:

My understanding is that according to the hashing trick, if bucket is < total # of subwords, there will be collisions and some subwords will be mapped to the same integers.  Am I wrong? 
However, it is not what I see on a toy example: 

```python
import gensim
from gensim.models.fasttext import FastText

sent = [['lol', 'dds', 'sdsf'], ['anticonsti']]
model = FastText(min_count = 1, bucket = 20)
model.build_vocab(sentences=sent)
model.train(sentences = sent, epochs = 1, report_delay = 1.0)

model.wv.ngrams
```
#### Expected Results
Dictionary with ngrams and their mappings to integers between 0 and 19 ( buckets = 20)

#### Actual Results
Dictionary with ngrams and their mappings to integers between 0 and 55 ( number of ngrams is 56 here)

#### Versions
>>> import platform; print(platform.platform())
Windows-10-10.0.14393-SP0
>>> import sys; print(""Python"", sys.version)
Python 3.5.2 |Continuum Analytics, Inc.| (default, Jul  5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.13.3
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.0.0
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.1.0
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 0
>>> 



"
92,https://github.com/RaRe-Technologies/gensim/issues/1771,1771,[],closed,2017-12-08 19:12:02+00:00,,Pyro4.naming exception in `get_my_ip`,"On a multi home nic computer, get_my_ip() is failing to use socket connection to nameserver to retrieve the external ip address to use. The code is proceeding to the default case to use hostname and to look up by ip address, which is currently resolving to virtualbox ethernet adapter that is not reachable from the dispatcher.

Specifically, the line 
`ns = Pyro4.naming.locateNS()`
is throwing exception 
`module 'Pyro4' has no attribute 'naming'`

when using Pyro4 version 4.62, thus get_my_ip() is defaulting to use
`result = socket.gethostbyname(socket.gethostname())`

The solution is to add 
`import Pyro4.naming`"
93,https://github.com/RaRe-Technologies/gensim/issues/1778,1778,"[{'id': 175642, 'node_id': 'MDU6TGFiZWwxNzU2NDI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/wishlist', 'name': 'wishlist', 'color': 'd7e102', 'default': False, 'description': 'Feature request'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2017-12-11 23:28:12+00:00,,Explore the possibility of using Tangent for gradients in Poincare embeddings,"The current implementation makes use of [autograd](https://github.com/HIPS/autograd/) to auto-differentiate the loss function. As the automatic differentiation is too slow, we chose to not use this feature for training, instead computing the derivatives ourselves and adding an option to perform verification of the computed derivatives by comparing it to the autograd values every 10k iterations or so. This is a very useful feature for debugging.

Another library to consider is [Tangent](https://github.com/google/tangent) library (thanks to @alexbw for the suggestion!), which does ahead-of-time gradient computations. The main concern here is speed - auto-differentiation should be similar to or faster than computing the derivatives ourselves.

"
94,https://github.com/RaRe-Technologies/gensim/issues/1779,1779,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",open,2017-12-12 00:00:02+00:00,,Bucket bug for FastText.load_fasttext_format ,"Hi,
I tried loading a pretrained model from Facebook's fasttext into gemsim using FastText.load_fasttext_format, and it looks like there is a bug to be fixed for bucket here as well. 

I noticed that for bucket = 2,000,000 we had model.wv.syn0_ngrams.shape[0] = 7,221,731 instead of 2,000,000. 

Also, in https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/wrappers/fasttext.py 

I don't see why we do have to compute the n-grams from the word vocabulary again. Aren't these already imported from the fastText .bin file? 




#### Steps/Code/Corpus to Reproduce

>>> from gensim.models.wrappers import FastText 

First download the zip file from https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.en.zip.
Then unzip and put the file 'wiki.en.bin' in your working directory.
>>> model = FastText.load_fasttext_format('wiki.en')

>>> print(model.wv.syn0_ngrams.shape)[0]

#### Expected Results
Expected value of 2,000,000 which is the default value of bucket. 

#### Actual Results
7,221,731 which is here equal to len(model.wv.ngrams).
In other words, it looks like there were no collusions although we had more n-grams than buckets.

Also, please note that it took 10 minutes to load the fasttext model. I wonder if some parts of the code (especially in load_vectors) are really needed.  

Thanks,
Carl

#### Versions
>>> import platform; print(platform.platform())
Windows-10-10.0.14393-SP0
>>> import sys; print(""Python"", sys.version)
Python 3.5.2 |Continuum Analytics, Inc.| (default, Jul  5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.13.3
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.0.0
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.1.0
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 0
-->




"
95,https://github.com/RaRe-Technologies/gensim/issues/1782,1782,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2017-12-12 23:22:48+00:00,,New Feature save_fasttext_format ? ,"Hi, 
Are there plans to release the feature save_fasttext_format based on save_word2vec_format but for FastText? If so when are you planning to release it?
Currently, we have to use load and save, which saves the whole model. If we do not want to continue training it, we only need the .wv attribute, which is smaller in size than the whole model object... 

Thanks,
Carl

"
96,https://github.com/RaRe-Technologies/gensim/issues/1783,1783,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2017-12-13 08:13:00+00:00,,Reduce gensim distribution size,"Right now, size of gensim `wheel`/`tar.gz` is `~16MB`, this is less than `50MB+`, but still huge.
Need to ""cut"" big files that used for tests and rewrite the affected tests

Previous issue #1698 "
97,https://github.com/RaRe-Technologies/gensim/issues/1784,1784,[],closed,2017-12-13 12:26:17+00:00,,why HDP model topic is always 150?,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
**I use hdp model to get topics，I want to get all topics 。so I set `num_topic = -1`, but get topics number are alway 150。I found some reason [here](https://stackoverflow.com/questions/31543542/hierarchical-dirichlet-process-gensim-topic-number-independent-of-corpus-size/31847553), but it did not working for me。so, how I get all topics**

TODO: change commented example
<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce

```
import os
import re
import jieba
import codecs
import numpy as np
from gensim.corpora import Dictionary
from gensim.models import hdpmodel

def hdp_train(doc_path, stop_path):
    stop_file = codecs.open(stop_path, 'r', 'utf-8')
    stopwords = [line.strip() for line in stop_file]
    stop_file.close()

    doc_file = codecs.open(doc_path, 'r', 'utf-8')
    documents = [document.strip() for document in doc_file]
    doc_file.close()

    word_counts = []
    for document in documents:
        word_counts_id = []
        tokens = jieba.cut(document)
        for word in tokens:
            if len(word) > 1 and not re.search('[0-9]', word) and word not in stopwords:
                word_counts_id.append(word)
        word_counts.append(word_counts_id)

    dic = Dictionary(word_counts)
    corpus = [dic.doc2bow(i) for i in word_counts]

    return dic, corpus

yuzhang_dic, yuzhang_corpus = hdp_train(""data/yuzhang.txt"", ""data/stopWord.dic"")
yuzhang_hdp_model = hdpmodel.HdpModel(corpus=yuzhang_corpus, id2word=yuzhang_dic)
yuzhang_hdp_model.print_topics(num_topics=-1)
```


#### Expected Results
I want get all topics

#### Actual Results
but HdpModel init `T=150`，so `num_topics=-1` get 150 ?。please give some links how do I get all topics (Forgive my poor English.)


#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->


<!-- Thanks for contributing! -->

"
98,https://github.com/RaRe-Technologies/gensim/issues/1785,1785,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 175642, 'node_id': 'MDU6TGFiZWwxNzU2NDI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/wishlist', 'name': 'wishlist', 'color': 'd7e102', 'default': False, 'description': 'Feature request'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2017-12-13 13:45:27+00:00,,Add smart information retrieval system for TFIDF,"https://en.wikipedia.org/wiki/SMART_Information_Retrieval_System

The current [TFIDF](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/tfidfmodel.py) model uses natural TF and IDF for computing TFIDF. The idea is to try various transformation like logarithmic, augmented,boolean etc. before computing the vectors.

More about this - http://www.cs.odu.edu/~jbollen/IR04/readings/article1-29-03.pdf and https://nlp.stanford.edu/IR-book/pdf/06vect.pdf

Will send a PR tomorrow.
"
99,https://github.com/RaRe-Technologies/gensim/issues/1786,1786,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2017-12-13 18:22:13+00:00,,Add contributor information to developers wiki page,"#1604 mentions that the developer documentation is outdated. Besides updating it, I think there is some information missing for contributors.

The main things I think are missing:
- How to set up a developer environment
- How to build Gensim
- How to send a pull request following the git flow described in the page

While the information provided seems appropriate for core developers of the project, contributors sending pull requests would in my opinion require those additional sections.

Regarding the developer environment, I don't see a requirements.txt (or requirements-dev.txt) file that can be used to install it. I guess there are also other project requirements for the project, and it'd be nice to know how contributors are expected to set up those things.

About the git flow, I think it should be obvious for open source contributors how to send a pull request to master. But given that the pull requests need to be sent to develop, I think it'd be useful to have a short documentation on how the whole flow looks like. It's nicely documented for core developers who can push to the repo, but not for contributors sending pull requests.

May be it could be a good idea to have separate pages for core developers and external contributors. And may be move this content to the CONTRIBUTING.md page."
100,https://github.com/RaRe-Technologies/gensim/issues/1788,1788,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2017-12-15 01:50:21+00:00,,os.path.isfile('question-words.txt') should be 'questions-...,"Minor typo in file doc2vec-IMDB.ipynb

File name used in the statement (Note missing 's' after the word `question` in file name)

`if os.path.isfile('question-words.txt')
`
should be:

`if os.path.isfile('questions-words.txt')`"
101,https://github.com/RaRe-Technologies/gensim/issues/1789,1789,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2017-12-15 01:57:07+00:00,,"open('aclImdb/alldata-id.txt', encoding='utf-8') doesn't work in Python 2.x ","In file doc2vec-IMDB.ipynb, this statement is not supported in Python 2.x but is in Python 3.x

`with open('aclImdb/alldata-id.txt', encoding='utf-8') as alldata:
`

This works in Python 2.7:

`import codecs
`
`with codecs.open('aclImdb/alldata-id.txt', encoding='utf-8') as alldata:
`"
102,https://github.com/RaRe-Technologies/gensim/issues/1790,1790,[],closed,2017-12-15 06:58:52+00:00,,accuracy had KeyError,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
TODO: change commented example
<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce
<!--
Example:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->
while going to have an accuracy computation by calling
```
model.wv.accuracy('question-file-name')
```
I got error message as followings:

```
KeyErrorTraceback (most recent call last)
<ipython-input-123-8a545c3407ef> in <module>()
----> 1 model.wv.accuracy('./questions_words.txt',restrict_vocab=1000000)

/opt/anaconda2/lib/python2.7/site-packages/gensim/models/keyedvectors.pyc in accuracy(self, questions, restrict_vocab, most_similar, case_insensitive)
    662 
    663         """"""
--> 664         ok_vocab = [(w, self.vocab[w]) for w in self.index2word[:restrict_vocab]]
    665         ok_vocab = dict((w.upper(), v) for w, v in reversed(ok_vocab)) if case_insensitive else dict(ok_vocab)
    666 

KeyError: u'a'
```

When I looked into the code inside the file **keyedvectors.py** for the called function **accuracy** I found this:

```
ok_vocab = [(w, self.vocab[w]) for w in self.index2word[:restrict_vocab]]
```

Then I double checked the size of both `self.vocab` and `self.index2word` , surprisingly I found both size are not matched. That told me that word 'a' is **NOT** in `self.vocab` though it **IS** in `self.index2word`.

My questions raised:

1. why and how happened for the different size of two (self.vocab and self.index2word)?
2. how about change the calculation code to:

```
ok_vocab = [(w, self.vocab[w]) for w in self.index2word if w in self.vocab][:restrict_vocab]
```

Any helps? Thanks.
"
103,https://github.com/RaRe-Technologies/gensim/issues/1794,1794,[],closed,2017-12-15 18:29:47+00:00,,"Use magic ""%%time"" for timing your code instead of using getting start and end time","The use of

`%%time
`

to time a cell is much cleaner than explicitly having to get the start and end times.  (%% indicates to time the whole cell.)

See::  http://ipython.readthedocs.io/en/stable/interactive/magics.html
"
104,https://github.com/RaRe-Technologies/gensim/issues/1798,1798,[],closed,2017-12-18 22:30:45+00:00,,init_ngrams in wrapper filling the wrong dictionary? (syn0 instead of syn0_vocab)? (FastText),"By looking again at the init_ngrams() function used when loading a pre-trained model in fasttext (see fasttext wrapper) in the .bin format, apart from the other issues discussed previously, I was wondering: 

Shouldn't the words embeddings be filled into syn0_vocab and not syn0, and then compute ourselves the average embeddings of word and subwords in order to get syn0? 

Thanks,
Carl"
105,https://github.com/RaRe-Technologies/gensim/issues/1807,1807,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2017-12-20 08:39:43+00:00,,Move building documentation to CircleCI,"Travis has problems with some ""latex-related"" packages, than needed for us for build documentation, for example `dvipng`, `texlive-latex-extra`, etc. 

The problem happens first time in #1714, where we need some additional stuff for png-rendering from latex (because we fix formulas).

Also, this related to really useful feature #1725 (than easier to implement based on `CircleCI`)

"
106,https://github.com/RaRe-Technologies/gensim/issues/1808,1808,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2017-12-20 18:08:04+00:00,,Reformat API reference page,"Currently, [API reference page](https://radimrehurek.com/gensim/apiref.html) doesn't reflect the structure of gensim and has a lot of redundant references, I think that it should be fixed.

There's [sklearn API reference](http://scikit-learn.org/stable/modules/classes.html), which can be used as a model."
107,https://github.com/RaRe-Technologies/gensim/issues/1810,1810,[],closed,2017-12-21 18:17:53+00:00,,word2vec: is there a way to change the smoothing parameter 0.75,"I am trying to use word2vec in gensim and reading https://radimrehurek.com/gensim/models/word2vec.html

The negative samples are sampled using `make_cum_table(power=0.75, domain=2147483647)`, which is called internally. I am wondering is there a way to change this smoothing parameter 0.75 when the function `word2vec.Word2Vec()` is called?


Thanks,
Matt

"
108,https://github.com/RaRe-Technologies/gensim/issues/1818,1818,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2017-12-26 22:11:55+00:00,,Incorrect setting of FastText parameters during online training  ,"#### Description
The `FastText` model is trained with wrong parameters (`epochs`, `total_examples`, `start_alpha`, `end_alpha`) when calling `FastText.train` after building vocabulary. Since the above-mentioned training parameters are not logged, this bug is hidden from the users (probably explains why no one reported this issue earlier). This is a result of incorrect parameter setting ([here](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/fasttext.py#L531)) in the original pure python native implementation PR #1525 ([here](https://github.com/RaRe-Technologies/gensim/pull/1525/files#diff-d600f54965c37a9b12d856fe05956d90R205)).

#### Steps/Code/Corpus to Reproduce
No code -- since this issue is not detectable through code.

#### Expected Results
On calling `model.train(....)`, the model should train with parameters provided in the method call.

#### Actual Results
Model trains with the parameters set during model initialization.
"
109,https://github.com/RaRe-Technologies/gensim/issues/1820,1820,"[{'id': 175986, 'node_id': 'MDU6TGFiZWwxNzU5ODY=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/testing', 'name': 'testing', 'color': '444444', 'default': False, 'description': 'Issue related with testing (code, documentation, etc)'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2017-12-27 15:00:00+00:00,,Re-run & fix all notebooks with python3,"It's hard to support both python versions for notebook (and make completely impossible any testing), for this reason, need to do several things:
- [ ] Re-run all notebooks with python3
- [ ] Add `!pip install` line in the head of the notebook, if notebook required some additional dependencies 
- [ ] Fix PEP8
- [ ] Fix bugs (if exist)
- [ ] Make easier work with downloaded datasets (add to gensim-data or something else)



"
110,https://github.com/RaRe-Technologies/gensim/issues/1824,1824,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2018-01-03 15:12:11+00:00,,FastText memory usage greatly exceeds value returned by `estimate_memory`,"#### Description
When using `gensim.models.fasttext.FastText`, the actual memory usage is much higher (>2x) than predicted by `FastText.estimate_memory`.
My usage scenario is to generate 300-dimensional word embeddings using SkipGram training with window size 8. My corpus has ~55,000,000 documents with ~4,144,457 word types across ~20,000,000,000 tokens. The machine has 16GB of available memory, 15GB of which are available for the Gensim process, as well as 16GB of Swap space.

The estimated memory usage is ~11.2GB (see below), which is identical to the size estimated for the Word2Vec model with the same parameters. Training with Word2Vec works flawlessly and uses almost exactly as much memory as estimated.

It seems that `FastText` does not implement its own `estimate_memory` method, but inherits it from the `Word2Vec` class, yielding unreliable values as can be seen below.  The critical section where the most memory is used seems to be this part in `FastText.init_ngrams`:

```python
all_ngrams = []
for w, v in self.wv.vocab.items():
    self.wv.ngrams_word[w] = compute_ngrams(w, self.min_n, self.max_n)
    all_ngrams += self.wv.ngrams_word[w]
```

#### Steps/Code/Corpus to Reproduce

```python
from gensim.models import fasttext

model = fasttext.FastText(size=300, sg=1, window=8, min_count=50, workers=8, iter=5)

# Word frequencies loaded from a finite state transducer on disk, i.e. no memory usage
freqs = load_frequencies()
vocab_size = sum(1 for typ, cnt in freqs.items() if cnt >= 50)
model.estimate_memory(vocab_size=vocab_size, report=True)
# { 'syn0': 4973348400,
#   'syn1neg': 4973348400,
#   'vocab': 2072228500
#   'total': 12018925300 }
# I.e. ~11.2GB, well within the available memory

model.build_vocab_from_freq(freqs, corpus_count=54878750)
# Memory usage is at ~7GB now, identical to Word2Vec

model.init_ngrams()
# ... Killed by OOM killer after swap space has run out
```

#### Expected Results
Should finish training without running out of memory.

#### Actual Results
Runs out of memory.

#### Versions
```
Linux-4.10.0-28-generic-x86_64-with-Ubuntu-16.04-xenial
Python 3.5.2 (default, Nov 23 2017, 16:37:01)
[GCC 5.4.0 20160609]
NumPy 1.13.3
SciPy 1.0.0
gensim 3.2.0
FAST_VERSION (fasttext) 1
FAST_VERSION (word2vec) 1
```

"
111,https://github.com/RaRe-Technologies/gensim/issues/1828,1828,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2018-01-07 10:36:39+00:00,,BM25 : Incorrect scoring function,"https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/summarization/bm25.py
**Instead of ""len(document)"" it should be the length of the _index_ document of the corpus.**
  
```
 def get_score(self, document, index, average_idf): 
           # in this line it should be the length of the index document in the corpus
            score += (idf * self.f[index][word] * (PARAM_K1 + 1)
                      / (self.f[index][word] + PARAM_K1 * (1 - PARAM_B + PARAM_B * len(document) / self.avgdl)))
```
"
112,https://github.com/RaRe-Technologies/gensim/issues/1834,1834,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2018-01-09 08:01:23+00:00,,D2VTransformer.fit_transform doesn't work,"The **X** parameter of the **fit_transform** method of **D2VTransformer** doesn't accept variables of any type, nor list of token lists (raises _AttributeError: 'list' object has no attribute 'words'_), nor list of TaggedDocument (raises _TypeError: sequence item 0: expected str instance, list found_).

Example:
```python
from gensim.sklearn_api import D2VTransformer
from gensim.models import doc2vec

class_dict = {'mathematics': 1, 'physics': 0}
train_data = [
    (['calculus', 'mathematical'], 'mathematics'), (['geometry', 'operations', 'curves'], 'mathematics'),
    (['natural', 'nuclear'], 'physics'), (['science', 'electromagnetism', 'natural'], 'physics')
]
d2v_sentences = [doc2vec.TaggedDocument(words[0], [i]) for i, words in enumerate(train_data)]
train_input = list(map(lambda x: x[0], train_data))
train_target = list(map(lambda x: class_dict[x[1]], train_data))

model = D2VTransformer(min_count=1)
model.fit_transform(train_input, train_target)
#model.fit_transform(d2v_sentences, train_target)
```
Versions:
Windows-10-10.0.16299-SP0
Python 3.6.4 | packaged by conda-forge | (default, Dec 24 2017, 10:11:43) [MSC v.1900 64 bit (AMD64)]
NumPy 1.13.3
SciPy 0.19.1
gensim 3.2.0
FAST_VERSION 1"
113,https://github.com/RaRe-Technologies/gensim/issues/1836,1836,[],closed,2018-01-11 14:12:39+00:00,,Word2Vec 3.2.0 performance regression for corpus on s3 with smart-open 1.5.6,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
Upgrading to gensim 3.2.0 also upgrades smart-open to 1.5.6 which seems to have changed s3 code.
After the upgrade there is a performance regression in Word2Vec that leads to a > 2x slowdown when streaming a gzipped corpus from s3 (> 250K Words/sec  =>  < 100K Words/sec).
Downgrading smart-open to 1.5.3 fixes the issue.

The release notes of smart-open 1.5.6 from Dec 28 state:
- Improve S3 read performance. Fix #152 (PR #157, @mpenkov)
Perhaps there need to be some adjustments made

#### Steps/Code/Corpus to Reproduce
We use a private corpus of about 4M documents with about 150M words, chunked up into 2-3 MB sized gzipped files that we stream from s3 using smart-open.

#### Expected Results
Performance should be back to level of smart open 1.5.3.

#### Actual Results
See above

#### Versions
gensim with smart-open 1.5.6
"
114,https://github.com/RaRe-Technologies/gensim/issues/1844,1844,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2018-01-18 11:55:07+00:00,,CalledProcessError,"Key lines:
Mallet_Loc = r""/Users/myself/mallet-2.0.7""
lda = gensim.models.wrappers.LdaMallet(Mallet_Loc,corpus, num_topics=Nos_Topics, id2word = dictionary)

gives the following error

Traceback (most recent call last):
  File ""/Users/myself/Documents/JH_LDA Processing Gensim Mallet v3.py"", line 91, in <module>
    lda = gensim.models.wrappers.LdaMallet(Mallet_Loc,corpus, num_topics=Nos_Topics, id2word = dictionary)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/wrappers/ldamallet.py"", line 98, in __init__
    self.train(corpus)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/wrappers/ldamallet.py"", line 156, in train
    self.convert_input(corpus, infer=False)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/wrappers/ldamallet.py"", line 153, in convert_input
    check_output(args=cmd, shell=True)
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/utils.py"", line 1174, in check_output
    raise error
subprocess.CalledProcessError: Command '/Users/jamiehamilton/mallet-2.0.7 import-file --preserve-case --keep-sequence --remove-stopwords --token-regex ""\S+"" --input /var/folders/hl/vxz79b3d7qd_ktk3dxs6gt680000gn/T/750b51_corpus.txt --output /var/folders/hl/vxz79b3d7qd_ktk3dxs6gt680000gn/T/750b51_corpus.mallet' returned non-zero exit status 126.

Cant find reference to similar - any ideas?

All the best
Jamie

import platform; print(platform.platform())
Darwin-14.5.0-x86_64-i386-64bit
>>> import sys; print(""Python"", sys.version)
Python 3.6.2 (v3.6.2:5fd33b5926, Jul 16 2017, 20:11:06) 
[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.13.3
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 0.19.1
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.0.0
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 0
>>> "
115,https://github.com/RaRe-Technologies/gensim/issues/1846,1846,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2018-01-19 07:41:43+00:00,,Lda Model does not work with numpy 1.13,"It gives that following warning, 
RuntimeWarning: invalid value encountered in subtract  result = psi(alpha) - psi(np.sum(alpha))

It also does not result proper words probabilities for topics, and the result of show_topics looks like this: nan*w1 + nan*w2

When I upgrade numpy to 1.14, LdaModel works properly.
"
116,https://github.com/RaRe-Technologies/gensim/issues/1847,1847,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-01-19 16:06:35+00:00,,Running word2vec2tensor produces UnicodeDecodeError,"Hi,

When I run 

`python -m gensim.scripts.word2vec2tensor --input dans-word2vec.model --output tsv`

It returns the following error:

```
2018-01-19 17:02:50,687 : MainThread : INFO : running /home/brandsena/exp/lib/python3.4/site-packages/gensim/scripts/word2vec2tensor.py --input dans-word2vec.model --output tsv
2018-01-19 17:02:50,709 : MainThread : INFO : loading projection weights from dans-word2vec.model
Traceback (most recent call last):
  File ""/usr/lib64/python3.4/runpy.py"", line 170, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/usr/lib64/python3.4/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/brandsena/exp/lib/python3.4/site-packages/gensim/scripts/word2vec2tensor.py"", line 83, in <module>
    word2vec2tensor(args.input, args.output, args.binary)
  File ""/home/brandsena/exp/lib/python3.4/site-packages/gensim/scripts/word2vec2tensor.py"", line 55, in word2vec2tensor
    model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_model_path, binary=binary)
  File ""/home/brandsena/exp/lib/python3.4/site-packages/gensim/models/keyedvectors.py"", line 196, in load_word2vec_format
    header = utils.to_unicode(fin.readline(), encoding=encoding)
  File ""/home/brandsena/exp/lib/python3.4/site-packages/gensim/utils.py"", line 243, in any2unicode
    return unicode(text, encoding, errors=errors)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte

```

I'm not sure what's going on or how to fix this..

Thanks,

Alex.

"
117,https://github.com/RaRe-Technologies/gensim/issues/1848,1848,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-01-19 17:32:54+00:00,,time series plot of the topics,"How to create the time series plot like the once in the paper from ldaseqmodel output.

Thx!!!

<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
TODO: change commented example
<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce
<!--
Example:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->

#### Expected Results
<!-- Example: Expected shape of (100,2).-->

#### Actual Results
<!-- Example: Actual shape of (100,5). 

Please paste or specifically describe the actual output or traceback. -->

#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->


<!-- Thanks for contributing! -->

"
118,https://github.com/RaRe-Technologies/gensim/issues/1849,1849,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2018-01-22 11:37:37+00:00,,Store images from README directly in repository,"**Problem**: We have [adopters table](https://github.com/RaRe-Technologies/gensim#adopters) that contains concrete companies with logo & additional information. Images (logo) stored everywhere (random CDN, sites, etc) -> can be broken (unavailable) -> README doesn't looks good.

**Solution**: Store all images in repository

**Warning**: We don't want to store large `.jpg`, all images should be optimized before."
119,https://github.com/RaRe-Technologies/gensim/issues/1851,1851,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 1602279836, 'node_id': 'MDU6TGFiZWwxNjAyMjc5ODM2', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20MEDIUM', 'name': 'reach MEDIUM', 'color': 'ef7a1a', 'default': False, 'description': 'Affects a significant number of users'}, {'id': 1602334472, 'node_id': 'MDU6TGFiZWwxNjAyMzM0NDcy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20MEDIUM', 'name': 'impact MEDIUM', 'color': '7af49f', 'default': False, 'description': 'Big annoyance for affected users'}]",closed,2018-01-23 12:37:30+00:00,,Support streaming models split into multiple files from S3 / GCS,"Streaming small d2v models from s3 bucket works fine. Simply insert the s3 address into model.load. e.g. model.load('s3://<bucket>/<path>). However, when the model gets bigger and is split into multiple files all files except the main model file cannot be loaded. These other files are loaded by numpy and not smart_open. 

The essential part of my code is

```
def load_model(model_file):
    return Doc2Vec.load(model_file)

# infer 
def infer_docs(input_string, model_file, inferred_docs=5):
    model = load_model(model_file)
    processed_str = simple_preprocess(input_string, min_len=2, max_len=35)    
    inferred_vector = model.infer_vector(processed_str)
    return model.docvecs.most_similar([inferred_vector], topn=inferred_docs)
```
Trying to load from s3 on a bugger model yields: 

```
[INFO]  2018-01-21T20:44:59.613Z    f2689816-feeb-11e7-b397-b7ff2947dcec    testing keys in event dict
[INFO]  2018-01-21T20:44:59.614Z    f2689816-feeb-11e7-b397-b7ff2947dcec    loading model from s3://data-d2v/trained_models/model_law
[INFO]  2018-01-21T20:44:59.614Z    f2689816-feeb-11e7-b397-b7ff2947dcec    loading Doc2Vec object from s3://data-d2v/trained_models/model_law
[INFO]  2018-01-21T20:44:59.650Z    f2689816-feeb-11e7-b397-b7ff2947dcec    Found credentials in environment variables.
[INFO]  2018-01-21T20:44:59.707Z    f2689816-feeb-11e7-b397-b7ff2947dcec    Starting new HTTPS connection (1): s3.eu-west-1.amazonaws.com
[INFO]  2018-01-21T20:44:59.801Z    f2689816-feeb-11e7-b397-b7ff2947dcec    Starting new HTTPS connection (2): s3.eu-west-1.amazonaws.com
[INFO]  2018-01-21T20:45:35.830Z    f2689816-feeb-11e7-b397-b7ff2947dcec    loading wv recursively from s3://data-d2v/trained_models/model_law.wv.* with mmap=None
[INFO]  2018-01-21T20:45:35.830Z    f2689816-feeb-11e7-b397-b7ff2947dcec    loading syn0 from s3://data-d2v/trained_models/model_law.wv.syn0.npy with mmap=None
[Errno 2] No such file or directory: 's3://data-d2v/trained_models/model_law.wv.syn0.npy': FileNotFoundError
Traceback (most recent call last):
  File ""/var/task/handler.py"", line 20, in infer_handler
    event['input_text'], event['model_file'], inferred_docs=10)
  File ""/var/task/infer_doc.py"", line 26, in infer_docs
    model = load_model(model_file)
  File ""/var/task/infer_doc.py"", line 21, in load_model
    return Doc2Vec.load(model_file)
  File ""/var/task/gensim/models/word2vec.py"", line 1569, in load
    model = super(Word2Vec, cls).load(*args, **kwargs)
  File ""/var/task/gensim/utils.py"", line 282, in load
    obj._load_specials(fname, mmap, compress, subname)
  File ""/var/task/gensim/models/word2vec.py"", line 1593, in _load_specials
    super(Word2Vec, self)._load_specials(*args, **kwargs)
  File ""/var/task/gensim/utils.py"", line 301, in _load_specials
    getattr(self, attrib)._load_specials(cfname, mmap, compress, subname)
  File ""/var/task/gensim/utils.py"", line 312, in _load_specials
    val = np.load(subname(fname, attrib), mmap_mode=mmap)
  File ""/var/task/numpy/lib/npyio.py"", line 372, in load
    fid = open(file, ""rb"")
FileNotFoundError: [Errno 2] No such file or directory: 's3://data-d2v/trained_models/model_law.wv.syn0.npy'
```
My use case is to serve the models on a AWS lambda. My current workarond is to download all model files to a local folder and then load the model from the local folder which is rather slow
"
120,https://github.com/RaRe-Technologies/gensim/issues/1854,1854,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2018-01-24 09:47:10+00:00,,"gensim.matutils.hellinger d(x,y) != d(y,x) if len(x) = len(y)","<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->
Compute the distance between 2 distribution with gensim.matutils.hellinger. The d(x,y) do not equal to d(y,x) if len(x) = len(y)
#### Steps/Code/Corpus to Reproduce
<!--
Example:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->
from gensim.matutils import hellinger
vec_1 = [(2, 0.1), (3, 0.4), (4, 0.1), (5, 0.1), (1, 0.1), (7, 0.2)]
vec_2 = [(1, 0.1), (3, 0.8), (4, 0.1), (8, 0.1), (10, 0.8), (9, 0.1)]
hellinger(vec_1,vec_2) == hellinger(vec_2,vec_1)

#### Expected Results
<!-- Example: Expected shape of (100,2).-->
True
#### Actual Results
<!-- Example: Actual shape of (100,5). 
Please paste or specifically describe the actual output or traceback. -->
False
#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->
Linux-4.13.0-26-generic-x86_64-with-debian-stretch-sid
('Python', '2.7.11 |Anaconda custom (64-bit)| (default, Dec  6 2015, 18:08:32) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]')
('NumPy', '1.13.3')
('SciPy', '1.0.0')
('gensim', '3.1.0')
('FAST_VERSION', 1)

<!-- Thanks for contributing! -->

"
121,https://github.com/RaRe-Technologies/gensim/issues/1855,1855,[],closed,2018-01-24 15:09:55+00:00,,Swapped edges in the Poincare embeddings code ?,"#### Description
Directed edges of the Wordnet transitive closure (directed acyclic graph) used in the Poincare embeddings code are swapped in the input file wordnet_noun_hypernyms.tsv and they are never swapped back in the actual code. Why ? 

#### Steps/Code/Corpus to Reproduce
Edges are not swapped back in all the places in the Gensim Poincare implementation, e.g. in the function get_root_and_leaf_nodes from docs/notebooks/Poincare%20Evaluation.ipynb . The original wordnet_file with swapped edges is here: https://github.com/jayantj/gensim/raw/wordnet_data/docs/notebooks/poincare/data/wordnet_noun_hypernyms.tsv

If not processed with the correct direction of the edges, this affects both training and evaluation. Is there any explanation for this ?
"
122,https://github.com/RaRe-Technologies/gensim/issues/1857,1857,[],closed,2018-01-25 12:25:13+00:00,,Poincare - Link Prediction train set should not exclude links with leaves,"#### Description
Links containing root/leaves should not be excluded from the train set of the Link Prediction task in the Poincare embeddings code.

#### Steps/Code/Corpus to Reproduce
In the Poincare embeddings paper it is stated that links containing the root or a leaf node should be excluded from the validation and test set. However, in the Gensim code they are excluded also from the train set. This cannot be useful since there will be no knowledge at all about leaves at both train and test time, making the task much harder and potentially explaining the worse results obtained so far.

The function that generates the train file is `train_test_split(data_file, test_ratio=0.1)` from
https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/Poincare%20Evaluation.ipynb

@jayantj can you please elaborate?"
123,https://github.com/RaRe-Technologies/gensim/issues/1858,1858,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2018-01-25 14:04:56+00:00,,Wrong distance in Lexical entailment experiment for Poincare embeddings,"The following line https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/poincare.py#L1522
should be:
```
return -1 * (1 + self.alpha * (norm_2 - norm_1)) * min_distance
```
otherwise `distance` is the last encountered distance, not the smallest one."
124,https://github.com/RaRe-Technologies/gensim/issues/1862,1862,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-01-28 15:01:20+00:00,,EOFError while on make_wiki,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
Midway running `gensim.scripts.make_wiki` on latest WikiPedia article dump, EOFError was spit out, which stopped the processing.
<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

```
2018-01-28 15:45:35,500 : INFO : resulting dictionary: Dictionary(2000000 unique tokens: [u'tripolitan', u'ftdna', u'padanagan', u'soestdijk', u'farmobil']...)
2018-01-28 15:45:35,573 : INFO : adding document #4180000 to Dictionary(2000000 unique tokens: [u'tripolitan', u'ftdna', u'padanagan', u'soestdijk', u'farmobil']...)
Process InputQueue-4:
Traceback (most recent call last):
  File ""/usr/lib64/python2.7/multiprocessing/process.py"", line 267, in _bootstrap
    self.run()
  File ""/home/psukys/.local/lib/python2.7/site-packages/gensim/utils.py"", line 845, in run
    wrapped_chunk = [list(chunk)]
  File ""/home/psukys/.local/lib/python2.7/site-packages/gensim/corpora/wikicorpus.py"", line 361, in <genexpr>
    ((text, self.lemmatize, title, pageid, tokenization_params)
  File ""/home/psukys/.local/lib/python2.7/site-packages/gensim/corpora/wikicorpus.py"", line 221, in extract_pages
    for elem in elems:
  File ""/home/psukys/.local/lib/python2.7/site-packages/gensim/corpora/wikicorpus.py"", line 206, in <genexpr>
    elems = (elem for _, elem in iterparse(f, events=(""end"",)))
  File ""<string>"", line 100, in next
EOFError: compressed file ended before the logical end-of-stream was detected
```

#### Steps/Code/Corpus to Reproduce
Run on [latest](https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2) (21-Jan-2018 21:27         14705396388)
```
python -m gensim.script.make_wiki
```
"
125,https://github.com/RaRe-Technologies/gensim/issues/1869,1869,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2018-02-01 10:03:05+00:00,,MmCorpus file-like object support bug,"**Into**
We have some ""weird"" behavior if a user passes a `file-like` object to `MmCorpus`, based on [this mailing list thread](https://groups.google.com/forum/#!topic/gensim/420pRBwexKQ)

**Demonstration**

```python
from gensim.corpora import MmCorpus
import bz2

f = bz2.BZ2File(""testcorpus.mm.bz2"")
print(f.closed)  # 0
corpus = MmCorpus(f)
print(f.closed)  # 1 ???
```

**What happens**
File-like object was closed when we call `MmReader`, problem located here

https://github.com/RaRe-Technologies/gensim/blob/5342153eb4f4b02bb45bfa3951eef8250ac9f6b6/gensim/matutils.py#L1274


`with` automatically close `file-like` when we out of scope, **this is OK if we open this file**, but we **shouldn't close file-like passed from user**.

Related PR #1867 


**UPD:** another problem here - call `IndexCopus.__init__`, that didn't support `file-like` object at all."
126,https://github.com/RaRe-Technologies/gensim/issues/1872,1872,[],closed,2018-02-02 03:02:50+00:00,,Doesn't work word2vectensor.py,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
TODO: change commented example
Used word2vectensor.py to generate tensor and metadata files
<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce
<!--
Example:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->
python word2vec2tensor.py -i trained_tensor.w2v -o texts_plot

#### Expected Results
<!-- Example: Expected shape of (100,2).-->

#### Actual Results
<!-- Example: Actual shape of (100,5). 

Please paste or specifically describe the actual output or traceback. -->
2018-02-02 11:52:23,501 : MainThread : INFO : running word2vec2tensor.py -i trained_tensor.w2v -o texts_plot
2018-02-02 11:52:23,504 : MainThread : INFO : loading projection weights from trained_tensor.w2v
2018-02-02 11:53:04,497 : MainThread : INFO : loaded (73935, 400) matrix from trained_tensor.w2v
Traceback (most recent call last):
  File ""word2vec2tensor.py"", line 75, in <module>
    word2vec2tensor(args.input, args.output, args.binary)
  File ""word2vec2tensor.py"", line 53, in word2vec2tensor
    file_metadata.write(gensim.utils.to_utf8(word) + gensim.utils.to_utf8('\n'))
TypeError: write() argument must be str, not bytes

#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->
>>> import platform; print(platform.platform())
Darwin-15.6.0-x86_64-i386-64bit
>>> import sys; print(""Python"", sys.version)
Python 3.6.2 |Anaconda custom (64-bit)| (default, Sep 21 2017, 18:29:43)
[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.13.1
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 0.19.1
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.1.0
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1

<!-- Thanks for contributing! -->

"
127,https://github.com/RaRe-Technologies/gensim/issues/1873,1873,[],closed,2018-02-02 06:02:03+00:00,,Is this a bug in the CBOW code or my misunderstanding?,"In `gensim/gensim/models/word2vec.py`, line 394 and line 401

```
    if learn_vectors:
        # learn input -> hidden, here for all words in the window separately
        if is_ft:
            **if not model.cbow_mean and input_word_indices:**
                neu1e /= (len(input_word_indices[0]) + len(input_word_indices[1]))
            for i in input_word_indices[0]:
                context_vectors_vocab[i] += neu1e * context_locks_vocab[i]
            for i in input_word_indices[1]:
                context_vectors_ngrams[i] += neu1e * context_locks_ngrams[i]
        else:
            **if not model.cbow_mean and input_word_indices:**
                neu1e /= len(input_word_indices)
            for i in input_word_indices:
                context_vectors[i] += neu1e * context_locks[i]

    return neu1e
```

Shouldn't this be `if model.cbow_mean and input_word_indices` rather than `if not model.cbow_mean and input_word_indices`?"
128,https://github.com/RaRe-Technologies/gensim/issues/1874,1874,[],closed,2018-02-02 15:05:13+00:00,,Dov2Vec: AttributeError: Can't get attribute 'EuclideanKeyedVectors',"Hi,

I can't find anything related to my issue, so I'm posting it here. I trained a doc2vec model, then saved it using `model.save(""my.model"")`. It saved 4 files:

- my.model
- my.model.docvecs.doctag_syn0.npy
- my.model.syn1neg.npy
- my.model.wv.syn0.npy

I then try to load it, using `d2v = gensim.models.Doc2Vec.load('my.model')`, and it returns:
```
Traceback (most recent call last):
  File ""lstm.py"", line 41, in <module>
    d2v = gensim.models.Doc2Vec.load('my.model')
  File ""/home/fiorinin/deeplearning/lib/python3.4/site-packages/gensim/models/word2vec.py"", line 1412, in load
    model = super(Word2Vec, cls).load(*args, **kwargs)
  File ""/home/fiorinin/deeplearning/lib/python3.4/site-packages/gensim/utils.py"", line 276, in load
    obj = unpickle(fname)
  File ""/home/fiorinin/deeplearning/lib/python3.4/site-packages/gensim/utils.py"", line 938, in unpickle
    return _pickle.load(f, encoding='latin1')
AttributeError: Can't get attribute 'EuclideanKeyedVectors' on <module 'gensim.models.keyedvectors' from '/home/fiorinin/deeplearning/lib/python3.4/site-packages/gensim/models/keyedvectors.py'>
```

Any idea? Is it normal that it uses word2vec anyway - I assume this is a parent class? 
I tried updating, just in case, but there's the same error. Also, note that the training was done on a different machine, accessing the same directory. Can it be an incompatibility maybe, and if so, how to solve it?

Thanks!"
129,https://github.com/RaRe-Technologies/gensim/issues/1877,1877,[],closed,2018-02-04 04:37:31+00:00,,ImportError: cannot import name KeyedVectors,"Python 2.7.12, Mac OS High Sierra, gensim (0.13.4.1)

from sklearn.externals import joblib
from gensim.models import KeyedVectors

Traceback (most recent call last):
  File ""Test_for_ adversariality.py"", line 5, in <module>
    from gensim.models import KeyedVectors
ImportError: cannot import name KeyedVectors

I am trying to load the skipgram.txt files. "
130,https://github.com/RaRe-Technologies/gensim/issues/1878,1878,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2018-02-04 14:58:19+00:00,,DeprecationWarning: inspect.getargspec() is deprecated in phrases.py:317,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
I wanted to add bigrams/trigrams by using `Phrases()` but something went wrong
#### Steps/Code/Corpus to Reproduce

``` python
from gensim.models import Phrases 
#1st way to get error
bigram_model = Phrases()

#2nd way to get error
bigram_model = Phrases(['aaa', 'aaa'])
```

#### Expected Results
Two get bigrams. I have got them, but I have confused by the errors/warnings below
#### Actual Results
```
C:\Users\...\AppData\Local\Continuum\anaconda3\lib\site-packages\gensim\models\phrases.py:317: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()
  if all(parameter in getargspec(scoring)[0] for parameter in scoring_parameters):
C:\Users\...\AppData\Local\Continuum\anaconda3\lib\site-packages\gensim\models\phrases.py:317: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()
  if all(parameter in getargspec(scoring)[0] for parameter in scoring_parameters):
C:\Users\...\AppData\Local\Continuum\anaconda3\lib\site-packages\gensim\models\phrases.py:317: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()
  if all(parameter in getargspec(scoring)[0] for parameter in scoring_parameters):
C:\Users\...\AppData\Local\Continuum\anaconda3\lib\site-packages\gensim\models\phrases.py:317: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()
  if all(parameter in getargspec(scoring)[0] for parameter in scoring_parameters):
C:\Users\...\AppData\Local\Continuum\anaconda3\lib\site-packages\gensim\models\phrases.py:317: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()
  if all(parameter in getargspec(scoring)[0] for parameter in scoring_parameters):
C:\Users\...\AppData\Local\Continuum\anaconda3\lib\site-packages\gensim\models\phrases.py:317: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()
  if all(parameter in getargspec(scoring)[0] for parameter in scoring_parameters):
```
Please paste or specifically describe the actual output or traceback. -->

#### Versions
```
Windows-10-10.0.15063-SP0
Python 3.6.3 |Anaconda, Inc.| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)]
NumPy 1.14.0
SciPy 0.19.1
gensim 3.3.0
FAST_VERSION 1
```


<!-- Thanks for contributing! -->

"
131,https://github.com/RaRe-Technologies/gensim/issues/1879,1879,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2018-02-07 04:44:32+00:00,,Add methods for mixture of word-vectors,"**Intro**
Users want to construct document vector from word-vectors (that already exist). As I see now, we have a really huge number of high-quality word-vectors (from Stanford, Google, Numberbatch, etc), for this reason, this feature can be really useful 

**To Do**
1. Collect ways, how we can mix-up word-vectors to document vector
    - the average of all word-vectors
    - the average with weights (like TfIdf or some custom weights from a user)
    - https://openreview.net/pdf?id=SyK00v5xx (IMO most powerful method here)
    - something else (investigate more methods is also part of this step)
2. Add this approaches as one (or several) methods to gensim (to ""vector-storage classes"") 
3. Write a Notebook with demonstration (how you can use it) + benchmarking (comparing this technique with document-vectors on several tasks, good benchmark reference is https://openreview.net/pdf?id=SyK00v5xx).


Based on https://groups.google.com/forum/#!topic/gensim/OfBjD0GU2xA (this is the latest thread about it)"
132,https://github.com/RaRe-Technologies/gensim/issues/1881,1881,[],closed,2018-02-07 18:21:34+00:00,,How can I create StackedAreaChart with adding focus chart on the botton like lineWithFocusChart()  , How can I create StackedAreaChart with focus chart with slider at the botton like the lineWithFocusChart() 
133,https://github.com/RaRe-Technologies/gensim/issues/1882,1882,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",open,2018-02-07 22:27:16+00:00,,Accesing vector model vocabulary broken in Gensim 3.3 when loading from word2vec format,"After upgrading to 3.3.0, it is now impossible to get the model's vocabulary with `model.wv.vocab` method, if the model is loaded from a text or binary word2vec file. However, it works for models saved in the Gensim native format. 
I suppose it is related to re-designing vector models implementations in #1777.  Anyway, it is not good to break compatibility in this way, without even notifying users.

#### Steps/ to Reproduce
```
import gensim, logging
logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)
model = gensim.models.KeyedVectors.load_word2vec_format('ANY_MODEL.bin.gz', binary=True)
WORD in model.wv.vocab
```
#### Expected Results
`True` or `False`, as it is in Gensim 3.2

#### Actual Results
```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
AttributeError: 'Word2VecKeyedVectors' object has no attribute 'wv'
```

#### Versions
```
Linux-4.13.0-32-generic-x86_64-with-LinuxMint-18.2-sonya
Python 3.5.2 (default, Nov 23 2017, 16:37:01) 
[GCC 5.4.0 20160609]
NumPy 1.14.0
SciPy 1.0.0
gensim 3.3.0
FAST_VERSION 1
```
"
134,https://github.com/RaRe-Technologies/gensim/issues/1883,1883,[],closed,2018-02-08 06:55:30+00:00,,gensim.similarities.SparseMatrixSimilarity get segmentation-fault,"I want to get the similarity of one document to other documents. I use gensim. The program can run correctly, but after some steps it exits with Segmentation fault.The version of gensim is ''3.3.0'' and the python version is '2.7.6'

Below is my code:

    from gensim import corpora, models, similarities
    docs = [['Looking', 'for', 'the', 'meanings', 'of', 'words'],
            ['phrases'],
            ['and', 'expressions'],
            ['We', 'provide', 'hundreds', 'of', 'thousands', 'of', 'definitions'],
            ['synonyms'],
            ['antonyms'],
            ['and', 'pronunciations', 'for', 'English', 'and', 'other', 'languages'],
            ['derived', 'from', 'our', 'language', 'research', 'and', 'expert', 'analysis'],
            ['We', 'also', 'offer', 'a', 'unique', 'set', 'of', 'examples', 'of', 'real', 'usage'],
            ['as', 'well', 'as', 'guides', 'to:']]
    dictionary = corpora.Dictionary(docs)
    corpus = [dictionary.doc2bow(text) for text in docs]
    nf=len(dictionary.dfs)
    index = similarities.SparseMatrixSimilarity(corpus, num_features=nf)
    phrases = [['This',
                'section',
                'gives',
                'guidelines',
                'on',
                'writing',
                'in',
                'everyday',
                'situations'],
               ['from',
                'applying',
                'for',
                'a',
                'job',
                'to',
                'composing',
                'letters',
                'of',
                'complaint',
                'or',
                'making',
                'an',
                'insurance',
                'claim'],
               ['There',
                'are',
                'plenty',
                'of',
                'sample',
                'documents',
                'to',
                'help',
                'you',
                'get',
                'it',
                'right',
                'every',
                'time'],
               ['create',
                'a',
                'good',
                'impression'],
               ['and',
                'increase',
                'the',
                'likelihood',
                'of',
                'achieving',
                'your',
                'desired',
                'outcome']]
    phrase2word=[dictionary.doc2bow(text,allow_update=True) for text in phrases]
    sims=index[phrase2word]

It can run normally until get sims, but it cannot get sims, and using `gdb` gets the following info:

> Program received signal SIGSEGV, Segmentation fault.
> 0x00007fffd881d809 in csr_tocsc<int, float> (n_row=5, n_col=39,
> Ap=0x4a4eb10, Aj=0x9fc6ec0, Ax=0x1be4a00, Bp=0xa15f6a0, Bi=0x9f3ee80,
> Bx=0x9f85f60) at scipy/sparse/sparsetools/csr.h:411 411    
> scipy/sparse/sparsetools/csr.h: 没有那个文件或目录.

"
135,https://github.com/RaRe-Technologies/gensim/issues/1886,1886,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2018-02-08 15:00:29+00:00,,cannot import name 'LabeledSentence',"
#### Description
LabeledSentence is not being imported from gensim.models.doc2vec. 

``from gensim.models.doc2vec import LabeledSentence``

the error I am getting is 
``cannot import name 'LabeledSentence'``


"
136,https://github.com/RaRe-Technologies/gensim/issues/1888,1888,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 708430967, 'node_id': 'MDU6TGFiZWw3MDg0MzA5Njc=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/performance', 'name': 'performance', 'color': 'd93f0b', 'default': False, 'description': 'Issue related to performance (in HW meaning)'}]",open,2018-02-08 23:22:16+00:00,,Optimize sparse * random dense matrix multiply in LsiModel ,"Progress tracking bug.

- [x] Fork https://github.com/brianmingus/gensim
- [x] Find initial work https://gist.github.com/brianmingus/ff6c3e9816c2cb7de0efc17d9bed06e6
- [x] Get most up-to-date CSparse. This was extracted from SuiteSparse-5.1.0 and placed in gensim/gensim/CSparse
- [x] Find example gensim Cython compilation and refactor our setup.py code to comply
- [x] Refactor the python code into a gensim.csparse module
- [ ] Refactor the test code into a gensim-style test that ensures the new code produces identical results and is faster
  - [x] Figure out why pmultiply is returning an array of 0s 
  - [ ] Get the test to actually run
- [x] Current import structure is gensim.csparse.psparse is this ideal
- [x] Modify LsiModel to use pmultiply
  - [ ] Test that LsiModel works
- [x] Look into other uses of sparsetools, see what can be removed
- [ ] Fix import structure. csparse/gaxpy seems to clobber csparse/psparse/pmultiply"
137,https://github.com/RaRe-Technologies/gensim/issues/1889,1889,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-02-09 04:04:11+00:00,,"MmCorpus.load --> UnpicklingError: invalid load key, '%'.","<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
I'm getting an error in using MmCorpus.load('file.mm'), even immediately after saving saving with MmCorpus.serialize('file.mm', corpus). I am using windows10.

<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce
<!--
Coded:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->

Corpus created with:

corpus = [dictionary.doc2bow(text) for text in texts]
MmCorpus.serialize('file.mm', corpus')

corpus = MmCorpus.serialize('file.mm') #breaks here

#### Expected Results
<!-- Example: Expected shape of (100,2).-->

Expecting corpus to load as called.

#### Actual Results
<!-- Example: Actual shape of (100,5). 
---------------------------------------------------------------------------
UnpicklingError                           Traceback (most recent call last)
<ipython-input-58-a457dfa9135e> in <module>()
----> 1 c = MmCorpus.load(str(path))

c:\users\user\.virtualenvs\key_log-v5coq-ss\lib\site-packages\gensim\utils.py in load(cls, fname, mmap)
    393         compress, subname = SaveLoad._adapt_by_suffix(fname)
    394 
--> 395         obj = unpickle(fname)
    396         obj._load_specials(fname, mmap, compress, subname)
    397         logger.info(""loaded %s"", fname)

c:\users\user\.virtualenvs\key_log-v5coq-ss\lib\site-packages\gensim\utils.py in unpickle(fname)
   1300         # Because of loading from S3 load can't be used (missing readline in smart_open)
   1301         if sys.version_info > (3, 0):
-> 1302             return _pickle.load(f, encoding='latin1')
   1303         else:
   1304             return _pickle.loads(f.read())

UnpicklingError: invalid load key, '%'.



#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->

Windows-10-10.0.16299-SP0
Python 3.6.3 |Anaconda, Inc.| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)]
NumPy 1.14.0
SciPy 1.0.0
gensim 3.3.0
FAST_VERSION 0

<!-- Thanks for contributing! -->

"
138,https://github.com/RaRe-Technologies/gensim/issues/1890,1890,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2018-02-09 04:14:22+00:00,,segment_all_articles(include_interlinks=True) errors in image links,"When using the script, 

https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/scripts/segment_wiki.py#L69

with the include_interlinks=True kwarg, I get some links that are very long and do not match any enwiki page titles.  After investigating the first one, I found that it is inside an image caption.  For example, in the page ""Anarchism"" one of the links is, 

> 'link_title': 'individualist anarchist and social anarchist thinkers.'
> 'raw_anchor_text': 'individualist anarchist and social anarchist thinkers.'

In the page xml you can see the wikitext, 

> == Anarchist schools of thought ==                                                                                    
> {{Main|Anarchist schools of thought}}                                                                                 
> [[File:Portrait of Pierre Joseph Proudhon 1865.jpg|thumb|upright|Portrait of philosopher Pierre-Joseph Proudhon (1809–1865) by Gustave Courbet. Proudhon was the primary proponent of anarchist mutualism, and influenced many future [[individualist anarchist]] and social anarchist thinkers.]]

Looks like the doubly nested double square brackets is throwing the parser off.   

#### Steps/Code/Corpus to Reproduce
Example:
```
segment_wiki.segment_and_write_all_articles(                                                                      
        in_fname, out_fname, min_article_character=10, include_interlinks=True) 
```


#### Expected Results
I expect the interlink result to have the anchor text = ""individualist anarchist"", title=""individualist anarchist"".

#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->
Linux-4.4.0-1049-aws-x86_64-with-debian-stretch-sid
Python 3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) 
[GCC 7.2.0]
NumPy 1.14.0
SciPy 1.0.0
gensim 3.3.0
FAST_VERSION 1

<!-- Thanks for contributing! -->

"
139,https://github.com/RaRe-Technologies/gensim/issues/1898,1898,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-02-12 11:26:08+00:00,,Missing Attributes when loading old model in gensim 3.3 (retro-compatibility issue),"#### Description
AttributeError breaking retro-compatibility of old (0.10.3) trained model

#### Steps/Code/Corpus to Reproduce
```
from gensim.models import word2vec

model = word2vec.Word2Vec.load(path_to_model)
```

#### Expected Results
Model loaded

#### Actual Results
```
Traceback (most recent call last):
  File ""/home/max/virtualenvs/experts-python3/lib/python3.5/site-packages/gensim/models/word2vec.py"", line 975, in load
    return super(Word2Vec, cls).load(*args, **kwargs)
  File ""/home/max/virtualenvs/experts-python3/lib/python3.5/site-packages/gensim/models/base_any2vec.py"", line 629, in load
    model = super(BaseWordEmbeddingsModel, cls).load(*args, **kwargs)
  File ""/home/max/virtualenvs/experts-python3/lib/python3.5/site-packages/gensim/models/base_any2vec.py"", line 278, in load
    return super(BaseAny2VecModel, cls).load(fname_or_handle, **kwargs)
  File ""/home/max/virtualenvs/experts-python3/lib/python3.5/site-packages/gensim/utils.py"", line 396, in load
    obj._load_specials(fname, mmap, compress, subname)
  File ""/home/max/virtualenvs/experts-python3/lib/python3.5/site-packages/gensim/utils.py"", line 461, in _load_specials
    setattr(self, attrib, None)
  File ""/home/max/virtualenvs/experts-python3/lib/python3.5/site-packages/gensim/utils.py"", line 1368, in new_func1
    return func(*args, **kwargs)
  File ""/home/max/virtualenvs/experts-python3/lib/python3.5/site-packages/gensim/models/base_any2vec.py"", line 450, in cum_table
    self.vocabulary.cum_table = value
AttributeError: 'Word2Vec' object has no attribute 'vocabulary'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/max/virtualenvs/experts-python3/lib/python3.5/site-packages/gensim/models/word2vec.py"", line 979, in load
    return load_old_word2vec(*args, **kwargs)
  File ""/home/max/virtualenvs/experts-python3/lib/python3.5/site-packages/gensim/models/deprecated/word2vec.py"", line 195, in load_old_word2vec
    new_model.min_alpha_yet_reached = old_model.min_alpha_yet_reached
AttributeError: 'Word2Vec' object has no attribute 'min_alpha_yet_reached'
```

#### Versions
```
>>> import platform; print(platform.platform())
Linux-4.9.0-4-amd64-x86_64-with-debian-9.3
>>> import sys; print(""Python"", sys.version)
Python 3.5.3 (default, Jan 19 2017, 14:11:04) 
[GCC 6.3.0 20170118]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.14.0
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.0.0
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.3.0
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1
```"
140,https://github.com/RaRe-Technologies/gensim/issues/1899,1899,[],closed,2018-02-12 16:06:08+00:00,,`corpus_count` restarts from 0 when adding to trained model,"#### Description

I'm using the online training feature of gensim to add to an existing model when I got new data, I've mainly followed the tutorial [here](https://github.com/RaRe-Technologies/gensim/blob/master/docs/notebooks/online_w2v_tutorial.ipynb). 

In the specifics, I've pre-trained a model over roughly 1.5 million sentences, saved it and am now adding more sentences to it.

#### Steps/Code/Corpus to Reproduce

```
import gensim

# Load existing trained model
model = gensim.models.Word2Vec.load('gensim_model')

print('model counts', model.corpus_count, len(model.wv.vocab))

sents = [['new', 'sentence', 'one'], ['new', 'sentence', 'two']]

# Keep training it with new data
model.build_vocab(sents, update=True)
model.train(sents, total_examples=model.corpus_count, epochs=model.iter)

print('model counts', model.corpus_count, len(model.wv.vocab))
```
While the first prints gives `model counts 1470958 126927`, the second gives `model counts 2 126928`, so apparently the counts of texts scanned has restarted while the vocabulary has been added to. I'd have expected the count of corpus texts scanned to be added to as well?

#### Expected Results

Would have expected the second print to give `model 1478023 126933`.

#### Actual Results

The second print gives `model counts 2 126928`.

#### Versions

```
Darwin-17.4.0-x86_64-i386-64bit
Python 3.6.3 (default, Oct  4 2017, 06:09:38)
[GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.37)]
NumPy 1.14.0
SciPy 1.0.0
gensim 3.2.0
FAST_VERSION 0
```"
141,https://github.com/RaRe-Technologies/gensim/issues/1900,1900,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2018-02-14 02:00:53+00:00,,Seems Word2VecKeyedVectors.get_keras_embedding should take care of 'mask_zero',"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description

As described in Groups, create this issue for tracking, thanks Ivan for a quick view.
[Google Groups tracking](https://groups.google.com/forum/#!topic/gensim/Wk4CnPqL_OY)

This is a question about combining gensim with Keras.
As KeyedVectors.vectors as start with index of '0', then the word indices with index '0' should be valid word to obtain a word vector from embedding layer. [code line](https://github.com/RaRe-Technologies/gensim/blob/e1022729e986688438b9079db6aefaf892bc8478/gensim/models/keyedvectors.py#L1141)
And Keras Embedding layer do provide mask_zero to have eyes on padding '0'([Keras Embedding](https://keras.io/layers/embeddings/)).
And as shown in tutorials of [Keras blog](https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html) , they do provide a embedding matrix to Embedding layer with index starting from '1' and input_dim=len(vocab) + 1.
Thus, if we get_keras_embedding from Word2VecKeyedVectors, we'll take all '0' padding as the first word, or missing all the first word if we set mask_zero=True.
So I smell bug here.
And changing the behavior of get_keras_embedding may also need to change model.index2word or KeyedVectors.vocab.

I know there are many ways to work around this issue, such as manually pad with other values instead of '0' or manually build a Keras Embedding layer. Then what if we could do to both take the advantage of get_keras_embedding and pad_sequeneces in Keras?

Thanks!

#### Steps/Code/Corpus to Reproduce
```python
import os

import numpy as np
from gensim.models.keyedvectors import KeyedVectors
from keras.layers import Embedding, Input
from keras.preprocessing.sequence import pad_sequences
from keras.models import Model
import keras.backend as K

emb_file = 'gensim.txt'
"""""" Content in gensim.txt
2 3
the 0 1 2
and 3 4 5
""""""
kvecs = KeyedVectors.load_word2vec_format(emb_file)
#print(kvecs.word_index)
#print(kvecs.vectors)
#print(kvecs.syn0)
emb_layer = kvecs.get_keras_embedding()


emb_weights = np.arange((2*3)).reshape((2, 3))
inputs = np.array([0, 1, 1]).reshape((1, 3))
inputs_pad = pad_sequences(inputs, maxlen=10)
inp=Input((10,))
#out=Embedding(input_dim=2, output_dim=3, weights=[emb_weights])(inp)
out=emb_layer(inp)
model = Model(inp, out)
print(model.predict(inputs_pad))
```
#### Actual Results
```python
[[[0. 1. 2.]
  [0. 1. 2.]
  [0. 1. 2.]
  [0. 1. 2.]
  [0. 1. 2.]
  [0. 1. 2.]
  [0. 1. 2.]
  [0. 1. 2.]
  [3. 4. 5.]
  [3. 4. 5.]]]
```

#### Expected Results
And  the expected result maybe
```python
[[[0. 0. 0.]
  [0. 0. 0.]
  [0. 0. 0.]
  [0. 0. 0.]
  [0. 0. 0.]
  [0. 0.0.]
  [0. 0. 0.]
  [0. 1. 2.]
  [3. 4. 5.]
  [3. 4. 5.]]]
```
#### Versions
```
Darwin-16.7.0-x86_64-i386-64bit
Python 3.6.1 |Anaconda custom (64-bit)| (default, May 11 2017, 13:04:09)
[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]
NumPy 1.14.0
SciPy 1.0.0
gensim 3.3.0
FAST_VERSION 0
(Tough have nothing to do with the environment but do need gensim >= 3.3.0)
```
<!-- Thanks for contributing! -->

"
142,https://github.com/RaRe-Technologies/gensim/issues/1901,1901,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 175986, 'node_id': 'MDU6TGFiZWwxNzU5ODY=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/testing', 'name': 'testing', 'color': '444444', 'default': False, 'description': 'Issue related with testing (code, documentation, etc)'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 1584013467, 'node_id': 'MDU6TGFiZWwxNTg0MDEzNDY3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/conda', 'name': 'conda', 'color': 'c9ef58', 'default': False, 'description': ''}]",open,2018-02-14 08:30:54+00:00,,Add anaconda-cloud badge & setup build for MacOSX,"Into
-----
We build gensim for [conda-forge/conda-cloud](https://github.com/conda-forge/gensim-feedstock), but nobody knows about it.

Todo
-----
- [x] (easy) Add conda-cloud badge to gensim `README.md` (#1905)
- [ ] (medium) Setup MacOSX build in gensim-feedstock, related issue https://github.com/conda-forge/gensim-feedstock/issues/2 
"
143,https://github.com/RaRe-Technologies/gensim/issues/1902,1902,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2018-02-14 08:54:57+00:00,,Add method for showing base info about gensim,"Intro
----
When users report something, we need to know more information (not only gensim version, versions of related packages, OS and so on), and user need to copy-paste&run something like this

````
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
````

We can easily add it as method to gensim and use as `python -m gensim.scripts.package_info --info`

Todo
-------
Implement this method, information, that should be showed
- gensim version
- python version
- numpy version
- scipy version
- os version
- smart_open version
- `FAST_VERSION` variable
- path (where gensim installed)
- ??? (maybe something else)


"
144,https://github.com/RaRe-Technologies/gensim/issues/1906,1906,[],closed,2018-02-14 18:27:41+00:00,,Support ngram by gensim ?,"It seems gensim only support bigram by phrase. However, it seems to be hard to extract n-gram (uni, bi, trigram) all together once. The tfidfmodel and other models seems only support one phrase, if I can't use the uni,bi,trigram together in the models. Any solutions for this issue?"
145,https://github.com/RaRe-Technologies/gensim/issues/1914,1914,[],closed,2018-02-18 10:30:11+00:00,,Training dataset too large to download,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

#### Description
The dataset to be downloaded from baidu site is too large 
I found this URL from page : translation_matrix.ipynb

https://pan.baidu.com/s/1boP0P7D

Is the file available on S3?
"
146,https://github.com/RaRe-Technologies/gensim/issues/1917,1917,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2018-02-20 09:27:07+00:00,,Poincare training bug,"#### Description
I trained Poincare model on wiki graph and receive this exception


#### Steps/Code/Corpus to Reproduce
I have no good example for reproducing, but what I exactly did

```python
from gensim.models.poincare import PoincareModel
import logging
import json
from tqdm import tqdm
from smart_open import smart_open

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')

class WikiGraphReader(object):
    def __init__(self, pth):
        self.pth = pth
        
    def __iter__(self):
        with smart_open(self.pth, 'r') as infile:
            for row in tqdm(infile):
                row = json.loads(row)
                src = row[""s""]

                for dst in row[""d""]:
                    yield (src, dst)
         
corpus = WikiGraphReader(""edges.jsonl.gz"")
model = PoincareModel(corpus)
model.train(epochs=1, batch_size=1000)  # all fine, trained successfully
model.save(""poincare-1ep-wiki.model"")
model.train(epochs=1, batch_size=1000)  # exception from here line
model.save(""p_model/poincare-1.5ep-wiki.model"")  # I saved this model too
```

Full stack trace from second `model.train(epochs=1, batch_size=1000)`
```
2018-02-05 10:49:58,008 - training model of size 50 with 1 workers on 128138847 relations for 1 epochs and 10 burn-in epochs, using lr=0.01000 burn-in lr=0.01000 negative=10
2018-02-05 10:49:58,010 - Starting burn-in (10 epochs)----------------------------------------
2018-02-05 10:56:51,400 - Training on epoch 1, examples #999000-#1000000, loss: 2188.85
2018-02-05 10:56:51,404 - Time taken for 1000000 examples: 329.60 s, 3033.98 examples / s
2018-02-05 11:01:44,625 - Training on epoch 1, examples #1999000-#2000000, loss: 2187.71
2018-02-05 11:01:44,627 - Time taken for 1000000 examples: 293.22 s, 3410.41 examples / s
2018-02-05 11:06:38,729 - Training on epoch 1, examples #2999000-#3000000, loss: 2186.41
2018-02-05 11:06:38,731 - Time taken for 1000000 examples: 294.10 s, 3400.18 examples / s
2018-02-05 11:11:28,291 - Training on epoch 1, examples #3999000-#4000000, loss: 2185.42
2018-02-05 11:11:28,293 - Time taken for 1000000 examples: 289.56 s, 3453.52 examples / s
2018-02-05 11:16:16,831 - Training on epoch 1, examples #4999000-#5000000, loss: 2184.04
2018-02-05 11:16:16,833 - Time taken for 1000000 examples: 288.54 s, 3465.75 examples / s
2018-02-05 11:21:06,625 - Training on epoch 1, examples #5999000-#6000000, loss: 2182.88
2018-02-05 11:21:06,630 - Time taken for 1000000 examples: 289.79 s, 3450.75 examples / s
2018-02-05 11:26:55,483 - Training on epoch 1, examples #6999000-#7000000, loss: 2181.47
2018-02-05 11:26:55,484 - Time taken for 1000000 examples: 348.85 s, 2866.54 examples / s
2018-02-05 11:31:45,830 - Training on epoch 1, examples #7999000-#8000000, loss: 2180.34
2018-02-05 11:31:45,839 - Time taken for 1000000 examples: 290.34 s, 3444.18 examples / s
2018-02-05 11:36:30,690 - Training on epoch 1, examples #8999000-#9000000, loss: 2179.56
2018-02-05 11:36:30,692 - Time taken for 1000000 examples: 284.85 s, 3510.62 examples / s
2018-02-05 11:41:15,313 - Training on epoch 1, examples #9999000-#10000000, loss: 2178.03
2018-02-05 11:41:15,315 - Time taken for 1000000 examples: 284.62 s, 3513.45 examples / s
2018-02-05 11:46:00,357 - Training on epoch 1, examples #10999000-#11000000, loss: 2177.52
2018-02-05 11:46:00,358 - Time taken for 1000000 examples: 285.04 s, 3508.26 examples / s
2018-02-05 11:50:48,905 - Training on epoch 1, examples #11999000-#12000000, loss: 2175.87
2018-02-05 11:50:48,910 - Time taken for 1000000 examples: 288.55 s, 3465.64 examples / s
2018-02-05 11:55:35,918 - Training on epoch 1, examples #12999000-#13000000, loss: 2174.76
2018-02-05 11:55:35,919 - Time taken for 1000000 examples: 287.01 s, 3484.23 examples / s
2018-02-05 12:00:24,240 - Training on epoch 1, examples #13999000-#14000000, loss: 2173.49
2018-02-05 12:00:24,242 - Time taken for 1000000 examples: 288.32 s, 3468.36 examples / s
2018-02-05 12:05:07,573 - Training on epoch 1, examples #14999000-#15000000, loss: 2172.35
2018-02-05 12:05:07,574 - Time taken for 1000000 examples: 283.33 s, 3529.45 examples / s
2018-02-05 12:09:52,164 - Training on epoch 1, examples #15999000-#16000000, loss: 2171.20
2018-02-05 12:09:52,165 - Time taken for 1000000 examples: 284.59 s, 3513.83 examples / s
2018-02-05 12:14:41,436 - Training on epoch 1, examples #16999000-#17000000, loss: 2170.33
2018-02-05 12:14:41,438 - Time taken for 1000000 examples: 289.27 s, 3456.97 examples / s
2018-02-05 12:19:34,138 - Training on epoch 1, examples #17999000-#18000000, loss: 2169.56
2018-02-05 12:19:34,142 - Time taken for 1000000 examples: 292.70 s, 3416.47 examples / s
2018-02-05 12:24:27,812 - Training on epoch 1, examples #18999000-#19000000, loss: 2168.17
2018-02-05 12:24:27,814 - Time taken for 1000000 examples: 293.67 s, 3405.19 examples / s
2018-02-05 12:29:15,083 - Training on epoch 1, examples #19999000-#20000000, loss: 2167.16
2018-02-05 12:29:15,085 - Time taken for 1000000 examples: 287.27 s, 3481.06 examples / s
2018-02-05 12:34:03,589 - Training on epoch 1, examples #20999000-#21000000, loss: 2165.85
2018-02-05 12:34:03,590 - Time taken for 1000000 examples: 288.50 s, 3466.17 examples / s
2018-02-05 12:38:50,770 - Training on epoch 1, examples #21999000-#22000000, loss: 2164.89
2018-02-05 12:38:50,772 - Time taken for 1000000 examples: 287.18 s, 3482.14 examples / s
2018-02-05 12:43:41,125 - Training on epoch 1, examples #22999000-#23000000, loss: 2163.63
2018-02-05 12:43:41,129 - Time taken for 1000000 examples: 290.35 s, 3444.09 examples / s
2018-02-05 12:48:27,127 - Training on epoch 1, examples #23999000-#24000000, loss: 2162.46
2018-02-05 12:48:27,129 - Time taken for 1000000 examples: 286.00 s, 3496.53 examples / s
2018-02-05 12:53:17,683 - Training on epoch 1, examples #24999000-#25000000, loss: 2161.23
2018-02-05 12:53:17,684 - Time taken for 1000000 examples: 290.55 s, 3441.71 examples / s
2018-02-05 12:58:02,880 - Training on epoch 1, examples #25999000-#26000000, loss: 2160.17
2018-02-05 12:58:02,881 - Time taken for 1000000 examples: 285.20 s, 3506.37 examples / s
2018-02-05 13:02:47,177 - Training on epoch 1, examples #26999000-#27000000, loss: 2158.66
2018-02-05 13:02:47,179 - Time taken for 1000000 examples: 284.30 s, 3517.46 examples / s
2018-02-05 13:07:31,441 - Training on epoch 1, examples #27999000-#28000000, loss: 2157.93
2018-02-05 13:07:31,442 - Time taken for 1000000 examples: 284.26 s, 3517.89 examples / s
2018-02-05 13:12:20,000 - Training on epoch 1, examples #28999000-#29000000, loss: 2156.97
2018-02-05 13:12:20,004 - Time taken for 1000000 examples: 288.56 s, 3465.52 examples / s
2018-02-05 13:17:06,050 - Training on epoch 1, examples #29999000-#30000000, loss: 2155.66
2018-02-05 13:17:06,051 - Time taken for 1000000 examples: 286.04 s, 3495.96 examples / s
2018-02-05 13:21:56,627 - Training on epoch 1, examples #30999000-#31000000, loss: 2154.42
2018-02-05 13:21:56,628 - Time taken for 1000000 examples: 290.58 s, 3441.45 examples / s
2018-02-05 13:26:41,004 - Training on epoch 1, examples #31999000-#32000000, loss: 2153.39
2018-02-05 13:26:41,005 - Time taken for 1000000 examples: 284.37 s, 3516.49 examples / s
2018-02-05 13:31:26,601 - Training on epoch 1, examples #32999000-#33000000, loss: 2152.29
2018-02-05 13:31:26,603 - Time taken for 1000000 examples: 285.59 s, 3501.49 examples / s
2018-02-05 13:36:11,844 - Training on epoch 1, examples #33999000-#34000000, loss: 2151.36
2018-02-05 13:36:11,845 - Time taken for 1000000 examples: 285.24 s, 3505.82 examples / s
2018-02-05 13:41:08,003 - Training on epoch 1, examples #34999000-#35000000, loss: 2150.06
2018-02-05 13:41:08,008 - Time taken for 1000000 examples: 296.16 s, 3376.58 examples / s
2018-02-05 13:45:59,593 - Training on epoch 1, examples #35999000-#36000000, loss: 2149.02
2018-02-05 13:45:59,594 - Time taken for 1000000 examples: 291.58 s, 3429.54 examples / s
2018-02-05 13:50:52,455 - Training on epoch 1, examples #36999000-#37000000, loss: 2148.05
2018-02-05 13:50:52,457 - Time taken for 1000000 examples: 292.86 s, 3414.59 examples / s
2018-02-05 13:55:42,711 - Training on epoch 1, examples #37999000-#38000000, loss: 2146.37
2018-02-05 13:55:42,712 - Time taken for 1000000 examples: 290.25 s, 3445.26 examples / s
2018-02-05 14:00:31,112 - Training on epoch 1, examples #38999000-#39000000, loss: 2145.71
2018-02-05 14:00:31,113 - Time taken for 1000000 examples: 288.40 s, 3467.42 examples / s
2018-02-05 14:05:18,087 - Training on epoch 1, examples #39999000-#40000000, loss: 2144.32
2018-02-05 14:05:18,088 - Time taken for 1000000 examples: 286.97 s, 3484.65 examples / s
2018-02-05 14:10:08,383 - Training on epoch 1, examples #40999000-#41000000, loss: 2143.63
2018-02-05 14:10:08,388 - Time taken for 1000000 examples: 290.29 s, 3444.78 examples / s
2018-02-05 14:15:01,954 - Training on epoch 1, examples #41999000-#42000000, loss: 2142.36
2018-02-05 14:15:01,955 - Time taken for 1000000 examples: 293.57 s, 3406.40 examples / s
2018-02-05 14:19:58,021 - Training on epoch 1, examples #42999000-#43000000, loss: 2141.21
2018-02-05 14:19:58,023 - Time taken for 1000000 examples: 296.07 s, 3377.63 examples / s
2018-02-05 14:24:43,944 - Training on epoch 1, examples #43999000-#44000000, loss: 2140.30
2018-02-05 14:24:43,945 - Time taken for 1000000 examples: 285.92 s, 3497.48 examples / s
2018-02-05 14:29:36,938 - Training on epoch 1, examples #44999000-#45000000, loss: 2138.98
2018-02-05 14:29:36,939 - Time taken for 1000000 examples: 292.99 s, 3413.06 examples / s
2018-02-05 14:34:31,522 - Training on epoch 1, examples #45999000-#46000000, loss: 2137.78
2018-02-05 14:34:31,523 - Time taken for 1000000 examples: 294.58 s, 3394.64 examples / s
2018-02-05 14:39:24,775 - Training on epoch 1, examples #46999000-#47000000, loss: 2136.79
2018-02-05 14:39:24,780 - Time taken for 1000000 examples: 293.25 s, 3410.04 examples / s
2018-02-05 14:44:15,172 - Training on epoch 1, examples #47999000-#48000000, loss: 2135.49
2018-02-05 14:44:15,174 - Time taken for 1000000 examples: 290.39 s, 3443.62 examples / s
2018-02-05 14:49:07,628 - Training on epoch 1, examples #48999000-#49000000, loss: 2135.08
2018-02-05 14:49:07,630 - Time taken for 1000000 examples: 292.45 s, 3419.34 examples / s
2018-02-05 14:53:51,284 - Training on epoch 1, examples #49999000-#50000000, loss: 2133.45
2018-02-05 14:53:51,285 - Time taken for 1000000 examples: 283.65 s, 3525.43 examples / s
2018-02-05 14:58:39,403 - Training on epoch 1, examples #50999000-#51000000, loss: 2132.59
2018-02-05 14:58:39,404 - Time taken for 1000000 examples: 288.12 s, 3470.81 examples / s
2018-02-05 15:03:27,455 - Training on epoch 1, examples #51999000-#52000000, loss: 2131.60
2018-02-05 15:03:27,456 - Time taken for 1000000 examples: 288.05 s, 3471.65 examples / s
2018-02-05 15:08:19,622 - Training on epoch 1, examples #52999000-#53000000, loss: 2130.17
2018-02-05 15:08:19,627 - Time taken for 1000000 examples: 292.17 s, 3422.71 examples / s
2018-02-05 15:13:12,975 - Training on epoch 1, examples #53999000-#54000000, loss: 2129.34
2018-02-05 15:13:12,976 - Time taken for 1000000 examples: 293.35 s, 3408.92 examples / s
2018-02-05 15:18:01,815 - Training on epoch 1, examples #54999000-#55000000, loss: 2128.32
2018-02-05 15:18:01,816 - Time taken for 1000000 examples: 288.84 s, 3462.15 examples / s
2018-02-05 15:22:45,226 - Training on epoch 1, examples #55999000-#56000000, loss: 2126.67
2018-02-05 15:22:45,227 - Time taken for 1000000 examples: 283.41 s, 3528.47 examples / s
2018-02-05 15:27:31,026 - Training on epoch 1, examples #56999000-#57000000, loss: 2126.11
2018-02-05 15:27:31,027 - Time taken for 1000000 examples: 285.79 s, 3499.01 examples / s
2018-02-05 15:32:19,805 - Training on epoch 1, examples #57999000-#58000000, loss: 2125.11
2018-02-05 15:32:19,807 - Time taken for 1000000 examples: 288.77 s, 3462.90 examples / s
2018-02-05 15:37:11,024 - Training on epoch 1, examples #58999000-#59000000, loss: 2123.99
2018-02-05 15:37:11,028 - Time taken for 1000000 examples: 291.22 s, 3433.87 examples / s
2018-02-05 15:42:06,631 - Training on epoch 1, examples #59999000-#60000000, loss: 2123.01
2018-02-05 15:42:06,632 - Time taken for 1000000 examples: 295.60 s, 3382.92 examples / s
2018-02-05 15:46:54,707 - Training on epoch 1, examples #60999000-#61000000, loss: 2121.46
2018-02-05 15:46:54,709 - Time taken for 1000000 examples: 288.07 s, 3471.33 examples / s
2018-02-05 15:51:42,019 - Training on epoch 1, examples #61999000-#62000000, loss: 2120.72
2018-02-05 15:51:42,021 - Time taken for 1000000 examples: 287.31 s, 3480.57 examples / s
2018-02-05 15:56:29,973 - Training on epoch 1, examples #62999000-#63000000, loss: 2119.82
2018-02-05 15:56:29,974 - Time taken for 1000000 examples: 287.95 s, 3472.81 examples / s
2018-02-05 16:01:22,243 - Training on epoch 1, examples #63999000-#64000000, loss: 2118.50
2018-02-05 16:01:22,247 - Time taken for 1000000 examples: 292.27 s, 3421.52 examples / s
2018-02-05 16:06:09,893 - Training on epoch 1, examples #64999000-#65000000, loss: 2117.51
2018-02-05 16:06:09,894 - Time taken for 1000000 examples: 287.64 s, 3476.51 examples / s
2018-02-05 16:11:00,706 - Training on epoch 1, examples #65999000-#66000000, loss: 2116.77
2018-02-05 16:11:00,707 - Time taken for 1000000 examples: 290.81 s, 3438.66 examples / s
2018-02-05 16:15:46,906 - Training on epoch 1, examples #66999000-#67000000, loss: 2115.44
2018-02-05 16:15:46,908 - Time taken for 1000000 examples: 286.20 s, 3494.08 examples / s
2018-02-05 16:20:32,582 - Training on epoch 1, examples #67999000-#68000000, loss: 2114.07
2018-02-05 16:20:32,584 - Time taken for 1000000 examples: 285.67 s, 3500.49 examples / s
2018-02-05 16:25:18,195 - Training on epoch 1, examples #68999000-#69000000, loss: 2113.42
2018-02-05 16:25:18,197 - Time taken for 1000000 examples: 285.61 s, 3501.27 examples / s
---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
<ipython-input-15-50d51e10cfa2> in <module>()
----> 1 model.train(epochs=1, batch_size=1000)

~/.virtualenvs/wiki-graph/lib/python3.5/site-packages/gensim/models/poincare.py in train(self, epochs, batch_size, print_every, check_gradients_every)
    542             self._train_batchwise(
    543                 epochs=self.burn_in, batch_size=batch_size, print_every=print_every,
--> 544                 check_gradients_every=check_gradients_every)
    545             self._burn_in_done = True
    546             logger.info(""Burn-in finished"")

~/.virtualenvs/wiki-graph/lib/python3.5/site-packages/gensim/models/poincare.py in _train_batchwise(self, epochs, batch_size, print_every, check_gradients_every)
    583                 batch_indices = indices[i:i + batch_size]
    584                 relations = [self.all_relations[idx] for idx in batch_indices]
--> 585                 result = self._train_on_batch(relations, check_gradients=check_gradients)
    586                 avg_loss += result.loss
    587                 if should_print:

~/.virtualenvs/wiki-graph/lib/python3.5/site-packages/gensim/models/poincare.py in _train_on_batch(self, relations, check_gradients)
    442         """"""
    443         all_negatives = self._sample_negatives_batch([relation[0] for relation in relations])
--> 444         batch = self._prepare_training_batch(relations, all_negatives, check_gradients)
    445         self._update_vectors_batch(batch)
    446         return batch

~/.virtualenvs/wiki-graph/lib/python3.5/site-packages/gensim/models/poincare.py in _prepare_training_batch(self, relations, all_negatives, check_gradients)
    363 
    364         vectors_u = self.kv.syn0[indices_u]
--> 365         vectors_v = self.kv.syn0[indices_v].reshape((batch_size, 1 + self.negative, self.size))
    366         vectors_v = vectors_v.swapaxes(0, 1).swapaxes(1, 2)
    367         batch = PoincareBatch(vectors_u, vectors_v, indices_u, indices_v, self.regularization_coeff)

IndexError: index 13971421 is out of bounds for axis 0 with size 13971421

```

From the first sight, looks like problem with `self.negative`.

#### All files, mentioned in code
- [edges.jsonl.gz](https://drive.google.com/file/d/1waas84tIppy2M1Lsy-qhHQBce3ceeMbe/view?usp=sharing)
- models (will be loaded later, 14GB of `.tar.gz`)

#### Versions
```
Linux-4.4.0-62-generic-x86_64-with-Ubuntu-16.04-xenial
Python 3.5.2 (default, Sep 14 2017, 22:51:06) 
[GCC 5.4.0 20160609]
NumPy 1.14.0
SciPy 1.0.0
gensim 3.3.0
FAST_VERSION 1
```


<!-- Thanks for contributing! -->

"
147,https://github.com/RaRe-Technologies/gensim/issues/1920,1920,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}]",closed,2018-02-21 11:43:52+00:00,,Document how word2vec is training,"I would like to see a documentation how word2vec is training skip-gram and CBOW.

### First, the Skip-Gram model:

From the Internet I found two alternative ways. For that let us establish that each word is encoded as a one-hot-vector, which is put into the NN returning a probability vector for each word of finding this word near (in the neighborhood, being a context word) the input word. Let us assume there are `C` context words for each word, which we can also one-hot-encode. For training we have a word and it's `C` context words as targets (all vectors one-hot-encoded).

1. https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/ describes that the NN output of a word is compared with each of the `C` target context words one-hot-vectors. For each of the comparisons an error vector is calculated. Those error vectors are added up to the total error vector and this is used for the training / updating of the weights via backpropagation. So the a training set is `Word -> {C1, C2, C3, C4}`. This is also the description of https://iksinc.online/tag/continuous-bag-of-words-cbow/ and I get the impression it is also what the original publication is suggesting.
2. http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/ suggests each word produces up to `C` training sets (less than `C` if the word is at the beginning or end of the sentence). So one word produces multiple training sets for backpropagation, so `Word -> C1, Word -> C2, Word -> C3, Word -> C4` and for each backpropagation there is only one error vector calculated.

To find out how gensim is doing it checked `gensim.models.word2vec` and there especially the method

```
    def train_batch_sg(model, sentences, alpha, work=None, compute_loss=False):
        result = 0
        for sentence in sentences:
            word_vocabs = [model.wv.vocab[w] for w in sentence if w in model.wv.vocab and
                           model.wv.vocab[w].sample_int > model.random.rand() * 2**32]
            for pos, word in enumerate(word_vocabs):
                reduced_window = model.random.randint(model.window)  # `b` in the original word2vec code

                # now go over all words from the (reduced) window, predicting each one in turn
                start = max(0, pos - model.window + reduced_window)
                for pos2, word2 in enumerate(word_vocabs[start:(pos + model.window + 1 - reduced_window)], start):
                    # don't train on the `word` itself
                    if pos2 != pos:
                        train_sg_pair(
                            model, model.wv.index2word[word.index], word2.index, alpha, compute_loss=compute_loss
                        )

            result += len(word_vocabs)
        return result
```

from which I get the strong impression, that 2. way is used.

### Next, the CBOW model:

1. https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/ describes that each context word is put through the NN up to the hidden layer. There the results (after the hidden layer) of the different `C` context words are aggregated (using the mean). The aggregate is put through the output layer and the output is calculated. This is compared with the target word vector (one-hot-encoded), which is the ""central"" word of the sliding window that goes over the sentences. The resulting error vector is used for updating the weights via backpropgation. This is also the description of https://iksinc.online/tag/continuous-bag-of-words-cbow/ and I get the impression it is also what the original publication is suggesting.
2. An alternative (no reference) would be to also build CBOW analogous to 2. for the Skip-Gram training.

To find out how gensim is doing it checked `gensim.models.word2vec` and there especially the method
`train_cbow_pair` which is, with

```
    [...]
    if learn_vectors:
        [...]
            if not model.cbow_mean and input_word_indices:
                neu1e /= len(input_word_indices)
            for i in input_word_indices:
                context_vectors[i] += neu1e * context_locks[i]
```

suggesting that 1. is used.

### How is gensim doing it?

Please document how gensim is doing it. If my assessment is right and you want to, please feel free to build on my descriptions.

If I am right though, I found find it strange, that the skip-gram is not following the publication and I would appreciate an explanation."
148,https://github.com/RaRe-Technologies/gensim/issues/1921,1921,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-02-21 14:13:09+00:00,,Filipino Localization,I want to Localize your Files in Filipino
149,https://github.com/RaRe-Technologies/gensim/issues/1925,1925,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}]",open,2018-02-21 21:22:57+00:00,,Document how doc2vec is including tags into PV-DM and how PV-DBOW compares to the publication,"In the original Paragraph Vector publication only unique identifiers for the different paragraphs (""documents"" in gensim) are used. Two models are presented PV-DM, which is an extension of CBOW of word2vec, and PV-DBOW, which is analogous (not so much an extension) to Skip-Gram of word2vec.

In the following let's assume `C` context words.

### PV-DM

The article https://medium.com/scaleabout/a-gentle-introduction-to-doc2vec-db3e8c0cce5e explains the extension nicely: Additionally to the `C` input layers for the `C` context words (which share the same neural weights though!) we add a single additional input layer which is special, because it has it's own neural weights. Each paragraph/document has it's own ID which is like a special word. As far as I understand, the paragraph ID is also one-hot encoded. The article https://medium.com/scaleabout/a-gentle-introduction-to-doc2vec-db3e8c0cce5e further expands on this by adding another layer for tags, which are **not** paragraph IDs!

What is not clear to me though, is, whether each tag gets its own layer or whether all tags together get one layer. If it is the former, we would always need the same number of tags for each paragraph and the input of each layer would be an one-hot-encoded vector. If it is the later (one layer for all tags), then if there is more than one tag, obviously the tag-input-vector would be hot-encoded, but not one-hot-encoded. Either it is using multiple 1s, or it is using 1 divided by the number of tags of the paragraph as the ""hot"" entries. That is also speculation on my part.

The implementation of the article is with gensim. However, in the implementation it looks, like the document ID is handled like any other tag. This suggests that gensim is actually *not* implementing it as the article suggests (with ID and tags of separated layers), nor does gensim implement it with as the original publication (which only has *paragraph-unique* IDs), but basically it considers everything to be a tag. Further it seems to me from another article (which I can't find right now) that it is possible to give each document a different number of tags. This would suggest to me that gensim is using an implementation with one layer for those tags (I described before why I think that).

More specifically, my specific questions would be:

1. Can gensim documents have different numbers of tags per document?
2. Are there multiple layers for each tag per document?
3. Are document IDs and tags treated differently or within the same layer?
4. If there is one layer for tags, how are tags encoded? As hot-encoded with multiple 1s or with 1/(number of tags for this document) or how?

To find out I checked the source code of gensim, which wasn't that easy. I think the methods `train_document_dm`, `train_document_dm_concat` are most relevant here. Let's look at `train_document_dm` first. Here `window_pos` seems to be the sliding window, making `word2_indexes` the context words and `word` the central word. (Interestingly: In the original publication there is no central word, but the predicted word is the last word of the window!) There is also some random window reduction going on - I guess that is similar to negative sampling or something like that - not sure. `count` seems to be the number of context words and tags - I think it is used for locking weights at the end of the method. Before that however, we go into the method `train_cbow_pair`. Here I am basically lost... I guess `neu1e`(what kind of word is *this*?) is somehow the weight update - however - this would mean that the same learning step is applied to the word weights as well as to the tag weights (line 172 and 175) - which makes little sense: Even if `train_document_dm` is doing mean-averaging as the aggregation after the hidden layer, I expect different updates for the tag weights and the word weights.

`train_document_dm_concat` is using concatintion as aggregation instead of mean-averaging and `neu1e_r` seems to provide at least different updates for the different weight matrices, seen in line 241 and 243 with `neu1e_r[:doctag_len]` and `neu1e_r[doctag_len:]` respectively. 

### PV-DBOW

Regarding PV-DBOW, https://medium.com/scaleabout/a-gentle-introduction-to-doc2vec-db3e8c0cce5e sticks with the original publication. The relevant method in gensim seems to be `train_document_dbow`. According to publication, the input of PV-DBOW is the document ID and the target vectors are the one-hot-encoded words of the sliding window. This is very similar to Skip-Gram, so gensim is using that implementation. However, `train_document_dbow` seems in

```
        if train_words and learn_words:
            train_batch_sg(model, [doc_words], alpha, work)
        for doctag_index in doctag_indexes:
            for word in doc_words:
                train_sg_pair(
                    model, word, doctag_index, alpha, learn_vectors=learn_doctags, learn_hidden=learn_hidden,
                    context_vectors=doctag_vectors, context_locks=doctag_locks
                )
```

to first train a Skip-Gram model on the words without using the doctags and then train the Skip-Gram model in such a way that each word is the input and the tags are the output - very different to publication. Here I can only ask: What's up with that?

### Conclusion

I raised quite a few questions while comparing the original publication, an article on the topic I found only and the gensim implementation. The articles leaves a couple of questions open - checking out the gensim source code did not answer any, but raised more questions regarding PV-DM.

Comparing the gensim implementation of PV-DBOW with the original pubclication made matters worse, as they don't seem to be related at all.

I am sure there is a lot of misunderstanding on my part. However, I would appreciate it a lot if there could be clarification - first here in the thread. Later additionally in a documentation if possible. Adding a lot more commentary to the source code might also be a good addition."
150,https://github.com/RaRe-Technologies/gensim/issues/1927,1927,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2018-02-23 05:07:21+00:00,,LDA underflow problem,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
If we use `numpy.float32` dtype for `LdaModel`, it's possible to receive ""underflow"" problem. PR where this problem was investigated first time - #1767.
Also, @piskvorky suggested that this possible current algorithm problem, i.e. need to change algorithm.

#### Steps/Code/Corpus to Reproduce
```python
import logging, gensim
import gensim.downloader as api
import gensim.corpora
import numpy as np
from gensim.models.ldamodel import LdaModel
logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)

np.seterr(all='raise')  # convert underflow warning to exception

text = api.load('text8')
id2word = gensim.corpora.Dictionary(text)
corpus = [id2word.doc2bow(t) for t in text]

model = LdaModel(corpus=corpus, id2word=id2word, num_topics=100, dtype=np.float32)
```
#### Expected Results
Successfull run

#### Actual Results
```python
2018-02-23 09:54:09,287 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2018-02-23 09:54:25,048 : INFO : built Dictionary(253854 unique tokens: [u'biennials', u'tripolitan', u'mdbg', u'roadgear', u'vang']...) from 1701 documents (total 17005207 corpus positions)
2018-02-23 09:54:39,041 : INFO : using symmetric alpha at 0.01
2018-02-23 09:54:39,041 : INFO : using symmetric eta at 0.01
2018-02-23 09:54:39,070 : INFO : using serial LDA version on this node
2018-02-23 09:59:55,630 : INFO : running online (single-pass) LDA training, 100 topics, 1 passes over the supplied corpus of 1701 documents, updating model once every 1701 documents, evaluating perplexity every 1701 documents, iterating 50x with a convergence threshold of 0.001000
2018-02-23 09:59:55,630 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy
---------------------------------------------------------------------------
FloatingPointError                        Traceback (most recent call last)
<ipython-input-1-3fb5722fe654> in <module>()
     12 corpus = [id2word.doc2bow(t) for t in text]
     13 
---> 14 model = LdaModel(corpus=corpus, id2word=id2word, num_topics=100, dtype=np.float32)

/home/ivan/.virtualenvs/math/local/lib/python2.7/site-packages/gensim/models/ldamodel.pyc in __init__(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)
    396         if corpus is not None:
    397             use_numpy = self.dispatcher is not None
--> 398             self.update(corpus, chunks_as_numpy=use_numpy)
    399 
    400     def init_dir_prior(self, prior, name):

/home/ivan/.virtualenvs/math/local/lib/python2.7/site-packages/gensim/models/ldamodel.pyc in update(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)
    730 
    731                 if eval_every and ((reallen == lencorpus) or ((chunk_no + 1) % (eval_every * self.numworkers) == 0)):
--> 732                     self.log_perplexity(chunk, total_docs=lencorpus)
    733 
    734                 if self.dispatcher:

/home/ivan/.virtualenvs/math/local/lib/python2.7/site-packages/gensim/models/ldamodel.pyc in log_perplexity(self, chunk, total_docs)
    604         corpus_words = sum(cnt for document in chunk for _, cnt in document)
    605         subsample_ratio = 1.0 * total_docs / len(chunk)
--> 606         perwordbound = self.bound(chunk, subsample_ratio=subsample_ratio) / (subsample_ratio * corpus_words)
    607         logger.info(
    608             ""%.3f per-word bound, %.1f perplexity estimate based on a held-out corpus of %i documents with %i words"",

/home/ivan/.virtualenvs/math/local/lib/python2.7/site-packages/gensim/models/ldamodel.pyc in bound(self, corpus, gamma, subsample_ratio)
    842                 logger.debug(""bound: at document #%i"", d)
    843             if gamma is None:
--> 844                 gammad, _ = self.inference([doc])
    845             else:
    846                 gammad = gamma[d]

/home/ivan/.virtualenvs/math/local/lib/python2.7/site-packages/gensim/models/ldamodel.pyc in inference(self, chunk, collect_sstats)
    522                 gammad = self.alpha + expElogthetad * np.dot(cts / phinorm, expElogbetad.T)
    523                 Elogthetad = dirichlet_expectation(gammad)
--> 524                 expElogthetad = np.exp(Elogthetad)
    525                 phinorm = np.dot(expElogthetad, expElogbetad) + eps
    526                 # If gamma hasn't changed much, we're done.

FloatingPointError: underflow encountered in exp

```

#### Versions
```
OS: Linux-4.13.0-32-generic-x86_64-with-Ubuntu-17.10-artful
Python: 2.7.14 (default, Sep 23 2017, 22:06:14) [GCC 7.2.0]
NumPy: 1.14.0
SciPy: 1.0.0
gensim: 3.3.0
FAST_VERSION: 1
```
"
151,https://github.com/RaRe-Technologies/gensim/issues/1929,1929,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2018-02-24 14:32:23+00:00,,Make it possible for transform methods in sklearn_api to take a sparse matrix as an argument,"#### Description
`transform` methods of Transformers in a [sklearn_api  module](https://github.com/RaRe-Technologies/gensim/tree/develop/gensim/sklearn_api)  (such as [LdaTransformer](https://github.com/RaRe-Technologies/gensim/blob/72d4ff81b37720e287ae37958e138934fcdae7ac/gensim/sklearn_api/ldamodel.py#L75))  only takes a BOW list as an argument, not a numpy matrix.
It is not good in terms of scikit-learn API.

In `fit` methods, a sparse-matrix argument is converted into BOW by using matutils.Sparse2Corpus.

https://github.com/RaRe-Technologies/gensim/blob/72d4ff81b37720e287ae37958e138934fcdae7ac/gensim/sklearn_api/ldamodel.py#L61


I think it is better to make it possible for all the `transform` methods in sklearn_api to take both a BOW list and a sparse matrix as an argument like `fit` method.

"
152,https://github.com/RaRe-Technologies/gensim/issues/1936,1936,[],closed,2018-02-26 06:59:29+00:00,,Gensim's load fails to load a saved model ,"#### Description
I was trying to load fasttext embedding into Word2Vec. The load time is very slow. (10 mins). So I was trying out if saving and loading the model will be faster. However the load step is failing.


#### Steps/Code/Corpus to Reproduce
model_file = '/path/to/original'
saved_model = '/path/to/save'
model = gensim.models.KeyedVectors.load_word2vec_format(model_file)
model.save(saved_model)
model = Word2Vec.load(saved_model)


#### Actual Results
The load step fails with the following error.

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
~/.envs/dspy3/lib/python3.5/site-packages/gensim/models/word2vec.py in load(cls, *args, **kwargs)
    974         try:
--> 975             return super(Word2Vec, cls).load(*args, **kwargs)
    976         except AttributeError:

~/.envs/dspy3/lib/python3.5/site-packages/gensim/models/base_any2vec.py in load(cls, *args, **kwargs)
    629         model = super(BaseWordEmbeddingsModel, cls).load(*args, **kwargs)
--> 630         if model.negative and hasattr(model.wv, 'index2word'):
    631             model.vocabulary.make_cum_table(model.wv)  # rebuild cum_table from vocabulary

AttributeError: 'Word2VecKeyedVectors' object has no attribute 'negative'

During handling of the above exception, another exception occurred:

AttributeError                            Traceback (most recent call last)
<ipython-input-18-7af8ac3135e5> in <module>()
----> 1 model = LogExecTime(""LoadSaved"", LoadSaved)

<ipython-input-17-2402a78ca1d2> in LogExecTime(name, f, *args)
      7   start = time.time()
      8   print(""Starting {}"".format(name))
----> 9   ret = f(*args)
     10   print(""{} took {} secs"".format(name, time.time()-start))
     11   return ret

<ipython-input-17-2402a78ca1d2> in LoadSaved()
     23 def LoadSaved():
     24     saved_model = os.path.expanduser(""~/code/fb.fasttext/crawl-300d-2M.vec.gensim"")
---> 25     return Word2Vec.load(saved_model)
     26 
     27 

~/.envs/dspy3/lib/python3.5/site-packages/gensim/models/word2vec.py in load(cls, *args, **kwargs)
    977             logger.info('Model saved using code from earlier Gensim Version. Re-loading old model in a compatible way.')
    978             from gensim.models.deprecated.word2vec import load_old_word2vec
--> 979             return load_old_word2vec(*args, **kwargs)
    980 
    981 

~/.envs/dspy3/lib/python3.5/site-packages/gensim/models/deprecated/word2vec.py in load_old_word2vec(*args, **kwargs)
    151 
    152 def load_old_word2vec(*args, **kwargs):
--> 153     old_model = Word2Vec.load(*args, **kwargs)
    154     params = {
    155         'size': old_model.vector_size,

~/.envs/dspy3/lib/python3.5/site-packages/gensim/models/deprecated/word2vec.py in load(cls, *args, **kwargs)
   1614     @classmethod
   1615     def load(cls, *args, **kwargs):
-> 1616         model = super(Word2Vec, cls).load(*args, **kwargs)
   1617         # update older models
   1618         if hasattr(model, 'table'):

~/.envs/dspy3/lib/python3.5/site-packages/gensim/models/deprecated/old_saveload.py in load(cls, fname, mmap)
     85         compress, subname = SaveLoad._adapt_by_suffix(fname)
     86 
---> 87         obj = unpickle(fname)
     88         obj._load_specials(fname, mmap, compress, subname)
     89         logger.info(""loaded %s"", fname)

~/.envs/dspy3/lib/python3.5/site-packages/gensim/models/deprecated/old_saveload.py in unpickle(fname)
    378             b'gensim.models.wrappers.fasttext', b'gensim.models.deprecated.fasttext_wrapper')
    379         if sys.version_info > (3, 0):
--> 380             return _pickle.loads(file_bytes, encoding='latin1')
    381         else:
    382             return _pickle.loads(file_bytes)

AttributeError: Can't get attribute 'Word2VecKeyedVectors' on <module 'gensim.models.deprecated.keyedvectors' from '/Users/stps/.envs/dspy3/lib/python3.5/site-packages/gensim/models/deprecated/keyedvectors.py'>


Please paste or specifically describe the actual output or traceback. -->

#### Versions
Darwin-17.4.0-x86_64-i386-64bit
Python 3.5.2 (default, Jun 29 2016, 13:43:58)
[GCC 4.2.1 Compatible Apple LLVM 7.3.0 (clang-703.0.31)]
NumPy 1.14.1
SciPy 1.0.0
gensim 3.3.0
FAST_VERSION 0


"
153,https://github.com/RaRe-Technologies/gensim/issues/1937,1937,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2018-02-27 12:05:07+00:00,,sklearn_api.d2vmodel.D2VTransformer uses deprecated arguments size and iter,"#### Description
The D2VTransformer in `sklearn_api.d2vmodel` uses the deprecated arguments `size` instead of `vector_size` and `iter` instead of `epochs`. According to the warnings this will be breaking in version 4.0.0.

#### Code to Reproduce
```
from gensim.sklearn_api.d2vmodel import D2VTransformer
from gensim.models.doc2vec import TaggedDocument
d2v = D2VTransformer(size=1, iter=1).fit([TaggedDocument(['a','a','a','a','a'], [0])]) # gives warnings
d2v = D2VTransformer(vector_size=1, epochs=1).fit([TaggedDocument(['a','a','a','a','a'], [0])]) #gives errors
```

#### Resulting warnings and errors:
```
/lib/python3.6/site-packages/gensim/models/doc2vec.py:355: UserWarning: The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.
  warnings.warn(""The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead."")
/lib/python3.6/site-packages/gensim/models/doc2vec.py:359: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.
  warnings.warn(""The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead."")
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-108-561949d569bd> in <module>()
      2 from gensim.models.doc2vec import TaggedDocument
      3 d2v = D2VTransformer(size=1, iter=1).fit([TaggedDocument(['a','a','a','a','a'], [0])])
----> 4 d2v = D2VTransformer(vector_size=1, epochs=1).fit([TaggedDocument(['a','a','a','a','a'], [0])])

TypeError: __init__() got an unexpected keyword argument 'vector_size'
```

#### Versions
```
Linux-4.13.0-36-generic-x86_64-with-Ubuntu-17.10-artful
Python 3.6.3 (default, Oct  3 2017, 21:45:48) 
[GCC 7.2.0]
NumPy 1.14.1
SciPy 1.0.0
gensim 3.3.0
FAST_VERSION 1
```
"
154,https://github.com/RaRe-Technologies/gensim/issues/1938,1938,"[{'id': 175642, 'node_id': 'MDU6TGFiZWwxNzU2NDI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/wishlist', 'name': 'wishlist', 'color': 'd7e102', 'default': False, 'description': 'Feature request'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",open,2018-02-27 14:41:20+00:00,,dictionnary.filter_extremes with no_above = 1 still filter words that appear in every documents.,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
[`filter_extremes`](https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.filter_extremes) when `no_above = 1` still filters the words that appear at least one time in all the documents. It should filter no word at all (that means replacing a ""greater or equal"" with a ""strictly greater"" somewhere).

"
155,https://github.com/RaRe-Technologies/gensim/issues/1940,1940,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2018-02-28 05:24:26+00:00,,"FastText native VS original, different outputs","## Intro

As the person mentioned in [mailing list](https://groups.google.com/forum/#!topic/gensim/zPp8vr4n8pI), he receives different result with a pre-trained model with gensim code & original facebook code.

## How to reproduce
1. Install Facebook FastText
    ```bash
    wget https://github.com/facebookresearch/fastText/archive/v0.1.0.zip
    unzip v0.1.0.zip
    cd fastText-0.1.0
    make
    ```
2. Download pre-trained vectors from https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md (I pick english, only as example), you need `bin+text` link
3. Unpack archive with vectors
4. Try to retreive vectors with gensim
    ```python
    from gensim.models import FastText

    m = FastText.load_fasttext_format(""wiki.en.vec"")
    print(m[""hello""])  # existent word
    print(m[""someundefinedword""])  # non-existent word
5. Repeat it with original FastText implementation
    ```bash
    ./fasttext  print-word-vectors ../wiki.en.bin
    hello
    someundefinedword
    ```
6. Compare vectors from (5) and (6)

### Expected Results
Vectors for ""hello"" and ""someundefinedword"" exactly same (from gensim & Facebook)

### Actual result
Exactly same vectors for ""hello"", but different for ""someundefinedword""

CC: @manneshiva
"
156,https://github.com/RaRe-Technologies/gensim/issues/1941,1941,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-02-28 12:41:56+00:00,,IndexError when passing in num_features into MatrixSimilarity,"#### Description
Receiving error `IndexError: index 101 is out of bounds for axis 1 with size 100` when passing in number of features into gensim.similarities.docsim.MatrixSimilarity(model_tf_idf[model_corpus], num_features=100)`
`

#### Error
```
Traceback (most recent call last):
  File ""~~~~~~~~~~~~~~~~.py"", line 14, in <module>
    sims = gensim.similarities.docsim.MatrixSimilarity(model_tf_idf[model_corpus], num_features=100)
  File ""~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~/env/lib/python3.6/site-packages/gensim/similarities/docsim.py"", line 523, in __init__
    vector = matutils.unitvec(matutils.sparse2full(vector, num_features))
  File ""/~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~/env/lib/python3.6/site-packages/gensim/matutils.py"", line 395, in sparse2full
    result[list(doc)] = list(itervalues(doc))
IndexError: index 101 is out of bounds for axis 1 with size 100
```"
157,https://github.com/RaRe-Technologies/gensim/issues/1942,1942,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2018-02-28 15:16:17+00:00,,Make add_word part of keyedvectors.py interface,"Hi, I think it would be very useful to define `add_word` inside the class instead of inside the `load` function in [keyedvectors](https://github.com/RaRe-Technologies/gensim/blob/7127eeef8304852da589465b338e2bba14e881f1/gensim/models/keyedvectors.py).

Thanks ✌🏻"
158,https://github.com/RaRe-Technologies/gensim/issues/1943,1943,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-02-28 15:31:33+00:00,,[IndexError],"Hi all,
I built a huge model (254Mb + 2x2Gb npy) and everything work fine.
However, when entering the term ""matrix"" in the model to query the top similar concept, it raises the following error.

> 
> Enter: matrix
> Traceback (most recent call last):
>   File ""rapid_query.py"", line 43, in <module>
>     top_close = model.most_similar(positive=word, topn=3)
>   File ""/home/VENV/lib/python3.5/site-packages/gensim/utils.py"", line 1368, in new_func1
>     return func(*args, **kwargs)
>   File ""/home/VENV/lib/python3.5/site-packages/gensim/models/base_any2vec.py"", line 696, in most_similar
>     return self.wv.most_similar(positive, negative, topn, restrict_vocab, indexer)
>   File ""/home/VENV/lib/python3.5/site-packages/gensim/models/keyedvectors.py"", line 376, in most_similar
>     result = [(self.index2word[sim], float(dists[sim])) for sim in best if sim not in all_words]
>   File ""/home/VENV/lib/python3.5/site-packages/gensim/models/keyedvectors.py"", line 376, in <listcomp>
>     result = [(self.index2word[sim], float(dists[sim])) for sim in best if sim not in all_words]
> IndexError: list index out of range

I trie to go to the code see what's going wrong, but could not find why in 

`result = [(self.index2word[sim], float(dists[sim])) for sim in best if sim not in all_words]`


"
159,https://github.com/RaRe-Technologies/gensim/issues/1946,1946,[],closed,2018-03-01 20:45:18+00:00,,scripts.segment_wiki invalid argument,"#### Description
segment_wiki.py: error: unrecognized arguments: -i

```
python -m gensim.scripts.segment_wiki -i -f enwiki-latest-pages-articles.xml.bz2 -o enwiki-latest.json.gz
2018-03-01 17:40:37,055 : MainProcess : INFO : running /home/marco/miniconda2/envs/mrturing/lib/python2.7/site-packages/gensim/scripts/segment_wiki.py -i -f enwiki-latest-pages-articles.xml.bz2 -o enwiki-latest.json.gz
usage: segment_wiki.py [-h] -f FILE [-o OUTPUT] [-m MIN_ARTICLE_CHARACTER]
segment_wiki.py: error: unrecognized arguments: -i

```

#### My output versions:

>>> import platform; print(platform.platform())
Linux-4.13.0-36-generic-x86_64-with-debian-stretch-sid
>>> import sys; print(""Python"", sys.version)
('Python', '2.7.14 |Anaconda, Inc.| (default, Dec  7 2017, 17:05:42) \n[GCC 7.2.0]')
>>> import numpy; print(""NumPy"", numpy.__version__)
('NumPy', '1.13.3')
>>> import scipy; print(""SciPy"", scipy.__version__)
('SciPy', '1.0.0')
>>> import gensim; print(""gensim"", gensim.__version__)
('gensim', '3.1.0')
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
('FAST_VERSION', 1)
>>> 

"
160,https://github.com/RaRe-Technologies/gensim/issues/1947,1947,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 708430967, 'node_id': 'MDU6TGFiZWw3MDg0MzA5Njc=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/performance', 'name': 'performance', 'color': 'd93f0b', 'default': False, 'description': 'Issue related to performance (in HW meaning)'}]",open,2018-03-02 10:00:23+00:00,,AuthorTopicModel memory issue,"### Intro

Recently, I often get negative feedback about ATM.
Еhe main reason is memory issues (too much memory consuming), related mailing list threads (latest):
- https://groups.google.com/forum/#!searchin/gensim/author|sort:date/gensim/gG7aiNI1v-Y/SWPMuP8BAwAJ
- https://groups.google.com/forum/#!topic/gensim/wI3x1fqR5wk

I decided to figure out what was going on.

### Investigation

I run ATM based on data provided by the author of https://groups.google.com/forum/#!searchin/gensim/author|sort:date/gensim/gG7aiNI1v-Y/SWPMuP8BAwAJ (so far I can't publish it right now, I'm waiting for permission from its owner).

Basic stats of data:
- Size of dictionary: 12211
- Size of `author2doc` mapping: 106133
- Size of `author2doc` mapping: 73248

I run it with a debugger and found that **hugest** memory-consuming happens here:
https://github.com/RaRe-Technologies/gensim/blob/f9669bb8a0b5b4b45fa8ff58d951a11d3178116d/gensim/models/atmodel.py#L680-L684

I stop it when process already consume **8GB** of RAM, some useful statistics presented in table

| expr | value | comment |
|--------|---------|-------------|
|`len(author2doc.keys())`|106133 | |
|`author2doc.keys().index(_)`|3649| index of current processed element,  i.e. 3649 of 106133 (~3% of the total volume)  |
|`len(train_corpus_idx) ` | 1119955735 | `train_corpus_idx` is hugest memory consumer. Here, we essentially **load the whole corpus into memory** (and this **isn't ""online"" or ""batch""** processing) |

By simple calculations, when the cycle will be done, the **process will consume `~232GB of RAM`**.
This is definitely unacceptable and doesn't allow to use model even for some learning tasks (I'm not even talking about ""real"" tasks).

@olavurmortensen can you look into this problem, this is **supercritical**?

Related PR - #893."
161,https://github.com/RaRe-Technologies/gensim/issues/1948,1948,[],closed,2018-03-03 20:45:19+00:00,,_pickle.PicklingError,"The gensim test cannot passed.

```python
$python setup.py test
[snip]
test_show_topics (gensim.test.test_ldamodel.TestLdaModel) ... ok
testAlpha (gensim.test.test_ldamodel.TestLdaMulticore) ... Traceback (most recent call last):
  File ""/home/reon/.anaconda3/lib/python3.6/multiprocessing/queues.py"", line 234, in _feed
    obj = _ForkingPickler.dumps(obj)
  File ""/home/reon/.anaconda3/lib/python3.6/multiprocessing/reduction.py"", line 51, in dumps
    cls(buf, protocol).dump(obj)
_pickle.PicklingError: Can't pickle <function __RandomState_ctor at 0x7f067f57b1e0>: it's not the same object as numpy.random.__RandomState_ctor
```

#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->
Linux-4.4.0-116-generic-x86_64-with-debian-stretch-sid
Python 3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19)
[GCC 7.2.0]
NumPy 1.14.1
SciPy 1.0.0
gensim 3.4.0
FAST_VERSION 1


<!-- Thanks for contributing! -->

"
162,https://github.com/RaRe-Technologies/gensim/issues/1951,1951,[],closed,2018-03-04 20:58:28+00:00,,AttributeError: 'ConcatenatedDoc2Vec' object has no attribute 'save',"I have trained the doc2vec model models_by_name['dbow+dmm'].

I have made predictions with it an I am satisfied with its performance.

I want it to persist. I tried to save it with the command below.

models_by_name['dbow+dmm'].save('dbow+dmm.doc2vec')

I got the following wrror message.

AttributeError                            Traceback (most recent call last)
<ipython-input-178-0cf08eda641e> in <module>()
----> 1 models_by_name['dbow+dmm'].save('dbow+dmm.doc2vec')
      2 # model = Doc2Vec.load(fname)  # you can continue training with the loaded model!

AttributeError: 'ConcatenatedDoc2Vec' object has no attribute 'save'

How do I save a 'ConcatenatedDoc2Vec' doc2vec model?

Thanks!"
163,https://github.com/RaRe-Technologies/gensim/issues/1952,1952,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2018-03-05 04:47:12+00:00,,AttributeError: 'DocvecsArray' object has no attribute 'vector_size',"I have Doc2Vec models that were trained and saved before the Re-design ""*2vec"" implementations #1777 commit (specifically, they were trained in v3.2) . On trying to use them today, the above attribute error was raised when I tried to use `infer_vector`. This is because in gensim/models/doc2vec.py"", line 543, in infer_vector the line:

```doctag_vectors, doctag_locks = self.trainables.get_doctag_trainables(doc_words, self.docvecs.vector_size)```

Attempts to access `self.docvecs.vector_size`, which before version 3.4.0 is not an attribute of the DocVecsArray class.

#### Steps to Reproduce
```
from gensim.models import Doc2Vec

model = Doc2Vec.load('some-3.2-model/model')
model.infer_vector(['foo'])

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-13-851ff3602fcf> in <module>()
----> 1 model.infer_vector(['foo'])

~/anaconda2/envs/faker/lib/python3.6/site-packages/gensim/models/doc2vec.py in infer_vector(self, doc_words, alpha, min_alpha, steps)
    541 
    542         """"""
--> 543         doctag_vectors, doctag_locks = self.trainables.get_doctag_trainables(doc_words, self.docvecs.vector_size)
    544         doctag_indexes = [0]
    545         work = zeros(self.trainables.layer1_size, dtype=REAL)

AttributeError: 'DocvecsArray' object has no attribute 'vector_size'
```"
164,https://github.com/RaRe-Technologies/gensim/issues/1953,1953,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2018-03-05 06:48:12+00:00,,Support for OOV words using only word-vectors,"## Intro
The heavy limitation of word-vectors (Word2Vec, GloVe, etc) is ""fix"" vocab, i.e. if you have no word `""someword""` in the vocab of model - you have no vector for it. 
This situation fixed for character n-gram embedding models like FastText, but we already have many pretty nice word-embeddings model that trained on large corpora and show exciting results on the bench.

This will be really nice to construct a vector for OOV words to (based on some pre-trained word-vectors).

## Algorithm
The pretty nice algorithm presented in https://github.com/plasticityai/magnitude package (more information about the feature: https://github.com/plasticityai/magnitude#basic-out-of-vocabulary-keys and https://github.com/plasticityai/magnitude#advanced-out-of-vocabulary-keys)

Some piece of pseudo-code for demonstration, how this works
```python
import numpy as np

emb_dim = 300
oov_word = 'catsq'
random_vectors = []

for ngram in char_ngrams(oov_word):
    np.random.seed(seed=ngram)
     # why? some ""precision"" reasons?
    random_vectors.append((np.random.rand(emb_dim) * 2.0) - 1.0)

random_vectors = np.mean(random_vectors, axis=0)
random_vector = random_vector / np.linalg.norm(random_vector)


# _db_query_similar_keys_vector some kind of ""text search"" between ngrams & existent words in model
# This is the hardest part here, how to make it fast enough

final_vector = (random_vector * 0.3 + self._db_query_similar_keys_vector(key, oov_word) * 0.7)  
final_vector = final_vector / np.linalg.norm(final_vector)
```

## Discussion
Can you answer my questions in comments (`#` in code) and describe in details, how `_db_query_similar_keys_vector` works @AjayP13?
"
165,https://github.com/RaRe-Technologies/gensim/issues/1955,1955,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2018-03-05 18:39:00+00:00,,SoftCosineSimilarity: Unexpected Behavior for Query Input,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
Expected SoftCosineSimilarity self[query] syntax to accept any iterable of list of (int, number) as indicated by: https://github.com/RaRe-Technologies/gensim/blob/f9669bb8a0b5b4b45fa8ff58d951a11d3178116d/gensim/similarities/docsim.py#L925

#### Steps/Code/Corpus to Reproduce
```
import scipy as sp
import gensim

# import the common_corpus as a TextCorpus object
# We assume common_corpus is a text file containing the lines:
#
# Human machine interface for lab abc computer applications
# A survey of user opinion of computer system response time
# The EPS user interface management system
# System and human system engineering testing of EPS
# Relation of user perceived response time to error measurement
# The generation of random binary unordered trees
# The intersection graph of paths in trees
# Graph minors IV Widths of trees and well quasi ordering
# Graph minors A survey

corpus = gensim.corpora.TextCorpus(input=""path/common_corpus"")
tfidf = gensim.models.TfidfModel(
    corpus, id2word=corpus.dictionary, normalize=True)

# Behavior of MatrixSimilarity
cos_index = gensim.similarities.MatrixSimilarity(tfidf[corpus])
cos_index[tfidf[corpus]]  # :)

# Behavior of SoftCosineSimilarity
dim = len(corpus.dictionary)
M = sp.sparse.identity(dim).tocsc() # generate the identity matrix
softcos_index = gensim.similarities.SoftCosineSimilarity(tfidf[corpus], M)
softcos_index[tfidf[corpus]] # :(
softcos_index[tfidf[[bow for bow in corpus]]] # :|
softcos_index[[vec for vec in tfidf[corpus]]] # :|
```


#### Expected Results
I believe that the TransformedCorpus tfidf[corpus] is an iterable of list of (int, number):
```
In [248]: next(iter(tfidf[corpus]))
Out[248]:
[(0, 0.4500498962785324),
 (1, 0.4500498962785324),
 (2, 0.3080749612015952),
 (3, 0.3080749612015952),
 (4, 0.4500498962785324),
 (5, 0.4500498962785324)]
```
I would expect that to be taken as query input without incident. It seems that SoftCosineSimilarity was adapted from a copy of MatrixSimilarity and was meant to function in a similar spirit, however, they do not accept the same types of input. 

#### Actual Results
```
In [249]: softcos_index[tfidf[corpus]]
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-249-2d8c4d759cc9> in <module>()
----> 1 softcos_index[tfidf[corpus]]

/Users/natalied/Projects/canonical_answers/.venv/lib/python2.7/site-packages/gensim/interfaces.pyc in __getitem__(self, query)
    365                 else:
    366                     query = matutils.unitvec(query)
--> 367         result = self.get_similarities(query)
    368
    369         if self.num_best is None:

/Users/natalied/Projects/canonical_answers/.venv/lib/python2.7/site-packages/gensim/similarities/docsim.pyc in get_similarities(self, query)
    936             query = [self.corpus[i] for i in query]
    937
--> 938         if not query or not isinstance(query[0], list):
    939             query = [query]
    940

/Users/natalied/Projects/canonical_answers/.venv/lib/python2.7/site-packages/gensim/interfaces.pyc in __getitem__(self, docno)
    215             return self.obj[self.corpus[docno]]
    216         else:
--> 217             raise RuntimeError('Type {} does not support slicing.'.format(type(self.corpus)))
    218
    219

RuntimeError: Type <class 'gensim.corpora.textcorpus.TextCorpus'> does not support slicing.
```

#### Possible Code Involved
Compare the MatrixSimilarity get_similarities method: 
https://github.com/RaRe-Technologies/gensim/blob/f9669bb8a0b5b4b45fa8ff58d951a11d3178116d/gensim/similarities/docsim.py#L825
with the SoftCosineSimilarity get_similarities method:
https://github.com/RaRe-Technologies/gensim/blob/f9669bb8a0b5b4b45fa8ff58d951a11d3178116d/gensim/similarities/docsim.py#L938

Also we may need to expand this test: 
https://github.com/RaRe-Technologies/gensim/blob/f9669bb8a0b5b4b45fa8ff58d951a11d3178116d/gensim/test/test_similarities.py#L377

#### Versions
```
Darwin-15.6.0-x86_64-i386-64bit
('Python', '2.7.13 (default, Apr  4 2017, 08:46:44) \n[GCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.42.1)]')
('NumPy', '1.14.1')
('SciPy', '1.0.0')
('gensim', '3.4.0')
('FAST_VERSION', 0)
```


<!-- Thanks for contributing! -->

"
166,https://github.com/RaRe-Technologies/gensim/issues/1956,1956,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-03-06 11:19:02+00:00,,"ValueError: You must specify either total_examples or total_words, for proper alpha and progress calculations. The usual value is total_examples=model.corpus_count.","I am trying to train a doc2vec model using gensim but i get some confusing errors. i get teh above error when i use this line in a for loop to train:
    model.train(it, epochs=model.iter, total_examples=model.corpus_count)

"
167,https://github.com/RaRe-Technologies/gensim/issues/1958,1958,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2018-03-07 09:33:25+00:00,,"gensim.scripts.word2vec2tensor TypeError: write() argument must be str, not bytes ","Python environment

```
Python 3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) 
[GCC 7.2.0] on linux
```


**How I make article_body_w2v_300.txt**  

```
import gensim
from gensim.models import Word2Vec
from gensim.models.word2vec import LineSentence

sentences = LineSentence(""./data/article_body_corpus.txt"")

model = Word2Vec(sentences, size=300, window=5, min_count=5, workers=4)

model.wv.save_word2vec_format(""article_body_w2v_300.txt"", binary=False)
```


**Command I use to run gensim.scripts.word2vec2tensor** 

```
python -m gensim.scripts.word2vec2tensor -i article_body_w2v_300.txt -o meow/
```

Console output
```
word_embedding  python -m gensim.scripts.word2vec2tensor -i article_body_w2v_300.txt -o meow/
2018-03-07 16:30:29,484 - word2vec2tensor - INFO - running /home/cpu11453local/anaconda3/envs/gensim/lib/python3.6/site-packages/gensim/scripts/word2vec2tensor.py -i article_body_w2v_300.txt -o meow/
2018-03-07 16:30:29,484 - utils_any2vec - INFO - loading projection weights from article_body_w2v_300.txt
2018-03-07 16:30:41,992 - utils_any2vec - INFO - loaded (56543, 300) matrix from article_body_w2v_300.txt
Traceback (most recent call last):
  File ""/home/cpu11453local/anaconda3/envs/gensim/lib/python3.6/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/home/cpu11453local/anaconda3/envs/gensim/lib/python3.6/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/cpu11453local/anaconda3/envs/gensim/lib/python3.6/site-packages/gensim/scripts/word2vec2tensor.py"", line 93, in <module>
    word2vec2tensor(args.input, args.output, args.binary)
  File ""/home/cpu11453local/anaconda3/envs/gensim/lib/python3.6/site-packages/gensim/scripts/word2vec2tensor.py"", line 73, in word2vec2tensor
    file_metadata.write(gensim.utils.to_utf8(word) + gensim.utils.to_utf8('\n'))
TypeError: write() argument must be str, not bytes

```"
168,https://github.com/RaRe-Technologies/gensim/issues/1960,1960,"[{'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2018-03-07 18:00:04+00:00,,similarity_matrix: suspicous column indexing logic when tfidf model supplied,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
Expected gensim.models.keyedvectors WordEmbeddingsKeyedVectors property similarity_matrix to respect the reordering of terms dictated by a supplied tfidf model. This does not seem to be the case.  

#### Steps/Code/Corpus to Reproduce
This will be an unconventional bug report because I did not find this bug ""in the wild"".  In adapting the code for another purpose, I noticed some logic which might be problematic. I will 

- point out where I think the mistake lies in the original context
- show what corrected the problem in my context
- provide the test case that demonstrates correctness in my context 

##### Original Context: 

https://github.com/RaRe-Technologies/gensim/blob/f9669bb8a0b5b4b45fa8ff58d951a11d3178116d/gensim/models/keyedvectors.py#L516
```
        for row_number, w1_index in enumerate(word_indices):
            ...
            w1 = dictionary[w1_index]
            ...
            # Traverse upper triangle columns.
            if matrix_order <= nonzero_limit + 1:  # Traverse all columns.
                columns = (
                    (w2_index, self.similarity(w1, dictionary[w2_index]))
                    for w2_index in range(w1_index + 1, matrix_order)
                    if w1_index != w2_index and dictionary[w2_index] in self.vocab)
            ...
            for w2_index, similarity in columns:
                # Ensure that we don't exceed `nonzero_limit` by mirroring the upper triangle.
                if similarity > threshold and matrix_nonzero[w2_index] <= nonzero_limit:
                    element = similarity**exponent
                    matrix[w1_index, w2_index] = element
                    matrix_nonzero[w1_index] += 1
                    matrix[w2_index, w1_index] = element
                    matrix_nonzero[w2_index] += 1
```
A red flag for me was that while we consider the ""word_indices"" mapping for the row index, we are never considering it for the column index. Even in the case of rows, notice that we are filling ""matrix"" at the end without regard for the reordering that was supposed to have occurred. 

##### A Correction in Levenshtein Context: 

```
for row_number, w1_index in enumerate(word_indices):
...
    # Traverse upper triangle columns.
    # TODO: determine community preference for pylev.levenshtein or distance.levenshtein
    import pylev
    columns = []
    for col_number in range(row_number + 1, matrix_order):
        if row_number != col_number:
            w2_index = word_indices[col_number]
            w1 = dictionary[w1_index]
            w2 = dictionary[w2_index]
            similarity = pylev.levenshtein(w1, w2)/\
                         float(max(len(w1), len(w2)))
            columns.append((col_number, similarity))

    for col_number, similarity in columns:
        element = alpha * (1 - similarity) ** beta
        matrix[row_number, col_number] = element
        matrix[col_number, row_number] = element
```

##### Test Case
Consider the mini corpus:
```
mini_texts = [['abc'], ['lab', 'abc'], ['bad', 'abc']]
mini_dict = gensim.corpora.Dictionary(mini_texts)
mini_corpus = [mini_dict.doc2bow(text) for text in mini_texts]
mini_tfidf = gensim.models.TfidfModel(mini_corpus)
```
- The default ordering of terms is in order of appearance: 'abc', 'lab', 'bad'. 
- The Levenshtein similarity matrix returned without supplying tfidf will be: 
 ```
matrix([[1.        , 0.00740741, 0.        ],
        [0.00740741, 1.        , 0.00740741],
        [0.        , 0.00740741, 1.        ]], dtype=float32)


```

However, since 'abc' appears in every document, the tfidf coefficient will be zero. The ordering with respect to the tfidf weight will be: 'lab', 'bad', 'abc'. The default Levenshtein similarity scores are pretty symmetric, there are some reorderings for which the matrix will be the same. However, this example is contrived to so that the tfidf reordering will break the symmetry of the original Levenshtein similarity scores: 

```
matrix([[1.        , 0.00740741, 0.00740741],
        [0.00740741, 1.        , 0.        ],
        [0.00740741, 0.        , 1.        ]], dtype=float32)

```
We see that the revised logic correctly returns the reordered scores. The original logic returned the first matrix when the tfidf model was supplied to the function. A test case for the similarity_matrix function would need to be constructed so that a reordering of terms would lead to a definitive reordering of the relevant scores in the resulting matrix. 

#### Conclusion
While I have not taken the time to prove definitively that there is a bug in the original context, a unit test should be written to cover the case of a supplied tfidf reordering the terms in similarity_matrix. This is a high-risk piece of logic. If there is a bug, and a supplied tfidf isn't being incorporated properly, eventually SoftCosineSimilarity will return nonsense scores when fed documents transformed by the same tfidf model.  

#### Relevant Code
similarity_matrix: 
https://github.com/RaRe-Technologies/gensim/blob/f9669bb8a0b5b4b45fa8ff58d951a11d3178116d/gensim/models/keyedvectors.py#L440

existing unit tests: 
https://github.com/RaRe-Technologies/gensim/blob/f9669bb8a0b5b4b45fa8ff58d951a11d3178116d/gensim/test/test_keyedvectors.py#L30

See also related: #1961 
#### Versions
Darwin-15.6.0-x86_64-i386-64bit
('Python', '2.7.13 (default, Apr  4 2017, 08:46:44) \n[GCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.42.1)]')
('NumPy', '1.14.1')
('SciPy', '1.0.0')
('gensim', '3.4.0')
('FAST_VERSION', 0)


<!-- Thanks for contributing! -->

"
169,https://github.com/RaRe-Technologies/gensim/issues/1961,1961,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2018-03-07 18:16:14+00:00,,similarity_matrix: unit tests not run,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
The unit tests for the gensim.models.keyedvectors similarity_matrix cannot currently be found and are not being run.

https://github.com/RaRe-Technologies/gensim/blob/f9669bb8a0b5b4b45fa8ff58d951a11d3178116d/gensim/test/test_keyedvectors.py#L30

Fix is underway: 
https://github.com/nataliedurgin/gensim/commit/5bb6aea3a92b8e7ff7cecfca054a6057bb9b8fa8


<!-- Thanks for contributing! -->

"
170,https://github.com/RaRe-Technologies/gensim/issues/1964,1964,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}]",open,2018-03-08 12:40:09+00:00,,Improving Tutorials,"#### Documentation in general
In general, a well written and maintained documentation can be divided into 4 concrete elements as explained in this [talk](https://www.youtube.com/watch?v=azf6yzuJt54&feature=youtu.be&list=PLBQrpodM6rL-LDUw_gTZKhpYOidQXJNQe):
1. Reference
2. Discussions
3. Tutorials
4. How to Guides

**1** in our case is achieved with the docstrings and the Sphinx building the html content from them. 
We already have a strong base reference and multiple people are working on increasing coverage (myself included).

Regarding **2**, we already have gitter, mailing lists and issue specific discussions in the GitHub issues and Pull Requests pages. 

We have some overlap between **3 and 4** since we use jupyter notebooks for both but it is not very clear which notebook is a tutorial or a guide. For example I would say the `sklearn_api` notebooks are tutorials because they only show the basics (holding the user by the hand), while the model specific notebooks like `word2vec IMDB/Wikipedia` are more like guides because they solve a very specific problem. Perhaps we need to split them into two categories (folders) named `tutorials` and `guides`.

#### The problem
Its extremely important that the tutorials run **always** (new releases do not break the notebooks) and **everywhere** (the tutorial will run on every OS, python version or distribution etc.). This is very hard to guarantee at the moment.

#### Solution
We need to test the notebooks. By testing I mean make sure all cells run and not raise any error. (*Can we also test for exact outputs?*)
Most google results show bad solutions but these two seem promising (although a bit hacky):
* https://gist.github.com/lheagy/f216db7220713329eb3fc1c2cd3c7826
* https://blog.thedataincubator.com/2016/06/testing-jupyter-notebooks/
		  
**Advantages**
* Probably less work than the alternative
* No additional dependencies
		  
**Disadvantages**
* Seems a bit hacky to me (@menshikh-iv thoughts?)
* These tests will make sure that no error was raised but will say nothing about the correctness of results. We could put assertions in the notebooks to make sure they raise, but this will make the notebooks look ugly. 
* The notebooks are not automatically converted to `rst`s trivially, we therefore end up dealing with 2 ""sources of truth"" : the official [doc page](https://radimrehurek.com/gensim/tutorial.html) and the notebooks themselves.

#### Alternative
As we discussed with @menshikh-iv, maybe we should migrate from notebooks to [Sphinx gallery](https://github.com/sphinx-gallery/sphinx-gallery). Using this approach our tutorials are Python scripts.
 
**Advantages**
* The tutorials are python files rather than .ipynb files.
* We can generate the documentation `rst`s directly. This ensures that there is a single source of truth and that new notebooks can be trivially added to the online documentation.
			 
**Disadvantages**
* Requires new dependencies that have to do with plotting because this is mostly a plotting framework.
* Will take more time to implement since I need to get familiar with it.
 * It is not entirely obvious to me how we will be testing it.		  
<!-- Example: Expected shape of (100,2).-->

#### Extra thoughts
Could we also add visualizations in tutorials? This is easy using both alternatives but I am not sure if we can come up with meaningful graphs."
171,https://github.com/RaRe-Technologies/gensim/issues/1965,1965,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 175642, 'node_id': 'MDU6TGFiZWwxNzU2NDI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/wishlist', 'name': 'wishlist', 'color': 'd7e102', 'default': False, 'description': 'Feature request'}, {'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}]",open,2018-03-08 18:52:24+00:00,,Faster SVD using sampling & GPU,"This looks like an interesting algo, exploring the use of sampling and GPU to compute truncated SVD (~LSI) quickly:

*Sampling Algorithms to Update Truncated SVD. 2017. Yamazaki, I., S. Tomov, and J. Dongarra.*
 [PDF](http://icl.cs.utk.edu/projectsfiles/magma/pubs/70-bd17.pdf)

The core algorithm is similar to what we already have in Gensim (randomized) and expands on it. SVD is such a core algo across all statistics/ML that I think it's worth optimizing our (already fast) implementation further. Especially the BLAS-3 GPU variant looks exciting."
172,https://github.com/RaRe-Technologies/gensim/issues/1967,1967,[],closed,2018-03-09 02:58:35+00:00,,"Need documentation about word2vec ""# you can continue training with the loaded model!""","In documentation [models.word2vec](https://radimrehurek.com/gensim/models/word2vec.html), it said 
`model = Word2Vec.load(fname)  # you can continue training with the loaded model!`

However, I did not see any official document (with example) about this. 

There are a question on [stackoverflow](https://stackoverflow.com/questions/48443999/gensim-word2vec-continue-training-on-existing-model-attributeerror-word2ve/49185832#49185832)

```
# training_data: initial training data. contain list of tokenized sentences
model = Word2Vec(training_data, size=50, window=5, min_count=10, workers=4)
```

However, no matter what I put in total_examples, it worked (no error shown)  but I am not sure if it work correctly. 

As stackoverflow answer 

```
# datasmall: more sentences
# total_examples: number of additional sentence
# epochs: provide your current epochs. model.epochs is ok 
model.train(datasmall, total_examples=len(datasmall), epochs=model.epochs)
```

OR as doc in [word2vec.py](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/word2vec.py)

`model.train(datasmall, total_examples=model.corpus_count, epochs=model.epochs)`"
173,https://github.com/RaRe-Technologies/gensim/issues/1969,1969,[],closed,2018-03-09 22:45:18+00:00,,How to adapt gensim.corpora.wikicorpus to work with full Wikipedia revision history?,"I am interested in using doc2vec to study Wikipedia revisions on a per-article and per-author basis.  According to [the docs](https://radimrehurek.com/gensim/corpora/wikicorpus.html#gensim.corpora.wikicorpus.WikiCorpus), Wikicorpus() only supports these dump formats:

> <LANG>wiki-<YYYYMMDD>-pages-articles.xml.bz2
><LANG>wiki-latest-pages-articles.xml.bz2

Is it possible to adapt your code to work with `pages-meta-history.xml.bz2` files?"
174,https://github.com/RaRe-Technologies/gensim/issues/1970,1970,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-03-10 00:44:35+00:00,,Why i can't load model on Python 3.6 version?,"I have problem with loading model on Python 3.6 version:

> Traceback (most recent call last):
  File ""/Users/szymon/anaconda3/lib/python3.6/site-packages/gensim/models/word2vec.py"", line 975, in load
    return super(Word2Vec, cls).load(*args, **kwargs)
  File ""/Users/szymon/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py"", line 629, in load
    model = super(BaseWordEmbeddingsModel, cls).load(*args, **kwargs)
  File ""/Users/szymon/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py"", line 278, in load
    return super(BaseAny2VecModel, cls).load(fname_or_handle, **kwargs)
  File ""/Users/szymon/anaconda3/lib/python3.6/site-packages/gensim/utils.py"", line 426, in load
    obj._load_specials(fname, mmap, compress, subname)
  File ""/Users/szymon/anaconda3/lib/python3.6/site-packages/gensim/utils.py"", line 469, in _load_specials
    setattr(self, attrib, val)
  File ""/Users/szymon/anaconda3/lib/python3.6/site-packages/gensim/utils.py"", line 1398, in new_func1
    return func(*args, **kwargs)
  File ""/Users/szymon/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py"", line 380, in syn1neg
    self.trainables.syn1neg = value
AttributeError: 'Word2Vec' object has no attribute 'trainables'

> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""/Users/szymon/PycharmProjects/sentimentpl/workingLSTM.py"", line 57, in <module>
>     word2vec_model = Word2Vec.load('w2v_allwiki_nkjpfull_50.model')
>   File ""/Users/szymon/anaconda3/lib/python3.6/site-packages/gensim/models/word2vec.py"", line 979, in load
>     return load_old_word2vec(*args, **kwargs)
>   File ""/Users/szymon/anaconda3/lib/python3.6/site-packages/gensim/models/deprecated/word2vec.py"", line 195, in load_old_word2vec
>     new_model.min_alpha_yet_reached = old_model.min_alpha_yet_reached
> AttributeError: 'Word2Vec' object has no attribute 'min_alpha_yet_reached'

On Python 3.5 it's all correct."
175,https://github.com/RaRe-Technologies/gensim/issues/1973,1973,[],closed,2018-03-11 08:35:54+00:00,,"TypeError: doc2bow expects an array of unicode tokens on input, not a single string","Hi I using gensim for topic modelling, i am experiencing some errors message that i dont quite understand it please help!

Error message 
```
Traceback (most recent call last):
  File ""testTopic.py"", line 15, in <module>
    doc_term_matrix = [dictionary.doc2bow(doc) for doc in line]
  File ""C:\Python27\lib\site-packages\gensim\corpora\dictionary.py"", line 233, in doc2bow
    raise TypeError(""doc2bow expects an array of unicode tokens on input, not a single string"")
TypeError: doc2bow expects an array of unicode tokens on input, not a single string
```


"
176,https://github.com/RaRe-Technologies/gensim/issues/1975,1975,[],closed,2018-03-11 21:34:49+00:00,,Getting a problem regarding glove,"

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
I'm trying to implement Wordrank on a corpus, butting getting the following error.
```
from gensim.models.wrappers import Wordrank

wr_path = 'wordrank' # path to Wordrank directory
out_dir = 'model1' # name of output directory to save data to
data = 'test.cor' # sample corpus

model = Wordrank.train(wr_path, data, out_dir)
```
Getting this error
```
FileNotFoundError: [Errno 2] No such file or directory: 'wordrank/glove/vocab_count'
```
Please suggest any changes so that it executes.
Thanks"
177,https://github.com/RaRe-Technologies/gensim/issues/1977,1977,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2018-03-13 13:18:17+00:00,,Trouble re-loading Doc2Vec Model Generated In earlier Version,"I trained a Doc2Vec model in an earlier version of gensim and now can not load it. I tried both `Doc2Vec.load(fname)` and `Doc2Vec.load(fname, mmap = 'r')`. Both produce the same errors:

`AttributeError: Can't get attribute 'DocvecsArray' on <module 'gensim.models.doc2vec' from 'DIR/python/miniconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py'>`

` AttributeError: 'Doc2Vec' object has no attribute 'running_training_loss'`

Any help would be much appreciated. Thanks!
"
178,https://github.com/RaRe-Technologies/gensim/issues/1978,1978,[],closed,2018-03-13 13:37:45+00:00,,MmCorpus file attribute error,"Not able to serialize the corpus into a saved file.

corpora = [dictionary.doc2bow(text) for text in texts]
corpora.MmCorpus.serialize(os.path.join(TEMP_FOLDER,'deerwester.mm'), corpus) #store to disk, for later use
for c in corpus:
    print(c)

It is throwing a following error:

AttributeError                            Traceback (most recent call last)
<ipython-input-9-16983d1bfedb> in <module>()
      1 corpora = [dictionary.doc2bow(text) for text in texts]
----> 2 corpora.MmCorpus.serialize(os.path.join(TEMP_FOLDER,'deerwester.mm'), corpus) #store to disk, for later use
      3 for c in corpus:
      4     print(c)

AttributeError: 'list' object has no attribute 'MmCorpus'

"
179,https://github.com/RaRe-Technologies/gensim/issues/1979,1979,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2018-03-13 14:09:21+00:00,,Chaining Phrases objects produces inconsistent scores,"#### Description
When using the `Phrases` model for finding collocations and chaining them (using `Phraser`) to not only find bigrams but also trigrams. The returned scores for the trigram model are wrong in specific cases (e.g. using NPMI as scorer and finding score > 1).

#### Code to reproduce
Please find below the code to reproduce the problem (apologies for the German example):
```
from gensim.models import Phrases
from gensim.models.phrases import Phraser

sentences = [
    'Guten Tag meine Damen und Herren'.lower().split(),
    'Guten Tag meine Damen und Herren'.lower().split(),
    'Guten Tag meine Damen und Herren'.lower().split(),
    'Guten Tag Herr P'.lower().split(),
    'ich wünsche Ihnen einen guten Tag'.lower().split(),
    'ich wünsche Ihnen einen schönen Tag'.lower().split(),
    'ich wünsche Ihnen einen guten abend'.lower().split(),
]

bigrams = Phrases(sentences, min_count=2, scoring='npmi', threshold=0.8)
biphraser = Phraser(bigrams)
trigrams = Phrases(biphraser[sentences], min_count=1, scoring='npmi', threshold=0.5)
triphraser = Phraser(trigrams)

triphraser.phrasegrams 
```

#### Expected Results
All scores between -1 and 1.

#### Actual Results

```
{(b'guten', b'abend'): (1, 1.0000000000000002),
 (b'guten', b'tag'): (5, 3.172560717760953),
 (b'guten_tag', b'meine_damen'): (3, 0.7436167988124107),
 (b'ich_w\xc3\xbcnsche', b'ihnen_einen'): (3, 1.0),
 (b'ihnen_einen', b'guten'): (1, 0.6445819475968364),
 (b'ihnen_einen', b'sch\xc3\xb6nen'): (1, 0.6445819475968364),
 (b'ihnen_einen_guten', b'tag'): (1, 1.0000000000000002),
 (b'meine_damen', b'und_herren'): (3, 1.0),
 (b'sch\xc3\xb6nen', b'tag'): (1, 1.0000000000000002)}
```
The entry `(b'guten', b'tag')` has a score of 3.17 which, by definition, should not be possible when using npmi as scoring function.

##### My asssessment

My current understanding of the situation is that the bigram counts for subsequent `Phrases`objects are wrong when the same delimiter is used. In the above example, the bigram `guten_tag`appears 5 times, but `guten` and `tag` also appear in a different context:

```
print(list(biphraser[sentences]))

[['guten_tag', 'meine_damen', 'und_herren'],
 ['guten_tag', 'meine_damen', 'und_herren'],
 ['guten_tag', 'meine_damen', 'und_herren'],
 ['guten_tag', 'herr_p'],
 ['ich_wünsche', 'ihnen_einen', 'guten_tag'],
 ['ich_wünsche', 'ihnen_einen', 'schönen', 'tag'],
 ['ich_wünsche', 'ihnen_einen', 'guten', 'abend']]
```

Not all occurrences of `guten` or `tag` are merged into bigrams (e.g. the last two sentences). This is correct behaviour. However when the subsequent `Phrases` model (e.g. `trigrams`) is running on this input and using the same delimiter, it will learn the wrong bigram counts:

```
guten: 1
tag: 1
guten_tag: 5
```

As you can see, the bigram count for `guten_tag` is wrong (a bigram should never appear more often than any of its constituents). The confusion here arises from the fact the `guten_tag` is actually a single token for the `trigram` model. But due to the same delimiter, it is mistakenly considered as bigram count.
If my assumption is correct, this should only overestimate the bigram count and thus leading to more phrases passing the threshold.

##### Possible Workaround

When using different delimiters for the chained `Phrases` (preferably a delimiter which doesn't appear in the tokens), the problem does not appear.

I do not have an idea on how to fix this in an easy way. it would need to determine whether a token containing the delimiter is actually a bigram or a single token (which was created by a previous `Phraser` with the same delimiter). I actually also had the problem, if the delimiter appears as regular token in your corpus.

Because a workaround is available, I can live with this for the moment. But IMHO at least the documentation should be updated to reflect this shortcoming when chaining `Phrases` (since this is given as explicit example in the documentation).

#### Versions

Darwin-16.7.0-x86_64-i386-64bit
Python 3.6.4 (v3.6.4:d48ecebad5, Dec 18 2017, 21:07:28) 
[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)]
NumPy 1.14.2
SciPy 1.0.0
gensim 3.4.0
FAST_VERSION 0

Cheers,
Christian"
180,https://github.com/RaRe-Technologies/gensim/issues/1981,1981,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2018-03-14 22:32:50+00:00,,Reusing Vocabulary built with scan_vocab is impossible ,"I have a huge corpus which takes more than 3 days to build a vocabulary for. Thus, I really need to reuse the vocabulary. However, with the newer version it has become impossible to do so as explained in the code snippet below: 

```python
vocab = gensim.models.word2vec.Word2VecVocab(min_count=1, sorted_vocab=True)
vocab.scan_vocab(sentences, progress_per=PROGRESS_PER, trim_rule=None)
vocab.save(VOCAB_FILE_NAME)

#LATER
vocab  = gensim.models.word2vec.Word2VecVocab.load(VOCAB_FILE_NAME) 
#Word2VecVocab object doesn't keep total_words and corpus_count info
#it is now impossible for me to retrieve these values. 
#These values are returned from scan_vocab instead of being saved as fields of the object

#Create an empty model. 
model = gensim.models.word2vec.Word2Vec(min_count=MIN_COUNT, max_vocab_size=MAX_VOCAB_SIZE, seed=SEED, sg=SG, workers=WORKERS, size=SIZE)

#prepare the vocabulary. This step is also very confusing. 
#I think prepare_vocab should belong to the model object since it actually modifies model's parameters
vocab.prepare_vocab(model.hs, model.negative, model.wv, min_count=MIN_COUNT,  keep_raw_vocab=False)

#This part is even messier. There is no way I could have known what to do next without having to go thru the source code. 
#model.build_vocab rescans the whole vocabulary again, rendering my first phase useless. 
#instead, I have to use model.trainables.prepare_weights to have a workaround. 
#Again, what does vocabulary=model.vocabulary do? 
model.trainables.prepare_weights(model.hs, model.negative, model.wv, update=False, vocabulary=model.vocabulary)

#Now, most importantly, how do I set total_examples parameter? and why is it named differently? 
#model.corpus_count returns zero, because the only way of setting it up is to use build_vocab, which will rescan the vocabulary
#since model.corpus_count is zero now, I get this error:
#File ""/home/ahmed/anaconda3/lib/python3.5/site-packages/gensim/models/base_any2vec.py"", line 135, in _job_producer
#    epoch_progress = 1.0 * pushed_words / total_words
#ZeroDivisionError: float division by zero
#---
#there is no way I can get the total_words info from the vocabulary without scanning it again
model.train(sentences=sentences, total_examples=model.corpus_count, total_words=model.corpus_count, epochs=model.iter)

model.save(MODEL_FILE_NAME)
```"
181,https://github.com/RaRe-Technologies/gensim/issues/1982,1982,[],closed,2018-03-16 08:25:25+00:00,,dict2gensim,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
TODO: change commented example
<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->
i have a Word2Vec and it is saved by pickle. it's type is dict .
and now I want to know how can i do, to make the gensim load the dict .
thanks
#### Steps/Code/Corpus to Reproduce
<!--
Example:
```
from gensim.models import word2vec
dict = pickle.load(""vector.pkl"")
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->

#### Expected Results
<!-- Example: Expected shape of (100,2).-->

#### Actual Results
<!-- Example: Actual shape of (100,5). 

Please paste or specifically describe the actual output or traceback. -->

#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->


<!-- Thanks for contributing! -->

"
182,https://github.com/RaRe-Technologies/gensim/issues/1983,1983,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",open,2018-03-17 12:03:25+00:00,,Word2Vec and Doc2Vec do not update word embeddings if `negative` keyword is set to 0,"#### Description
Setting the `negative` keyword to `0` for Doc2Vec causes the training to not update word embeddings after the random initialisation.  
This happens silently and is behavior I wasn't expecting.

#### Steps/Code/Corpus to Reproduce
```python
from sklearn.datasets import fetch_20newsgroups
import pandas as pd
from gensim.models import Doc2Vec, Word2Vec
from gensim.models.doc2vec import TaggedDocument

df = pd.DataFrame(fetch_20newsgroups().data)
df[0] = df[0].str.split(' ')
documents = df.apply(lambda x: TaggedDocument(x[0], x.index), axis=1)

model1a = Doc2Vec(documents, negative=1, epochs=1)
model1b = Doc2Vec(documents, negative=0, epochs=1)
model2a = Doc2Vec(documents, negative=1, epochs=2)
model2b = Doc2Vec(documents, negative=0, epochs=2)

print('model1a:', model1a.wv.most_similar('test'))
print('model1b:', model1b.wv.most_similar('test'))
print('model2a:', model2a.wv.most_similar('test'))
print('model2b:', model2b.wv.most_similar('test'))

model1a = Word2Vec(df[0], negative=1, iter=1)
model1b = Word2Vec(df[0], negative=0, iter=1)
model2a = Word2Vec(df[0], negative=1, iter=2)
model2b = Word2Vec(df[0], negative=0, iter=2)

print('model1a:', model1a.most_similar('test'))
print('model1b:', model1b.most_similar('test'))
print('model2a:', model2a.most_similar('test'))
print('model2b:', model2b.most_similar('test'))
```


#### Results
As can be seen below, the results for the models that have a `negative=0` show the same results after 1 or 2 epochs of training, where the models with `negative=1` show different (and somewhat more sensible) results.
_Doc2Vec_:
```
model1a:
[('time', 0.9929366111755371),
 ('either', 0.9923557639122009),
 ('up', 0.9921339154243469),
 ('problem', 0.9915313720703125),
 ('being', 0.9915310144424438),
 ('getting', 0.991266131401062),
 ('group', 0.991013765335083),
 ('keeping', 0.9908334016799927),
 ('players', 0.9906938672065735),
 ('further', 0.9902615547180176)]
 
model1b:
[('518-393-7228', 0.4212157428264618),
 ('anyone?', 0.4167076647281647),
 ('it,', 0.3915032744407654),
 ('deliver', 0.3873376250267029),
 ('Books', 0.3643316328525543),
 ('stuck', 0.35024553537368774),
 (""o'clock"", 0.34999915957450867),
 ('(Dostoevsky)', 0.34075409173965454),
 ('(Thyagi', 0.33959853649139404),
 ('MSDOS', 0.3370114862918854)]
 
model2a:
[('chip,', 0.9874706268310547),
 ('moves', 0.9828106164932251),
 ('board', 0.9789682626724243),
 ('adding', 0.978229820728302),
 ('express', 0.9764397144317627),
 ('sport', 0.9763677716255188),
 ('correctly', 0.9756811261177063),
 ('restricted', 0.9725382328033447),
 ('concern', 0.9719469547271729),
 ('user,', 0.9711147546768188)]
 
model2b:
[('518-393-7228', 0.4212157428264618),
 ('anyone?', 0.4167076647281647),
 ('it,', 0.3915032744407654),
 ('deliver', 0.3873376250267029),
 ('Books', 0.3643316328525543),
 ('stuck', 0.35024553537368774),
 (""o'clock"", 0.34999915957450867),
 ('(Dostoevsky)', 0.34075409173965454),
 ('(Thyagi', 0.33959853649139404),
 ('MSDOS', 0.3370114862918854)]
```

_Word2Vec_:
```
model1a:
[('moral', 0.9974657297134399),
 ('obvious', 0.9970457553863525),
 ('high', 0.9967347979545593),
 ('ago,', 0.9966593384742737),
 ('food', 0.9964239001274109),
 ('case,', 0.996358335018158),
 ('in,', 0.9963352084159851),
 ('problems', 0.996278703212738),
 ('doctor', 0.9962717890739441),
 ('kept', 0.9961578845977783)]

model1b:
[('Fulk)\nSubject:', 0.43792209029197693),
 ('weak', 0.3926801085472107),
 ('Provine', 0.382274866104126),
 ('suspension,', 0.37375500798225403),
 ('kirsch@staff.tc.umn.edu', 0.3638245761394501),
 ('negligible', 0.3633933365345001),
 ('frozen', 0.36065810918807983),
 ('notch', 0.35705092549324036),
 ('_|_|_', 0.3445291221141815),
 ('(Grant', 0.3377472162246704)]

model2a:
[('motorcycle', 0.9882928729057312),
 ('grounds', 0.9797140955924988),
 ('charge', 0.977377712726593),
 ('goes', 0.9750747084617615),
 ('trip', 0.9731242060661316),
 ('mark', 0.9729797840118408),
 ('needed', 0.9718480706214905),
 ('directly', 0.9717421531677246),
 ('group,', 0.9714720845222473),
 ('store', 0.971139669418335)]

model2b:
[('Fulk)\nSubject:', 0.43792209029197693),
 ('weak', 0.3926801085472107),
 ('Provine', 0.382274866104126),
 ('suspension,', 0.37375500798225403),
 ('kirsch@staff.tc.umn.edu', 0.3638245761394501),
 ('negligible', 0.3633933365345001),
 ('frozen', 0.36065810918807983),
 ('notch', 0.35705092549324036),
 ('_|_|_', 0.3445291221141815),
 ('(Grant', 0.3377472162246704)]
```

#### Logs during training
##### Doc2Vec
**model1a:**
```2018-03-17 12:48:28,330 : INFO : collecting all words and their counts
2018-03-17 12:48:28,331 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2018-03-17 12:48:28,966 : INFO : PROGRESS: at example #10000, processed 3198312 words (5044963/s), 390776 word types, 1 tags
2018-03-17 12:48:29,049 : INFO : collected 427021 word types and 1 unique tags from a corpus of 11314 examples and 3593473 words
2018-03-17 12:48:29,050 : INFO : Loading a fresh vocabulary
2018-03-17 12:48:29,283 : INFO : min_count=5 retains 40708 unique words (9% of original 427021, drops 386313)
2018-03-17 12:48:29,284 : INFO : min_count=5 leaves 3082977 word corpus (85% of original 3593473, drops 510496)
2018-03-17 12:48:29,373 : INFO : deleting the raw counts dictionary of 427021 items
2018-03-17 12:48:29,379 : INFO : sample=0.001 downsamples 32 most-common words
2018-03-17 12:48:29,379 : INFO : downsampling leaves estimated 2056839 word corpus (66.7% of prior 3082977)
2018-03-17 12:48:29,490 : INFO : estimated required memory for 40708 words and 100 dimensions: 52920800 bytes
2018-03-17 12:48:29,490 : INFO : resetting layer weights
2018-03-17 12:48:29,840 : INFO : training model with 3 workers on 40708 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=1 window=5
2018-03-17 12:48:30,848 : INFO : EPOCH 1 - PROGRESS: at 56.44% examples, 1165806 words/s, in_qsize 5, out_qsize 0
2018-03-17 12:48:31,587 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-03-17 12:48:31,588 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-03-17 12:48:31,594 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-03-17 12:48:31,595 : INFO : EPOCH - 1 : training on 3593473 raw words (2068258 effective words) took 1.8s, 1180569 effective words/s
2018-03-17 12:48:31,595 : INFO : training on a 3593473 raw words (2068258 effective words) took 1.8s, 1178829 effective words/s
```
**model1b:**
```
2018-03-17 12:48:31,596 : INFO : collecting all words and their counts
2018-03-17 12:48:31,597 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2018-03-17 12:48:32,172 : INFO : PROGRESS: at example #10000, processed 3198312 words (5569233/s), 390776 word types, 1 tags
2018-03-17 12:48:32,252 : INFO : collected 427021 word types and 1 unique tags from a corpus of 11314 examples and 3593473 words
2018-03-17 12:48:32,253 : INFO : Loading a fresh vocabulary
2018-03-17 12:48:32,413 : INFO : min_count=5 retains 40708 unique words (9% of original 427021, drops 386313)
2018-03-17 12:48:32,414 : INFO : min_count=5 leaves 3082977 word corpus (85% of original 3593473, drops 510496)
2018-03-17 12:48:32,506 : INFO : deleting the raw counts dictionary of 427021 items
2018-03-17 12:48:32,511 : INFO : sample=0.001 downsamples 32 most-common words
2018-03-17 12:48:32,512 : INFO : downsampling leaves estimated 2056839 word corpus (66.7% of prior 3082977)
2018-03-17 12:48:32,557 : INFO : estimated required memory for 40708 words and 100 dimensions: 36637600 bytes
2018-03-17 12:48:32,557 : INFO : resetting layer weights
2018-03-17 12:48:32,910 : INFO : training model with 3 workers on 40708 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=0 window=5
2018-03-17 12:48:33,913 : INFO : EPOCH 1 - PROGRESS: at 66.48% examples, 1398264 words/s, in_qsize 5, out_qsize 0
2018-03-17 12:48:34,396 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-03-17 12:48:34,403 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-03-17 12:48:34,409 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-03-17 12:48:34,412 : INFO : EPOCH - 1 : training on 3593473 raw words (2067706 effective words) took 1.5s, 1378469 effective words/s
2018-03-17 12:48:34,412 : INFO : training on a 3593473 raw words (2067706 effective words) took 1.5s, 1376358 effective words/s
```
**model2a:**
```
2018-03-17 12:48:34,413 : INFO : collecting all words and their counts
2018-03-17 12:48:34,415 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2018-03-17 12:48:35,073 : INFO : PROGRESS: at example #10000, processed 3198312 words (4869749/s), 390776 word types, 1 tags
2018-03-17 12:48:35,152 : INFO : collected 427021 word types and 1 unique tags from a corpus of 11314 examples and 3593473 words
2018-03-17 12:48:35,153 : INFO : Loading a fresh vocabulary
2018-03-17 12:48:35,452 : INFO : min_count=5 retains 40708 unique words (9% of original 427021, drops 386313)
2018-03-17 12:48:35,453 : INFO : min_count=5 leaves 3082977 word corpus (85% of original 3593473, drops 510496)
2018-03-17 12:48:35,563 : INFO : deleting the raw counts dictionary of 427021 items
2018-03-17 12:48:35,568 : INFO : sample=0.001 downsamples 32 most-common words
2018-03-17 12:48:35,569 : INFO : downsampling leaves estimated 2056839 word corpus (66.7% of prior 3082977)
2018-03-17 12:48:35,686 : INFO : estimated required memory for 40708 words and 100 dimensions: 52920800 bytes
2018-03-17 12:48:35,687 : INFO : resetting layer weights
2018-03-17 12:48:36,044 : INFO : training model with 3 workers on 40708 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=1 window=5
2018-03-17 12:48:37,052 : INFO : EPOCH 1 - PROGRESS: at 42.69% examples, 886813 words/s, in_qsize 5, out_qsize 0
2018-03-17 12:48:38,052 : INFO : EPOCH 1 - PROGRESS: at 98.46% examples, 1013776 words/s, in_qsize 5, out_qsize 0
2018-03-17 12:48:38,090 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-03-17 12:48:38,091 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-03-17 12:48:38,102 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-03-17 12:48:38,102 : INFO : EPOCH - 1 : training on 3593473 raw words (2067777 effective words) took 2.1s, 1006127 effective words/s
2018-03-17 12:48:39,107 : INFO : EPOCH 2 - PROGRESS: at 57.09% examples, 1186646 words/s, in_qsize 5, out_qsize 0
2018-03-17 12:48:39,865 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-03-17 12:48:39,873 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-03-17 12:48:39,874 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-03-17 12:48:39,875 : INFO : EPOCH - 2 : training on 3593473 raw words (2067767 effective words) took 1.8s, 1168711 effective words/s
2018-03-17 12:48:39,875 : INFO : training on a 7186946 raw words (4135544 effective words) took 3.8s, 1079693 effective words/s
```
**model2b:**
```
2018-03-17 12:48:39,876 : INFO : collecting all words and their counts
2018-03-17 12:48:39,878 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2018-03-17 12:48:40,616 : INFO : PROGRESS: at example #10000, processed 3198312 words (4332917/s), 390776 word types, 1 tags
2018-03-17 12:48:40,697 : INFO : collected 427021 word types and 1 unique tags from a corpus of 11314 examples and 3593473 words
2018-03-17 12:48:40,698 : INFO : Loading a fresh vocabulary
2018-03-17 12:48:40,982 : INFO : min_count=5 retains 40708 unique words (9% of original 427021, drops 386313)
2018-03-17 12:48:40,985 : INFO : min_count=5 leaves 3082977 word corpus (85% of original 3593473, drops 510496)
2018-03-17 12:48:41,106 : INFO : deleting the raw counts dictionary of 427021 items
2018-03-17 12:48:41,111 : INFO : sample=0.001 downsamples 32 most-common words
2018-03-17 12:48:41,112 : INFO : downsampling leaves estimated 2056839 word corpus (66.7% of prior 3082977)
2018-03-17 12:48:41,156 : INFO : estimated required memory for 40708 words and 100 dimensions: 36637600 bytes
2018-03-17 12:48:41,157 : INFO : resetting layer weights
2018-03-17 12:48:41,517 : INFO : training model with 3 workers on 40708 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=0 window=5
2018-03-17 12:48:42,525 : INFO : EPOCH 1 - PROGRESS: at 65.36% examples, 1362872 words/s, in_qsize 5, out_qsize 0
2018-03-17 12:48:43,161 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-03-17 12:48:43,166 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-03-17 12:48:43,169 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-03-17 12:48:43,170 : INFO : EPOCH - 1 : training on 3593473 raw words (2067697 effective words) took 1.7s, 1252184 effective words/s
2018-03-17 12:48:44,173 : INFO : EPOCH 2 - PROGRESS: at 55.19% examples, 1149188 words/s, in_qsize 5, out_qsize 0
2018-03-17 12:48:44,820 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-03-17 12:48:44,825 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-03-17 12:48:44,828 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-03-17 12:48:44,829 : INFO : EPOCH - 2 : training on 3593473 raw words (2067746 effective words) took 1.7s, 1248269 effective words/s
2018-03-17 12:48:44,829 : INFO : training on a 7186946 raw words (4135443 effective words) took 3.3s, 1248589 effective words/s
```

##### Word2Vec
**model1a**:
```
2018-03-17 12:54:55,113 : INFO : collecting all words and their counts
2018-03-17 12:54:55,114 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-03-17 12:54:55,710 : INFO : PROGRESS: at sentence #10000, processed 3198312 words, keeping 390776 word types
2018-03-17 12:54:55,789 : INFO : collected 427021 word types from a corpus of 3593473 raw words and 11314 sentences
2018-03-17 12:54:55,789 : INFO : Loading a fresh vocabulary
2018-03-17 12:54:55,943 : INFO : min_count=5 retains 40708 unique words (9% of original 427021, drops 386313)
2018-03-17 12:54:55,943 : INFO : min_count=5 leaves 3082977 word corpus (85% of original 3593473, drops 510496)
2018-03-17 12:54:56,036 : INFO : deleting the raw counts dictionary of 427021 items
2018-03-17 12:54:56,041 : INFO : sample=0.001 downsamples 32 most-common words
2018-03-17 12:54:56,042 : INFO : downsampling leaves estimated 2056839 word corpus (66.7% of prior 3082977)
2018-03-17 12:54:56,154 : INFO : estimated required memory for 40708 words and 100 dimensions: 52920400 bytes
2018-03-17 12:54:56,154 : INFO : resetting layer weights
2018-03-17 12:54:56,501 : INFO : training model with 3 workers on 40708 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=1 window=5
2018-03-17 12:54:57,505 : INFO : EPOCH 1 - PROGRESS: at 78.98% examples, 1626661 words/s, in_qsize 5, out_qsize 0
2018-03-17 12:54:57,768 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-03-17 12:54:57,769 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-03-17 12:54:57,772 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-03-17 12:54:57,773 : INFO : EPOCH - 1 : training on 3593473 raw words (2056644 effective words) took 1.3s, 1620306 effective words/s
2018-03-17 12:54:57,773 : INFO : training on a 3593473 raw words (2056644 effective words) took 1.3s, 1618042 effective words/s
```
**model1b**:
```
2018-03-17 12:54:57,780 : INFO : collecting all words and their counts
2018-03-17 12:54:57,782 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-03-17 12:54:58,335 : INFO : PROGRESS: at sentence #10000, processed 3198312 words, keeping 390776 word types
2018-03-17 12:54:58,412 : INFO : collected 427021 word types from a corpus of 3593473 raw words and 11314 sentences
2018-03-17 12:54:58,413 : INFO : Loading a fresh vocabulary
2018-03-17 12:54:58,703 : INFO : min_count=5 retains 40708 unique words (9% of original 427021, drops 386313)
2018-03-17 12:54:58,703 : INFO : min_count=5 leaves 3082977 word corpus (85% of original 3593473, drops 510496)
2018-03-17 12:54:58,791 : INFO : deleting the raw counts dictionary of 427021 items
2018-03-17 12:54:58,796 : INFO : sample=0.001 downsamples 32 most-common words
2018-03-17 12:54:58,797 : INFO : downsampling leaves estimated 2056839 word corpus (66.7% of prior 3082977)
2018-03-17 12:54:58,841 : INFO : estimated required memory for 40708 words and 100 dimensions: 36637200 bytes
2018-03-17 12:54:58,842 : INFO : resetting layer weights
2018-03-17 12:54:59,194 : INFO : training model with 3 workers on 40708 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=0 window=5
2018-03-17 12:55:00,184 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-03-17 12:55:00,189 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-03-17 12:55:00,189 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-03-17 12:55:00,190 : INFO : EPOCH - 1 : training on 3593473 raw words (2057464 effective words) took 1.0s, 2069005 effective words/s
2018-03-17 12:55:00,190 : INFO : training on a 3593473 raw words (2057464 effective words) took 1.0s, 2064908 effective words/s
```
**model2a**:
```
2018-03-17 12:55:00,198 : INFO : collecting all words and their counts
2018-03-17 12:55:00,200 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-03-17 12:55:00,760 : INFO : PROGRESS: at sentence #10000, processed 3198312 words, keeping 390776 word types
2018-03-17 12:55:00,835 : INFO : collected 427021 word types from a corpus of 3593473 raw words and 11314 sentences
2018-03-17 12:55:00,836 : INFO : Loading a fresh vocabulary
2018-03-17 12:55:01,001 : INFO : min_count=5 retains 40708 unique words (9% of original 427021, drops 386313)
2018-03-17 12:55:01,001 : INFO : min_count=5 leaves 3082977 word corpus (85% of original 3593473, drops 510496)
2018-03-17 12:55:01,102 : INFO : deleting the raw counts dictionary of 427021 items
2018-03-17 12:55:01,108 : INFO : sample=0.001 downsamples 32 most-common words
2018-03-17 12:55:01,108 : INFO : downsampling leaves estimated 2056839 word corpus (66.7% of prior 3082977)
2018-03-17 12:55:01,215 : INFO : estimated required memory for 40708 words and 100 dimensions: 52920400 bytes
2018-03-17 12:55:01,215 : INFO : resetting layer weights
2018-03-17 12:55:01,583 : INFO : training model with 3 workers on 40708 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=1 window=5
2018-03-17 12:55:02,588 : INFO : EPOCH 1 - PROGRESS: at 70.71% examples, 1471948 words/s, in_qsize 5, out_qsize 0
2018-03-17 12:55:02,957 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-03-17 12:55:02,958 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-03-17 12:55:02,960 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-03-17 12:55:02,961 : INFO : EPOCH - 1 : training on 3593473 raw words (2056026 effective words) took 1.4s, 1494852 effective words/s
2018-03-17 12:55:03,970 : INFO : EPOCH 2 - PROGRESS: at 78.28% examples, 1614596 words/s, in_qsize 6, out_qsize 0
2018-03-17 12:55:04,240 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-03-17 12:55:04,241 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-03-17 12:55:04,244 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-03-17 12:55:04,245 : INFO : EPOCH - 2 : training on 3593473 raw words (2057234 effective words) took 1.3s, 1611148 effective words/s
2018-03-17 12:55:04,245 : INFO : training on a 7186946 raw words (4113260 effective words) took 2.7s, 1545423 effective words/s
```
**model2b**:
```
2018-03-17 12:55:04,255 : INFO : collecting all words and their counts
2018-03-17 12:55:04,257 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2018-03-17 12:55:04,810 : INFO : PROGRESS: at sentence #10000, processed 3198312 words, keeping 390776 word types
2018-03-17 12:55:04,882 : INFO : collected 427021 word types from a corpus of 3593473 raw words and 11314 sentences
2018-03-17 12:55:04,882 : INFO : Loading a fresh vocabulary
2018-03-17 12:55:05,177 : INFO : min_count=5 retains 40708 unique words (9% of original 427021, drops 386313)
2018-03-17 12:55:05,177 : INFO : min_count=5 leaves 3082977 word corpus (85% of original 3593473, drops 510496)
2018-03-17 12:55:05,278 : INFO : deleting the raw counts dictionary of 427021 items
2018-03-17 12:55:05,283 : INFO : sample=0.001 downsamples 32 most-common words
2018-03-17 12:55:05,284 : INFO : downsampling leaves estimated 2056839 word corpus (66.7% of prior 3082977)
2018-03-17 12:55:05,329 : INFO : estimated required memory for 40708 words and 100 dimensions: 36637200 bytes
2018-03-17 12:55:05,329 : INFO : resetting layer weights
2018-03-17 12:55:05,674 : INFO : training model with 3 workers on 40708 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=0 window=5
2018-03-17 12:55:06,562 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-03-17 12:55:06,566 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-03-17 12:55:06,567 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-03-17 12:55:06,567 : INFO : EPOCH - 1 : training on 3593473 raw words (2056953 effective words) took 0.9s, 2308747 effective words/s
2018-03-17 12:55:07,450 : INFO : worker thread finished; awaiting finish of 2 more threads
2018-03-17 12:55:07,451 : INFO : worker thread finished; awaiting finish of 1 more threads
2018-03-17 12:55:07,458 : INFO : worker thread finished; awaiting finish of 0 more threads
2018-03-17 12:55:07,459 : INFO : EPOCH - 2 : training on 3593473 raw words (2056387 effective words) took 0.9s, 2313723 effective words/s
2018-03-17 12:55:07,462 : INFO : training on a 7186946 raw words (4113340 effective words) took 1.8s, 2300980 effective words/s
```

#### Versions
```
Python 3.6.3 (default, Oct  3 2017, 21:45:48) 
[GCC 7.2.0]
NumPy 1.14.1
SciPy 1.0.0
gensim 3.4.0
FAST_VERSION 1
```"
183,https://github.com/RaRe-Technologies/gensim/issues/1986,1986,[],closed,2018-03-19 13:49:08+00:00,,Gensim classifies a document as a certain topic despite having no words in common,"The topic id returned by print_topics is different from the topic id returned when looking at the categorized topics of a document. 

I have trained an LDA model using a tfidf corpus. I then viewed the top 30 words for the top 10 topics with 

`model.print_topics(10,30)`

As expected from the documentation, print_topics gives a list of of tuples, with the first value being the topic id. The first thirty words are enough that the probability of each word is 0 by the end. 

To examine the topics, I use:

```
doc_topics = []
for doc in corpus:
    doc_topics.append(model[doc])
```

`model[doc]` returns a list of tuples containing topic id and probability. But if I examine all documents from the top topic ids returned from` print_topics`, none of the words first thirty words show up. So for example, topic 13 was identified as the top topic, but none of the top thirty words show up at all in the documents that are listed as having some probability of being topic 13. 

To make sure it wasn't an off-by-one error, I also checked 12 and 14, no luck. 

Version information: 

> Linux-4.4.0-66-generic-x86_64-with-debian-8.8
> Python 3.6.1 | packaged by conda-forge | (default, May 23 2017, 14:16:20) 
> [GCC 4.8.2 20140120 (Red Hat 4.8.2-15)]
> NumPy 1.12.1
> SciPy 1.0.0
> gensim 3.4.0
> FAST_VERSION 1

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

"
184,https://github.com/RaRe-Technologies/gensim/issues/1988,1988,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}]",open,2018-03-20 02:47:27+00:00,,LdaMulticore and OpenMP BLAS,"Many python installations these days use a version of numpy linked with a highly optimized BLAS that, by default, uses as many cores as are available.  This means that running `LdaMulticore` with `workers=5` on a six-core machine ends up trying to use 30 cores, with a pretty serious hit to performance.

Take this test program:
````
from gensim.corpora import Dictionary
from gensim.models import LdaModel, LdaMulticore
from nltk.corpus import brown
from time import perf_counter

vocab = Dictionary(brown.words(f) for f in brown.fileids())
vocab.filter_extremes(no_below=50, no_above=0.5)
corpus = [vocab.doc2bow(brown.words(f)) for f in brown.fileids()]

start = perf_counter()
lda = LdaModel(corpus=corpus, id2word=vocab, num_topics=100, chunksize=50, passes=5)
print('%15s %5.2f'%('LdaModel', perf_counter()-start))

start = perf_counter()
lda = LdaMulticore(corpus=corpus, id2word=vocab, num_topics=100, chunksize=50, passes=5,
                                     workers=5)
print('%15s %5.2f'%('LdaMulticore', perf_counter()-start))
````

Run on a six-core CPU using the Intel Python distribution, I get:
```` 
       LdaModel 10.38
   LdaMulticore 14.24
````
But, with MKL_NUM_THREADS set to 1 to disable parallelism inside numpy, I get:
````
       LdaModel 20.46
   LdaMulticore  4.85
````

Using Intel's parallel MKL BLAS, `LdaModel` is actually faster than `LdaMulticore`, though `LdaMulticore` with a single-threaded BLAS is by far the fastest.

As far as I can tell there isn't any portable and reliable way to control how many threads numpy's numeric core might be using, so for now maybe the best thing to do is to add a warning about this to the documentation.




"
185,https://github.com/RaRe-Technologies/gensim/issues/1989,1989,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2018-03-20 08:32:18+00:00,,Benchmark Gensim vs Amazon SageMaker ,"#### Description
We want to compare gensim and [SageMaker](https://aws.amazon.com/ru/sagemaker/):

- LSI (after #1896) vs [SageMaker PCA](https://docs.aws.amazon.com/sagemaker/latest/dg/pca.html)
- LDA vs [SageMaker NTM](https://docs.aws.amazon.com/sagemaker/latest/dg/ntm.html) vs [SageMaker LDA](https://docs.aws.amazon.com/sagemaker/latest/dg/lda.html)

#### Metrics
- hardware performance:
  - time
  - memory
- algorithm performance (corresponding to a particular algorithm. for example - perplexity for LDA, etc). Also possible solve some supervised task with end2end evaluation with simple linear classifier on top).

The expected result is a benchmark table + a blog post describing the motivation, results and analysis."
186,https://github.com/RaRe-Technologies/gensim/issues/1990,1990,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}]",open,2018-03-20 15:44:31+00:00,,TextCorpus.sample_texts() does not use get_texts(),"The `sample_texts()` method is supposed to return sample documents but if an implementation derives from `TextCorpus` and overrides `get_texts()`, this is completely ignored by the implementation of `sample_texts()` which uses `getstream()` only. 
This applies to the most recent develop (58d560b545e6df4cfc5fd3879f8647ba3a7a0e3b) and maste
(885430d136c87c613ab58ad6b1dc55fee47a43c7) branches. 
"
187,https://github.com/RaRe-Technologies/gensim/issues/1991,1991,"[{'id': 175986, 'node_id': 'MDU6TGFiZWwxNzU5ODY=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/testing', 'name': 'testing', 'color': '444444', 'default': False, 'description': 'Issue related with testing (code, documentation, etc)'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 708430967, 'node_id': 'MDU6TGFiZWw3MDg0MzA5Njc=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/performance', 'name': 'performance', 'color': 'd93f0b', 'default': False, 'description': 'Issue related to performance (in HW meaning)'}]",closed,2018-03-21 16:28:17+00:00,,Word2Bits benchmark,"#### Description
Pretty interesting paper [Word2Bits - Quantized Word Vectors by Maximilian Lam](https://arxiv.org/abs/1803.05651), looks like it possible to apply ""quantization"" to the current w2v algorithm and receive a memory-compact representation without sacrificing quality.

#### ToDo
1. Make needed changes in current w2v code (according to this article), only for testing
2. Compare this approach by embedding quality (+memory consumption) with current w2v implementation (reproduce evaluation from paper)
   - **Train corpus:** English wikipedia
   - **Benchmark:**
      - `accuracy` method (classical approach)
      - SQuAD task (more detailed described in the paper)

If benchmark shows good-enough results, this will be a part of Gensim.
"
188,https://github.com/RaRe-Technologies/gensim/issues/1993,1993,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-03-22 09:59:58+00:00,,add document to Lsi Model dynamically,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
gensim version：3.1.0
my code:
lsi = models.LsiModel.load(path)
lsi.add_document(corpus, chunksize=50000)

at the first time, the lsi model can add 50000 corpus in to lsi model,
but once more, report an error, i check the core file which shows the second line code running error
i tried to change the size of chunksize, but when reach the size of 50000, and then i got the same error!
![wechatimg5850](https://user-images.githubusercontent.com/27185685/37763377-d4d6f494-2df9-11e8-8bcc-f6d3b20907f2.jpeg)
![wechatimg5851](https://user-images.githubusercontent.com/27185685/37763380-d6246962-2df9-11e8-894d-7a1b132a6c39.jpeg)

<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->



<!-- Thanks for contributing! -->

"
189,https://github.com/RaRe-Technologies/gensim/issues/1994,1994,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}]",open,2018-03-22 12:41:53+00:00,,'Word2VecKeyedVectors' object has no attribute 'vectors',"I have a word2vec model which I was able to load into Gensim, normalize and retrieve word vectors with `model.init_sims(replace=True)` and `model[word]` previously. After updating to gensim 3.4.0 I'm receiving the following error messages for these operations:

```
Traceback (most recent call last):
  File ""/Users/lzfelix/anaconda3/envs/mirror/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2862, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-13-4a9edd1d9ae5>"", line 1, in <module>
    vsm.init_sims()
  File ""/Users/lzfelix/anaconda3/envs/mirror/lib/python3.5/site-packages/gensim/models/keyedvectors.py"", line 1048, in init_sims
    self.vectors_norm = (self.vectors / sqrt((self.vectors ** 2).sum(-1))[..., newaxis]).astype(REAL)
AttributeError: 'Word2VecKeyedVectors' object has no attribute 'vectors'
```

and 

```
Traceback (most recent call last):
  File ""/Users/lzfelix/anaconda3/envs/mirror/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2862, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-14-b955394cb092>"", line 1, in <module>
    vsm['oi']
  File ""/Users/lzfelix/anaconda3/envs/mirror/lib/python3.5/site-packages/gensim/models/keyedvectors.py"", line 169, in __getitem__
    return self.get_vector(entities)
  File ""/Users/lzfelix/anaconda3/envs/mirror/lib/python3.5/site-packages/gensim/models/keyedvectors.py"", line 277, in get_vector
    return self.word_vec(word)
  File ""/Users/lzfelix/anaconda3/envs/mirror/lib/python3.5/site-packages/gensim/models/keyedvectors.py"", line 269, in word_vec
    result = self.vectors[self.vocab[word].index]
AttributeError: 'Word2VecKeyedVectors' object has no attribute 'vectors'
```

This seems related to the issues caused by the vector models re-implementation  #1777, similarly to #1882 and #1952. Unfortunately I can't provide the binary file.

Thank you,
Luiz Felix

"
190,https://github.com/RaRe-Technologies/gensim/issues/1995,1995,[],closed,2018-03-22 16:40:54+00:00,,KeyError in the LDA model when log is showing the top 5 topics,"I am running the LDA multicore function using the logging function that will show the top 5 topics as the model passes through the corpus.
After a few passes (occurs randomly) I get the following error

      Traceback (most recent call last):
      File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2910, in 
         run_code exec(code_obj, self.user_global_ns, self.user_ns)
      File ""<ipython-input-13-378e8a62a33f>"", line 1, in <module>
         topic_ = [(self.id2word[id], topic_[id]) for id in bestn]
      File ""<ipython-input-13-378e8a62a33f>"", line 1, in <listcomp>
          topic_ = [(self.id2word[id], topic_[id]) for id in bestn]
      KeyError: 199704

Problem occurs in the show_topics() function when looping through the chosen_topics (line 881):

        topic = self.state.get_lambda()

        for i in chosen_topics:
            topic_ = topic[i]
            topic_ = topic_ / topic_.sum()  # normalize to probability distribution
            bestn = matutils.argsort(topic_, num_words, reverse=True)

            topic_ = [(self.id2word[id], topic_[id]) for id in bestn]

The last line generates an error as some of the ids are not in my dictionary id2word.
I checked my Document Term Matrix I pass in input and there is no trace of this word anywhere (and if there was, the LDA model wouldn't be able to pass through the corpus several times).

I'm using Python 3.6 with gensim 3.4.
Unfortunately I can't upload any model as it hasn't finished computing.

What I can tell you is that I do have `len(topic_)` equal to `max(self.id2word.keys()) + 1` which is to be expected.

It is important to mention that I am working on a filtered dictionary/DocumentTermMatrix. So the keys in my dictionary are not contiguous as some of the words have been deleted.

The only difference I notice for the topic that triggers the error compared to the others is that the topic_ variable has the same value for all the elements of the vector. I assume that in this case the indices returned by matutils.argsort are somehow random which might cause the error as the index returned will range between 0 and `len(topic_)` but aren't necessarily indices in the dictionary.

So I suspect the problem might come from my dictionary that has gaps between its keys.

Any help on why I get this issue will be much appreciated. Thanks!
"
191,https://github.com/RaRe-Technologies/gensim/issues/1997,1997,[],closed,2018-03-25 10:21:49+00:00,,Feature Suggestion: Save intermediate states of the model while training. ,"When training a large model, it might take quite a while, sometimes several days, especially if you have set EPOCH to a higher value. 
I think it would be much better if it was possible to save the model in an incremental fashion - that is, save it as soon as Epoch1 is completed, then when Epoch2 is completed and so on. This way, one doesn't have to wait for several days to experiment with the model they created. Or, when, for some reason, one has to cancel the training process in the middle (for example, because the time slot you have reserved on a server has expired), they at least have something, instead of wasting those 3 days with no result at all. 
It should be quite easily, by adding a new parameter to the model.train method (save_icrementally), together with a file_name, and calling model.save every time an Epoch is completed. "
192,https://github.com/RaRe-Technologies/gensim/issues/1998,1998,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2018-03-25 17:22:20+00:00,,OverflowError when loading a large term-document matrix in Matrix Market format,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
While loading the LSI vectors containing 4411273 documents and 500 terms in Matrix Market format , gensim complained the OverflowError.

#### Steps/Code/Corpus to Reproduce
```
In [14]: gensim.__version__
Out[14]: '3.4.0'

In [6]: corpus = MmCorpus(datapath('lsi_vectors.mm.gz'))
---------------------------------------------------------------------------
OverflowError                             Traceback (most recent call last)
<ipython-input-6-9e22aec68b3c> in <module>()
----> 1 corpus = MmCorpus(datapath('lsi_vectors.mm.gz'))

/Users/aukauk/anaconda3.6/anaconda3/envs/py27/lib/python2.7/site-packages/gensim/corpora/mmcorpus.pyc in __init__(self, fname)
     62         # avoid calling super(), too confusing
     63         IndexedCorpus.__init__(self, fname)
---> 64         matutils.MmReader.__init__(self, fname)
     65 
     66     def __iter__(self):

/Users/aukauk/anaconda3.6/anaconda3/envs/py27/lib/python2.7/site-packages/gensim/corpora/_mmreader.pyx in gensim.corpora._mmreader.MmReader.__init__()
     58         logger.info(""initializing cython corpus reader from %s"", input)
     59         self.input, self.transposed = input, transposed
---> 60         with utils.open_file(self.input) as lines:
     61             try:
     62                 header = utils.to_unicode(next(lines)).strip()

/Users/aukauk/anaconda3.6/anaconda3/envs/py27/lib/python2.7/site-packages/gensim/corpora/_mmreader.pyx in gensim.corpora._mmreader.MmReader.__init__()
     73                 line = utils.to_unicode(line)
     74                 if not line.startswith('%'):
---> 75                     self.num_docs, self.num_terms, self.num_nnz = (int(x) for x in line.split())
     76                     if not self.transposed:
     77                         self.num_docs, self.num_terms = self.num_terms, self.num_docs

OverflowError: value too large to convert to int

cat lsi_vectors.mm |wc -l
2213498865

head lsi_vectors.mm
%%MatrixMarket matrix coordinate real general
4427006 500 2213498863                            
1 1 0.3913027376444812
1 2 -0.07658791716226626
1 3 -0.020870794080588395
1 4 0.2145833024464887
1 5 0.16483779845897858
1 6 -0.05127146459864627
1 7 0.007765814982918945
1 8 -0.01817635794795088

```
"
193,https://github.com/RaRe-Technologies/gensim/issues/1999,1999,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-03-26 04:57:16+00:00,,gensim/docs/notebooks/word2vec.ipnb doesn't work out of the box,I had to modify the code in order to get it to work
194,https://github.com/RaRe-Technologies/gensim/issues/2000,2000,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}]",closed,2018-03-26 10:20:59+00:00,,'Word2Vec' object has no attribute 'trainables',"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->
```
from gensim.models import word2vec
model = word2vec.Word2Vec.load('myModel')
```

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
I got this:
```
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/gensim/models/word2vec.py"", line 975, in load
    return super(Word2Vec, cls).load(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/gensim/models/base_any2vec.py"", line 629, in load
    model = super(BaseWordEmbeddingsModel, cls).load(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/gensim/models/base_any2vec.py"", line 278, in load
    return super(BaseAny2VecModel, cls).load(fname_or_handle, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/gensim/utils.py"", line 426, in load
    obj._load_specials(fname, mmap, compress, subname)
  File ""/usr/local/lib/python3.5/dist-packages/gensim/utils.py"", line 469, in _load_specials
    setattr(self, attrib, val)
  File ""/usr/local/lib/python3.5/dist-packages/gensim/utils.py"", line 1398, in new_func1
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/gensim/models/base_any2vec.py"", line 380, in syn1neg
    self.trainables.syn1neg = value
AttributeError: 'Word2Vec' object has no attribute 'trainables'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""word.py"", line 164, in <module>
    X_vector, Y_vector = XY_vector(X, Y)
  File ""word.py"", line 116, in XY_vector
    model = gensim.models.word2vec.Word2Vec.load('./word_vector/Word60.model')
  File ""/usr/local/lib/python3.5/dist-packages/gensim/models/word2vec.py"", line 979, in load
    return load_old_word2vec(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/gensim/models/deprecated/word2vec.py"", line 195, in load_old_word2vec
    new_model.min_alpha_yet_reached = old_model.min_alpha_yet_reached
AttributeError: 'Word2Vec' object has no attribute 'min_alpha_yet_reached'

```
<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->


#### Versions
I used gensim version 3.4.0, python version 3.5.2

#### Please share your model (very important for reproducing your error)
What should I do for this?

#### What's a python and OS?
ubuntu16.04LTS
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->


<!-- Thanks for contributing! -->

"
195,https://github.com/RaRe-Technologies/gensim/issues/2002,2002,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 175986, 'node_id': 'MDU6TGFiZWwxNzU5ODY=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/testing', 'name': 'testing', 'color': '444444', 'default': False, 'description': 'Issue related with testing (code, documentation, etc)'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2018-03-27 09:21:02+00:00,,Use coveralls,"While contributing in gensim I felt a need of an automated system which can confirm whether I have written tests corresponding to **every line of code** I wrote. I propose the immediate use of https://coveralls.io/ for ensuring this. 

Here is coveralls in action - https://coveralls.io/github/jellAIfish/omega?branch=master for my own repository."
196,https://github.com/RaRe-Technologies/gensim/issues/2005,2005,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-03-28 05:25:01+00:00,,LDA Python3 - TypeError: '>' not supported between instances of 'float' and 'NoneType',"I have trained an LDA model using gensim library and I am using it to extract topic vectors of a document and I am using the following code

    def clean_doc(data_string):    
        global en_stop
        tokenizer = RegexpTokenizer(r'\w+') #Create appropriate tokenizer
        p_stemmer = PorterStemmer() #Create object from Porter Stemmer
        #clean and tokenize document string
        raw = data_string.lower()
        tokens = tokenizer.tokenize(raw)
        # remove stop words from tokens
        stopped_tokens = [i for i in tokens if not i in en_stop]
        # stem tokens
        stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]
        return stemmed_tokens
    
    def infer_lda_vector(s, dictionary, model, dimensions):
        #s = s.decode('utf-8')
        vector = [0.0]*dimensions
        s = clean_doc(s)
        bow_vector = dictionary.doc2bow(s)   
        lda_vector = model[bow_vector]            
        for i in lda_vector:
            vector[i[0]] = i[1]
        return vector

I call it as follows:

    text = ""this a test""
    lda_vector = infer_lda_vector(text, dictionary, lda_model, 300)

This exact piece of code was working when I was using Python2.7 but when I updated my system to Python3.x, its throwing the following error:

    ---------------------------------------------------------------------------
    TypeError                                 Traceback (most recent call last)
    <ipython-input-36-723f03d03620> in <module>()
          1 text = ""this a a test""
    ----> 2 lda_vector = infer_lda_vector(text, dictionary, lda_model, 300)
          3 lda_vector
    
    <ipython-input-34-885205b68d9e> in infer_lda_vector(s, dictionary, model, dimensions)
         34     s = clean_doc(s)
         35     bow_vector = dictionary.doc2bow(s)
    ---> 36     lda_vector = model[bow_vector]
         37     for i in lda_vector:
         38         vector[i[0]] = i[1]
    
    C:\ProgramData\Anaconda3\lib\site-packages\gensim\models\ldamodel.py in __getitem__(self, bow, eps)
       1158             `(topic_id, topic_probability)` 2-tuples.
       1159         """"""
    -> 1160         return self.get_document_topics(bow, eps, self.minimum_phi_value, self.per_word_topics)
       1161 
       1162     def save(self, fname, ignore=('state', 'dispatcher'), separately=None, *args, **kwargs):
    
    C:\ProgramData\Anaconda3\lib\site-packages\gensim\models\ldamodel.py in get_document_topics(self, bow, minimum_probability, minimum_phi_value, per_word_topics)
        979         if minimum_probability is None:
        980             minimum_probability = self.minimum_probability
    --> 981         minimum_probability = max(minimum_probability, 1e-8)  # never allow zero values in sparse output
        982 
        983         if minimum_phi_value is None:
    
    TypeError: '>' not supported between instances of 'float' and 'NoneType'

    
What am I doing wrong?
"
197,https://github.com/RaRe-Technologies/gensim/issues/2006,2006,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}]",open,2018-03-28 15:21:14+00:00,,Addition of entity embedding model,"It would be really nice to have the entity embedding model to become part of the family of algorithms 
at gensim.
[Here](https://gist.github.com/shubham0704/78ffcb38756c7c0bcdf84e0d4f53baf8) is a short write up about the same.
Reference paper - > [link](https://arxiv.org/abs/1604.06737)"
198,https://github.com/RaRe-Technologies/gensim/issues/2009,2009,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-03-30 14:38:51+00:00,,LDA Python3 - TypeError: '>' not supported between instances of 'float' and 'NoneType',"I had reported the same issues some time back and it was fixed by reinstallation but the issue has reappeared and reinstallation is not resolving it.

I have trained an LDA model using gensim library and I am using it to extract topic vectors of a document and I am using the following code

    def clean_doc(data_string):    
        global en_stop
        tokenizer = RegexpTokenizer(r'\w+') #Create appropriate tokenizer
        p_stemmer = PorterStemmer() #Create object from Porter Stemmer
        #clean and tokenize document string
        raw = data_string.lower()
        tokens = tokenizer.tokenize(raw)
        # remove stop words from tokens
        stopped_tokens = [i for i in tokens if not i in en_stop]
        # stem tokens
        stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]
        return stemmed_tokens
    
    def infer_lda_vector(s, dictionary, model, dimensions):
        #s = s.decode('utf-8')
        print (s)
        vector = [0.0]*dimensions
        s = clean_doc(s)
        print (s)
        bow_vector = dictionary.doc2bow(s)   
        lda_vector = model[bow_vector]            
        for i in lda_vector:
            vector[i[0]] = i[1]
        return vector

I call it as follows:

    text = ""this a test""
    lda_vector = infer_lda_vector(text, dictionary, lda_model, 300)

This exact piece of code was working when I was using Python2.7 but when I updated my system to Python3.x, its throwing the following error:

```
this is a test on office and firefox
['test', 'offic', 'firefox']
[(4, 1), (85, 1), (1458, 1)]
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-12-ddb10c8f6b5d> in <module>()
      1 text = ""this is a test on office and firefox""
----> 2 lda_vector = infer_lda_vector(text, dictionary, lda_model, 300)
      3 lda_vector

<ipython-input-9-62f10637e316> in infer_lda_vector(s, dictionary, model, dimensions)
     36     bow_vector = dictionary.doc2bow(s)
     37     print (bow_vector)
---> 38     lda_vector = model[bow_vector]
     39     print (lda_vector)
     40     vector = [0.0]*dimensions

~\AppData\Local\Continuum\anaconda3\lib\site-packages\gensim\models\ldamodel.py in __getitem__(self, bow, eps)
   1158             `(topic_id, topic_probability)` 2-tuples.
   1159         """"""
-> 1160         return self.get_document_topics(bow, eps, self.minimum_phi_value, self.per_word_topics)
   1161 
   1162     def save(self, fname, ignore=('state', 'dispatcher'), separately=None, *args, **kwargs):

~\AppData\Local\Continuum\anaconda3\lib\site-packages\gensim\models\ldamodel.py in get_document_topics(self, bow, minimum_probability, minimum_phi_value, per_word_topics)
    979         if minimum_probability is None:
    980             minimum_probability = self.minimum_probability
--> 981         minimum_probability = max(minimum_probability, 1e-8)  # never allow zero values in sparse output
    982 
    983         if minimum_phi_value is None:

TypeError: '>' not supported between instances of 'float' and 'NoneType'
```

What am I doing wrong?
"
199,https://github.com/RaRe-Technologies/gensim/issues/2010,2010,[],closed,2018-03-31 00:28:18+00:00,,Compatibility issue with pathlib,"#### Description
There is a `TypeError` when I try to get files from disk using `pathlib` library.

#### Steps/Code/Corpus to Reproduce
```python
from pathlib import Path
import gensim
model_path = Path('d:/MasterFiles/Paper/DATA/')
# model.bin is the trained model file
model = gensim.models.KeyedVectors.load_word2vec_format(model_path / 'model.bin')
```

#### Actual Results
```python
TypeError                                 Traceback (most recent call last)
<ipython-input-6-7c1779a8b9c9> in <module>()
----> 1 model = gensim.models.KeyedVectors.load_word2vec_format(model_path / 'model.bin')

~\Anaconda3\lib\site-packages\gensim\models\keyedvectors.py in load_word2vec_format(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)
   1117         return _load_word2vec_format(
   1118             Word2VecKeyedVectors, fname, fvocab=fvocab, binary=binary, encoding=encoding, unicode_errors=unicode_errors,
-> 1119             limit=limit, datatype=datatype)
   1120 
   1121     def get_keras_embedding(self, train_embeddings=False):

~\Anaconda3\lib\site-packages\gensim\models\utils_any2vec.py in _load_word2vec_format(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)
    171 
    172     logger.info(""loading projection weights from %s"", fname)
--> 173     with utils.smart_open(fname) as fin:
    174         header = utils.to_unicode(fin.readline(), encoding=encoding)
    175         vocab_size, vector_size = (int(x) for x in header.split())  # throws for invalid file format

~\Anaconda3\lib\site-packages\smart_open\smart_open_lib.py in smart_open(uri, mode, **kw)
    213         return uri
    214     else:
--> 215         raise TypeError('don\'t know how to handle uri %s' % repr(uri))
    216 
    217 

TypeError: don't know how to handle uri WindowsPath('d:/MasterFiles/Paper/DATA/model.bin')
```

#### Versions
Windows-10-10.0.16299-SP0
Python 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]
NumPy 1.14.1
SciPy 0.19.1
gensim 3.4.0
FAST_VERSION 1"
200,https://github.com/RaRe-Technologies/gensim/issues/2013,2013,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-04-02 10:21:08+00:00,,load_fasttext_model() -> save() failed with no attribute generate_tokens(),"- i trained a fasttext model(sent2vec) on huge corpus and got 15G model.
  - trained by sent2vec : https://github.com/epfml/sent2vec

- and tried to load the fasttext model and save it using bellow code 
```
#!/usr/bin/env python
#-*- coding: utf8 -*-

import os
import sys
reload(sys)
sys.setdefaultencoding('utf-8')
from optparse import OptionParser

from gensim import models
import logging
logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)
from sparser import Sparser
import reader

# global variable
VERBOSE = 0

def load_wv(wv_path) :
        wv = models.fasttext.FastText.load_fasttext_format(wv_path, encoding='utf-8')
        if VERBOSE : print wv[u'가다']
        return wv

def save_wv(wv, save_path) :
        wv.save(save_path)

if __name__ == '__main__':

        parser = OptionParser()
        parser.add_option(""--verbose"", action=""store_const"", const=1, dest=""verbose"", help=""verbose mode"")
        parser.add_option(""-w"", ""--wvectors"", dest=""wv_path"", help=""word vector(fasttext binary format) path"", metavar=""WV_PATH"")
        parser.add_option(""-s"", ""--save"", dest=""save_path"", help=""save(gensim format) path"", metavar=""SAVE_PATH"")
        (options, args) = parser.parse_args()

        if options.verbose : VERBOSE = 1

        wv_path = options.wv_path
        save_path = options.save_path
        if not wv_path or not save_path :
                parser.print_help()
                sys.exit(1)

        wv = load_wv(wv_path)
        save_wv(wv, save_path)
```

- but, i got following errors
```
$ python fasttext2gensim.py -w news_model_morph.bin -s news_model_morph.gensim.bin
2018-04-02 19:12:44,623 : INFO : loading 853067 words for fastText model from news_model_morph.bin
2018-04-02 19:13:13,861 : INFO : loading weights for 853067 words for fastText model from news_model_morph.bin
2018-04-02 19:13:39,057 : INFO : loaded (853067, 700) weight matrix for fastText model from news_model_morph.bin
2018-04-02 19:13:39,057 : INFO : saving FastText object under news_model_morph.gensim.bin, separately None
2018-04-02 19:13:39,058 : INFO : not storing attribute vectors_ngrams_norm
2018-04-02 19:13:39,058 : INFO : storing np array 'vectors' to news_model_morph.gensim.bin.wv.vectors.npy
Traceback (most recent call last):
  File ""fasttext2gensim.py"", line 44, in <module>
    save_wv(wv, save_path)
  File ""fasttext2gensim.py"", line 25, in save_wv
    wv.save(save_path)
  File ""/usr/lib64/python2.7/site-packages/gensim/models/fasttext.py"", line 699, in save
    super(FastText, self).save(*args, **kwargs)
  File ""/usr/lib64/python2.7/site-packages/gensim/models/base_any2vec.py"", line 281, in save
    super(BaseAny2VecModel, self).save(fname_or_handle, **kwargs)
  File ""/usr/lib64/python2.7/site-packages/gensim/utils.py"", line 691, in save
    self._smart_save(fname_or_handle, separately, sep_limit, ignore, pickle_protocol=pickle_protocol)
  File ""/usr/lib64/python2.7/site-packages/gensim/utils.py"", line 548, in _smart_save
    compress, subname)
  File ""/usr/lib64/python2.7/site-packages/gensim/utils.py"", line 608, in _save_specials
    restores.extend(val._save_specials(cfname, None, sep_limit, ignore, pickle_protocol, compress, subname))
  File ""/usr/lib64/python2.7/site-packages/gensim/utils.py"", line 620, in _save_specials
    np.save(subname(fname, attrib), np.ascontiguousarray(val))
  File ""/data1/users/index.shin/.local/lib/python2.7/site-packages/numpy/lib/npyio.py"", line 511, in save
    pickle_kwargs=pickle_kwargs)
  File ""/data1/users/index.shin/.local/lib/python2.7/site-packages/numpy/lib/format.py"", line 565, in write_array
    version)
  File ""/data1/users/index.shin/.local/lib/python2.7/site-packages/numpy/lib/format.py"", line 308, in _write_array_header
    header = asbytes(_filter_header(header))
  File ""/data1/users/index.shin/.local/lib/python2.7/site-packages/numpy/lib/format.py"", line 459, in _filter_header
    for token in tokenize.generate_tokens(StringIO(string).readline):
AttributeError: 'module' object has no attribute 'generate_tokens'
```

- gensim, numpy version
```
>>> print gensim.__version__
3.4.0
>>> print numpy.__version__
1.14.2
```

- similar issue : https://groups.google.com/forum/#!topic/gensim/hHksTh8NIF4
"
201,https://github.com/RaRe-Technologies/gensim/issues/2014,2014,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 1602334472, 'node_id': 'MDU6TGFiZWwxNjAyMzM0NDcy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20MEDIUM', 'name': 'impact MEDIUM', 'color': '7af49f', 'default': False, 'description': 'Big annoyance for affected users'}]",open,2018-04-03 13:49:49+00:00,,model.wv.accuracy messes up the model object,"I was playing around with model.wv.accuracy to test the accuracy of my model. It worked fine when the only parameter I set was the filename:

`model.wv.accuracy(""questions-words.txt"")
`
Things get weird though when I set the 'most_similar' parameter of the function: 

`model.wv.accuracy(""questions-words.txt"", most_similar=gensim.models.KeyedVectors.most_similar_cosmul)`

First, it gives an error saying that gensim.models.KeyedVectors.most_similar_cosmul doesn't have a parameter named 'retrict_vocabulary'. 

Most importantly, right after that, the model vocabulary is messed up for some reason. That is, when calling model.wv.accuracy(""question-words.txt"") again, I get the following error: 

```
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
<ipython-input-36-41dd7cacf846> in <module>()
----> 1 model.wv.accuracy(""questions-words.txt"", most_similar=gensim.models.KeyedVectors.most_similar_cosmul)
      2 model.wv.evaluate_word_pairs(""wordsim353.tsv"")

/home/user/anaconda3/lib/python3.5/site-packages/gensim/models/keyedvectors.py in accuracy(self, questions, restrict_vocab, most_similar, case_insensitive)
    772 
    773         """"""
--> 774         ok_vocab = [(w, self.vocab[w]) for w in self.index2word[:restrict_vocab]]
    775         ok_vocab = {w.upper(): v for w, v in reversed(ok_vocab)} if case_insensitive else dict(ok_vocab)
    776 

/home/user/anaconda3/lib/python3.5/site-packages/gensim/models/keyedvectors.py in <listcomp>(.0)
    772 
    773         """"""
--> 774         ok_vocab = [(w, self.vocab[w]) for w in self.index2word[:restrict_vocab]]
    775         ok_vocab = {w.upper(): v for w, v in reversed(ok_vocab)} if case_insensitive else dict(ok_vocab)
    776 

KeyError: 'the'
```
calling model.wv.most_similar also gives the same error. 
"
202,https://github.com/RaRe-Technologies/gensim/issues/2015,2015,[],closed,2018-04-04 10:26:53+00:00,,AttributeError: 'Word2Vec' object has no attribute 'vector_size',"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
I'm trying to load an already trained word2vec model downloaded from [here](http://hlt.isti.cnr.it/wordembeddings/) by using the following code, as suggested by the aforementioned website:
`from gensim.models import Word2Vec
model=Word2Vec.load('wiki_iter=5_algorithm=skipgram_window=10_size=300_neg-samples=10.m')`
When I try to execute that code, I get the following error:
`UserWarning: detected Windows; aliasing chunkize to chunkize_serial
warnings.warn(""detected Windows; aliasing chunkize to chunkize_serial"")
Traceback (most recent call last):
File ""d:\DavideV\documents\visual studio 2017\Projects\tesi\tesi\tesi.py"", line 112, in <module>
model=Word2Vec.load('wiki_iter=5_algorithm=skipgram_window=10_size=300_neg-samples=10.m')
File ""C:\Users\admin\Anaconda3\lib\site-packages\gensim\models\word2vec.py"", line 979, in load
return load_old_word2vec(*args, **kwargs)
File ""C:\Users\admin\Anaconda3\lib\site-packages\gensim\models\deprecated\word2vec.py"", line 155, in load_old_word2vec
'size': old_model.vector_size,
AttributeError: 'Word2Vec' object has no attribute 'vector_size'`
I suppose that this is due to the fact that the model has probably been trained with a previous version of gensim, but I would prefer to avoid to retrain it.


#### Versions

Windows-10-10.0.16299-SP0
Python 3.6.3 |Anaconda, Inc.| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)]
gensim 3.4.0


<!-- Thanks for contributing! -->

"
203,https://github.com/RaRe-Technologies/gensim/issues/2017,2017,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2018-04-05 17:42:42+00:00,,`intersect_word2vec_format()` no longer works for Doc2Vec,"Recent refactors left `intersect_word2vec_format()` solely on `Word2Vec`, while its related-siblings `save_word2vec_format()`/`load_word2vec_format()` remain available elsewhere (`Doc2Vec`, `KeyeVectors`). 

See discussion in project group thread: https://groups.google.com/d/msg/gensim/pHMCj3LvW1o/5Ns0jbs9BQAJ

It definitely fits on `KeyedVectors`, and then could be used in any situation where a model already has initialized word-vectors (including `Doc2Vec`), though not necessarily by calling in the same way (on the top model). "
204,https://github.com/RaRe-Technologies/gensim/issues/2018,2018,[],closed,2018-04-05 21:58:15+00:00,,Word Embedding Models loaded through gensim.downloader crash when used in Celery Tasks,"#### Description
After loading models with the `gensim.downloader` api, using methods in a Celery task causes the worker to crash and the task to fail.

When running the function normally (not as a task), the function gives expected results.

When loading in models through `KeyedVectors.load_word2vec_format()`, the task executes without issue, both when using the original source files and the ones downloaded from the `gensim.downloader` api.

Possibly related: https://github.com/RaRe-Technologies/gensim/issues/1293

#### Steps/Code/Corpus to Reproduce

I've created a [gist](https://gist.github.com/pmbaumgartner/7b5d8d08392b21816c90e189c78277b4) with the relevant files to reproduce. There are 3 relevant files. 

- `tasks.py` contains the tasks and the model loading code. Currently loading models is commented out to test loading only one specific model at a time.
- `run.py` is generic code that is used to run the tasks.
- `Procfile` is used to run the redis-server and celery worker using [honcho](https://honcho.readthedocs.io/en/latest/index.html).

To run celery and redis with the Procfile and honcho, use `honcho start` from the shell.

After redis and celery are up, we can run the tasks. When running the task with one of the non-working models from the `gensim.downloder` api, the following occurs when attempting to run the task:

```
17:43:24 celery_worker.1 | [2018-04-05 17:43:24,697: INFO/MainProcess] Received task: tasks.most_sim[ab7aa3af-1b10-462f-accb-9c269d8eda2f]
17:43:24 celery_worker.1 | [2018-04-05 17:43:24,700: WARNING/ForkPoolWorker-7] hello
17:43:24 celery_worker.1 | [2018-04-05 17:43:24,703: ERROR/MainProcess] Process 'ForkPoolWorker-7' pid:1734 exited with 'signal 11 (SIGSEGV)'
17:43:24 celery_worker.1 | [2018-04-05 17:43:24,721: ERROR/MainProcess] Task handler raised error: WorkerLostError('Worker exited prematurely: signal 11 (SIGSEGV).',)
17:43:24 celery_worker.1 | Traceback (most recent call last):
17:43:24 celery_worker.1 |   File ""/Users/pbaumgartner/anaconda3/envs/celery-nlp/lib/python3.6/site-packages/billiard/pool.py"", line 1223, in mark_as_worker_lost
17:43:24 celery_worker.1 |     human_status(exitcode)),
17:43:24 celery_worker.1 | billiard.exceptions.WorkerLostError: Worker exited prematurely: signal 11 (SIGSEGV).
```

#### Expected Results
When the task completes regularly, I am able to retrieve the result and I see the following from the celery worker:

```
17:40:59 celery_worker.1 | [2018-04-05 17:40:59,879: INFO/MainProcess] Received task: tasks.most_sim[8096ab3a-de4a-45d2-8814-cc4c2bfe15d0]
17:40:59 celery_worker.1 | [2018-04-05 17:40:59,881: WARNING/ForkPoolWorker-8] hello
17:40:59 celery_worker.1 | [2018-04-05 17:40:59,910: INFO/ForkPoolWorker-8] Task tasks.most_sim[8096ab3a-de4a-45d2-8814-cc4c2bfe15d0] succeeded in 0.030041170000913553s: [('dog', 0.9218006134033203), ('rabbit', 0.8487820625305176), ('monkey', 0.8041081428527832), ('rat', 0.7891963124275208), ('cats', 0.7865269780158997), ('snake', 0.7798910140991211), ('dogs', 0.7795814871788025), ('pet', 0.7792249917984009), ('mouse', 0.773166835308075), ('bite', 0.7728800177574158)]
```

#### Actual Results
```
17:43:24 celery_worker.1 | [2018-04-05 17:43:24,697: INFO/MainProcess] Received task: tasks.most_sim[ab7aa3af-1b10-462f-accb-9c269d8eda2f]
17:43:24 celery_worker.1 | [2018-04-05 17:43:24,700: WARNING/ForkPoolWorker-7] hello
17:43:24 celery_worker.1 | [2018-04-05 17:43:24,703: ERROR/MainProcess] Process 'ForkPoolWorker-7' pid:1734 exited with 'signal 11 (SIGSEGV)'
17:43:24 celery_worker.1 | [2018-04-05 17:43:24,721: ERROR/MainProcess] Task handler raised error: WorkerLostError('Worker exited prematurely: signal 11 (SIGSEGV).',)
17:43:24 celery_worker.1 | Traceback (most recent call last):
17:43:24 celery_worker.1 |   File ""/Users/pbaumgartner/anaconda3/envs/celery-nlp/lib/python3.6/site-packages/billiard/pool.py"", line 1223, in mark_as_worker_lost
17:43:24 celery_worker.1 |     human_status(exitcode)),
17:43:24 celery_worker.1 | billiard.exceptions.WorkerLostError: Worker exited prematurely: signal 11 (SIGSEGV).
```

#### Versions
```python
>>> import platform; print(platform.platform())
Darwin-17.4.0-x86_64-i386-64bit
>>> import sys; print(""Python"", sys.version)
Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:14:23)
[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.14.2
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.0.1
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.4.0
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 0
```

There is also a `requirements.txt` file in the gist."
205,https://github.com/RaRe-Technologies/gensim/issues/2019,2019,[],closed,2018-04-06 02:49:04+00:00,,Dynamic Author Topic Model,"It would be nice to have a dynamic author topic model implemented in gensim. See an [example here](https://www.researchgate.net/profile/Shuo_Xu/publication/257836005_Author-Topic_over_Time_AToT_A_Dynamic_Users'_Interest_Model/links/00463525f3d6b42e65000000.pdf) using Gibbs sampling. Any plan to include something similar?


"
206,https://github.com/RaRe-Technologies/gensim/issues/2020,2020,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2018-04-06 10:38:45+00:00,,Fix implementation of smartirs Document Frequency n,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
tfidfmodel.updated_wglobal(docfreq, totaldoc, 'n') returns utils.identity(docfreq) instead of 1.
This means that all term frequencies will be multiplied by the document frequency. For a large corpus this is particularly bad and will cause normalisation to crash.


<!-- Thanks for contributing! -->

"
207,https://github.com/RaRe-Technologies/gensim/issues/2022,2022,[],closed,2018-04-06 10:57:59+00:00,,"Gensim lda update gives index error expElogbetad = self.expElogbeta[:, ids]","I am using gensim's lda model for topic modelling. I created the id to word mapping using the following : 
dictionary = gensim.corpora.Dictionary(text_content), where text_content is a list of lists containing word tokens.
and then I am creating the model using the following:

```python
corpus = [dictionary.doc2bow(text, allow_update=True) for text in text_content]
lda_model = gensim.models.LdaMulticore(num_topics=number_of_topics, corpus=corpus)
```

the Model is working fine till this point. However, after updating the dictionary with new documents, when I attempt to update the lda model with the new corpus, I get error:

```python
new_corpus = [dictionary.doc2bow(text, allow_update=True) for text in new_text_content]
lda_model.update(new_corpus)

The error:
Traceback (most recent call last):
  File ""C:\Users\Parabole\AppData\Local\Programs\Python\Python36\lib\multiprocessing\process.py"", line 249, in _bootstrap
    self.run()
  File ""C:\Users\Parabole\AppData\Local\Programs\Python\Python36\lib\multiprocessing\process.py"", line 93, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Users\Parabole\AppData\Local\Programs\Python\Python36\lib\multiprocessing\pool.py"", line 103, in worker
    initializer(*initargs)
  File ""C:\Users\Parabole\AppData\Local\Programs\Python\Python36\lib\site-packages\gensim\models\ldamulticore.py"", line 277, in worker_e_step
    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?
  File ""C:\Users\Parabole\AppData\Local\Programs\Python\Python36\lib\site-packages\gensim\models\ldamodel.py"", line 492, in do_estep
    gamma, sstats = self.inference(chunk, collect_sstats=True)
  File ""C:\Users\Parabole\AppData\Local\Programs\Python\Python36\lib\site-packages\gensim\models\ldamodel.py"", line 444, in inference
    expElogbetad = self.expElogbeta[:, ids]
IndexError: index 50 is out of bounds for axis 1 with size 50
C:\Users\Parabole\AppData\Local\Programs\Python\Python36\lib\site-packages\gensim\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial
  warnings.warn(""detected Windows; aliasing chunkize to chunkize_serial"")
```"
208,https://github.com/RaRe-Technologies/gensim/issues/2023,2023,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 175642, 'node_id': 'MDU6TGFiZWwxNzU2NDI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/wishlist', 'name': 'wishlist', 'color': 'd7e102', 'default': False, 'description': 'Feature request'}]",open,2018-04-08 19:39:11+00:00,,Adding quadratic regularization proves to boost the performance of word2vec?,"The recent paper [Revisiting Skip-Gram Negative Sampling Model with Regularization](https://arxiv.org/pdf/1804.00306.pdf) extends the original skip-gram negative sampling (SGNS) by adding simply quadratic regularization, which is reported to substantially boost Google’s analytical reasoning task.

I am wondering whether we can also incorporate this quadratic regularization feature into gensim's word2vec.


Thanks,
Matt
"
209,https://github.com/RaRe-Technologies/gensim/issues/2024,2024,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-04-10 12:45:39+00:00,,Word2Vec scan_vocab() pruning method,"Not really an issue, but i wondered why it is done that way.

In the word2vec scan_vocab() method the `min_reduce` count is increased after every pruning ([link to code](https://github.com/RaRe-Technologies/gensim/blob/06f5f5c4fa9fb54a169e53034a3bf3fa035cbc3c/gensim/models/word2vec.py#L1187)). New tokens, that appear late or evenly spreaded in the dataset will be very likely pruned out that way. 

Wouldn't it be better to restart the pruning from 1 every time pruning is needed and increase it by 1 until vocab_size < max_vocab_size?


"
210,https://github.com/RaRe-Technologies/gensim/issues/2025,2025,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}]",open,2018-04-10 14:35:17+00:00,,model.trainables.update_weights executes even when no new vocabulary is added,"This one is not a major issue, but I think it is important to fix in order to avoid confusion. 

Even when there is no new vocabulary, `model.trainables.update_weights`  takes a while to execute (with no effect on the model) because it doesn't check whether `gained_vocab` is greater than zero or not. 

https://github.com/RaRe-Technologies/gensim/blob/06f5f5c4fa9fb54a169e53034a3bf3fa035cbc3c/gensim/models/word2vec.py#L1467

should be replaced by:
```python
gained_vocab = len(wv.vocab) - len(wv.vectors)
if gained_vocab <= 0:
	raise RuntimeError(
	    ""There is no new vocabulary added.  ""
	    ""If you want to update the weights with a new vocabulary, please first update model.vocab""
	)

```
"
211,https://github.com/RaRe-Technologies/gensim/issues/2028,2028,[],closed,2018-04-11 21:22:01+00:00,,"TypeError: doc2bow expects an array of unicode tokens on input, not a single string","Hello,

I looked for all suggestion, where everyone says to break the string into tokens by split function. All that has been done already, but still it seems to have same error again and again.

```
for r in words:
        if not r in stop_words:
            processed_txt+=str(str(ps.stem(r) + "" ""))
    tokenizer = RegexpTokenizer(r'\w+')
    tokens = tokenizer.tokenize(processed_txt)
    #print(tokens)
    dictionary = corpora.Dictionary(tokens)
    #corpus = [dictionary.doc2bow(text) for text in tokens]
    print(dictionary)
```

So now it gives below error.

> raise TypeError(""doc2bow expects an array of unicode tokens on input, not a 
> single string"")
> TypeError: doc2bow expects an array of unicode tokens on input, not a single 
> string

and the output under ""tokens"" variable seems like this as below

`['becom', 'effect', 'willingli', 'without', 'need', 'obtain', 'knowledg', 'other', 'obtain', 'acquir', 'must', 'testamentari','claim', 'ownership', 'task', 'establish', 'endow', 'recept', 'willing', 'willsend', 'anoth', 'given', 'efficaci', 'presuppos']`

Please help"
212,https://github.com/RaRe-Technologies/gensim/issues/2029,2029,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-04-12 19:36:02+00:00,,word2vec2tensor.py : Number of tensors do not match the number of lines in metadata,"#### Description
When I used word2vec2tensor.py on my model, the resulting tsv files (_tensor and _metadata) have different dimensions: when I load them into TensorBoard, it tells me that ""Number of tensors (10000) do not match the number of lines in metadata (25681)"".

Is there a max limit in the number of tensors produced by the code?

#### Expected Results
tensor.tsv and metadata.tsv with the same number 

#### Actual Results
tensor.tsv has 10000 tensors, metadata  has 25681.


#### Versions
""numpy"",""1.11.0""
""sklearn"", ""0.17""
""scipy"", ""0.15.1""
'gensim','3.1.0'


"
213,https://github.com/RaRe-Technologies/gensim/issues/2031,2031,[],closed,2018-04-16 00:10:36+00:00,,How to use PerplexityMetric with LdaMulticore?,How can I get the perplexity from LdaMulticore? Since the object doesn't have a callbacks attributes I don't see how to use PerplexityMetric.
214,https://github.com/RaRe-Technologies/gensim/issues/2032,2032,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-04-16 14:30:01+00:00,,Word2Vec evaluate_word_pairs,"I am trying to get Pearsons and Spearmans correlation using the method evaluate_word_pairs.
When I run 
`word_vectors.evaluate_word_pairs(os.path.join(module_path, 'test_data','wordsim353.tsv'))`

I get this error:
```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.6/site-packages/gensim/models/keyedvectors.py"", line 976, in evaluate_word_pairs
    ok_vocab = [(w, self.vocab[w]) for w in self.index2word[:restrict_vocab]]
  File ""/usr/local/lib/python3.6/site-packages/gensim/models/keyedvectors.py"", line 976, in <listcomp>
    ok_vocab = [(w, self.vocab[w]) for w in self.index2word[:restrict_vocab]]
KeyError: '</s>'
```

Versions:
Darwin-17.5.0-x86_64-i386-64bit
Python 3.6.1 (v3.6.1:69c0db5050, Mar 21 2017, 01:21:04)
[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)]

NumPy 1.14.2
gensim 3.4.0
FAST_VERSION 0


<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

"
215,https://github.com/RaRe-Technologies/gensim/issues/2034,2034,[],closed,2018-04-21 10:47:19+00:00,,obsolete python-dateutil requirement,"#### Description
I had to remove your package from my Dockerfile modeled on the popular Kaggle/docker-python container, because gensim requires indirectly an obsolete version of python-dateutil  [required: <2.7.0,>=2.1]:

The dependency path looks like this:
gensim -> smart-open -> boto3 -> botocore -> python-dateutil

#### Steps/Code/Corpus to Reproduce
```
pip install pipdeptree
pipdeptree --reverse --packages python-dateutil
```

During container building I get this error message:
```
botocore 1.10.4 has requirement python-dateutil<2.7.0,>=2.1, but you'll have python-dateutil 2.7.2 which is incompatible.
```

Output from pipdeptree:
```
python-dateutil==2.7.2
  - arrow==0.12.1 [requires: python-dateutil]
  - bokeh==0.12.15 [requires: python-dateutil>=2.1]
  - botocore==1.10.4 [requires: python-dateutil>=2.1,<2.7.0]
    - boto3==1.7.4 [requires: botocore<1.11.0,>=1.10.4]
      - smart-open==1.5.7 [requires: boto3]
        - gensim==3.4.0 [requires: smart-open>=1.2.1]
[..]
```"
216,https://github.com/RaRe-Technologies/gensim/issues/2036,2036,[],closed,2018-04-24 13:09:59+00:00,,Documentation on jointly learning feature representations with a higher task,"I can't find any documentation on training, say, FastText jointly with a classification task.

The `callbacks` parameter is mentioned in the API documentation but not explained.

"
217,https://github.com/RaRe-Technologies/gensim/issues/2037,2037,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",open,2018-04-30 07:56:43+00:00,,Documentation fixes,"This issue collects PRs related to improving the Gensim documentation.

Merged
--------

https://github.com/RaRe-Technologies/gensim/pull/1633
https://github.com/RaRe-Technologies/gensim/pull/1625
https://github.com/RaRe-Technologies/gensim/pull/1640
https://github.com/RaRe-Technologies/gensim/pull/1702
https://github.com/RaRe-Technologies/gensim/pull/1684
https://github.com/RaRe-Technologies/gensim/pull/1709
https://github.com/RaRe-Technologies/gensim/pull/1739
https://github.com/RaRe-Technologies/gensim/pull/1681
https://github.com/RaRe-Technologies/gensim/pull/1806
https://github.com/RaRe-Technologies/gensim/pull/1802
https://github.com/RaRe-Technologies/gensim/pull/1797
https://github.com/RaRe-Technologies/gensim/pull/1804
https://github.com/RaRe-Technologies/gensim/pull/1803
https://github.com/RaRe-Technologies/gensim/pull/1805
https://github.com/RaRe-Technologies/gensim/pull/1714
https://github.com/RaRe-Technologies/gensim/pull/1814
https://github.com/RaRe-Technologies/gensim/pull/1729
https://github.com/RaRe-Technologies/gensim/pull/1793
https://github.com/RaRe-Technologies/gensim/pull/1801
https://github.com/RaRe-Technologies/gensim/pull/1913
https://github.com/RaRe-Technologies/gensim/pull/1859
https://github.com/RaRe-Technologies/gensim/pull/1835
https://github.com/RaRe-Technologies/gensim/pull/1792
https://github.com/RaRe-Technologies/gensim/pull/1904
https://github.com/RaRe-Technologies/gensim/pull/1910
https://github.com/RaRe-Technologies/gensim/pull/1919
https://github.com/RaRe-Technologies/gensim/pull/1892
https://github.com/RaRe-Technologies/gensim/pull/1880
https://github.com/RaRe-Technologies/gensim/pull/1861
https://github.com/RaRe-Technologies/gensim/pull/1876
https://github.com/RaRe-Technologies/gensim/pull/2026
https://github.com/RaRe-Technologies/gensim/pull/1944

WIP
----
https://github.com/RaRe-Technologies/gensim/pull/1809

"
218,https://github.com/RaRe-Technologies/gensim/issues/2038,2038,[],closed,2018-04-30 19:53:31+00:00,,"KeyError: ""word 'གུ་རུ་' not in vocabulary""","#### Description

Regardless of trying out several answers from stackoverflow etc. I'm still getting the ""word not found in vocabulary""

#### Steps/Code/Corpus to Reproduce

```
documents = [['༄༅། '],
 ['ལྷ་ བྲག་ ཐུགས་ སྒྲུབ་ དྲག་པོ་ རྩལ་ གྱི་ སྨིན་ ལམ་ དབང་ གི་ ཆུ་བོ་ ཆེན་ མོ་ ཁྱེར་ བདེར་ བསྡེབས་པ་ རིན་ཆེན་ ཕྲ་ མཛེས་ ཞེས་ བྱ་བ་ བཞུགས་ སོ'],
 [' ན་མོ་ གུ་རུ་ ཀྲོ་ ཤྲཱི་ ཧེ་ རུ་ ཀཱ་'],
 [' རིག་རྩལ་ དབང་ ཐོབ་ རྡོ་རྗེ་ དྲག་པོ་ རྩལ'],
 ['དཀོན་མཆོག་ རྩ་ གསུམ་ ཡོངས་འདུས་ ཞབས་ པདྨོ'],
 ['མི་ འབྲལ་ གི་ ཐིག་ལེར་ བཀོད་པ་ ལ'],
 ['རྡོ་རྗེའི་ བྱིན་ ཕོབ་ བཀའ་ ཡི་ གནང་ སྩོལ'],
 ['བོད་ ཁམས་ སྐྱོབ་ བྱེད་ མཛོད་ ལྔའི་ ལྷོ་ཕྱོགས་ བཅུད'],
 ['དྲག་རྩལ་ ཐུགས་ སྒྲུབ་ ཆོས་ཚན་ ཉེར་ ལྔ་ པའི'],
 ['བདུན་ པ་ ལས་ཅན་ སྨིན་ ལམ་ ཐེམས་ ཀྱི']]

model = gensim.models.Word2Vec(
    documents,
    size=150,
    window=10,
    min_count=1,
    workers=10)
model.train(documents, total_examples=len(documents), epochs=10)

model['གུ་རུ་']
```

#### Actual Results

```
KeyError                                  Traceback (most recent call last)
<ipython-input-153-ed3ff6a264de> in <module>()
     26 model.train(documents, total_examples=len(documents), epochs=10)
     27 
---> 28 model['གུ་རུ་']

~/dev/astetik_test/lib/python3.6/site-packages/gensim/utils.py in new_func1(*args, **kwargs)
   1396                     stacklevel=2
   1397                 )
-> 1398                 return func(*args, **kwargs)
   1399 
   1400             return new_func1

~/dev/astetik_test/lib/python3.6/site-packages/gensim/models/word2vec.py in __getitem__(self, words)
    819         Refer to the documentation for `gensim.models.keyedvectors.Word2VecKeyedVectors.__getitem__`
    820         """"""
--> 821         return self.wv.__getitem__(words)
    822 
    823     @deprecated(""Method will be removed in 4.0.0, use self.wv.__contains__() instead"")

~/dev/astetik_test/lib/python3.6/site-packages/gensim/models/keyedvectors.py in __getitem__(self, entities)
    167         if isinstance(entities, string_types):
    168             # allow calls like trained_model['office'], as a shorthand for trained_model[['office']]
--> 169             return self.get_vector(entities)
    170 
    171         return vstack([self.get_vector(entity) for entity in entities])

~/dev/astetik_test/lib/python3.6/site-packages/gensim/models/keyedvectors.py in get_vector(self, word)
    275 
    276     def get_vector(self, word):
--> 277         return self.word_vec(word)
    278 
    279     def words_closer_than(self, w1, w2):

~/dev/astetik_test/lib/python3.6/site-packages/gensim/models/keyedvectors.py in word_vec(self, word, use_norm)
    272             return result
    273         else:
--> 274             raise KeyError(""word '%s' not in vocabulary"" % word)
    275 
    276     def get_vector(self, word):

KeyError: ""word 'གུ་རུ་' not in vocabulary""


```

#### Versions

Darwin-15.6.0-x86_64-i386-64bit
Python 3.6.5 (default, Mar 30 2018, 06:41:49) 
[GCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.42.1)]
NumPy 1.14.2
SciPy 1.0.1
gensim 3.4.0
FAST_VERSION 0


"
219,https://github.com/RaRe-Technologies/gensim/issues/2039,2039,[],closed,2018-05-02 05:10:25+00:00,,"Differen values on ""get_latest_training_loss"" in Word2Vec","I train a Word2Vec using the standard way described in the API document. To get loss of each epoch, I also train the same model with decreasing learning rate per epoch. 
Based on the [source code](https://github.com/RaRe-Technologies/gensim/blob/916e423a1654d87646fc522d8862a81c7a7cb4fc/gensim/models/base_any2vec.py#L579), the internal learning rate is decreasing linearly per epoch, so I do the same thing as shown below. The last loss values are quite different. 

* Standard way

 ```
word2vec_params = {
    'sg': 0,  # 0 ： CBOW； 1 : skip-gram
    ""size"": 300,
    ""alpha"": 0.5,
    ""min_alpha"": 0.001,
    'window':10,
    'min_count': 1,
    'seed': 1,
    ""workers"": 4,
    ""negative"": 0,
    ""hs"": 1,  # 0: negative sampling, 1:hierarchical  softmax
    'compute_loss': True,
    'iter': 10,
    'cbow_mean':1,
}

model = Word2Vec(**word2vec_params)
model.build_vocab(sentences)

trained_word_count, raw_word_count = model.train(sentences, compute_loss=True,
                                                 total_examples=model.corpus_count,
                                                 epochs=model.epochs)
model.get_latest_training_loss()
# return: 49245.1171875
```

* Per epoch (type 1) 

start alpha = end_alpha
```
model = Word2Vec(**word2vec_params)
model.build_vocab(sentences)
losses = []
learning_rate = 0.5
step_size = (0.5 - 0.001) / 10

for i in range(10):
    trained_word_count, raw_word_count = model.train(sentences, compute_loss=True,
                                                     start_alpha=learning_rate,
                                                     end_alpha=learning_rate,
                                                     total_examples=model.corpus_count,
                                                     epochs=1)
    loss = model.get_latest_training_loss()
    losses.append(loss)
    print(i, loss, learning_rate)
    learning_rate -= step_size
```
Each epoch loss is 
```
[58784.37109375,
 2431.101806640625,
 1676.5684814453125,
 1455.739990234375,
 1259.876953125,
 1206.9366455078125,
 1156.148193359375,
 1021.84326171875,
 1008.6217041015625,
 887.54541015625]
```



* Per epoch (type 2) 

start_alpha - end_alpha = step_size
```
model = Word2Vec(**word2vec_params)
model.build_vocab(sentences)
losses = []
learning_rate = 0.5
step_size = (0.5 - 0.001) / 10

for i in range(10):
    end_lr = learning_rate - step_size
    trained_word_count, raw_word_count = model.train(sentences, compute_loss=True,
                                                     start_alpha=learning_rate,
                                                     end_alpha=end_lr,
                                                     total_examples=model.corpus_count,
                                                     epochs=1)
    loss = model.get_latest_training_loss()
    losses.append(loss)
    print(i, loss, learning_rate)
    learning_rate -= step_size
```
Each epoch loss is 
```
[35804.48828125,
 2652.100830078125,
 1748.483642578125,
 1293.23583984375,
 1150.828369140625,
 918.9574584960938,
 951.2122192382812,
 871.8506469726562,
 888.2496337890625,
 846.38427734375]
```"
220,https://github.com/RaRe-Technologies/gensim/issues/2040,2040,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-05-03 02:02:02+00:00,,Forget my password,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
TODO: change commented example
<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce
<!--
Example:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->

#### Expected Results
<!-- Example: Expected shape of (100,2).-->

#### Actual Results
<!-- Example: Actual shape of (100,5). 

Please paste or specifically describe the actual output or traceback. -->

#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->


<!-- Thanks for contributing! -->

"
221,https://github.com/RaRe-Technologies/gensim/issues/2041,2041,[],closed,2018-05-03 04:41:53+00:00,,Can not build similarity matrix when the dictionary contains word indices are not continuous,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
For some reasons, the gensim.corpora.Dictionary contains word indices are not continuous. I met the `KeyError` in _similarity_matrix()_ function when it tried to re-index from 0 to n-1. 

<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce
```
import gensim.downloader as api

def get_similarity_matrix(dictionary):
    '''
    In some cases, the dictionary contains word indices are not continuous.
    For example, the dictionary contains theses items: (1, u'car'), (2, u'so'), (4, 'nice')
    '''
    w2v_model = api.load('glove-wiki-gigaword-50', return_path=False)
    return w2v_model.wv.similarity_matrix(dictionary, nonzero_limit=100)
```
<!--
Example:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->

#### Expected Results
Term similarity matrix in `scipy.sparse.csc_matrix` format
<!-- Example: Expected shape of (100,2).-->

#### Actual Results
```
    return w2v_model.wv.similarity_matrix(dictionary, nonzero_limit=100)
  File ""/home/jen/anaconda2/lib/python2.7/site-packages/gensim/models/keyedvectors.py"", line 510, in similarity_matrix
    w1 = dictionary[w1_index]
  File ""/home/jen/anaconda2/lib/python2.7/site-packages/gensim/corpora/dictionary.py"", line 104, in __getitem__
    return self.id2token[tokenid]  # will throw for non-existent ids
KeyError: 0
ERROR: Non-zero return code '1' from command: Process exited with status 1
```
<!-- Example: Actual shape of (100,5). 

Please paste or specifically describe the actual output or traceback. -->

#### Versions
('Python', '2.7.14 |Anaconda custom (64-bit)| (default, Mar 27 2018, 17:29:31) \n[GCC 7.2.0]')
('NumPy', '1.14.2')
('SciPy', '1.0.1')
('gensim', '3.4.0')
('FAST_VERSION', 1)

<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->


<!-- Thanks for contributing! -->

"
222,https://github.com/RaRe-Technologies/gensim/issues/2043,2043,[],closed,2018-05-09 23:04:49+00:00,,Performance question on sorting on Dictionary.doc2bow and MmWriter.write_vector,"I have a question on performance. I have several large documents, on the order of several megabytes, and was performing some profiling and noticed some hot spots.

I see that the doc2bow on Dictionary on returning the result, i.e. list of tuples of tokenid's, and their frequency, sorts this list
```
# return tokenids, in ascending id order
result = sorted(iteritems(result))
```
What is more interesting is that this behavior is not defined in the documentation

```
Convert `document` into the bag-of-words (BoW) format = list of (token_id, token_count)
```

Then when saving  the document into market matrix file, using MmWriter.write_vector, the  tokenids are again sorted.
```
vector = sorted((i, w) for i, w in vector if abs(w) > 1e-12)  # ignore near-zero entries
```

Is there a specific reason why the tokenids are sorted? I can see from a debugging perspective, but not from a performance aspect, and the sorting can always be done by the user after calling doc2bow, or prior to calling write_vector.

I have another side question on MmWriter, why is it writing to files in binary mode, when either it's text, i.e. the header line, or values of integer and/or float, as I'm concerned with the overhead that  
```
self.fout.write(utils.to_utf8(""%i %i %s\n"" % (docno + 1, termid + 1, weight)))
```
adds, in performing the conversion to binary and the string formating, when these values are integers  for docno and termid, and weight can be either integer or float."
223,https://github.com/RaRe-Technologies/gensim/issues/2045,2045,[],closed,2018-05-11 08:41:29+00:00,,Importing fasttext models still not working,"from gensim.models.wrappers import FastText
fasttext_model = FastText.load_fasttext_format('wiki-news-300d-1M.vec')
print(fasttext_model(""TestTest""))

results in: NotImplementedError: Supervised fastText models are not supported

Alternative approach:
from gensim.models import KeyedVectors
fasttext_model = KeyedVectors.load_word2vec_format('wiki-news-300d-1M.vec')
print(fasttext_model(""TestTest""))

results in: ""KeyError(""word '%s' not in vocabulary"" % word)

I would have expected these issues fixed by this update: https://github.com/RaRe-Technologies/gensim/pull/1916. Could you please check?

#### Versions
Linux-4.4.0-124-generic-x86_64-with-Ubuntu-16.04-xenial
Python 3.5.2 (default, Nov 23 2017, 16:37:01) 
[GCC 5.4.0 20160609]
NumPy 1.13.3
SciPy 1.0.1
gensim 3.4.0
FAST_VERSION 1

"
224,https://github.com/RaRe-Technologies/gensim/issues/2046,2046,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}]",open,2018-05-12 04:50:03+00:00,,Error while importing old wiki-dump (2010) with `WikiCorpus`,"#### Description
When I try to load the following Wikicorpus from 2010 ([Link](https://dumps.wikimedia.org/archive/enwiki/20100312/enwiki-20100312-pages-articles.xml.bz2)) I get an error (see bellow)


#### Code
```python
from gensim.corpora import WikiCorpus, MmCorpus
import gensim
import pattern
import pickle
import logging
import os.path
import sys


if __name__ == '__main__':
    program = os.path.basename(sys.argv[0])
    logger = logging.getLogger(program)

    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s')
    logging.root.setLevel(level=logging.INFO)
    logger.info(""running %s"", ' '.join(sys.argv))

    wiki_corpus = WikiCorpus('enwiki-20100312-pages-articles.xml.bz2', lemmatize=True)
    print('corpus loaded')
```

#### Expected Results
Correct processing of the wikipedia corpus


#### Actual Results
```
C:\Users\fabiansvenkarst\Documents\BA\Wiki_py27\venv\Scripts\python.exe C:/Users/fabiansvenkarst/Documents/BA/Wiki_py27/Wiki_corpus_Verarbeitung.py
C:\Users\fabiansvenkarst\Documents\BA\Wiki_py27\venv\lib\site-packages\gensim\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial
  warnings.warn(""detected Windows; aliasing chunkize to chunkize_serial"")
2018-05-12 04:38:51,516 : INFO : running C:/Users/fabiansvenkarst/Documents/BA/Wiki_py27/Wiki_corpus_Verarbeitung.py
Traceback (most recent call last):
  File ""C:/Users/fabiansvenkarst/Documents/BA/Wiki_py27/Wiki_corpus_Verarbeitung.py"", line 20, in <module>
    wiki_corpus = WikiCorpus('enwiki-20100312-pages-articles.xml.bz2', lemmatize=True)
  File ""C:\Users\fabiansvenkarst\Documents\BA\Wiki_py27\venv\lib\site-packages\gensim\corpora\wikicorpus.py"", line 552, in __init__
    self.dictionary = dictionary or Dictionary(self.get_texts())
  File ""C:\Users\fabiansvenkarst\Documents\BA\Wiki_py27\venv\lib\site-packages\gensim\corpora\dictionary.py"", line 79, in __init__
    self.add_documents(documents, prune_at=prune_at)
  File ""C:\Users\fabiansvenkarst\Documents\BA\Wiki_py27\venv\lib\site-packages\gensim\corpora\dictionary.py"", line 187, in add_documents
    for docno, document in enumerate(documents):
  File ""C:\Users\fabiansvenkarst\Documents\BA\Wiki_py27\venv\lib\site-packages\gensim\corpora\wikicorpus.py"", line 587, in get_texts
    for group in utils.chunkize(texts, chunksize=10 * self.processes, maxsize=1):
  File ""C:\Users\fabiansvenkarst\Documents\BA\Wiki_py27\venv\lib\site-packages\gensim\utils.py"", line 1219, in chunkize
    for chunk in chunkize_serial(corpus, chunksize, as_numpy=as_numpy):
  File ""C:\Users\fabiansvenkarst\Documents\BA\Wiki_py27\venv\lib\site-packages\gensim\utils.py"", line 1153, in chunkize_serial
    wrapped_chunk = [list(itertools.islice(it, int(chunksize)))]
  File ""C:\Users\fabiansvenkarst\Documents\BA\Wiki_py27\venv\lib\site-packages\gensim\corpora\wikicorpus.py"", line 579, in <genexpr>
    ((text, self.lemmatize, title, pageid, tokenization_params)
  File ""C:\Users\fabiansvenkarst\Documents\BA\Wiki_py27\venv\lib\site-packages\gensim\corpora\wikicorpus.py"", line 370, in extract_pages
    ns = elem.find(ns_path).text
AttributeError: 'NoneType' object has no attribute 'text'
```

#### Versions
('Python', '2.7.11 (v2.7.11:6d1b6a68f775, Dec  5 2015, 20:40:30) [MSC v.1500 64 bit (AMD64)]')
('NumPy', '1.14.3')
('SciPy', '1.1.0')
('gensim', '3.4.0')
('FAST_VERSION', 0)

"
225,https://github.com/RaRe-Technologies/gensim/issues/2049,2049,[],closed,2018-05-15 04:31:41+00:00,,Issue in class HashDictionary,"My goal is to have a dictionary and a bag of words model by streaming over the corpus stream only once (fully online learning). For this, I looked at the Hashing trick described in the tutorials.

In `HashDictionary.add_documents()` method, there are [calls](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/corpora/hashdictionary.py#L188) to the `doc2bow()` method which forms a Bag of Words model for the current document and [returns](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/corpora/hashdictionary.py#L260) the same.

But the value returned by `doc2bow()`is not stored in any variable in `add_documents()`. Thus, although a bag of words model is formed, there is no way to view/process it without using another corpus stream.

I am not sure if this is expected behavior, but by moving the functionality of add_documents to an `__iter__()` method (and a few other changes), I could get the bag-of-words stream directly from the HashDictionary object. But this entails that the Dictionary wouldn't be formed till I iterate over the HashDictionary object.


Version Information:

Darwin-17.2.0-x86_64-i386-64bit
Python 3.6.2 |Continuum Analytics, Inc.| (default, Jul 20 2017, 13:14:59) 
[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]
NumPy 1.13.1
SciPy 1.0.0
gensim 3.4.0
FAST_VERSION 0

"
226,https://github.com/RaRe-Technologies/gensim/issues/2051,2051,"[{'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 708430967, 'node_id': 'MDU6TGFiZWw3MDg0MzA5Njc=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/performance', 'name': 'performance', 'color': 'd93f0b', 'default': False, 'description': 'Issue related to performance (in HW meaning)'}]",closed,2018-05-15 19:41:05+00:00,,Redundant get_Elogbeta calls in LdaModel,"In reviewing performance profiling I'm finding that get_Elogbeta is taking some time.

I notice that there are 2 calls to this function, one after the other, LdaModel.do_mstep

The first call is obvious, in LdaModel.do_mstep we have
```python
logger.debug(""updating topics"")
# update self with the new blend; also keep track of how much did
# the topics change through this update, to assess convergence
diff = np.log(self.expElogbeta)
self.state.blend(rho, other)
diff -= self.state.get_Elogbeta()
self.sync_state()
```
But do you see the second call? In sync_state we have
```python
def sync_state(self):
    self.expElogbeta = np.exp(self.state.get_Elogbeta())
    assert self.expElogbeta.dtype == self.dtype
```

The question then becomes does get_Elogbeta perform some side effect that the 2nd call would be different from the first?

Looking at  get_Elogbeta
```python
def get_Elogbeta(self):
    return dirichlet_expectation(self.get_lambda())
```
This function doesn't modify state directly.

Looking at dirichlet_expectation python code (easier to read than the cython code).
```python
def dirichlet_expectation(alpha):
    """"""Expected value of log(theta) where theta is drawn from a Dirichlet distribution.

    Parameters
    ----------
    alpha : numpy.ndarray
        Dirichlet parameter 2d matrix or 1d vector, if 2d - each row is treated as a separate parameter vector.

    Returns
    -------
    numpy.ndarray
        Log of expected values, dimension same as `alpha.ndim`.

    """"""
    if len(alpha.shape) == 1:
        result = psi(alpha) - psi(np.sum(alpha))
    else:
        result = psi(alpha) - psi(np.sum(alpha, 1))[:, np.newaxis]
    return result.astype(alpha.dtype, copy=False)  # keep the same precision as input

```
This doesn't modify the input alpha, and the function psi is from scipy.special.

Thus it appears that the second call get_Elogbeta duplicates the work on the first and can be eliminated.

Is this analysis correct?

Here is a profile chart showing the timing.
![image](https://user-images.githubusercontent.com/3588158/40079863-0d0d8788-583e-11e8-9176-1d19b7a8b27d.png)

This is taken from the overall ldaModel init & update where get_Elogbeta is the two top boxes on the far right over lda'ing a 1.3M corpus.

![image](https://user-images.githubusercontent.com/3588158/40080708-a7667e32-5840-11e8-9952-8abdab90c283.png)
"
227,https://github.com/RaRe-Technologies/gensim/issues/2052,2052,[],closed,2018-05-16 12:35:44+00:00,,WikiCorpus scans corpus to determine vocabulary when an empty dictionary is provided,"I have the following code:

```python
wiki = WikiCorpus(inp, dictionary={}, lemmatize=False)
```

When I use it, it tries to scan through the corpus to determine vocabulary, while a dictionary **is** provided.

It clearly violates what is being said in the documentation:
> dictionary (Dictionary, optional) – Dictionary, if not provided, this scans the corpus once, to determine its vocabulary (this needs really long time)."
228,https://github.com/RaRe-Technologies/gensim/issues/2053,2053,[],closed,2018-05-16 13:36:59+00:00,,Correct way to use pos_tagger option in /summarization/keywords.py,"

#### Description
While using ""[keywords()](https://github.com/RaRe-Technologies/gensim/blob/8766edcd8e4baf3cfa08cdc22bb25cb9f2e0b55f/gensim/summarization/keywords.py#L200)"" in summarization/keywords.py file, I am getting the same set of tags, no matter what value I choose for pos_tagger=['NN'], ['JJ'] or ['NN','JJ']

#### Steps/Code/Corpus to Reproduce

Example:
```
from gensim.summarization import keywords
import requests
text = requests.get('https://www.nytimes.com/2018/05/16/opinion/ramadan-spirit-america.html
').text
print keywords(text,words=15,pos_filter=('NN'),lemmatize=True,scores=True)
print()
print keywords(text,words=15,pos_filter=('NN','JJ'),lemmatize=True,scores=True)
print()
print keywords(text,words=15,pos_filter=('JJ'),lemmatize=True,scores=True)
```

#### Expected Results
 If  I am giving pos_filter as 'NN', only nouns should come as tags, however, tags like ""started"", ""looking"" are also coming as output.
Similarly, there is no difference in the output irresepective of pos_filter='NN', pos_filter='NN','JJ', pos_filter='JJ' 

**What is the correct way of using pos_filter to reflect appropriate output?**


#### Actual Results
student:0.20870111939889552, muslims:0.18960896637225794, americans:0.18895097005190414, ramadan:0.17605599898176202, month:0.12130699512494893, started:0.11817668681654464, community:0.11691583075245701, places:0.1117677772315554, spirituality:0.103727092629442, car:0.09988305780275739, white:0.09747271853405554, trump:0.09747271853405551, looking:0.09538360210000996, president:0.09538360210000986, black:0.0920316444206821

student:0.2087011193988958, muslims:0.18960896637225758, americans:0.1889509700519042, ramadan:0.17605599898176225, month:0.12130699512494901, started:0.11817668681654461, community:0.11691583075245732, places:0.11176777723155559, spirituality:0.10372709262944187, car:0.099883057802757, trump:0.09747271853405544, white:0.09747271853405512, president:0.0953836021000099, looking:0.09538360210000954, black:0.09203164442068222

student:0.20870111939889593, muslims:0.1896089663722575, americans:0.1889509700519037, ramadan:0.17605599898176255, month:0.1213069951249494, started:0.11817668681654483, community:0.11691583075245665, places:0.11176777723155547, spirituality:0.10372709262944207, car:0.09988305780275722, white:0.09747271853405541, trump:0.09747271853405526, looking:0.09538360210000975, president:0.0953836021000096, black:0.09203164442068222


#### Versions

Please run the following snippet and paste the output below.
Linux-4.13.0-39-generic-x86_64-with-Ubuntu-16.04-xenial
('Python', '2.7.12 (default, Dec  4 2017, 14:50:18) \n[GCC 5.4.0 20160609]')
('NumPy', '1.14.3')
('SciPy', '1.1.0')
('gensim', '3.4.0')
('FAST_VERSION', 1)

"
229,https://github.com/RaRe-Technologies/gensim/issues/2054,2054,[],closed,2018-05-17 13:55:09+00:00,,TypeError: '<' not supported between instances of 'str' and 'int',"

#### Description
gensim.model.docvecs.most_similar('A sample string')

#### Steps/Code/Corpus to Reproduce
<!--
model = Doc2Vec(tag_doc, window=10, workers=1, alpha=0.025, min_alpha=0.01)

where tag_doc comes from 
for i in range(max_rows):
    #print (i)
    tag_doc.append(TaggedDocument(token_s[i],LabelList[i]))

and token_s is a list of words and labelList is a list of sentences

#### Expected Results
to find similar tags

#### Actual Results
TypeError: '<' not supported between instances of 'str' and 'int'

what exactly should I expect of model.docves.most_similar or model.wv.most_similar; by the way the above issue- gensim.model.docvecs.most_similar('A sample string'); this sample string exists in the list :  LabelList (or Tag )

#### Versions
<!--
Windows-7-6.1.7601-SP1
Python 3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]
NumPy 1.14.0
SciPy 1.0.0
gensim 3.4.0
FAST_VERSION 1

-->


<!-- Thanks for contributing! -->

"
230,https://github.com/RaRe-Technologies/gensim/issues/2055,2055,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-05-22 03:10:31+00:00,,Error on Gensim based Topic Modeling on Custom Corpus,"After segmentation, when calculating the **Step 2: Probability estimation**
The following error occurs
`per_topic_postings, num_windows = measure.prob(texts=train_texts, segmented_topics=segmented_topics,dictionary=dictionary, window_size=2)`

```python
Anaconda3\lib\site-packages\gensim\topic_coherence\text_analysis.py in __getitem__(self, word_or_words)
125     def __getitem__(self, word_or_words):
126         if isinstance(word_or_words, string_types) or not hasattr(word_or_words, '__iter__'):
--> 127             return self.get_occurrences(word_or_words)
128         else:
129             return self.get_co_occurrences(*word_or_words)

\Anaconda3\lib\site-packages\gensim\topic_coherence\text_analysis.py in get_occurrences(self, word)
193         except KeyError:
194             word_id = word
--> 195         return self._get_occurrences(self.id2contiguous[word_id])
196 
197     def _word2_contiguous_id(self, word):
```

**Windows-8.1-6.3.9600-SP0
Python 3.5.5 |Anaconda, Inc.| (default, Apr  7 2018, 04:52:34) [MSC v.1900 64 bit (AMD64)]
NumPy 1.14.2
SciPy 1.0.0**

Any pointers are greatly appreciated"
231,https://github.com/RaRe-Technologies/gensim/issues/2056,2056,[],closed,2018-05-23 10:24:48+00:00,,"""AttributeError: 'Doc2VecTrainables' object has no attribute 'syn1'"" when verifying if model.syn1 is callable","Here is a snippet of code that reproduces the issue:
```
from gensim.models.doc2vec import Doc2Vec
model = Doc2Vec(documents=mycorpus, dm=1, dbow_words=0, dm_concat=0, dm_tag_count=1, trim_rule=None)
for method_name in dir(model):
    try:
        callable(getattr(model, method_name))
    except AttributeError as err:
        print(method_name)
        raise err
```


Here's the stack trace:
```
syn1
Traceback (most recent call last):
  File ""<stdin>"", line 6, in <module>
  File ""<stdin>"", line 3, in <module>
  File ""/home/syncrossus/ProgramFiles/anaconda3/lib/python3.6/site-packages/gensim/utils.py"", line 1398, in new_func1
    return func(*args, **kwargs)
  File ""/home/syncrossus/ProgramFiles/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py"", line 360, in syn1
    return self.trainables.syn1
AttributeError: 'Doc2VecTrainables' object has no attribute 'syn1'
```
As we can see from the result of the `print`, it is when callability of `model.syn1` is checked that the issue arises."
232,https://github.com/RaRe-Technologies/gensim/issues/2057,2057,[],closed,2018-05-23 12:06:26+00:00,,"How can make the embedding values fall into [-1,1] after training the model ?","I trained the embedding from model.train(train, total_examples=model.corpus_count, epochs=5).
But some of the values in the embedding are not fall into [-1, 1]. So is there any param to set for the range of the output values ?  Thanks"
233,https://github.com/RaRe-Technologies/gensim/issues/2059,2059,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",closed,2018-05-23 22:51:32+00:00,,fasttext ft_hash and unicode handling,"Fasttext uses the hashing trick to map ngrams to a an index in [0, N]. Gensim supports loading models trained with original fasttext implementation from facebook research. It is therefore important that both gensims and the original implementation use the same hash function to make sure that ngrams are associated with the correct vectors.

The [original implementation](https://github.com/facebookresearch/fastText/blob/53dd4c5/src/dictionary.cc#L143) is in C++ and considers ngrams as `std::basic_string<char>`, ie. a sequence of bytes:

```
uint32_t Dictionary::hash(const std::string& str) const {
  uint32_t h = 2166136261;
  for (size_t i = 0; i < str.size(); i++) {
    h = h ^ uint32_t(str[i]);
    h = h * 16777619;
  }
  return h;
}
```

However the [gensim python implementation](https://github.com/RaRe-Technologies/gensim/blob/9021ea8b31871e760095086669651dd1f072fce0/gensim/models/utils_any2vec.py#L26) consider a ngram as a sequence of unicode characters:

```
        h = np.uint32(2166136261)
        for c in string:
            h = h ^ np.uint32(ord(c))
            h = h * np.uint32(16777619)
        return h

```

The two are not equivalent. Consider:
```
In [1]: import numpy as np

In [2]: def hash_unicode(s):
   ...:     h = np.uint32(2166136261)
   ...:     for c in s:
   ...:         h = h ^ np.uint32(ord(c))
   ...:         h = h * np.uint32(16777619)
   ...:     return h
   ...:
   ...:
   ...: def hash_bytes(s):
   ...:     h = np.uint32(2166136261)
   ...:     s = s.encode('utf-8')
   ...:     for c in s:
   ...:         h = h ^ np.uint32(c)
   ...:         h = h * np.uint32(16777619)
   ...:     return h
   ...:
   ...:

In [3]: hash_unicode(""é"")
Out[3]: 1812687940

In [4]: hash_bytes(""é"")
Out[4]: 513665217
```

I am not really familiar with gensims code, so I may have overlooked something.

I assume that the cython implementation treats the iteration over a `unicode` string also as an iteration over unicode characters, so the same consideration as above would apply, but I haven't verified this.

Edit: I checked the inputs to the hash function of the original fasttext implementation. There, eg. `<α>` is represented by `3c ffffffce ffffffb1 3e`"
234,https://github.com/RaRe-Technologies/gensim/issues/2060,2060,[],closed,2018-05-25 04:25:40+00:00,,Why I got negative number of model.score(sentences)?,"I use Word2Vec model to get the word2vec,and want to classify whether it's a correct sentence or not.
And when i use model.score to get the log probability of this sentence,I got a negative score.Why?
Thx for answering this question:)"
235,https://github.com/RaRe-Technologies/gensim/issues/2061,2061,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}]",closed,2018-05-25 15:00:57+00:00,,Doc2Vec.infer_vector learning rate decays extremely fast (non-linearly),"I am working with a corpus of very short documents and noticed that the inferred vectors for the same document were very different.

```python
from scipy.spatial.distance import pdist, squareform
testdoc = ""This is a small sample document.""
vectors = [d2vmod.infer_vector(testdoc) for _ in range(5)]
squareform(pdist(vectors, ""cosine""))
```

```
array([[0.        , 0.05987812, 0.06183155, 0.06931093, 0.05466599],
       [0.05987812, 0.        , 0.03724874, 0.05006329, 0.04789369],
       [0.06183155, 0.03724874, 0.        , 0.04771786, 0.05983109],
       [0.06931093, 0.05006329, 0.04771786, 0.        , 0.0367826 ],
       [0.05466599, 0.04789369, 0.05983109, 0.0367826 , 0.        ]])
```

More training steps makes things worse in this case:
```python
vectors = [d2vmod.infer_vector(testdoc, 10000) for _ in range(5)]
squareform(pdist(vectors, ""cosine""))
```
```
array([[0.        , 0.27392197, 0.308742  , 0.51374501, 0.45744246],
       [0.27392197, 0.        , 0.14912033, 0.32902151, 0.1822687 ],
       [0.308742  , 0.14912033, 0.        , 0.2895444 , 0.27019636],
       [0.51374501, 0.32902151, 0.2895444 , 0.        , 0.38096254],
       [0.45744246, 0.1822687 , 0.27019636, 0.38096254, 0.        ]])
```
Note: This is more extreme than what I'm seeing with more domain-specific sample documents, where start to get more consistent after about 5000 steps.

I believe this is happening because the learning rate decays extremely rapidly:
 https://github.com/RaRe-Technologies/gensim/blob/8b810918d59781116794a6679999afdc76b857ef/gensim/models/doc2vec.py#L565

```python
alpha = 0.025
min_alpha = 0.001
steps = 100
for i in range(steps):
    print(alpha)
    alpha = ((alpha - min_alpha) / (steps - i)) + min_alpha
```
```
0.025
0.00124
0.0010024242424242424
0.0010000247371675943
...
```
Notice that `alpha` is very close to `min_alpha` after the first step and this is exaggerated even more when the number of steps is larger. 

When I change Doc2Vec to have a linear decay in learning rate
```python
alpha_delta = (alpha-min_alpha)/(steps-1)
for i in range(steps):
    # ...
    alpha -= alpha_delta
```

I get much better results. With 20 steps, we get pairwise cosine distances of
```
array([[0.        , 0.01617053, 0.02467067, 0.01828433, 0.01834735],
       [0.01617053, 0.        , 0.01879757, 0.00910884, 0.01358116],
       [0.02467067, 0.01879757, 0.        , 0.01521225, 0.01392789],
       [0.01828433, 0.00910884, 0.01521225, 0.        , 0.01121792],
       [0.01834735, 0.01358116, 0.01392789, 0.01121792, 0.        ]])
```
, with 100 we get
```
array([[0.        , 0.00282428, 0.00373375, 0.00331408, 0.00362875],
       [0.00282428, 0.        , 0.0036147 , 0.0028999 , 0.00210812],
       [0.00373375, 0.0036147 , 0.        , 0.0032986 , 0.00361321],
       [0.00331408, 0.0028999 , 0.0032986 , 0.        , 0.00318849],
       [0.00362875, 0.00210812, 0.00361321, 0.00318849, 0.        ]])
```
, and with 1000 steps:
```
array([[0.        , 0.00055459, 0.000633  , 0.00074271, 0.00036596],
       [0.00055459, 0.        , 0.00067211, 0.00075522, 0.00058975],
       [0.000633  , 0.00067211, 0.        , 0.00109709, 0.00049239],
       [0.00074271, 0.00075522, 0.00109709, 0.        , 0.00072527],
       [0.00036596, 0.00058975, 0.00049239, 0.00072527, 0.        ]])
```"
236,https://github.com/RaRe-Technologies/gensim/issues/2062,2062,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",closed,2018-05-25 16:01:04+00:00,,'FastTextTrainables' object has no attribute 'vectors',"Using the [pre-trained FastText English Wikipedia model](https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md), I load it and then save it to gensim's format. When I load the new file, I get a ```'FastTextTrainables' object has no attribute 'vectors'``` error. I am using version 3.4.0.

```python
from gensim.models import FastText
model = FastText.load_fasttext_format('./wiki.en.bin')
model.save('./gensim_en_fasttext_wiki_lg')
new_model = FastText.load('./gensim_en_fasttext_wiki_lg')
```

**Saved Files**
```
gensim_en_fasttext_wiki_lg
gensim_en_fasttext_wiki_lg.wv.vectors_ngrams.npy
gensim_en_fasttext_wiki_lg.wv.vectors.npy
```

**Error**
```
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/gensim/models/fasttext.py"", line 718, in load
    model.trainables.vectors_vocab_lockf = ones(len(model.trainables.vectors), dtype=REAL)
AttributeError: 'FastTextTrainables' object has no attribute 'vectors'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""cluster_vectors.py"", line 26, in <module>
    new_model = FastText.load('./gensim_en_fasttext_wiki_lg')
  File ""/usr/local/lib/python3.5/dist-packages/gensim/models/fasttext.py"", line 725, in load
    return load_old_fasttext(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/gensim/models/deprecated/fasttext.py"", line 53, in load_old_fasttext
    old_model = FastText.load(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/gensim/models/deprecated/word2vec.py"", line 1616, in load
    model = super(Word2Vec, cls).load(*args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/gensim/models/deprecated/old_saveload.py"", line 87, in load
    obj = unpickle(fname)
  File ""/usr/local/lib/python3.5/dist-packages/gensim/models/deprecated/old_saveload.py"", line 380, in unpickle
    return _pickle.loads(file_bytes, encoding='latin1')
AttributeError: Can't get attribute 'FastTextVocab' on <module 'gensim.models.deprecated.fasttext' from '/usr/local/lib/python3.5/dist-packages/gensim/models/deprecated/fasttext.py'>
```

"
237,https://github.com/RaRe-Technologies/gensim/issues/2065,2065,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2018-05-25 20:13:46+00:00,,scipy2scipy_clipped may return a matrix with a different shape to that of the input matrix,"#### Description
The function scipy2scipy_clipped may return a clipped matrix with a different shape if the last dimension item is not among the top similar items of any row of the input matrix. This is particularly possible while chunking in SparseMatrixSimilarity, as the similarity matrix is incomplete and thus we don't get to see the last column of the last row (which, being a similarity matrix, usually contains 1)

#### Steps/Code/Corpus to Reproduce

Example:

```python
from scipy.sparse import random, vstack
from gensim.matutils import scipy2scipy_clipped
from sklearn.metrics.pairwise import cosine_similarity

#Some random sparse matrix
X = random(1000, 2000, density=.2, format=""csc"")

#Getting its similarity matrix
X_sim = cosine_similarity(X, dense_output=False)

#Splitting it to simulate chunking
X_sim_chunk1 = X[:500, :]
X_sim_chunk2 = X[500:, :]

#Assuring that in the first chunk no row is similar to the last item
X_sim_chunk1[:, -1] = 0

X_clipped1 = scipy2scipy_clipped(X_sim_chunk1, 100)
print(X_clipped1.shape) # (500, 1999)

X_clipped2 = scipy2scipy_clipped(X_sim_chunk2, 100)
print(X_clipped2.shape) # (500, 2000)

#While trying to recreate the matrix, this fails because of dimensions' inconsistency
vstack([X_clipped1, X_clipped2])
# ValueError: incompatible dimensions for axis 1

```


#### Expected Results
```
X_clipped1 = scipy2scipy_clipped(X_sim_chunk1, 100)
print(X_clipped1.shape) # (500, 1000)
```
#### Actual Results
```
X_clipped1 = scipy2scipy_clipped(X_sim_chunk1, 100)
print(X_clipped1.shape) # (500, 999)
```
#### Versions
Linux-4.4.0-116-generic-x86_64-with-debian-stretch-sid
('Python', '2.7.14 |Anaconda, Inc.| (default, Nov  8 2017, 22:44:41) \n[GCC 7.2.0]')
('NumPy', '1.13.3')
('SciPy', '1.0.0')
('gensim', '3.4.0')
('FAST_VERSION', 1)


<!-- Thanks for contributing! -->"
238,https://github.com/RaRe-Technologies/gensim/issues/2067,2067,[],closed,2018-05-28 11:28:39+00:00,,AttributeError: 'Word2VecKeyedVectors' object has no attribute 'train',"I want to do Online Training/ Resuming training on my previously trained model. But it is showing the error `AttributeError: 'Word2VecKeyedVectors' object has no attribute 'train'` . 

My code is:
`import gensim.models.keyedvectors as word2vec`
`model = word2vec.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)`
`model.KeyedVectors.train(""Hello"")
`
"
239,https://github.com/RaRe-Technologies/gensim/issues/2068,2068,[],closed,2018-05-28 13:13:19+00:00,,Gensim Summarizer Memory Error,"I am getting the Following error while using the Summarizer:
[https://stackoverflow.com/questions/50567108/gensim-summarizer-throws-memoryerror-any-solution](url)

Could you please tell me the workaroud of this problem."
240,https://github.com/RaRe-Technologies/gensim/issues/2069,2069,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2018-05-28 18:28:15+00:00,,Incoherent topic word distributions after `malletmodel2ldamodel`,"Hi everyone,
first off many thanks for providing such an awesome module! I am using `gensim` to do topic modeling with LDA and encountered the following bug/issue. I have already read about it in the [mailing list](https://groups.google.com/forum/#!topic/gensim/ZesMoKZCf4c), but apparently no issue has been created on Github.

#### Description
After training an LDA model with the gensim mallet wrapper I converted the model to a native gensim LDA model via the `malletmodel2ldamodel` function provided with the wrapper. Before and after the conversion the topic word distributions are quite different. The ldamallet version returns comprehensible topics with sensible weights, whereas the topic word distribution after conversion is nearly uniform, leading to topics without a clear focus. 

I am assuming that the resulting topics are supposed to be at least somewhat similar before and after conversion. Am I doing something wrong? What could be causing this behaviour?

#### Steps/Code/Corpus to Reproduce
```python
import gensim
from sklearn.datasets import fetch_20newsgroups

# select five quite distinct categories from the 20 newsgroups
cat = ['soc.religion.christian', 'comp.graphics', 'rec.motorcycles', 
       'sci.space', 'talk.politics.guns']

# keep and use only the main text
newsgroups_train = fetch_20newsgroups(subset='all', categories=cat,
                                      remove=('headers', 'footers', 'quotes'))

tokenized = [gensim.utils.simple_preprocess(doc) for doc in newsgroups_train.data]
dictionary = gensim.corpora.Dictionary(tokenized)
corpus = [dictionary.doc2bow(text) for text in tokenized]

lda_mallet = gensim.models.wrappers.ldamallet.LdaMallet(
        'c:/mallet/bin/mallet', corpus=corpus, 
        num_topics=5, id2word=dictionary, iterations=1000)

lda_gensim = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(
        lda_mallet, iterations=1000)

for topic in lda_mallet.show_topics(num_topics=5, num_words=10):
    print(topic)
for topic in lda_gensim.show_topics(num_topics=5, num_words=10):
    print(topic)
```
#### Expected Results
These are the results I get from the mallet wrapper using `lda_mallet.show_topics(num_topics=5, num_words=10)`. Those are what one would expect considering the chosen categories from 20newsgroups: 
```python
(0, '0.021*""god"" + 0.009*""people"" + 0.007*""jesus"" + 0.007*""church"" + 0.006*""christ"" + 0.005*""life"" + 0.005*""christian"" + 0.005*""bible"" + 0.004*""christians"" + 0.004*""man""')
(1, '0.014*""don"" + 0.011*""ve"" + 0.009*""good"" + 0.008*""bike"" + 0.007*""time"" + 0.007*""back"" + 0.007*""make"" + 0.006*""ll"" + 0.006*""problem"" + 0.006*""thing""')
(2, '0.017*""space"" + 0.006*""nasa"" + 0.006*""earth"" + 0.005*""system"" + 0.005*""launch"" + 0.004*""shuttle"" + 0.004*""orbit"" + 0.003*""years"" + 0.003*""mission"" + 0.003*""moon""')
(3, '0.012*""people"" + 0.011*""gun"" + 0.005*""guns"" + 0.005*""government"" + 0.005*""state"" + 0.005*""law"" + 0.005*""fire"" + 0.005*""control"" + 0.004*""don"" + 0.004*""fbi""')
(4, '0.013*""image"" + 0.009*""graphics"" + 0.008*""jpeg"" + 0.007*""file"" + 0.006*""images"" + 0.006*""data"" + 0.006*""bit"" + 0.006*""software"" + 0.006*""ftp"" + 0.006*""mail""')
```
#### Actual Results
These are the results I get from the converted native gensim model using `lda_gensim.show_topics(num_topics=5, num_words=10)`. The word probabilities are all very low and not very distinctive, resulting in mostly incoherent topics: 
```python
(0, '0.000*""tribunal"" + 0.000*""insruance"" + 0.000*""damper"" + 0.000*""unfurl"" + 0.000*""urinalisys"" + 0.000*""saturnation"" + 0.000*""stupider"" + 0.000*""improved"" + 0.000*""waltons"" + 0.000*""t_ng""')
(1, '0.000*""ott"" + 0.000*""raved"" + 0.000*""warped"" + 0.000*""onesies"" + 0.000*""speculating"" + 0.000*""irrigate"" + 0.000*""bodies"" + 0.000*""inherant"" + 0.000*""illustrations"" + 0.000*""filler""')
(2, '0.000*""datasets"" + 0.000*""addiction"" + 0.000*""lr"" + 0.000*""overturning"" + 0.000*""supertrapp"" + 0.000*""collision"" + 0.000*""nl__"" + 0.000*""someone"" + 0.000*""switch"" + 0.000*""pirate""')
(3, '0.000*""inbetweens"" + 0.000*""hostname"" + 0.000*""obsevatory"" + 0.000*""dscharge"" + 0.000*""ecclesiates"" + 0.000*""drills"" + 0.000*""ranching"" + 0.000*""metz"" + 0.000*""omnivorous"" + 0.000*""normals""')
(4, '0.000*""uad"" + 0.000*""undecidable"" + 0.000*""eroded"" + 0.000*""summarized"" + 0.000*""reposition"" + 0.000*""sttod"" + 0.000*""sanctas"" + 0.000*""broadest"" + 0.000*""inception"" + 0.000*""turntable""')
```

#### Versions
- Windows-7-6.1.7601-SP1
- Python 3.6.5 | packaged by conda-forge | (default, Apr  6 2018, 16:13:55) [MSC v.1900 64 bit (AMD64)]
- NumPy 1.14.2
- SciPy 1.0.1
- gensim 3.4.0
- FAST_VERSION 1
- mallet version 2.0.8


Thanks in advance for any help! Cheers,
Wolfgang"
241,https://github.com/RaRe-Technologies/gensim/issues/2075,2075,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2018-06-01 04:47:22+00:00,,ZeroDivisionError: float division by zero,"Getting error :  ZeroDivisionError: float division by zero

https://github.com/RaRe-Technologies/gensim/blob/9481915915bf61aa6e4e719a2f26d509677e6779/gensim/summarization/pagerank_weighted.py#L53


![error](https://user-images.githubusercontent.com/11848354/40821543-3283e832-6585-11e8-9a66-3a4d8ba95eeb.JPG)
"
242,https://github.com/RaRe-Technologies/gensim/issues/2077,2077,[],closed,2018-06-04 08:46:09+00:00,,Doc2vec most_similar method returns similarity score higher than 1,"#### Description
I have trained doc2vec model by following this tutorial for 500.000 documents. 
https://github.com/abtpst/Doc2Vec/blob/master/trainDoc2Vec.py

However, when I try to find most_similar documents for a given document, the results have similarity higher than 1. As you can see in the code and the outputs, docvecs.similarity returns 0.246 and docvecs.most_similar return 9.996 for similarity between same documents. You can see the code and the output below:

Code:
```
from gensim.models import doc2vec

def myhash(obj):
    return hash(obj) % (2 ** 32)    

model = doc2vec.Doc2Vec(hashfxn=myhash)
model = doc2vec.Doc2Vec.load(""d2v.model"")

tag1 = ""012020171590""
tag2 = ""0109201716181""

print(tag1 in model.docvecs.doctags)
print(tag2 in model.docvecs.doctags)

print(model.docvecs.similarity(tag1, tag2))
print(model.docvecs.most_similar(tag1))
```

#### Results
True
True
0.24682570854972158
[('0109201716181', 9.996172904968262), ('0120201611372', 9.853036880493164), ('010120166996', 9.613503456115723), ('012020173027', 8.97104263305664), ('01202017423', 8.886014938354492), ('01002009541', 8.783470153808594), ('00002004106', 8.682585716247559), ('0109201616963', 8.671405792236328), ('011020171931', 8.659266471862793), ('011020175199', 8.573907852172852)]

#### Versions
Linux-4.9.0-6-amd64-x86_64-with-debian-9.4
Python 3.5.3 (default, Jan 19 2017, 14:11:04)
NumPy 1.14.3
SciPy 1.1.0
gensim 3.4.0
FAST_VERSION 1

"
243,https://github.com/RaRe-Technologies/gensim/issues/2079,2079,[],closed,2018-06-04 14:39:31+00:00,,Unable to save the Lsi model,"unable to save the LSI model 
/usr/local/lib/python2.7/dist-packages/gensim/interfaces.py:101: UserWarning: corpus.save() stores only the (tiny) iteration object; to serialize the actual corpus content, use e.g. MmCorpus.serialize(corpus)
  ""corpus.save() stores only the (tiny) iteration object; ""
Code:
bow_vector1=[]
for X in tokenize_data:
    bow_vector1.append(dct.doc2bow(X));

tfidf_vector1=tfidf1_model[bow_vector1]

lsi_vector1=lsi_model[tfidf_vector1]

lsi_vector1.save(""/home/vikash/gen/lsi_vector1.lsi"", separately=None, sep_limit=10485760, 
                               ignore=frozenset([]), pickle_protocol=2)
"
244,https://github.com/RaRe-Technologies/gensim/issues/2080,2080,[],closed,2018-06-04 14:45:05+00:00,,how to give the lsi model as input to train an model in multi layer perceptron,"Here I took the amazon reviews dataset containing two features reviews and sentiment.I had made a model on this using LSI which gives feature vectors.Now I want this model to give as an input to train a model for sentiment analysis using multi layer perceptron. can you tell me the process
"
245,https://github.com/RaRe-Technologies/gensim/issues/2082,2082,[],closed,2018-06-04 23:57:44+00:00,,the probability distribution in LDA,"After I had trained an LDA model by gensim, I use the statement of get_topics to get the probability distribution of doc and topic. But I find most of them are 0.00, why does this happen? And will it 
influence accuracy？ Thank you very much!
"
246,https://github.com/RaRe-Technologies/gensim/issues/2083,2083,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2018-06-05 11:20:27+00:00,,Doc2vec fails to train when using build_vocab_from_freq(),"#### Description
I have a Doc2Vec model trained using the `build_vocab_from_file()` function. This is so I can include a `<PAD>` token manually at index 0. This token does not appears in the original dataset, but is needed further down my program.

#### Steps/Code/Corpus to Reproduce
Here is a simple example of of what I am trying to achieve:
```python
import collections, sys

import gensim
from gensim import models
from gensim.models.doc2vec import TaggedDocument

lines = [u'It is a truth universally acknowledged',
        u'This was invitation enough.', 
        u'An invitation to dinner was soon afterwards dispatched']
words = [line.split() for line in lines]
doc_labels = [u'text0', u'tex1', u'text2']
word_freq = collections.Counter([w for line in words for w in line])
word_freq['<PAD>'] = sys.maxint # this ensure that the pad token has index 0 in gensim's vocabulary

class DocIterator(object):
    def __init__(self, docs, labels):
        self.docs = docs
        self.labels = labels
    def __iter__(self):
        for idx, doc in enumerate(self.docs):
            yield TaggedDocument(words=doc, tags=[self.labels[idx]])
            
doc_it = DocIterator(words, doc_labels)
model = gensim.models.Doc2Vec(vector_size=100, min_count=0)
model.build_vocab_from_freq(word_freq)
model.train(doc_it, total_examples=len(lines), epochs=10)
```

#### Expected Results
Expected size of `model.docvecs.count` is 3 (not 0).

#### Actual Results
Actual size of `model.docvecs.count` is 0

`print(model.docvecs.count)` -> 0

#### Versions
Linux-3.19.0-82-generic-x86_64-with-Ubuntu-15.04-vivid
('Python', '2.7.9 (default, Apr  2 2015, 15:33:21) \n[GCC 4.9.2]')
('NumPy', '1.14.3')
('SciPy', '1.1.0')
('gensim', '3.4.0')
('FAST_VERSION', 1)

Now my questions are:
- What is the correct way of using `build_vocab_from_freq()` to get a valid model? 
- Failling this, what is the best way to force gensim to include an unseen token at a specific index value in the vocabulary?"
247,https://github.com/RaRe-Technologies/gensim/issues/2084,2084,[],closed,2018-06-06 01:44:27+00:00,,Error in sklearn_api.ldamodel.LdaTransformer: Coherence scorer 'u_mass',"**OS:** macOS High Sierra 10.13.4
**Python Version:** 3.6.5
**Gensim Version:** 3.4.0

I am using the `sklearn_api.ldamodel.LdaTransformer` in an sklearn RandomizedSearchCV:
```
term_dct = Dictionary(docs)
bow_corpus = [term_dct.doc2bow(doc) for doc in docs]

param_dict = {
    'num_topics': [4, 6, 8, 20, 25, 40],
    'decay': [0.01, 0.05]
}
lda_model = LdaTransformer(id2word=term_dct,
                           passes=10,
                           iterations=100,
                           alpha='auto',
                           eta='auto',
                           scorer='u_mass')
lda_cv = RandomizedSearchCV(lda_model, param_dict, n_iter=12, n_jobs=5, cv=5, verbose=2)
lda_cv.fit(bow_corpus)
```
Once the hyperparameter search hits `num_topics=20` and `decay==0.01`, I start getting these warnings:
```
/usr/local/opt/miniconda3/envs/.../lib/python3.6/site-packages/gensim/models/ldamodel.py:775: RuntimeWarning: divide by zero encountered in log
  diff = np.log(self.expElogbeta)
```
Then, at the conclusion of the search, I get a very long stack trace for `TransportableException` for a `ZeroDivisionError`. 
```
ZeroDivisionError: float division by zero
___________________________________________________________________________

During handling of the above exception, another exception occurred:

JoblibZeroDivisionError                   Traceback (most recent call last)
<ipython-input-8-c2e0eda40a9d> in <module>()
----> 1 lda_cv.fit(bow_corpus)

/usr/local/opt/miniconda3/envs/.../lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self, X, y, groups, **fit_params)
    637                                   error_score=self.error_score)
    638           for parameters, (train, test) in product(candidate_params,
--> 639                                                    cv.split(X, y, groups)))
    640 
    641         # if one choose to see train score, ""out"" will contain train score info

/usr/local/opt/miniconda3/envs/.../lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self, iterable)
    787                 # consumption.
    788                 self._iterating = False
--> 789             self.retrieve()
    790             # Make sure that we get a last message telling us we are done
    791             elapsed_time = time.time() - self._start_time

/usr/local/opt/miniconda3/envs/.../lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in retrieve(self)
    738                     exception = exception_type(report)
    739 
--> 740                     raise exception
    741 
    742     def __call__(self, iterable):

JoblibZeroDivisionError: JoblibZeroDivisionError
___________________________________________________________________________
```
 From what I understand of the `u_mass` formula, and my BoW representations, I am not sure what is going on here...

[stacktrace.txt](https://github.com/RaRe-Technologies/gensim/files/2074505/stacktrace.txt)

"
248,https://github.com/RaRe-Technologies/gensim/issues/2085,2085,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",open,2018-06-07 13:13:53+00:00,,Doc2Vec to wikipedia articles notebook error -  object has no attribute,"For the Doc2Vec to wikipedia articles notebook (https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-wikipedia.ipynb) I get this error:

```python
pre = Doc2Vec(min_count=0)
pre.scan_vocab(documents)
```

```
executed in 11ms, finished 09:09:33 2018-06-07
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-10-0b281772fe9f> in <module>()
      1 pre = Doc2Vec(min_count=0)
----> 2 pre.scan_vocab(documents)
AttributeError: 'Doc2Vec' object has no attribute 'scan_vocab'
```

I also get a similar error for the next cell of the notebook:

```
AttributeError: 'Doc2Vec' object has no attribute 'scale_vocab'
```

Your Doc2Vec notebook on the Lee dataset (https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-lee.ipynb) works fine for me though.

=======================
I am using Ubuntu 16.04.4 , Python 3.6, and the latest version of Gensim."
249,https://github.com/RaRe-Technologies/gensim/issues/2086,2086,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2018-06-07 17:09:47+00:00,,NPMI scorer does not take into account `min_count`,"in phrases.py, npmi_scorer does not take into account min_count when scoring bigrams.

I suggest the following alternative for taking min_count into account when using NPMI scoring.  This function has yielded good results for me; however,  I have not explored other ways to  use min_count:

```
# Custom scoring function to take into account min_counts when using npmi
def npmi_scorer_with_min_count(worda_count, wordb_count, bigram_count, len_vocab, min_count, corpus_word_count):

    if bigram_count < min_count:
        return -1

    pa = worda_count / corpus_word_count
    pb = wordb_count / corpus_word_count
    pab = bigram_count / corpus_word_count
    return log(pab / (pa * pb)) / -log(pab)

```"
250,https://github.com/RaRe-Technologies/gensim/issues/2088,2088,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}]",closed,2018-06-12 06:25:22+00:00,,"aliasing chunkize to chunkize_serial warning, on Windows","On Windows, I have it that after initial installation, when importing gensim for the first time in python (Jupyter Notebook) we get:

> UserWarning: detected Windows; aliasing chunkize to chunkize_serial 
    warnings.warn(""detected Windows; aliasing chunkize to chunkize_serial"")

I've been unable to gather what trouble or missing functionality should we expect, the warning is rather opaque, yet I assume it is there in the code to tell us something, as API users. Which is my lame excuse for having an issue here, so that there's an official comment on what to understand from this warning."
251,https://github.com/RaRe-Technologies/gensim/issues/2090,2090,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2018-06-13 20:46:47+00:00,,Gensim doesn't allow changing negative sampling distribution parameter,"#### Description
Like pointed out in the following article, the negative sampling distribution parameter, which is fixed as 0.75 in Gensim, is worth tuning, specially for other applications beyond NLP. So, I'd be very helpful to make it a parameter for the Word2Vec, instead of fixing it.

https://arxiv.org/abs/1804.04212

"
252,https://github.com/RaRe-Technologies/gensim/issues/2091,2091,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2018-06-14 04:27:56+00:00,,AttributeError: 'Doc2VecKeyedVectors' object has no attribute 'ffset2doctag',"![image](https://user-images.githubusercontent.com/12460007/41391590-1b9089ac-6fce-11e8-8211-ec02072b1af1.png)
Maybe it is offset2doctag"
253,https://github.com/RaRe-Technologies/gensim/issues/2092,2092,[],closed,2018-06-14 16:54:09+00:00,,contradiction between the code comments and website tutorial,"Hi, 
I found a contradiction between the code comments and the website tutorial, about the sg parameter, so if you look in the code comments you find that if **sg** parameter is **1**, **CBOW** is used, otherwise, **skip-gram** is employed : 
![image](https://user-images.githubusercontent.com/15655871/41426402-65aa7ea8-6ffb-11e8-9265-4f21d2134849.png)

but when i checked [the tutorial website](https://radimrehurek.com/gensim/models/word2vec.html) i found the inverse : 
![image](https://user-images.githubusercontent.com/15655871/41426505-c504ae00-6ffb-11e8-902d-0026048afca7.png)

"
254,https://github.com/RaRe-Technologies/gensim/issues/2097,2097,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}]",open,2018-06-20 19:40:47+00:00,,"Ambiguous `docvecs` indexing, documentation missing","#### Description
The tagging system for training corpora appears to result in ambiguous indexing on `model.docvecs`

#### Steps/Code/Corpus to Reproduce

This example is a lightly modified version of code snippets from [the main demo](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-lee.ipynb).
```python
import os
import smart_open
import gensim

# Set file names for train and test data
test_data_dir = '{}'.format(os.sep).join([gensim.__path__[0], 'test', 'test_data'])
lee_train_file = test_data_dir + os.sep + 'lee_background.cor'

def read_corpus(fname, offset = 0):
    with smart_open.smart_open(fname, encoding=""iso-8859-1"") as f:
        for i, line in enumerate(f):
            yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(line), [i + offset])

def build_model(corpus):
    model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=55)
    model.build_vocab(corpus)
    model.train(corpus, total_examples=model.corpus_count, epochs=model.epochs)
    return model

corpus = list(read_corpus(lee_train_file))
offset_corpus = list(read_corpus(lee_train_file, offset = 100))

model = build_model(corpus)
offset_model = build_model(offset_corpus)
```
#### Expected Results
The only difference between the two models is that the training corpora use different sets of tags.

1. The number of training documents is the same for both, so I would expect `len(model.docvecs) == len(offset_model.docvecs)`

2. `offset_corpus.docvecs[0]` should throw an error since `0` is not among its tags.

3. OR ... if not (2), then `offset_corpus.docvecs[0]` should correspond to the first document, in which case `offset_corpus.docvecs[0] == offset_corpus.docvecs[100]`. Specifically, note that `offset_corpus.docvecs[399]` appears to return a valid result.

#### Actual Results

None of (1), (2), or (3) hold.

#### Versions

```python
>>> import platform; print(platform.platform())
Darwin-16.7.0-x86_64-i386-64bit
>>> import sys; print(""Python"", sys.version)
Python 3.6.1 |Anaconda 4.4.0 (x86_64)| (default, May 11 2017, 13:04:09)
[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.14.2
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.0.1
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.4.0
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 0

```


"
255,https://github.com/RaRe-Technologies/gensim/issues/2099,2099,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2018-06-21 17:59:37+00:00,,BasedKeyedVectors functions (eg `rank()`) using vocab field fail when called from Doc2VecKeyedVectors,"#### Description
[Link to original post in mailing list](https://groups.google.com/forum/#!topic/gensim/_udvKsdWZ6M)

To restate here:

When calling functions on a Doc2VecKeyedVectors model that are part of the base class BasedKeyedVectors (which appear to use entity1 and entity2 as their variable names) it throws a KeyError that it doesn't recognize the doc tag. Using the same doc tags on a function like distance which runs within the Doc2VecKeyedVectors class returns the expected result.

#### Steps/Code/Corpus to Reproduce
Relevant code is linked in the description, let me know if you prefer I copy into here as well.

#### Expected Results
Expect the function to recognize the doc tags and perform the relevant calculation.

#### Actual Results
Throws a KeyError.

```python
Traceback (most recent call last):
  File ""C:/Users/cmiramontes/Documents/Projects/PyCharm/otb-ml-integration/Server/OTB_ML_Services.py"", line 192, in <module>
    main()
  File ""C:/Users/cmiramontes/Documents/Projects/PyCharm/otb-ml-integration/Server/OTB_ML_Services.py"", line 188, in main
    d2v.rank(sens, e1, e2)
  File ""C:\Users\cmiramontes\Documents\Projects\PyCharm\otb-ml-integration\Server\doc2vec_services.py"", line 70, in rank
    return model.docvecs.rank(entity1, entity2)
  File ""C:\Users\cmiramontes\Documents\Projects\PyCharm\otb-ml-integration\venv\lib\site-packages\gensim\models\keyedvectors.py"", line 190, in rank
    return len(self.closer_than(entity1, entity2)) + 1
  File ""C:\Users\cmiramontes\Documents\Projects\PyCharm\otb-ml-integration\venv\lib\site-packages\gensim\models\keyedvectors.py"", line 183, in closer_than
    e1_index = self.vocab[entity1].index
KeyError: '00359a92-f243-4b59-b998-33ad0d23b0cd'
```

#### Versions
```
Windows-7-6.1.7601-SP1
Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)]
NumPy 1.14.3
SciPy 1.1.0
gensim 3.4.0
FAST_VERSION 0
```
"
256,https://github.com/RaRe-Technologies/gensim/issues/2100,2100,[],closed,2018-06-21 20:57:14+00:00,,wikicorpus,see below
257,https://github.com/RaRe-Technologies/gensim/issues/2104,2104,[],closed,2018-06-26 05:03:42+00:00,,trying to  get percentage contribution of each topic,"Hi,
i built the LDA model and getting optimal no. of topics. now i want to get each topic percentage contribution. my first step is
```python
for i, row in enumerate(ldamodel[corpus]):
    row = sorted(row, key=lambda x:x[1], reverse=True)
```
 
but i am getting error  as `TypeError: '<' not supported between instances of 'int' and 'tuple'`

can anyone help me this issue.

Thank you,
"
258,https://github.com/RaRe-Technologies/gensim/issues/2105,2105,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-06-26 09:38:57+00:00,,AssertionError: sparse documents must not contain any explicit zero entries and the similarity matrix S must satisfy x^T * S * x > 0 for any nonzero bag-of-words vector x.,"Hello there,

Maybe you can help me out with this real quick. I cannot run any of your examples. Not the one from https://radimrehurek.com/gensim/similarities/docsim.html, nor the one from this repo. All of them give me the following Assertion. 

```
AssertionError: sparse documents must not contain any explicit zero entries and the similarity matrix S must satisfy x^T * S * x > 0 for any nonzero bag-of-words vector x.
```

This is not working (other similaritiy measures of this module work fine):

```python
from gensim.test.utils import common_texts
from gensim.corpora import Dictionary
from gensim.models import Word2Vec
from gensim.similarities import SoftCosineSimilarity

model = Word2Vec(common_texts, size=20, min_count=1)  # train word-vectors
dictionary = Dictionary(common_texts)
bow_corpus = [dictionary.doc2bow(document) for document in common_texts]

similarity_matrix = model.wv.similarity_matrix(dictionary)  # construct similarity matrix
index = SoftCosineSimilarity(bow_corpus, similarity_matrix, num_best=10)

# Make a query.
query = 'graph trees computer'.split()
# calculate similarity between query and each doc from bow_corpus
sims = index[dictionary.doc2bow(query)]
```

Neither is this from the repo (I followed all previous steps):

```python
similarity = softcossim(sentence_obama, sentence_orange, similarity_matrix)
print('similarity = %.4f' % similarity)
```

Thanks in advance. I am trying to run this for two days now but nothing works.

Best,
Dennis"
259,https://github.com/RaRe-Technologies/gensim/issues/2107,2107,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 175986, 'node_id': 'MDU6TGFiZWwxNzU5ODY=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/testing', 'name': 'testing', 'color': '444444', 'default': False, 'description': 'Issue related with testing (code, documentation, etc)'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2018-06-27 06:03:50+00:00,,Make docstring examples executable,"Need to make **all** python examples in docstrings executable, i.e. possible to run with `python -m doctest`. For now, part of this work is done, but not all.

Tasks:
- Investigate, what need to do with different output values for `py2`/`py3` (sometimes doesn't match, because matching are an exact (symbol to symbol), same issue with float values)
- Fix existing docstring examples
- Add `doctest` to Travis"
260,https://github.com/RaRe-Technologies/gensim/issues/2108,2108,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-06-27 19:29:07+00:00,,error i using mallet ,"hi 
 i installed mallet in c and it to variable environment in windows 10 and when use it by 
ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)  
i got the error 
![image](https://user-images.githubusercontent.com/30591782/41995135-57f71b8c-7a59-11e8-87f3-693a29424513.png)


"
261,https://github.com/RaRe-Technologies/gensim/issues/2109,2109,[],closed,2018-06-28 12:58:23+00:00,,TypeError: '>' not supported between instances of 'function' and 'function',"def makeSummary(sentences, best_sentence, query, summary_length, lambta, IDF):
    summary = [best_sentence]
    print(""line 264  summary "",summary)
    sum_len = len(best_sentence.getPreProWords())

    MMRval = {}

    # keeping adding sentences until number of words exceeds summary length
    while (sum_len < summary_length):
        MMRval = {}

        for sent in sentences:
            MMRval[sent] = MMRScore(sent, query, summary, lambta, IDF)
            print(""type of MMR value   "",MMRval)

        **maxxer = max(MMRval, key=MMRval.get)**                                           #getting error here
        summary.append(maxxer)
        sentences.remove(maxxer)
        sum_len += len(maxxer.getPreProWords())

    return summary
=================================================
FULL CODE

import nltk
import os
import math
import string
import re
import sentence

from nltk.corpus import stopwords


# ---------------------------------------------------------------------------------
# Description	: Function to preprocess the files in the document cluster before
#				  passing them into the MMR summarizer system. Here the sentences
#				  of the document cluster are modelled as sentences after extracting
#				  from the files in the folder path. 
# Parameters	: file_name, name of the file in the document cluster
# Return 		: list of sentence object
# ---------------------------------------------------------------------------------
def processFile(file_name):
    # read file from provided folder path
    f = open(file_name, 'r')
    text_0 = f.read()

    # extract content in TEXT tag and remove tags
    text_1 = re.search(r""<TEXT>.*</TEXT>"", text_0, re.DOTALL)
    text_1 = re.sub(""<TEXT>\n"", """", text_1.group(0))
    text_1 = re.sub(""\n</TEXT>"", """", text_1)

    # replace all types of quotations by normal quotes
    text_1 = re.sub(""\n"", "" "", text_1)

    text_1 = re.sub(""\"""", ""\"""", text_1)
    text_1 = re.sub(""''"", ""\"""", text_1)
    text_1 = re.sub(""``"", ""\"""", text_1)

    text_1 = re.sub("" +"", "" "", text_1)
    # segment data into a list of sentences
    sentence_token = nltk.data.load('tokenizers/punkt/english.pickle')
    lines = sentence_token.tokenize(text_1.strip())

    # setting the stemmer
    sentences = []
    porter = nltk.PorterStemmer()

    # modelling each sentence in file as sentence object
    for line in lines:

        # original words of the sentence before stemming
        originalWords = line[:]
        line = line.strip().lower()

        # word tokenization
        sent = nltk.word_tokenize(line)

        # stemming words
        stemmedSent = [porter.stem(word) for word in sent]
        # stemmedSent = filter(lambda x: x != '.' and x != '`' and x != ',' and x != '?' and x != ""'""
        #                                and x != '!' and x != '''""''' and x != ""''"" and x != ""'s"", stemmedSent)

        # list of sentence objects
        if stemmedSent != []:
            sentences.append(sentence.sentence(file_name, stemmedSent, originalWords))


    return sentences


# ---------------------------------------------------------------------------------
# Description	: Function to find the term frequencies of the words in the
#				  sentences present in the provided document cluster
# Parameters	: sentences, sentences of the document cluster
# Return 		: dictonary of word, term frequency score
# ---------------------------------------------------------------------------------
def TFs(sentences):
    # initialize tfs dictonary
    tfs = {}

    # for every sentence in document cluster
    print(""line   79   sentences    "", sentences)
    for sent in sentences:
        # retrieve word frequencies from sentence object
        wordFreqs = sent.getWordFreq()
        # print(""line 82 frequency "",wordFreqs)

        # for every word
        for word in wordFreqs.keys():
            # if word already present in the dictonary
            if tfs.get(word, 0) != 0:
                tfs[word] = tfs[word] + wordFreqs[word]
            # else if word is being added for the first time
            else:
                tfs[word] = wordFreqs[word]
    return tfs


# ---------------------------------------------------------------------------------
# Description	: Function to find the inverse document frequencies of the words in
#				  the sentences present in the provided document cluster 
# Parameters	: sentences, sentences of the document cluster
# Return 		: dictonary of word, inverse document frequency score
# ---------------------------------------------------------------------------------
def IDFs(sentences):
    N = len(sentences)
    print(""line 101 total number of sentences are   "", N)
    print(""line 104 sentences  "", sentences)
    idf = 0
    idfs = {}
    words = {}
    w2 = []
    # every sentence in our cluster
    for sent in sentences:
        #print(""line 113 success"", (str(sent)))
        #print(""print  line 114  "", sent.getPreProWords())
        #print(""print  line 115  "", type(sent.getPreProWords()))
        #print(""print  line 116  "", len(list(sent.getPreProWords())))
        # every word in a sentence
        for word in sent.getPreProWords():
            print(""line 118 word is   "", word)
            # not to calculate a word's IDF value more than once
            if sent.getWordFreq().get(word, 0) != 0:
                words[word] = words.get(word, 0) + 1

    # for each word in words
    for word in words:
        n = words[word]
        # avoid zero division errors
        try:
            w2.append(n)
            idf = math.log10(float(N) / n)
        except ZeroDivisionError:
            idf = 0

        # reset variables
        idfs[word] = idf
        print(""words    "", word)
        print(""idf   "", idf)

    return idfs


# ---------------------------------------------------------------------------------
# Description	: Function to find TF-IDF score of the words in the document cluster
# Parameters	: sentences, sentences of the document cluster
# Return 		: dictonary of word, TF-IDF score
# ---------------------------------------------------------------------------------
def TF_IDF(sentences):
    # Method variables
    tfs = TFs(sentences)
    idfs = IDFs(sentences)
    retval = {}
    print(""tfs is    "" + str(tfs))
    print(""idfs is   "" + str(idfs))

    # for every word
    for word in tfs:
        # calculate every word's tf-idf
        print(""words  are    "" + word)
        print(""tfs of word is   "" + str(tfs[word]))
        # print(""idfs of word is   "" + str(idfs[word]))
        tf_idfs = tfs[word] * idfs[word]

        # add word and its tf-idf score to dictionary
        if retval.get(tf_idfs, None) == None:
            retval[tf_idfs] = [word]
        else:
            retval[tf_idfs].append(word)
    print(""TF IDF return value is   "", retval)

    return retval


# ---------------------------------------------------------------------------------
# Description	: Function to find the sentence similarity for a pair of sentences
#				  by calculating cosine similarity
# Parameters	: sentence1, first sentence
#				  sentence2, second sentence to which first sentence has to be compared
#				  IDF_w, dictinoary of IDF scores of words in the document cluster
# Return 		: cosine similarity score
# ---------------------------------------------------------------------------------
def sentenceSim(sentence1, sentence2, IDF_w):
    numerator = 0
    denominator = 0

    for word in sentence2.getPreProWords():
        numerator += sentence1.getWordFreq().get(word, 0) * sentence2.getWordFreq().get(word, 0) * IDF_w.get(word,
                                                                                                             0) ** 2

    for word in sentence1.getPreProWords():
        denominator += (sentence1.getWordFreq().get(word, 0) * IDF_w.get(word, 0)) ** 2

    # check for divide by zero cases and return back minimal similarity
    try:
        return numerator / math.sqrt(denominator)
    except ZeroDivisionError:
        return float(""-inf"")


# ---------------------------------------------------------------------------------
# Description	: Function to build a query of n words on the basis of TF-IDF value
# Parameters	: sentences, sentences of the document cluster
#				  IDF_w, IDF values of the words
#				  n, desired length of query (number of words in query)
# Return 		: query sentence consisting of best n words
# ---------------------------------------------------------------------------------
def buildQuery(sentences, TF_IDF_w, n):
    # sort in descending order of TF-IDF values
    scores = TF_IDF_w.keys()
    scores = sorted(scores,reverse=True)

    # scores.sort(reverse=True)

    i = 0
    j = 0
    queryWords = []

    # select top n words
    while (i < n):
        words = TF_IDF_w[scores[j]]
        for word in words:
            queryWords.append(word)
            i = i + 1
            if (i > n):
                break
        j = j + 1

    # return the top selected words as a sentence
    return sentence.sentence(""query"", queryWords, queryWords)


# ---------------------------------------------------------------------------------
# Description	: Function to find the best sentence in reference to the query
# Parameters	: sentences, sentences of the document cluster
#				  query, reference query
#				  IDF, IDF value of words of the document cluster
# Return 		: best sentence among the sentences in the document cluster
# ---------------------------------------------------------------------------------
def bestSentence(sentences, query, IDF):
    best_sentence = None
    maxVal = float(""-inf"")

    for sent in sentences:
        similarity = sentenceSim(sent, query, IDF)

        if similarity > maxVal:
            best_sentence = sent
            maxVal = similarity
    sentences.remove(best_sentence)

    return best_sentence


# ---------------------------------------------------------------------------------
# Description	: Function to create the summary set of a desired number of words 
# Parameters	: sentences, sentences of the document cluster
#				  best_sentnece, best sentence in the document cluster
#				  query, reference query for the document cluster
#				  summary_length, desired number of words for the summary
#				  labmta, lambda value of the MMR score calculation formula
#				  IDF, IDF value of words in the document cluster 
# Return 		: name 
# ---------------------------------------------------------------------------------
def makeSummary(sentences, best_sentence, query, summary_length, lambta, IDF):
    summary = [best_sentence]
    print(""line 264  summary "",summary)
    sum_len = len(best_sentence.getPreProWords())

    MMRval = {}

    # keeping adding sentences until number of words exceeds summary length
    while (sum_len < summary_length):
        MMRval = {}

        for sent in sentences:
            MMRval[sent] = MMRScore(sent, query, summary, lambta, IDF)
            print(""type of MMR value   "",MMRval)

       # maxxer = max(MMRval, key=MMRval.get)

        maxxer = max(MMRval, key=MMRval.get)
        summary.append(maxxer)
        sentences.remove(maxxer)
        sum_len += len(maxxer.getPreProWords())

    return summary







# ---------------------------------------------------------------------------------
# Description	: Function to calculate the MMR score given a sentence, the query
#				  and the current best set of sentences
# Parameters	: Si, particular sentence for which the MMR score has to be calculated
#				  query, query sentence for the particualr document cluster
#				  Sj, the best sentences that are already selected
#				  lambta, lambda value in the MMR formula
#				  IDF, IDF value for words in the cluster
# Return 		: name 
# ---------------------------------------------------------------------------------
def MMRScore(Si, query, Sj, lambta, IDF):
    Sim1 = sentenceSim(Si, query, IDF)
    l_expr = lambta * Sim1
    value = [float(""-inf"")]

    for sent in Sj:
        Sim2 = sentenceSim(Si, sent, IDF)
        value.append(Sim2)

    r_expr = (1 - lambta) * max(value)
    MMR_SCORE = l_expr - r_expr

    return MMRScore


# -------------------------------------------------------------
#	MAIN FUNCTION
# -------------------------------------------------------------
if __name__ == '__main__':

    # set the main Document folder path where the subfolders are present
    main_folder_path = os.getcwd() + ""/Documents""

    # read in all the subfolder names present in the main folder
    for folder in os.listdir(main_folder_path):

        print(""Running MMR Summarizer for files in folder: "", folder)
        # for each folder run the MMR summarizer and generate the final summary
        curr_folder = main_folder_path + ""/"" + folder

        # find all files in the sub folder selected
        files = os.listdir(curr_folder)
        print(""line 326  files are   "" + str(files))

        sentences = []

        for file in files:
            sentences = sentences + processFile(curr_folder + ""/"" + file)
        print(""line 332 sentences are   "" + str(sentences))
        print(""line 333    "", type(sentences))
        print(""lines 334 "", type(sentences))
        print(""line 335   "", type(sentences[1]))

        # calculate TF, IDF and TF-IDF scores
        #TF_w = TFs(sentences)
        #print(""line 338 TF_w is   "", TF_w)
        IDF_w = IDFs(sentences)
        print(""line 340 IDF-w is   "", IDF_w)
        TF_IDF_w = TF_IDF(sentences)

        # build query; set the number of words to include in our query
        query = buildQuery(sentences, TF_IDF_w, 10)

        # pick a sentence that best matches the query
        best1sentence = bestSentence(sentences, query, IDF_w)

        # build summary by adding more relevant sentences
        summary = makeSummary(sentences, best1sentence, query, 100, 0.5, IDF_w)

        final_summary = """"
        for sent in summary:
            final_summary = final_summary + sent.getOriginalWords() + ""\n""
        final_summary = final_summary[:-1]
        results_folder = os.getcwd() + ""/MMR_results""
        with open(os.path.join(results_folder, (str(folder) + "".MMR"")), ""w"") as fileOut:
            fileOut.write(final_summary)
"
262,https://github.com/RaRe-Technologies/gensim/issues/2110,2110,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-06-28 13:45:14+00:00,,Wikipedia : TypeError: '<' not supported between instances of 'str' and 'int',"Hi,

I am following the tutorial about train a doc2vec model with wikipedia corpus on this tutorial : 
https://markroxor.github.io/gensim/static/notebooks/doc2vec-wikipedia.html
i used the function  `TaggedWikiDocument` without the `decode(""utf-8"")`  in the following manner : 
```python
class TaggedWikiDocument(object)
    def __init__(self, wiki):
        self.wiki = wiki
        self.wiki.metadata = True
    def __iter__(self):
        for content, (page_id, title) in self.wiki.get_texts():
            yield TaggedDocument([c for c in content], [title])
```
After that i trained my model only on PV-DM and i have this problem at the step 10 when i want to use the similarity : 
```python
--> 466             elif doc in self.doctags or doc < self.count:
    467                 mean.append(weight * self.doctag_syn0norm[self._int_index(doc)])
    468                 all_docs.add(self._int_index(doc))

TypeError: '<' not supported between instances of 'str' and 'int'
```
I dont understand why ? if anyone had the same problem. i will be grateful if he answer

Thanks
 
"
263,https://github.com/RaRe-Technologies/gensim/issues/2111,2111,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}]",closed,2018-06-28 15:47:22+00:00,,Phrases documentation for threshold argument is misleading,"https://github.com/RaRe-Technologies/gensim/blob/37e49971efa74310b300468a5b3cf531319c6536/gensim/models/phrases.py#L252-L255

It feels to me like this should have said the opposite: ""**Heavily** depends on concrete scoring-function"" rather than ""**Hardly** depends on concrete socring-function"".

For example, if you choose npmi instead of the default, the threshold has to between -1 and 1, which makes the default (10.0) make no sense. The current documentation suggests that 10.0 will be OK."
264,https://github.com/RaRe-Technologies/gensim/issues/2112,2112,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}]",closed,2018-06-28 17:46:47+00:00,,`WmdSimilarity` corpus type mismatch in documentation ,"
#### Description
It seems that the  WmdSimilarity doesn't need the bow_corpus .
The corpus can be in token level, so the following code is not needed:
```python
bow_corpus = [dictionary.doc2bow(document) for document in common_texts]
```

#### Versions
```
Darwin-15.6.0-x86_64-i386-64bit
Python 3.6.3 |Intel Corporation| (default, May  3 2018, 23:25:54) 
[GCC 4.2.1 Compatible Apple LLVM 7.3.0 (clang-703.0.31)]
NumPy 1.14.3
SciPy 1.1.0
gensim 3.4.0
FAST_VERSION 1
```
"
265,https://github.com/RaRe-Technologies/gensim/issues/2113,2113,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}]",closed,2018-06-28 19:59:44+00:00,,`SvmLightCorpus.serialize` issue when `labels` type are `numpy.ndarray`,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
Found error in check labels condition while creating corpus using SvmLightCorpus.serialize 

#### Steps/Code/Corpus to Reproduce 

- Use twenty_newsgroups dataset from sklearn.datasets
- tokenize data and create corpus using gensim dictionary.doc2bow 
- create tfidf of the corpus 
- Pass corpus_tfidf and labels in:
 gensim.corpora.SvmLightCorpus.serialize('svm_20_news_groups.train', corpus_tfidf, labels=labels)

Suggestion: 
Change line 117 to :
` label = labels[docno] if labels.any() else 0  # target class is 0 by default`
or 
` label = labels[docno] if labels is not None and len(labels)>0 else 0  # target class is 0 by default`

#### Expected Results
Should save a gensim corpus

#### Actual Results
Traceback (most recent call last):
File ""svm.py"", line 40, in <module>
    gensim.corpora.SvmLightCorpus.serialize('svm_20_news_groups.train', corpus_tfidf, labels=labels)
File ""C:\Users\shiwangisingh\AppData\Local\Programs\Python\Python36\lib\site-packages\gensim\corpora\indexedcorpus.py"", line 117, in serialize
    offsets = serializer.save_corpus(fname, corpus, id2word, **kwargs)
File ""C:\Users\shiwangisingh\AppData\Local\Programs\Python\Python36\lib\site-packages\gensim\corpora\svmlightcorpus.py"", line 117, in save_corpus
    label = labels[docno] if labels else 0  # target class is 0 by default
ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()

#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->


<!-- Thanks for contributing! -->

"
266,https://github.com/RaRe-Technologies/gensim/issues/2114,2114,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2018-06-29 01:51:47+00:00,,Ability to weight context words by distance from target word for `*2vec` models,"The `window` parameter in word2vec controls how far apart two words can be and still directly influence each other's resulting embedding. The current setup is that a given word is in another word's window or it's not, a binary outcome. By analogy to kernel regression, word2vec uses a uniform (or boxcar) kernel to predict target words from input words. So, again by analogy to kernel regression, could we allow the user to specify the kernel as something other than uniform?

For example, when computing the loss, I'd like to be able to assign a weight to each context word, something like w = exp(-beta*k), where k is how far the context word is from the target word, and beta is nonnegative.  So allowing the user to select beta would be a start. Alternatively they could directly provide their own function of k.

I've googled a bit but have not found anything related to this proposal for word2vec, but it seems commonsense enough that surely someone has tried it?"
267,https://github.com/RaRe-Technologies/gensim/issues/2115,2115,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2018-07-03 16:01:49+00:00,,gensim.models.LDAmodel producing NaN & same words in each topic,"#### Description
Here is a brief introduction on StackOverflow; I thought I'd post this here too because the other StackOverflow question with the **exact same issue** as mine hasn't gotten even a single response in 2 weeks.

Link: [https://stackoverflow.com/questions/51142294/gensim-ldamodel-error-nan-and-all-topics-the-same](https://stackoverflow.com/questions/51142294/gensim-ldamodel-error-nan-and-all-topics-the-same)

#### Steps/Code/Corpus to Reproduce
```python
#create pandas frame object w/ default rows
def tokenize(pd_object):
    for i, row in pd_object.iterrows():
        id = row[""ID""]
        sentences = split_sentences(str(row[""Comment""]))
        """""" **Time Consuming** """"""
        tokens =  [[id, sent, gensim.parsing.preprocessing.preprocess_string(sent.lower(), filters=[strip_punctuation,
            strip_multiple_whitespaces, strip_numeric, strip_short, wordnet_stem])] for sent in sentences]
#append tokens to new pandas dataframe object 
```

```python
def train(pd_object):
    t1 = time.time()
    phrases_and_tokens = tokenize(pd_object)
    bag_of_words = phrases_and_tokens[""Tokens""].tolist()
    t2 = time.time()
    print(""Time Taken %12f"" % (t2-t1))

    bigram = gensim.models.Phrases(bag_of_words, threshold=1)
    bigram_mod = gensim.models.phrases.Phraser(bigram)

    texts = [filter_stop(bigram_mod[t]) for t in bag_of_words]

    id2word = corpora.Dictionary(texts)
    sent_wordfreq = [id2word.doc2bow(sent) for sent in texts]

    lda_model = gensim.models.ldamodel.LdaModel(corpus=sent_wordfreq,
                                                id2word=id2word,
                                                num_topics=5)

    print(lda_model.print_topics())
```

-->

#### Expected Results
Something like this:
```python
[(0,
  '0.025*""game"" + 0.018*""team"" + 0.016*""year"" + 0.014*""play"" + 0.013*""good"" + '
  '0.012*""player"" + 0.011*""win"" + 0.007*""season"" + 0.007*""hockey"" + '
  '0.007*""fan""'),
 (1,
  '0.021*""window"" + 0.015*""file"" + 0.012*""image"" + 0.010*""program"" + '
  '0.010*""version"" + 0.009*""display"" + 0.009*""server"" + 0.009*""software"" + '
  '0.008*""graphic"" + 0.008*""application""'),
 (2,
  '0.021*""gun"" + 0.019*""state"" + 0.016*""law"" + 0.010*""people"" + 0.008*""case"" + '
  '0.008*""crime"" + 0.007*""government"" + 0.007*""weapon"" + 0.007*""police"" + '
  '0.006*""firearm""'),
 (3,
  '0.855*""ax"" + 0.062*""max"" + 0.002*""tm"" + 0.002*""qax"" + 0.001*""mf"" + '
  '0.001*""giz"" + 0.001*""_"" + 0.001*""ml"" + 0.001*""fp"" + 0.001*""mr""'),
 (4,
  '0.020*""file"" + 0.020*""line"" + 0.013*""read"" + 0.013*""set"" + 0.012*""program"" '
  '+ 0.012*""number"" + 0.010*""follow"" + 0.010*""error"" + 0.010*""change"" + '
  '0.009*""entry""'),
 (5,
  '0.021*""god"" + 0.016*""christian"" + 0.008*""religion"" + 0.008*""bible"" + '
  '0.007*""life"" + 0.007*""people"" + 0.007*""church"" + 0.007*""word"" + 0.007*""man"" '
  '+ 0.006*""faith""'),
 (..truncated..)]
```
#### Actual Results
```python
[(0, 'nan*""datalabs"" + nan*""india"" + nan*""frequently"" + nan*""inconsistency"" + nan*""standard"" + ....
(1, 'nan*""datalabs"" + nan*""india"" + nan*""frequently"" + nan*""inconsistency"" + nan*""standard"" + ...
(2, 'nan*""datalabs"" + nan*""india"" + nan*""frequently"" + nan*""inconsistency"" + nan*""standard"" + ...
(3, 'nan*""datalabs"" + nan*""india"" + nan*""frequently"" + nan*""inconsistency"" + nan*""standard"" + ..)
(4, 'nan*""datalabs"" + nan*""india"" + nan*""frequently"" + nan*""inconsistency"" + nan*""standard"" + ..)]
```

Please paste or specifically describe the actual output or traceback. -->

#### Versions
```python
>>> import platform; print(platform.platform())
Darwin-17.6.0-x86_64-i386-64bit
>>> import sys; print(""Python"", sys.version)
Python 3.6.5 |Anaconda, Inc.| (default, Apr 26 2018, 08:42:37) 
[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.14.5
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.1.0
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.4.0
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1
```

I think it probably has to do with a numpy issue but all my attempts to upgrade and reinstall have been fruitless. Another coworker ran this on his computer and it worked just fine. Probably a recent update in numpy has caused this recent issue (there's one other person who posted it on StackOverflow 2 weeks ago) but uninstalling packages has broken so many things that I don't want to take the risk. However, I am trying to learn how to use virtual environments and see if I can test out different versions of numpy with this code. Thank you! Hope to get a response soon. 

<!-- Thanks for contributing! -->

"
268,https://github.com/RaRe-Technologies/gensim/issues/2117,2117,[],closed,2018-07-05 11:55:30+00:00,,Saving and then loading corrupts Doc2Vec model,"I just saw that the gensim version provided by Arch is pretty old. I am going to test with the newest version from `pip` and report back if the problem still persists. Ignore for now ...
Sorry for that. Should have checked before ...

#### Description
I trained a Doc2Vec model from scratch and directly after training I am getting reasonable results. After saving the model and loading it again, I get completely different and more or less random results. Am I doing something wrong? Is this a bug? ...

#### Steps/Code/Corpus to Reproduce
```python
from gensim.corpora.wikicorpus import WikiCorpus
from gensim.models.doc2vec import Doc2Vec, TaggedDocument
from pprint import pprint
import multiprocessing

wiki = WikiCorpus(""/data/enwiki-latest-pages-articles.xml.bz2"")

class TaggedWikiDocument(object):
    def __init__(self, wiki):
        self.wiki = wiki
        self.wiki.metadata = True
    def __iter__(self):
        for content, (page_id, title) in self.wiki.get_texts():
            yield TaggedDocument(content, [title])

documents = TaggedWikiDocument(wiki)

cores = multiprocessing.cpu_count()
model = Doc2Vec(dm=1, dm_mean=1, size=200, window=8, min_count=10, iter =10, workers=cores)

model.build_vocab(documents)
model.train(documents, total_examples=model.corpus_count, epochs=model.iter)

pprint(model.docvecs.most_similar(positive=[""Machine learning""], topn=20))
# Here I get a good results

model.save(""./doc2vecmodel.mod"")
model = Doc2Vec.load(""./doc2vecmodel.mod"")
pprint(model.docvecs.most_similar(positive=[""Machine learning""], topn=20))
# Here I get more or less random results
```

#### Expected Results (before save and load)
```
[('Multi-task learning', 0.7568818926811218),
 ('Pattern recognition', 0.749046802520752),
 ('Statistical classification', 0.7360684871673584),
 ('Linear classifier', 0.7219105362892151),
 ('Prior knowledge for pattern recognition', 0.7102837562561035),
 ('Supervised learning', 0.7076001167297363),
 ('Naive Bayes classifier', 0.7071056365966797),
 ('Support vector machine', 0.7007730603218079),
 ('Statistical learning theory', 0.6968303322792053),
 ('Feature selection', 0.6903674602508545),
 ('Regularization (mathematics)', 0.6844260692596436),
 ('Meta learning (computer science)', 0.6837587952613831),
 ('Early stopping', 0.6815727353096008),
 ('Similarity learning', 0.6798273324966431),
 ('Predictive analytics', 0.6749750375747681),
 ('Artificial neural network', 0.6720495223999023),
 ('Empirical risk minimization', 0.6702870726585388),
 ('Structured prediction', 0.6696684956550598),
 ('Perceptron', 0.6685298085212708),
 ('Boosting (machine learning)', 0.6679200530052185)]
```

#### Actual Results (after save and load)
 
```
[('Mossant', 0.3701874911785126),
 ('Filatima fuliginea', 0.3571828305721283),
 ('Heinrich Barth', 0.33388739824295044),
 ('Caleb Suri', 0.33307966589927673),
 ('Wriddhiman Saha', 0.33189573884010315),
 ('Priyaa Lal', 0.3283548057079315),
 (""2nd Queen Victoria's Own Rajput Light Infantry"", 0.3266987204551697),
 ('United States presidential election in Missouri, 1988', 0.32637813687324524),
 ('Jim Payne (golfer)', 0.32357922196388245),
 ('Reflexe', 0.3232496678829193),
 ('Fobbing Marsh', 0.3231257498264313),
 ('Street Fighter 2010: The Final Fight', 0.32258525490760803),
 ('Saint-Thibault-des-Vignes', 0.3203728199005127),
 ('Frederick, Count of Verdun', 0.3182566165924072),
 ('Final Justice (1997 film)', 0.31800541281700134),
 ('List of national universities in South Korea', 0.3160543441772461),
 ('Lake Lafayette', 0.31462588906288147),
 ('Secrets of the Muse', 0.31268560886383057),
 ('Baihe Subdistrict', 0.31175172328948975),
 ('Robert III de Sablé', 0.3113846480846405)]
```

#### Versions
```
Linux-4.17.3-1-ARCH-x86_64-with-arch-Arch-Linux
Python 3.6.5 (default, May 11 2018, 04:00:52) 
[GCC 8.1.0]
NumPy 1.14.5
SciPy 1.1.0
gensim 2.3.0
FAST_VERSION 1
```

"
269,https://github.com/RaRe-Technologies/gensim/issues/2118,2118,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2018-07-05 18:13:22+00:00,,Setup script instructions are out of date.,"Setup script instructions are out of date.

Environment: no C++ build tools.

Running cmd in in windows:
easy_install -U gensim


EDIT: OR running cmd in in windows:
pip install --upgrade gensim

error message:
error: Setup script exited with error: Microsoft Visual C++ 14.0 is required. Get it with ""Microsoft Visual C++ Build Tools"": http://landinghub.visualstudio.com/visual-cpp-build-tools

Going to http://landinghub.visualstudio.com/visual-cpp-build-tools
Gives 404 - page not found

Suggestion:
replace URL with
https://visualstudio.microsoft.com/downloads/#build-tools-for-visual-studio-2017"
270,https://github.com/RaRe-Technologies/gensim/issues/2119,2119,[],closed,2018-07-06 10:12:11+00:00,,err_rate in IMDB tutorial ,"#### Description
While running the Gensim tutorial notebook on the IMDB sentiment dataset I'm getting an error in cell 8 that err_rate hasn't been defined. I can't see this variable mentioned anywhere above in the notebook either?   

### Error code 
```
`NameError                                 Traceback (most recent call last)
<ipython-input-8-b42daaad37cc> in <module>()
      5     print(""\nEvaluating %s"" % model)
      6     get_ipython().run_line_magic('time', 'err_rate, err_count, test_count, predictor = error_rate_for_model(model, train_docs, test_docs)')
----> 7     error_rates[str(model)] = err_rate
      8     print(""\n%f %s\n"" % (err_rate, model))

NameError: name 'err_rate' is not defined`
```

### Notes 
I __am__ running the script with a different dataset, but I __believe__ I have made the correct changes. The only changes where to the first cell dirname 


#### Versions
Windows-10-10.0.16299-SP0
Python 3.6.4 |Anaconda custom (64-bit)| (default, Mar 12 2018, 20:20:50) [MSC v.1900 64 bit (AMD64)]
NumPy 1.14.2
SciPy 1.0.0
gensim 3.4.0
FAST_VERSION 1




"
271,https://github.com/RaRe-Technologies/gensim/issues/2120,2120,[],closed,2018-07-06 12:28:50+00:00,,Why I got more docvec vectors than the number of my actual number of docs?,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
I am using Doc2Vec to embed my docs into vectors, the training was successful but the results are strange to me. I have 46k docs, while the size of docvecs is 200k. I don't know what's wrong with my code.
<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce
```
class LabeledLineSentence(object):
    def __init__(self, doc_list, labels_list):
        self.labels_list = labels_list
        self.doc_list = doc_list
    def __iter__(self):
        for idx, doc in enumerate(self.doc_list):
              yield gensim.models.doc2vec.TaggedDocument(doc, [self.labels_list[idx]])


df = pd.read_csv(""data/DATA_HADM.csv"", escapechar='\\')
texts = df['text'].values  # this a ~46K array
label = list(df['id'])

size = 600 
it = LabeledLineSentence(texts, label)
    
model_d2v = Doc2Vec(min_count=10, window=5, vector_size=size, sample=1e-3, negative=5, workers=8)
model_d2v.build_vocab(it)
model_d2v.train(it, epochs=10, total_examples=model_d2v.corpus_count)
```
<!--
Example:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->

#### Expected Results
I expect the `model_d2v.docvecs` is a 46k-by-600 matrix.
<!-- Example: Expected shape of (100,2).-->

#### Actual Results
The actual resulting matrix is a 200k-by-600 matrix, I don't understand.
<!-- Example: Actual shape of (100,5). 

Please paste or specifically describe the actual output or traceback. -->

#### Versions
Linux-4.4.0-1062-aws-x86_64-with-debian-stretch-sid
Python 3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) 
[GCC 7.2.0]
NumPy 1.14.3
SciPy 1.1.0
gensim 3.4.0
FAST_VERSION 1

<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->


<!-- Thanks for contributing! -->

"
272,https://github.com/RaRe-Technologies/gensim/issues/2123,2123,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}]",closed,2018-07-09 11:30:09+00:00,,Poincare visualization breaks with plotly 3.0.0    ,"#### Description

poincare_2d_visualization - receives the following error - 
ValueError: 
    Invalid value of type 'builtins.str' received for the 'textposition' property of scatter
        Received value: 'bottom'

#### Steps/Code/Corpus to Reproduce
Example:
```
from gensim.viz.poincare import poincare_2d_visualization
import plotly


vis = poincare_2d_visualization(model, tuples, 'Poincare Plot')
```

#### Versions
Please run the following snippet and paste the output below.
Darwin-17.2.0-x86_64-i386-64bit
Python 3.6.5 |Anaconda, Inc.| (default, Apr 26 2018, 08:42:37) 
[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]
NumPy 1.14.3
SciPy 1.1.0
gensim 3.5.0
FAST_VERSION 1
Plotly 3.0.0"
273,https://github.com/RaRe-Technologies/gensim/issues/2126,2126,[],closed,2018-07-10 13:34:11+00:00,,import error even after installing,"Installing collected packages: gensim
Successfully installed gensim-3.5.0


Python 3.6.5 (default, Apr 26 2018, 00:14:31)
[GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import gensim
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ModuleNotFoundError: No module named 'gensim'

"
274,https://github.com/RaRe-Technologies/gensim/issues/2129,2129,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-07-12 18:05:25+00:00,,Troubles with randint while word2vec training,"Hey fellow developers,
I tried hard to fit word2vec on my sentences but on all the threads I received the following:

    Traceback (most recent call last):
      File ""/root/anaconda3/lib/python3.6/threading.py"", line 916, in _bootstrap_inner
        self.run()
      File ""/root/anaconda3/lib/python3.6/threading.py"", line 864, in run
        self._target(*self._args, **self._kwargs)
      File ""/root/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py"", line 164, in _worker_loop
        tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
      File ""/root/anaconda3/lib/python3.6/site-packages/gensim/models/word2vec.py"", line 771, in _do_train_job
        tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)
      File ""gensim/models/word2vec_inner.pyx"", line 533, in gensim.models.word2vec_inner.train_batch_sg
    AttributeError: 'NoneType' object has no attribute 'randint'

I have googled the error, fixed from 

    next_random = (2**24) * model.random.randint(0, 2**24) + model.random.randint(0, 2**24)

to 

    next_random = (2**24) * np.random.randint(0, 2**24) + np.random.randint(0, 2**24)

but it didn't help. Plz, help.

"
275,https://github.com/RaRe-Technologies/gensim/issues/2131,2131,[],closed,2018-07-17 15:02:44+00:00,,max_vocab_size is not what I expected when training Word2Vec,"When I train word2vec model with **max_vocab_size=10,000** words, the number of unique vocabulary I get is only about **4,000 words** (measured using len(model.wv.vocab)). 

max_vocab_size is supposed to limit the number of unique words to the specified number (i.e., 10,000 in my case). It is possible to get less than the limit, if the number of words in the corpus is small. But my corpus can produce more words; **when I set max_vocab_size=None, I get 47,000 words**. 

Could you please help me understand the reason why I'm having only 4,000 unique words although max_vocab_size is much larger (10,000 words) and the number of unique words that my corpus can produce is about 47,000 words --with max_vocab_size=None.

- Note that I use: one worker, min_count=0, and NLTK Brown Corpus data for training.

- I observed the same behavior when I used other training data. 

#### Versions
Linux-4.4.0-87-generic-x86_64-with-Ubuntu-16.04-xenial
Python 3.5.2 
[GCC 5.4.0 20160609]
NumPy 1.14.3
SciPy 1.1.0
gensim 3.4.0
FAST_VERSION 1

Thanks,"
276,https://github.com/RaRe-Technologies/gensim/issues/2134,2134,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}]",open,2018-07-19 02:48:40+00:00,,Add ELMo (Deep contextualized word representations),"## Introduction
ELMo is a deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). These word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. They can be easily added to existing models and significantly improve the state of the art across a broad range of challenging NLP problems, including question answering, textual entailment and sentiment analysis.

### Other Tools

- [ ] [allenai](https://github.com/allenai/bilm-tf)
- [ ] [elmo](https://allennlp.org/elmo)

### Issue Description

It's not easy to use them.
I need a more simple and convenient tool like ""Word2Vec"" in ""gensim""
"
277,https://github.com/RaRe-Technologies/gensim/issues/2136,2136,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2018-07-23 14:46:29+00:00,,Gensim's Doc2Vec/FastText/Word2Vec models with `callbacks` can't be loaded after saving,"#### Description

Gensim's Doc2Vec model can not be loaded after saving. 
I trained my Doc2Vec model using examples of code provided below, saved it on 9th epoch and than when I'm trying to load it I receive an error (listing added). 
No problems were received during training. 
Training was executed on the same machine, on which I'm trying to load it again. 

And please, provide the way to save this model to continue using it after training. 

#### Steps/Code/Corpus to Reproduce
#### Training phase 

```python
class EpochSaver(CallbackAny2Vec):
    '''Callback to save model after each epoch and show training parameters '''

    def __init__(self, savedir):
        self.savedir = savedir
        self.epoch = 0
        os.makedirs(self.savedir, exist_ok=True)

    def on_epoch_end(self, model):
        savepath = os.path.join(self.savedir, ""model_neg{}_epoch.gz"".format(self.epoch))
        model.save(savepath)
        print(
            ""Epoch saved: {}"".format(self.epoch + 1),
            ""Start next epoch ... "", sep=""\n""
            )
        if os.path.isfile(os.path.join(self.savedir, ""model_neg{}_epoch.gz"".format(self.epoch - 1))):
            print(""Previous model deleted "")
            os.remove(os.path.join(self.savedir, ""model_neg{}_epoch.gz"".format(self.epoch - 1))) 
        self.epoch += 1


def train():

    workers = multiprocessing.cpu_count()/2
    model = Doc2Vec(
        DocIter(),
        vec_size=700, alpha=0.03, min_alpha=0.00025, epochs=10,
        min_count=10, dm=1, hs=0, negative=10, workers=workers,
        window=20, callbacks=[EpochSaver(""./checkpoints"")]
    )  

```
**Load trained model:** 
```python
    from gensim.models.doc2vec import Doc2Vec
    model = Doc2Vec.load(""checkpoints/model_neg9_epoch.gz"")
```

#### Results
> Loading model
> INFO:gensim.utils:loading Doc2Vec object from checkpoints/model_neg9_epoch.gz
> INFO:gensim.models.doc2vec:Model saved using code from earlier Gensim Version. Re-loading old model in a compatible way.
> INFO:gensim.models.deprecated.old_saveload:loading Doc2Vec object from checkpoints/model_neg9_epoch.gz
> Traceback (most recent call last):
>   File ""/Users/user/Python/dynamic_topics/env/lib/python3.5/site-packages/gensim/models/doc2vec.py"", line 689, in load
>     return super(Doc2Vec, cls).load(*args, **kwargs)
>   File ""/Users/user/Python/dynamic_topics/env/lib/python3.5/site-packages/gensim/models/base_any2vec.py"", line 629, in load
>     model = super(BaseWordEmbeddingsModel, cls).load(*args, **kwargs)
>   File ""/Users/user/Python/dynamic_topics/env/lib/python3.5/site-packages/gensim/models/base_any2vec.py"", line 278, in load
>     return super(BaseAny2VecModel, cls).load(fname_or_handle, **kwargs)
>   File ""/Users/user/Python/dynamic_topics/env/lib/python3.5/site-packages/gensim/utils.py"", line 425, in load
>     obj = unpickle(fname)
>   File ""/Users/user/Python/dynamic_topics/env/lib/python3.5/site-packages/gensim/utils.py"", line 1332, in unpickle
>     return _pickle.load(f, encoding='latin1')
> AttributeError: Can't get attribute 'EpochSaver' on <module '__main__' from 'cluster_d2v.py'>
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""cluster_d2v.py"", line 71, in <module>
>     model = Doc2Vec.load(""checkpoints/model_neg9_epoch.gz"")
>   File ""/Users/user/Python/dynamic_topics/env/lib/python3.5/site-packages/gensim/models/doc2vec.py"", line 693, in load
>     return load_old_doc2vec(*args, **kwargs)
>   File ""/Users/user/Python/dynamic_topics/env/lib/python3.5/site-packages/gensim/models/deprecated/doc2vec.py"", line 84, in load_old_doc2vec
>     old_model = Doc2Vec.load(*args, **kwargs)
>   File ""/Users/user/Python/dynamic_topics/env/lib/python3.5/site-packages/gensim/models/deprecated/word2vec.py"", line 1616, in load
>     model = super(Word2Vec, cls).load(*args, **kwargs)
>   File ""/Users/user/Python/dynamic_topics/env/lib/python3.5/site-packages/gensim/models/deprecated/old_saveload.py"", line 87, in load
>     obj = unpickle(fname)
>   File ""/Users/user/Python/dynamic_topics/env/lib/python3.5/site-packages/gensim/models/deprecated/old_saveload.py"", line 380, in unpickle
>     return _pickle.loads(file_bytes, encoding='latin1')
> AttributeError: Can't get attribute 'EpochSaver' on <module '__main__' from 'cluster_d2v.py'>

#### Versions

Darwin-17.6.0-x86_64-i386-64bit
Python 3.5.4 (v3.5.4:3f56838976, Aug  7 2017, 12:56:33) 
[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)]
NumPy 1.14.5
SciPy 1.1.0
gensim 3.4.0
FAST_VERSION 0

<!-- Thanks for contributing! -->

"
278,https://github.com/RaRe-Technologies/gensim/issues/2137,2137,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}]",closed,2018-07-23 19:50:10+00:00,,Can't run Wrapper.LDAmallet via python due to FileNotFoundError & CalledProcessError,"I posted this issue on a dev branch for mallet, it's about the same problem (and it will probably have more depth cuz I might miss certain details this time around): https://github.com/mimno/Mallet/issues/135#issuecomment-407156116
Based on the response I got, I wanted to bring the issue here. I'm now just going to start copying most of the text from that post. A developer there felt as though the issue is that the gensim wrapper can't quite construct windows directory paths.

I'm using python 3 on windows 10, gensim 3.5.0 and mallet 2.0.8 (with Java SDK 8). I'm alternating between two error messages based on the changes that I make to the `MALLET_BINARY_PATH` variable below. My mallet folder lives in another directory called mallet_unzipped. This is the location to the binary: C:\Users\biney\mallet_unzipped\mallet-2.0.8\bin\mallet

```
from pathlib import Path
home = str(Path.home())
MALLET_BINARY_PATH = home + ""\\mallet_unzipped\\mallet-2.0.8\\bin\\mallet"" # absolute address
#MALLET_BINARY_PATH =""/c/users/biney/mallet_unzipped/mallet-2.0.8/bin/mallet"" # 
doc_term_matrix = [doc_dict.doc2bow(doc) for doc in docs_of_tokens]
Lda_mallet = LdaMallet(mallet_path=MALLET_BINARY_PATH, corpus=doc_term_matrix, id2word=doc_dict, iterations=30)
```

If I run this code as is, with MALLET_BINARY_PATH the first declaration (the one commented with ""absolute address""), I get the FileNotFoundError. In this case, MALLET_BINARY_PATH prints: `C:\Users\biney\mallet_unzipped\mallet-2.0.8\bin\mallet`

```
Traceback (most recent call last):
  File ""text_mining.py"", line 632, in <module>
    main()
  File ""text_mining.py"", line 563, in main
    mallet_LDA_implementation(name_of_lda=""mallet_lda_no_filter_t10"", create_dic
t=False, remove_low_freq=False)
  File ""text_mining.py"", line 458, in mallet_LDA_implementation
    Lda_mallet = LdaMallet(mallet_path=MALLET_BINARY_PATH,  corpus=doc_term_matr
ix, id2word=doc_dict, iterations=30)
  File ""C:\Users\biney\Miniconda3\lib\site-packages\gensim\models\wrappers\ldama
llet.py"", line 126, in __init__
    self.train(corpus)
  File ""C:\Users\biney\Miniconda3\lib\site-packages\gensim\models\wrappers\ldama
llet.py"", line 279, in train
    self.word_topics = self.load_word_topics()
  File ""C:\Users\biney\Miniconda3\lib\site-packages\gensim\models\wrappers\ldama
llet.py"", line 337, in load_word_topics
    with utils.smart_open(self.fstate()) as fin:
  File ""C:\Users\biney\Miniconda3\lib\site-packages\smart_open\smart_open_lib.py
"", line 231, in smart_open
    binary, filename = _open_binary_stream(uri, binary_mode, **kw)
  File ""C:\Users\biney\Miniconda3\lib\site-packages\smart_open\smart_open_lib.py
"", line 318, in _open_binary_stream
    fobj = io.open(parsed_uri.uri_path, mode)
FileNotFoundError: [Errno 2] No such file or directory: 'C:\\Users\\biney\\AppDa
ta\\Local\\Temp\\db41f1_state.mallet.gz'
```
It seems like what's problematic about this error message is the two backslashes used between directories. However, the way I've been typing in backslashes into python is through the following: '\\' and it's at least printing correctly.
If I comment out the MALLET_BINARY_PATH = home +... and comment in the line below it, I get the following error message:

```
Traceback (most recent call last):
  File ""text_mining.py"", line 632, in <module>
    main()
  File ""text_mining.py"", line 563, in main
    mallet_LDA_implementation(name_of_lda=""mallet_lda_no_filter_t10"", create_dic
t=False, remove_low_freq=False)
  File ""text_mining.py"", line 458, in mallet_LDA_implementation
    Lda_mallet = LdaMallet(mallet_path=MALLET_BINARY_PATH,  corpus=doc_term_matr
ix, id2word=doc_dict, iterations=30)
  File ""C:\Users\biney\Miniconda3\lib\site-packages\gensim\models\wrappers\ldama
llet.py"", line 126, in __init__
    self.train(corpus)
  File ""C:\Users\biney\Miniconda3\lib\site-packages\gensim\models\wrappers\ldama
llet.py"", line 267, in train
    self.convert_input(corpus, infer=False)
  File ""C:\Users\biney\Miniconda3\lib\site-packages\gensim\models\wrappers\ldama
llet.py"", line 256, in convert_input
    check_output(args=cmd, shell=True)
  File ""C:\Users\biney\Miniconda3\lib\site-packages\gensim\utils.py"", line 1832,
 in check_output
    raise error
subprocess.CalledProcessError: Command '/c/users/biney/mallet_unzipped/mallet-2.
0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --
token-regex ""\S+"" --input C:\Users\biney\AppData\Local\Temp\e0e83e_corpus.txt --
output C:\Users\biney\AppData\Local\Temp\e0e83e_corpus.mallet' returned non-zero
 exit status 1.
```

I've been bouncing back and forth between these errors and I really don't know what they mean or how to set the right foot forward. I have tried copying the command shown in the second error message into git bash and it worked without crashing. I had to make adjustments. This command seems to refer to two temporary files that were created prior to me getting the other two error messages I copied and pasted.

```
~/mallet_unzipped/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex ""\S+"" --input ~/AppData/Local/Temp/a0a87d_corpus.txt --output ~/AppData/Local/Temp/a0a87d_corpus.mallet
```

And you may wonder if I tried including `'~'` in the python code... in short, including the `'~'` char gives an ""error this character isn't recognizable"" message.
Specifying a prefix parameter location seems to always give me an error along the lines of
FileNotFoundError: [Errno 2] No such file or directory: 'mallet_temp/state.mallet.gz'
the 'mallet_temp/state.mallet' used the prefix 'mallet_temp'. Any error message I get shows the prefix location and states that no such file or directory exists with the name and extension shown.

The final attempt I made was the following choices with parameters:

```
prefix_path = ""/c/users/biney/Projects/twitter_gmu_2018/mallet_temp/""
Lda_mallet = LdaMallet(mallet_path=""/c/users/biney/mallet_unzipped/mallet-2.0.8/bin/mallet"", prefix=prefix_path, corpus=doc_term_matrix, id2word=doc_dict, iterations=30)
```
And I get the following error message

```
Traceback (most recent call last):
  File ""text_mining.py"", line 634, in <module>
    main()
  File ""text_mining.py"", line 565, in main
    mallet_LDA_implementation(name_of_lda=""mallet_lda_no_filter_t10"", create_dic
t=False, remove_low_freq=False)
  File ""text_mining.py"", line 460, in mallet_LDA_implementation
    Lda_mallet = LdaMallet(mallet_path=""/c/users/biney/mallet_unzipped/mallet-2.
0.8/bin/mallet"", prefix=prefix_path,  corpus=doc_term_matrix, id2word=doc_dict,
iterations=30)
  File ""C:\Users\biney\Miniconda3\lib\site-packages\gensim\models\wrappers\ldama
llet.py"", line 126, in __init__
    self.train(corpus)
  File ""C:\Users\biney\Miniconda3\lib\site-packages\gensim\models\wrappers\ldama
llet.py"", line 267, in train
    self.convert_input(corpus, infer=False)
  File ""C:\Users\biney\Miniconda3\lib\site-packages\gensim\models\wrappers\ldama
llet.py"", line 242, in convert_input
    with smart_open(self.fcorpustxt(), 'wb') as fout:
  File ""C:\Users\biney\Miniconda3\lib\site-packages\smart_open\smart_open_lib.py
"", line 181, in smart_open
    fobj = _shortcut_open(uri, mode, **kw)
  File ""C:\Users\biney\Miniconda3\lib\site-packages\smart_open\smart_open_lib.py
"", line 287, in _shortcut_open
    return io.open(parsed_uri.uri_path, mode, **open_kwargs)
FileNotFoundError: [Errno 2] No such file or directory: '/c/users/biney/Projects
/twitter_gmu_2018/mallet_temp/corpus.txt'
```
What's frustrating from that final error message is that from using file explorer and goingto the /mallet_temp/ directory... there actually is only one file in it called ""corpus.txt."" So that's suggesting to me that this file is somehow not being found when it actually should be.
"
279,https://github.com/RaRe-Technologies/gensim/issues/2138,2138,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2018-07-24 07:39:12+00:00,,Scikit learn wrapper for fasttext model,"Is there any plan to make this wrapper? I want to integrate fasttext model in scikit learn pipeline.

Thanks."
280,https://github.com/RaRe-Technologies/gensim/issues/2139,2139,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",closed,2018-07-24 08:56:28+00:00,,FastText incremental training fails,"#### Description
Having successfully trained model (with 20 epochs), which has been saved and loaded back without any problems, I'm trying to continue training it for another 10 epochs - on the same data, with the same parameters - but it fails with an error: `TypeError: 'NoneType' object is not subscriptable` (for full traceback see below).

#### Steps/Code/Corpus to Reproduce
```python
from gensim.models.fasttext import FastText

# `train_data' is just a list of lists of strings (words), e.g.
# `[['w1', 'w2', 'w3', ...], ['w1', 'w4', 'w5', ...], ...]'.
model = FastText(
    train_data,
    sg=1,
    size=200,
    window=5,
    min_count=1,
    workers=16,
    negative=20,
    iter=20,
    min_n=3,
    max_n=5,
    word_ngrams=1,
    bucket=int(2e6)
)

# `model_file' is a string with the path to the file where model is being saved
model.save(model_file)

model = FastText.load(model_file)

# `train_data' here is exactly the same as before
model.train(train_data, epochs=10, total_examples=model.corpus_count)
```

#### Expected Results
Successfully trained model.

#### Actual Results
```python
[WARNING 2018-07-23 14:42:00,222] Effective 'alpha' higher than previous training cycles
[INFO 2018-07-23 14:42:00,222] training model with 16 workers on 15145 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=20 window=5
Exception in thread Thread-50:
Traceback (most recent call last):
  File ""/usr/lib/python3.5/threading.py"", line 914, in _bootstrap_inner
    self.run()
  File ""/usr/lib/python3.5/threading.py"", line 862, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/ubuntu/env/lib/python3.5/site-packages/gensim/models/base_any2vec.py"", line 99, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""/home/ubuntu/env/lib/python3.5/site-packages/gensim/models/fasttext.py"", line 454, in _do_train_job
    tally += train_batch_sg(self, sentences, alpha, work, neu1)
  File ""gensim/models/fasttext_inner.pyx"", line 319, in gensim.models.fasttext_inner.train_batch_sg
TypeError: 'NoneType' object is not subscriptable
```

#### Versions
Linux-4.15.0-1014-gcp-x86_64-with-Ubuntu-16.04-xenial
Python 3.5.2 (default, Nov 23 2017, 16:37:01) 
[GCC 5.4.0 20160609]
NumPy 1.14.5
SciPy 1.1.0
gensim 3.4.0
FAST_VERSION 1"
281,https://github.com/RaRe-Technologies/gensim/issues/2140,2140,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2018-07-26 09:33:17+00:00,,Phrases keeps learned vocabs as bytestring,"#### Description
To collect phrase dictionary or to find appropriate parameters for a corpus with the Phrases model, I tried to see vocabularies built inside a trained instance of Pharses. However, there are full of bytestrings stored inside the member `vocab`. And I found that it intentionally converts all tokens into a bytestring by calling a method `any2utf8`. I think it is not normal as it produces unexpected behaviour with the docstring example code (below) inside the class.

#### Steps/Code/Corpus to Reproduce
This is an example code in gensim/models/phrases.py, which shows a way to get vocabulary list after training the model.

```python
>>> from gensim.test.utils import datapath
>>> from gensim.models.word2vec import Text8Corpus
>>> from gensim.models.phrases import Phrases
>>>
>>> sentences = Text8Corpus(datapath('testcorpus.txt'))
>>> pruned_words, counters, total_words = Phrases.learn_vocab(sentences, 100)
```

#### Expected Results
```python
>>> counters['computer']
2
>>> counters['response_time']
1
>>> counters.keys()
dict_keys(['computer', 'human', 'computer_human', 'interface', 'human_interface', 'interface_computer', 'response', 'computer_response', 'survey', 'response_survey', 'system', 'survey_system', 'time', 'system_time', 'user', 'time_user', 'user_interface', 'interface_system', 'system_user', 'eps', 'user_eps', 'eps_human', 'human_system', 'system_system', 'system_eps', 'eps_response', 'response_time', 'trees', 'user_trees', 'trees_trees', 'graph', 'trees_graph', 'graph_trees', 'minors', 'graph_minors', 'minors_survey', 'survey_graph'])
```

#### Actual Results
```python
>>> counters.keys()
dict_keys([b'computer', b'human', b'computer_human', b'interface', b'human_interface', b'interface_computer', b'response', b'computer_response', b'survey', b'response_survey', b'system', b'survey_system', b'time', b'system_time', b'user', b'time_user', b'user_interface', b'interface_system', b'system_user', b'eps', b'user_eps', b'eps_human', b'human_system', b'system_system', b'system_eps', b'eps_response', b'response_time', b'trees', b'user_trees', b'trees_trees', b'graph', b'trees_graph', b'graph_trees', b'minors', b'graph_minors', b'minors_survey', b'survey_graph', 'computer'])
>>> counters['computer']
0
>>> counters['response_time']
0
>>> counters[b'computer']
2
>>> counters[b'response_time']
1
```
The keys are stored in bytestring and only outputs expected countings with providing bytestring.

#### Versions
Linux-4.13.0-45-generic-x86_64-with-debian-stretch-sid
Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 17:14:51)
[GCC 7.2.0]
NumPy 1.14.5
SciPy 1.1.0
gensim 3.5.0
FAST_VERSION 1
"
282,https://github.com/RaRe-Technologies/gensim/issues/2141,2141,[],closed,2018-07-27 09:03:20+00:00,,Whether Doc2vec need build vocabulary?,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
Whether Doc2vec needs build vocabulary before training?
I'm following the code in [document](https://radimrehurek.com/gensim/models/doc2vec.html), it doesn't build vocabulary.

#### Steps/Code/Corpus to Reproduce
```
from gensim.test.utils import common_texts, get_tmpfile
from gensim.models.doc2vec import Doc2Vec, TaggedDocument


def train_doc2vec_model(corpus_list):
    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(corpus_list)]
    model = Doc2Vec(documents, vector_size=5, window=2, workers=2)
    model_save_name = get_tmpfile('doc2vec_model')
    model.save(model_save_name)


if __name__ == '__main__':
    train_doc2vec_model(common_texts)

```
#### Expected Results
<!-- Example: Expected shape of (100,2).-->

#### Actual Results
```
Traceback (most recent call last):
  File ""/home/ring/python3_code/demo_doc2vec.py"", line 61, in <module>
    train_doc2vec_model(common_texts)
  File ""/home/ring/python3_code/demo_doc2vec.py"", line 23, in train_doc2vec_model
    model = Doc2Vec(documents, vector_size=256, window=2, workers=multiprocessing.cpu_count())
  File ""/home/ring/anaconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py"", line 575, in __init__
    start_alpha=self.alpha, end_alpha=self.min_alpha, callbacks=callbacks)
  File ""/home/ring/anaconda3/lib/python3.6/site-packages/gensim/models/doc2vec.py"", line 717, in train
    queue_factor=queue_factor, report_delay=report_delay, callbacks=callbacks)
  File ""/home/ring/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py"", line 938, in train
    queue_factor=queue_factor, report_delay=report_delay, compute_loss=compute_loss, callbacks=callbacks)
  File ""/home/ring/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py"", line 421, in train
    total_words=total_words, **kwargs)
  File ""/home/ring/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py"", line 1044, in _check_training_sanity
    raise RuntimeError(""you must first build vocabulary before training the model"")
RuntimeError: you must first build vocabulary before training the model

```

#### Versions
Linux-4.15.0-24-generic-x86_64-with-debian-stretch-sid
Python 3.6.1 |Anaconda custom (64-bit)| (default, May 11 2017, 13:09:58)
NumPy 1.15.0
SciPy 1.1.0
gensim 3.5.0

"
283,https://github.com/RaRe-Technologies/gensim/issues/2142,2142,[],closed,2018-07-30 14:30:57+00:00,,Word2Vec online training not consistent,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
Word2Vec online training not consistent.
Initially I wanted to verify if this is due to any version upgrades but it is similar across the two versions I checked [Versions 0.13.3 and 3.4.0]. 
The basis is that we train a Word2Vec model on a corpus and make a copy of it and call the train method again but this time providing some new sentences to train on without any out of vocabulary words. The difference is expected to be non-zero as some vectors would be updated after the training but it is not consistent across corpus even if the initial word2vec are built the same way. 
Would this be some issue with the code or is it expected with Word2Vec?

#### Expected Results
When training some new sentences (in my case without any OOV words) on the created word2vec, some of the vectors should change in value.

#### Actual Results
While working on the reproduction script for different gensim version, observed that online training is not consistent for different corpus. Here are the output for two different corpus based on the above code found in gist:

```
Output for gensim 3.4.0 and Text8 corpus :-

('Non zero vectors present:', True)
('Total unique words updated:', 26)

Output for gensim 3.4.0 and Newsgroup corpus :-

('Non zero vectors present:', False)
('Total unique words updated:', 0)
```

#### Steps/Code/Corpus to Reproduce
https://gist.github.com/sairampillai/d0448bdc57999eb38016f0d6cd32defd

#### Versions
Windows-10-10.0.14393
'Python', '2.7.14 (v2.7.14:84471935ed, Sep 16 2017, 20:25:58) [MSC v.1500 64 bit (AMD64)]'
'NumPy', '1.14.1'
'SciPy', '1.0.0'
'gensim', '3.4.0'
'FAST_VERSION', 0
"
284,https://github.com/RaRe-Technologies/gensim/issues/2144,2144,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2018-08-02 11:25:10+00:00,,CalledProcessError: when running document influence model using dtm-win64.exe in gensim python wrapper,"Dear Sir,

I am able to successfully run the DTM model using dtm-win64.exe in gensim python wrapper. But I am getting error when running the DIM model using the dtm-win64.exe .
I am running this using python script in Anaconda windows:
```python
dimModel = DtmModel(dtm_path, corpus, time_slice, num_topics=60,id2word=corpus.dictionary, initialize_lda=True, model='fixed')
```
After running for almost 2 to 3 hours, the below error comes.
```python
The error below: CalledProcessError: Command '['C:\\dtm_master\\bin\\dtm\\dtm-win64.exe', '--ntopics=60', '--model=fixed', '--mode=fit', '--initialize_lda=true', '--corpus_prefix=C:\\Users\\ADMIN\\AppData\\Local\\Temp\\61138a_train', '--outname=C:\\Users\\ADMIN\\AppData\\Local\\Temp\\61138a_train_out', '--alpha=0.01', '--lda_max_em_iter=10', '--lda_sequence_min_iter=6', '--lda_sequence_max_iter=20', '--top_chain_var=0.005', '--rng_seed=0']' returned non-zero exit status 3
```

I have tried searching on google but didn't find any help. Could you please help me what this error referring and how to resolve.
Many thanks in Advance!!!!!!!

Regards,
Deepak
"
285,https://github.com/RaRe-Technologies/gensim/issues/2149,2149,"[{'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}]",closed,2018-08-08 07:35:50+00:00,,Duplication of code of phrases module,"I was going to submit a minor pull request for the phrases module, but then I noticed that the `__getitem__` methods of the classes `Phrases` and `Phraser` are identical. Would it be a good idea to move this code to a higher level, e.g. the `PhrasesTransformation` class, or somehow merge the duplicated code?"
286,https://github.com/RaRe-Technologies/gensim/issues/2152,2152,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",open,2018-08-09 19:21:46+00:00,,Adding Word-to-Context Prediction in Word2Vec (inverse of `predict_output_word()`),"In issue #863 there is the suggestion to predict a word given its contexts. 

Another nice feature would be the opposite: given a word, output the probability distribution over contexts (of some window length)."
287,https://github.com/RaRe-Technologies/gensim/issues/2155,2155,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}]",closed,2018-08-11 21:45:07+00:00,,"""AttributeError: 'Visdom' object has no attribute 'updateTrace'"" when running ""Training_visualizations.ipynb""","""updateTrace"" has been deprecated in the newest version of  Visdom, but it is still being called in Gensim, so failed to run callbacks in ""Training_visualizations.ipynb"". Hope this issue can be fixed, thanks!
See
https://github.com/facebookresearch/visdom/issues/358"
288,https://github.com/RaRe-Technologies/gensim/issues/2159,2159,"[{'id': 175642, 'node_id': 'MDU6TGFiZWwxNzU2NDI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/wishlist', 'name': 'wishlist', 'color': 'd7e102', 'default': False, 'description': 'Feature request'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 708430967, 'node_id': 'MDU6TGFiZWw3MDg0MzA5Njc=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/performance', 'name': 'performance', 'color': 'd93f0b', 'default': False, 'description': 'Issue related to performance (in HW meaning)'}]",open,2018-08-23 15:43:04+00:00,,Allow file-based *2vec training from compressed files,"All Gensim algorithms allow the use of `smart_open` to read their input data, meaning the data can be .gz, .bz2, live on s3, etc.

However, the new code path for file-based training of *2vec model from #2127 only accepts .txt files. This is problematic, because the main purpose of this file-based training is to be run on **very large datasets** (where its superior speed actually matters). Keeping such large text files uncompressed is wasteful and sometimes even impossible.

Task: **implement support for reading input from .gz compressed files** (at least). bz2 would be nice too, but the ""seeking into the middle of a file"" by each worker may be problematic for that format, technically speaking."
289,https://github.com/RaRe-Technologies/gensim/issues/2160,2160,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",closed,2018-08-24 08:48:37+00:00,,[Feature request] Load full native fastText model to continue training on new data,"Currently gensim cannot load and continue training native fastText model. According to the docs [[1]](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/fasttext.py#L685), this is because it only loads input-hidden matrix. However, fastText also saves hidden-output matrix [[2]](https://github.com/facebookresearch/fastText/blob/master/src/fasttext.cc#L176). 

Moreover, even the input-hidden matrix could support some sort of transfer learning, with hidden-output matrix inited randomly, similar to how `gensim.models.Word2Vec.intersect_word2vec_format()` works.

Please correct me if I'm wrong here, but I think there is no technical issue preventing loading and continue training fastText model. How about supporting this feature?"
290,https://github.com/RaRe-Technologies/gensim/issues/2162,2162,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2018-08-24 16:45:32+00:00,,Fix nested inline markup in `translation_matrix.py`,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description

reStructuredText parser cannot deal with nested inline markup according to http://docutils.sourceforge.net/FAQ.html#is-nested-inline-markup-possible .

So, [this line](https://github.com/RaRe-Technologies/gensim/blob/46124f4895b4bec6eee58c23e1686e5c9efb84fd/gensim/models/translation_matrix.py#L50) does not show correctly:

![2018-08-25 1 17 10](https://user-images.githubusercontent.com/7121753/44596212-60acaf00-a806-11e8-8525-936d894c8ed4.png)

There are two ways to deal with this nested inline problem, but they are not recommended by [this site](http://docutils.sourceforge.net/FAQ.html#is-nested-inline-markup-possible).

I guess that the most simple way is to avoid to use the bold style for the link part:
`**How to make translation between two** :class:`~gensim.models.doc2vec.Doc2Vec` **models**`.


![2018-08-25 1 42 56](https://user-images.githubusercontent.com/7121753/44596715-3eb42c00-a808-11e8-8614-5452d3314f7c.png)


What do you think about it?
"
291,https://github.com/RaRe-Technologies/gensim/issues/2163,2163,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-08-24 17:19:24+00:00,,Mallet Gensim error. (Non-zero exit status 1),"Hi all,

Please help me with the following error. I tried a lot to fix it but with no help.

Code:
```python
import os 
os.environ.update({'MALLET_HOME':r'C:/Users/I870648/mallet-2.0.8/'})

mallet_path = 'C:\\Users\\I870648\\mallet-2.0.8\\bin\\mallet\\'
ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)
```
Error:
```python
CalledProcessError: Command 'C:\Users\I870648\mallet-2.0.8\bin\mallet\ import-file --preserve-case --keep-sequence --remove-stopwords --token-regex ""\S+"" --input C:\Users\I870648\AppData\Local\Temp\3c1484_corpus.txt --output C:\Users\I870648\AppData\Local\Temp\3c1484_corpus.mallet' returned non-zero exit status 1.
```
Thank you,

Sincerely,
Prithvi"
292,https://github.com/RaRe-Technologies/gensim/issues/2166,2166,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}]",open,2018-08-26 10:35:42+00:00,,KeyedVectors TODOs,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
Hi! I'm new here :) I was digging through the `Doc2Vec` code and came across a bunch of TODOs in `KeyedVectors`.

 I was wondering if TODOs such as https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/keyedvectors.py#L1601 in [KeyedVectors](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/keyedvectors.py) can be implemented using `model.infer()` like in https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/keyedvectors.py#L1801

If so I'll be happy to submit a PR.
<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce
<!--
Example:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->
*N/A*

#### Expected Results
<!-- Example: Expected shape of (100,2).-->
*N/A*

#### Actual Results
<!-- Example: Actual shape of (100,5). 

Please paste or specifically describe the actual output or traceback. -->
*N/A*

#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->
Darwin-15.6.0-x86_64-i386-64bit
Python 3.6.4 (default, Jan  6 2018, 11:49:38) 
[GCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.42.1)]
NumPy 1.15.1
SciPy 1.1.0
gensim 3.5.0
FAST_VERSION 0


<!-- Thanks for contributing! -->

"
293,https://github.com/RaRe-Technologies/gensim/issues/2167,2167,[],closed,2018-08-26 11:06:05+00:00,,Doc2Vec understanding why are there many docvectors made?,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
TODO: change commented example
<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->
I expected the `Doc2Vec` model to make the number of paragraph vectors equal to the number of tags used to train the model.

In the below code snipped it looks like the count of the `docvecs` is equal to the maximum tag. I'm not too sure why.
#### Steps/Code/Corpus to Reproduce

```python
""""""
Doc2Vec learns representations for words and labels simultaneously.
If you wish to only learn representations for words,
you can use the flag train_lbls=False in your Doc2Vec class. Similarly,
if you only wish to learn representations for labels and leave the word
representations fixed, the model also has the flag train_words=False.
""""""
from gensim.models.doc2vec import Doc2Vec, TaggedDocument

EPOCHS = 500
LEARNING_RATE = 0.0001
DIMENSIONS = 100

sentences = [
    TaggedDocument([""hi"", ""there""], [1]),
    TaggedDocument([""byte""], [2]),

]
model = Doc2Vec(vector_size=DIMENSIONS, window=2, min_count=1, alpha=LEARNING_RATE, workers=4)

model.build_vocab(sentences, update=False, trim_rule=None)
print(""paragraph embeddings: %s"" % len(model.docvecs))  # 3.
print(""docvecs count %s"" % model.docvecs.count)  # 3.
print(model.docvecs.doctags)  # {}
print(""Offset %s"" % model.docvecs.offset2doctag)  # []
print(len(model.docvecs.vectors_docs))  # 3.
```

outputs
```
paragraph embeddings: 3
docvecs count 3
{}
Offset []
3
```
Which is along the lines of what I expected because only two tags are used. I don't really get why there are 3 elements in `model.docvecs`?

When I change the max tag to 200 for example

```python
sentences = [
    TaggedDocument([""hi"", ""there""], [1]),
    TaggedDocument([""byte""], [200]),

]
model = Doc2Vec(vector_size=DIMENSIONS, window=2, min_count=1, alpha=LEARNING_RATE, workers=4)
```
The output changes to 
```
paragraph embeddings: 201
docvecs count 201
{}
Offset []
201
```

Why does this occur? Does this mean 200 vectors are made even though there are only two tags in the corpus?


#### Expected Results
<!-- Example: Expected shape of (100,2).-->
*N/A*
#### Actual Results
<!-- Example: Actual shape of (100,5). 

Please paste or specifically describe the actual output or traceback. -->
*N/A*

#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->
Darwin-15.6.0-x86_64-i386-64bit
Python 3.6.4 (default, Jan 6 2018, 11:49:38)
[GCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.42.1)]
NumPy 1.15.1
SciPy 1.1.0
gensim 3.5.0
FAST_VERSION 0

<!-- Thanks for contributing! -->

"
294,https://github.com/RaRe-Technologies/gensim/issues/2168,2168,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-08-27 15:33:42+00:00,,Error calculating topic coherence using c_v,"#### Source Code
```python
def compute_coherence_values(self, corpus, texts, limit, start=2, step=3):
    coherence_values = []
    model_list = []
    for num_topics in range(start, limit, step):
        model = models.LdaModel(corpus, 
                                num_topics=num_topics, 
                                id2word=self.dictionary, 
                                passes=10,
                                random_state=100,
                                update_every=1,
                                chunksize=100,
                                alpha='auto',
                                per_word_topics=True)
        model_list.append(model)
        coherencemodel = models.CoherenceModel(model=model, texts=texts, dictionary=self.dictionary, coherence='c_v')
        coherence_values.append(coherencemodel.get_coherence())
    return model_list, coherence_values

def coherence_over_topics(self, corpus, cursor):
    tokenized_texts = [self.prepare(article['content']) for article in cursor if article['content']]
    tokenized_texts_filtered = [filter(lambda x: x in self.dictionary.values(), t) for t in tokenized_texts]
    model_list, coherence_values = self.compute_coherence_values(corpus=corpus, texts=tokenized_texts_filtered, start=2, limit=100, step=4)
    return coherence_values
```


#### Expected Results
Expected coherence values

#### Actual Results
```python
2018-08-27 04:19:54,399 : ERROR : worker encountered unexpected exception
Traceback (most recent call last):
  File ""/path/env/lib/python3.6/site-packages/gensim/topic_coherence/text_analysis.py"", line 561, in run
    self._run()
  File ""/path/env/lib/python3.6/site-packages/gensim/topic_coherence/text_analysis.py"", line 581, in _run
    self.accumulator.partial_accumulate(docs, self.window_size)
  File ""/path/env/lib/python3.6/site-packages/gensim/topic_coherence/text_analysis.py"", line 353, in partial_accumulate
    super(WordOccurrenceAccumulator, self).accumulate(texts, window_size)
  File ""/path/env/lib/python3.6/site-packages/gensim/topic_coherence/text_analysis.py"", line 289, in accumulate
    self.analyze_text(virtual_document, doc_num)
  File ""/path/env/lib/python3.6/site-packages/gensim/topic_coherence/text_analysis.py"", line 360, in analyze_text
    self._slide_window(window, doc_num)
  File ""/path/env/lib/python3.6/site-packages/gensim/topic_coherence/text_analysis.py"", line 375, in _slide_window
    self._token_at_edge = window[0]
IndexError: index 0 is out of bounds for axis 0 with size 0
```

#### Versions
>>> import platform; print(platform.platform())
Darwin-17.7.0-x86_64-i386-64bit
>>> import sys; print(""Python"", sys.version)
Python 3.6.5 (default, Apr 25 2018, 14:23:58)
[GCC 4.2.1 Compatible Apple LLVM 9.1.0 (clang-902.0.39.1)]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.14.5
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.1.0
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.5.0
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 0

"
295,https://github.com/RaRe-Technologies/gensim/issues/2169,2169,[],closed,2018-08-27 21:50:03+00:00,,Gensim import error,"Hi,

I have uninstalled and installed gensim on my box to check the version compatibility but, after re-installing, I was not able to import gensim even though it says gensim package is successfully installed.

I am getting the import error like ""No module name gensim""

I tried to do a pip uninstall gensim and did a conda install gensim. I even did an upgrade from conda.

Please help.

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
TODO: change commented example
<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce
<!--
Example:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->

#### Expected Results
Import should be successful

#### Actual Results
Import Error: ""No module name gensim"" 

Please paste or specifically describe the actual output or traceback. -->

#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
Linux-3.10.0-862.9.1.el7.x86_64-x86_64-with-centos-7.5.1804-Core
import sys; print(""Python"", sys.version)
('Python', '2.7.13 |Continuum Analytics, Inc.| (default, Dec 20 2016, 23:09:15) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]')
import numpy; print(""NumPy"", numpy.__version__)
('NumPy', '1.15.1')
import scipy; print(""SciPy"", scipy.__version__)
('SciPy', '0.19.1')
import gensim; print(""gensim"", gensim.__version__)
Import error
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
Import error
-->


<!-- Thanks for contributing! -->

"
296,https://github.com/RaRe-Technologies/gensim/issues/2170,2170,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-08-30 14:17:48+00:00,,Saving/loading Word2Vec as described in the tutorial fails,"#### Description

Trained a W2V model as shown in the documentation, along with a callback to save it to disk. When I try to reload one of the checkpoints, I get the following error:

```
'module' object has no attribute 'Word2VecVocab'
```

#### Steps/Code/Corpus to Reproduce
<!--
Example:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->

```
from XXX import get_output_path
from gensim.models.callbacks import CallbackAny2Vec
from gensim.models import Word2Vec
from datetime import datetime, timedelta
import os

class EpochSaver(CallbackAny2Vec):
    '''Callback to save model after each epoch.'''
    def __init__(self, start_date, end_date, identifier=None):
        self.epoch = 0
        
        self.base_path = get_output_path(...)
        
        try:
            os.makedirs(self.base_path)
        except OSError:
            pass
        
        
    def on_epoch_end(self, model):
        relpath = get_output_path(...)
        output_path = os.path.join(self.base_path, relpath)
        
        try:
            os.remove(output_path)
        except:
            pass
        
        model.save(output_path)

        self.epoch += 1

epoch_saver = EpochSaver(START_DATE, END_DATE, 'v0_1')

sentences = ...

model = Word2Vec(sentences,
                 size=128,
                 window=40,
                 min_count=10,
                 sg=1,
                 hs=0,
                 negative=20,
                 ns_exponent=-0.5,
                 sample=1e-4,
                 iter=10,
                 workers=10,
                 callbacks=[epoch_saver])
```

And then, from a different notebook, with the same environment:

```
from gensim.models import Word2Vec

model = Word2Vec.load(...)
```

#### Expected Results
Model loaded


#### Actual Results

```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-2-aebad99cda1c> in <module>()
----> 1 model = Word2Vec.load(...)

/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.pyc in load(cls, *args, **kwargs)
   1285             logger.info('Model saved using code from earlier Gensim Version. Re-loading old model in a compatible way.')
   1286             from gensim.models.deprecated.word2vec import load_old_word2vec
-> 1287             return load_old_word2vec(*args, **kwargs)
   1288 
   1289 

/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/deprecated/word2vec.pyc in load_old_word2vec(*args, **kwargs)
    151 
    152 def load_old_word2vec(*args, **kwargs):
--> 153     old_model = Word2Vec.load(*args, **kwargs)
    154     vector_size = getattr(old_model, 'vector_size', old_model.layer1_size)
    155     params = {

/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/deprecated/word2vec.pyc in load(cls, *args, **kwargs)
   1615     @classmethod
   1616     def load(cls, *args, **kwargs):
-> 1617         model = super(Word2Vec, cls).load(*args, **kwargs)
   1618         # update older models
   1619         if hasattr(model, 'table'):

/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/deprecated/old_saveload.pyc in load(cls, fname, mmap)
     85         compress, subname = SaveLoad._adapt_by_suffix(fname)
     86 
---> 87         obj = unpickle(fname)
     88         obj._load_specials(fname, mmap, compress, subname)
     89         logger.info(""loaded %s"", fname)

/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/deprecated/old_saveload.pyc in unpickle(fname)
    380             return _pickle.loads(file_bytes, encoding='latin1')
    381         else:
--> 382             return _pickle.loads(file_bytes)
    383 
    384 

AttributeError: 'module' object has no attribute 'Word2VecVocab'
```

#### Versions

```
Linux-4.4.0-1062-aws-x86_64-with-Ubuntu-16.04-xenial
('Python', '2.7.12 (default, Dec  4 2017, 14:50:18) \n[GCC 5.4.0 20160609]')
('NumPy', '1.13.1')
('SciPy', '0.19.1')
('gensim', '3.5.0')
('FAST_VERSION', 1)
```
"
297,https://github.com/RaRe-Technologies/gensim/issues/2171,2171,[],closed,2018-09-01 14:02:01+00:00,,How to use gensim.models.doc2vec.TaggedDocument.count(),"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
How do you use `gensim.models.doc2vec.TaggedDocument.count()` it keeps returning 0 for me?
Also, is it acceptable to pass a list of integers to `TaggedDocument`? It accepts it but the docs say it should be a list of unicode string tokens. 

<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce
<!--
Example:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->
```Python
from gensim.models.doc2vec import TaggedDocument

a = TaggedDocument(words=[""1"", ""2""], tags=[1])
print(repr(a))
b = TaggedDocument(words=[""1"", ""2"", ""1""], tags=[""1""])
print(repr(b))
print(b.count(""1""))  # 0

c = TaggedDocument(words=[1, 2, 1], tags=[1])
print(repr(c))
print(c.count(1))  # 0
print(c.count(""1""))  # 0
```
#### Expected Results
<!-- Example: Expected shape of (100,2).-->

I assumed `.count()` would return the occurance of a word in the list passed in to `words` so something like:

```python
b = TaggedDocument(words=[""1"", ""2"", ""1""], tags=[""1""])
print(b.count(""1""))  # 1

c = TaggedDocument(words=[1, 2, 1], tags=[1])
print(repr(c))
print(c.count(1))  # 1
print(c.count(""1""))  # 0
```
#### Actual Results
<!-- Example: Actual shape of (100,5). 

Please paste or specifically describe the actual output or traceback. -->
```python
b = TaggedDocument(words=[""1"", ""2"", ""1""], tags=[""1""])
print(b.count(""1""))  # 0

c = TaggedDocument(words=[1, 2, 1], tags=[1])
print(repr(c))
print(c.count(1))  # 0
print(c.count(""1""))  # 0
```

Everything had a count of 0.

#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->
Darwin-15.6.0-x86_64-i386-64bit
Python 3.6.4 (default, Jan  6 2018, 11:49:38) 
[GCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.42.1)]
NumPy 1.15.1
SciPy 1.1.0
gensim 3.5.0
FAST_VERSION 0
<!-- Thanks for contributing! -->

"
298,https://github.com/RaRe-Technologies/gensim/issues/2172,2172,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2018-09-03 08:30:51+00:00,,Allow asymmetrical windows for word2vec.,"I found that [WordRank ](https://radimrehurek.com/gensim/models/wrappers/wordrank.html) model could be trained with `symmetric` parameter. I allows to predict next word in sequence based only on the left ones. I think, this option should be also helpful for other models like Word2Vec and FastText."
299,https://github.com/RaRe-Technologies/gensim/issues/2174,2174,[],closed,2018-09-06 05:38:36+00:00,,Glove  embeddings,"Do we have a python  implementatipn for Glove embeddings  in Gensim?
"
300,https://github.com/RaRe-Technologies/gensim/issues/2175,2175,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2018-09-07 15:28:01+00:00,,Feature suggestion: relative cosine similarity for word2vec ,"Hi all,
Based on this paper, do you think it worths the effort to implement relative cosine similarity measure? 
https://ufal.mff.cuni.cz/pbml/105/art-leeuwenberg-et-al.pdf

Note that I'm not suggesting this as a potential contributor but as a grateful user.
Thank you,
Viktor
"
301,https://github.com/RaRe-Technologies/gensim/issues/2176,2176,[],closed,2018-09-07 16:50:37+00:00,,Gensim FastText() on custom corpus generates only .bin file ??,"I am using the Gensim implementation of FastText to train a custom corpus of text (and I don't want to use the pre-trained ones) . But the below command only saves the model as .bin file and there is no equivalent .vec file. Is this by design ? or am I missing something ?

>  model = FastText(sentences, size=embedding_size, window=10, min_count=1, iter=10, word_ngrams=1, sg=0, max_vocab_size=5000)

>  model.save(""somename"")
> 

please advice "
302,https://github.com/RaRe-Technologies/gensim/issues/2177,2177,[],closed,2018-09-10 02:52:58+00:00,,Defining alphabet,"I trying to use fast text for new language that I made to parse some text. I want to define my own set of characters so for instance, instead of a,b,c  I want to consider a12, b23, c34 as  a character when dealing with n-grams. Can any one inform me where I can edit this part? or how should I do it? is it possible?"
303,https://github.com/RaRe-Technologies/gensim/issues/2179,2179,[],closed,2018-09-12 10:36:54+00:00,,Training and accessing word vectors using Doc2Vec,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->
Hi! I was looking into how to get word vectors after training them using `doc2vec`. Issue #1513 outlined you can get the raw word vectors using `model.wv.syn0`. However, when I access these vectors before and after training the model the values are the same. Am I missing something? How can I access the trained word vectors after training a `Doc2Vec` model?

Also, according to the docs, the parameter `dbow_words=1` will train word vectors simultaneously with `DBOW`. Does this mean `dbow_words=1` only works with `dm=0` (PV-DBOW)? 
Is there a way to train word vectors with `dm=1` (PV-DM)? 

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
How to get trained word vectors after training with `Doc2Vec`?
<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce
<!--
Example:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->
```python
from gensim.models.doc2vec import Doc2Vec, TaggedDocument

corpus = [
    ""foo bar fork"",
    ""water wind fire earth"",
    ""artificial intelligence is the new electricity""
]


def corpus_generator(corpus):
    tag_template = ""%s_special_thing_here""
    for i, sentence in enumerate(corpus):
        yield TaggedDocument([str(c) for c in sentence.split()], [tag_template % i])


model = Doc2Vec(
    vector_size=100,
    min_count=1,
    alpha=0.001,
    workers=1,
    window=1,
    dbow_words=1,  # Trains word vectors in skip-gram fashion simultaneous with DBOW.
    dm=0  # if 1 trains PV-DM (distributed memory), otherwise is 0 and trains PV-DBOW (distributed bag of words).
)

model.build_vocab(corpus_generator(corpus))

# Check wvs are created.
untrained_word_vectors = []
for word_vec in model.wv.syn0:
    untrained_word_vectors.append(word_vec[::])

model.train(
    corpus_generator(corpus),
    epochs=500,
    total_examples=len(corpus)
)

trained_word_vectors = []
for word_vec in model.wv.syn0:
    trained_word_vectors.append(word_vec[::])

for i, untrained_vector in enumerate(untrained_word_vectors):
    trained_vector = trained_word_vectors[i]
    if untrained_vector.all() == trained_vector.all():
        print(""wv[%s] has not trained and is the same before and after training the model"" % i)
    else:
        print(""wv[%s] has been trained"" % i)
```
```
Outputs:
wv[0] has not trained and is the same before and after training the model
wv[1] has not trained and is the same before and after training the model
wv[2] has not trained and is the same before and after training the model
wv[3] has not trained and is the same before and after training the model
wv[4] has not trained and is the same before and after training the model
wv[5] has not trained and is the same before and after training the model
wv[6] has not trained and is the same before and after training the model
wv[7] has not trained and is the same before and after training the model
wv[8] has not trained and is the same before and after training the model
wv[9] has not trained and is the same before and after training the model
wv[10] has not trained and is the same before and after training the model
wv[11] has not trained and is the same before and after training the model
wv[12] has not trained and is the same before and after training the model
```
#### Expected Results
<!-- Example: Expected shape of (100,2).-->
Word vectors accessed via `model.wv.syn0` before and after training to be different.
#### Actual Results
<!-- Example: Actual shape of (100,5). 

Please paste or specifically describe the actual output or traceback. -->
Word vectors are the same.
#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->


Darwin-15.6.0-x86_64-i386-64bit
Python 3.6.4 (default, Jan  6 2018, 11:49:38) 
[GCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.42.1)]
NumPy 1.15.1
SciPy 1.1.0
gensim 3.5.0
FAST_VERSION 0
<!-- Thanks for contributing! -->

"
304,https://github.com/RaRe-Technologies/gensim/issues/2180,2180,[],closed,2018-09-12 13:43:39+00:00,,Race condition when running on_batch_end,"#### Description
Saving Word2Vec during a on_batch_end call keeps training it.

**UPDATE:** it seems the fault is on my end, I was using MongoDB for the dataset iterator with a cursor timeout implicit. Checkpointing meant that the cursor was not used for longer than the timeout, and thus killed by the server. It may still be an error you may want to handle differently on your end.

#### Steps/Code/Corpus to Reproduce
Train W2V with a callback that looks like:

```
    def on_batch_end(self, model):
        current_timestamp = datetime.utcnow()
        if current_timestamp - self._last_temporary_save >= timedelta(hours=1):
            relative_path = get_output_path(
                'PartialCheckpoint', add_kwargs=True, relative=self.base_path, epoch=self.epoch, batch=self.batch)
            output_path = os.path.join(self.base_path, relative_path)

            model.save(output_path)
            self._last_temporary_save = current_timestamp

        self.batch += 1
```

#### Expected Results
Model checkpoint after every hour of training

#### Actual Results
While running train:

```
Exception in thread Thread-8:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 167, in _worker_loop
    callback.on_batch_end(self)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/meli_recsys/pipelines/machine_learning/meta_prod2vec/mp2v_train.py"", line 60, in on_batch_end
    self._save_checkpoint(model, output_path)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/meli_recsys/pipelines/machine_learning/meta_prod2vec/mp2v_train.py"", line 90, in _save_checkpoint
    model.save(path)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 1214, in save
    super(Word2Vec, self).save(*args, **kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 501, in save
    super(BaseAny2VecModel, self).save(fname_or_handle, **kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/utils.py"", line 682, in save
    self._smart_save(fname_or_handle, separately, sep_limit, ignore, pickle_protocol=pickle_protocol)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/utils.py"", line 536, in _smart_save
    compress, subname)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/utils.py"", line 592, in _save_specials
    for attrib, val in iteritems(self.__dict__):
RuntimeError: dictionary changed size during iteration

Exception in thread Thread-18:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 167, in _worker_loop
    callback.on_batch_end(self)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/meli_recsys/pipelines/machine_learning/meta_prod2vec/mp2v_train.py"", line 60, in on_batch_end
    self._save_checkpoint(model, output_path)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/meli_recsys/pipelines/machine_learning/meta_prod2vec/mp2v_train.py"", line 90, in _save_checkpoint
    model.save(path)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 1214, in save
    super(Word2Vec, self).save(*args, **kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 501, in save
    super(BaseAny2VecModel, self).save(fname_or_handle, **kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/utils.py"", line 682, in save
    self._smart_save(fname_or_handle, separately, sep_limit, ignore, pickle_protocol=pickle_protocol)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/utils.py"", line 536, in _smart_save
    compress, subname)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/utils.py"", line 592, in _save_specials
    for attrib, val in iteritems(self.__dict__):
RuntimeError: dictionary changed size during iteration

Exception in thread Thread-9:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 164, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 771, in _do_train_job
    tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)
  File ""gensim/models/word2vec_inner.pyx"", line 497, in gensim.models.word2vec_inner.train_batch_sg
    cdef REAL_t *syn0 = <REAL_t *>(np.PyArray_DATA(model.wv.vectors))
AttributeError: 'Word2VecKeyedVectors' object has no attribute 'vectors'

Exception in thread Thread-15:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 164, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 771, in _do_train_job
    tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)
  File ""gensim/models/word2vec_inner.pyx"", line 497, in gensim.models.word2vec_inner.train_batch_sg
    cdef REAL_t *syn0 = <REAL_t *>(np.PyArray_DATA(model.wv.vectors))
AttributeError: 'Word2VecKeyedVectors' object has no attribute 'vectors'

Exception in thread Thread-17:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 164, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 771, in _do_train_job
    tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)
  File ""gensim/models/word2vec_inner.pyx"", line 497, in gensim.models.word2vec_inner.train_batch_sg
    cdef REAL_t *syn0 = <REAL_t *>(np.PyArray_DATA(model.wv.vectors))
AttributeError: 'Word2VecKeyedVectors' object has no attribute 'vectors'

Exception in thread Thread-11:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 164, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 771, in _do_train_job
    tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)
  File ""gensim/models/word2vec_inner.pyx"", line 497, in gensim.models.word2vec_inner.train_batch_sg
    cdef REAL_t *syn0 = <REAL_t *>(np.PyArray_DATA(model.wv.vectors))
AttributeError: 'Word2VecKeyedVectors' object has no attribute 'vectors'

Exception in thread Thread-10:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 164, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 771, in _do_train_job
    tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)
  File ""gensim/models/word2vec_inner.pyx"", line 497, in gensim.models.word2vec_inner.train_batch_sg
    cdef REAL_t *syn0 = <REAL_t *>(np.PyArray_DATA(model.wv.vectors))
AttributeError: 'Word2VecKeyedVectors' object has no attribute 'vectors'

Exception in thread Thread-20:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 203, in _job_producer
    for data_idx, data in enumerate(data_iterator):
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/meli_recsys/pipelines/machine_learning/meta_prod2vec/mongodb_sentence_dataset_iterator.py"", line 41, in __iter__
    has_more_results, sentences = self._load_sentences()
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/meli_recsys/pipelines/machine_learning/meta_prod2vec/mongodb_sentence_dataset_iterator.py"", line 54, in _load_sentences
    sentence = next(self._mongodb_cursor)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/pymongo/cursor.py"", line 1114, in next
    if len(self.__data) or self._refresh():
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/pymongo/cursor.py"", line 1056, in _refresh
    self.__max_await_time_ms))
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/pymongo/cursor.py"", line 928, in __send_message
    helpers._check_command_response(doc['data'][0])
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/pymongo/helpers.py"", line 207, in _check_command_response
    raise CursorNotFound(errmsg, code, response)
CursorNotFound: cursor id 34517510480 not found

Exception in thread Thread-19:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 164, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 771, in _do_train_job
    tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)
  File ""gensim/models/word2vec_inner.pyx"", line 497, in gensim.models.word2vec_inner.train_batch_sg
    cdef REAL_t *syn0 = <REAL_t *>(np.PyArray_DATA(model.wv.vectors))
AttributeError: 'Word2VecKeyedVectors' object has no attribute 'vectors'

Exception in thread Thread-14:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 164, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 771, in _do_train_job
    tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)
  File ""gensim/models/word2vec_inner.pyx"", line 497, in gensim.models.word2vec_inner.train_batch_sg
    cdef REAL_t *syn0 = <REAL_t *>(np.PyArray_DATA(model.wv.vectors))
AttributeError: 'Word2VecKeyedVectors' object has no attribute 'vectors'

Exception in thread Thread-13:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 164, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 771, in _do_train_job
    tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)
  File ""gensim/models/word2vec_inner.pyx"", line 497, in gensim.models.word2vec_inner.train_batch_sg
    cdef REAL_t *syn0 = <REAL_t *>(np.PyArray_DATA(model.wv.vectors))
AttributeError: 'Word2VecKeyedVectors' object has no attribute 'vectors'

Exception in thread Thread-16:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 164, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 771, in _do_train_job
    tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)
  File ""gensim/models/word2vec_inner.pyx"", line 497, in gensim.models.word2vec_inner.train_batch_sg
    cdef REAL_t *syn0 = <REAL_t *>(np.PyArray_DATA(model.wv.vectors))
AttributeError: 'Word2VecKeyedVectors' object has no attribute 'vectors'

Exception in thread Thread-12:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 164, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 771, in _do_train_job
    tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)
  File ""gensim/models/word2vec_inner.pyx"", line 497, in gensim.models.word2vec_inner.train_batch_sg
    cdef REAL_t *syn0 = <REAL_t *>(np.PyArray_DATA(model.wv.vectors))
AttributeError: 'Word2VecKeyedVectors' object has no attribute 'vectors'
```

#### Versions
Linux-4.4.0-1062-aws-x86_64-with-Ubuntu-16.04-xenial
('Python', '2.7.12 (default, Dec  4 2017, 14:50:18) \n[GCC 5.4.0 20160609]')
('NumPy', '1.15.1')
('SciPy', '0.19.1')
('gensim', '3.5.0')
('FAST_VERSION', 1)
"
305,https://github.com/RaRe-Technologies/gensim/issues/2181,2181,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-09-12 16:13:24+00:00,,Unpredictable ZeroDivisionErrors in direct_confirmation_measure,"Hello. 

Thank you for your great work!

It seems that the problem https://github.com/RaRe-Technologies/gensim/issues/1064 is back. I get a lot of this

```
  File ""train.py"", line 430, in <module>
    logger.info("" "".join([""Coherence:"", coh_type, ""\t\t"", str(coherence.get_coherence())]))
  File ""/usr/local/lib/python3.5/dist-packages/gensim/models/coherencemodel.py"", line 435, in get_coherence
    confirmed_measures = self.get_coherence_per_topic()
  File ""/usr/local/lib/python3.5/dist-packages/gensim/models/coherencemodel.py"", line 425, in get_coherence_per_topic
    return measure.conf(segmented_topics, self._accumulator, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/gensim/topic_coherence/direct_confirmation_measure.py"", line 71, in log_conditional_probability
    m_lc_i = np.log(((co_occur_count / num_docs) + EPSILON) / (w_star_count / num_docs))
ZeroDivisionError: float division by zero
```

when I use the version 3.5.0 installed from pypi.

Thanks in advance.

What other info should I provide?"
306,https://github.com/RaRe-Technologies/gensim/issues/2182,2182,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2018-09-12 18:54:37+00:00,,Word2Vec keeps on training during on_batch_end call,"#### Description
Saving Word2Vec during a on_batch_end call fails because of something that looks a lot like a race condition. It looks like some internal dict within gensim is still being changed during the call to save.

#### Steps/Code/Corpus to Reproduce
Train W2V with a callback that looks like:

```python
    def on_batch_end(self, model):
        current_timestamp = datetime.utcnow()
        if current_timestamp - self._last_temporary_save >= timedelta(hours=1):
            relative_path = get_output_path(
                'PartialCheckpoint', add_kwargs=True, relative=self.base_path, epoch=self.epoch, batch=self.batch)
            output_path = os.path.join(self.base_path, relative_path)

            model.save(output_path)
            self._last_temporary_save = current_timestamp

        self.batch += 1
```

#### Expected Results
Model checkpoint after every hour of training

#### Actual Results
While running train:

```
Exception in thread Thread-15:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 167, in _worker_loop
    callback.on_batch_end(self)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/meli_recsys/pipelines/machine_learning/meta_prod2vec/mp2v_train.py"", line 60, in on_batch_end
    self._save_checkpoint(model, output_path)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/meli_recsys/pipelines/machine_learning/meta_prod2vec/mp2v_train.py"", line 90, in _save_checkpoint
    model.save(path)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 1214, in save
    super(Word2Vec, self).save(*args, **kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 501, in save
    super(BaseAny2VecModel, self).save(fname_or_handle, **kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/utils.py"", line 682, in save
    self._smart_save(fname_or_handle, separately, sep_limit, ignore, pickle_protocol=pickle_protocol)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/utils.py"", line 536, in _smart_save
    compress, subname)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/utils.py"", line 592, in _save_specials
    for attrib, val in iteritems(self.__dict__):
RuntimeError: dictionary changed size during iteration

Exception in thread Thread-17:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 167, in _worker_loop
    callback.on_batch_end(self)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/meli_recsys/pipelines/machine_learning/meta_prod2vec/mp2v_train.py"", line 60, in on_batch_end
    self._save_checkpoint(model, output_path)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/meli_recsys/pipelines/machine_learning/meta_prod2vec/mp2v_train.py"", line 90, in _save_checkpoint
    model.save(path)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 1214, in save
    super(Word2Vec, self).save(*args, **kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 501, in save
    super(BaseAny2VecModel, self).save(fname_or_handle, **kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/utils.py"", line 682, in save
    self._smart_save(fname_or_handle, separately, sep_limit, ignore, pickle_protocol=pickle_protocol)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/utils.py"", line 536, in _smart_save
    compress, subname)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/utils.py"", line 592, in _save_specials
    for attrib, val in iteritems(self.__dict__):
RuntimeError: dictionary changed size during iteration

Exception in thread Thread-10:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 164, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 771, in _do_train_job
    tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)
  File ""gensim/models/word2vec_inner.pyx"", line 497, in gensim.models.word2vec_inner.train_batch_sg
    cdef REAL_t *syn0 = <REAL_t *>(np.PyArray_DATA(model.wv.vectors))
AttributeError: 'Word2VecKeyedVectors' object has no attribute 'vectors'

Exception in thread Thread-19:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 164, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 771, in _do_train_job
    tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)
  File ""gensim/models/word2vec_inner.pyx"", line 497, in gensim.models.word2vec_inner.train_batch_sg
    cdef REAL_t *syn0 = <REAL_t *>(np.PyArray_DATA(model.wv.vectors))
AttributeError: 'Word2VecKeyedVectors' object has no attribute 'vectors'

Exception in thread Thread-18:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 164, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 771, in _do_train_job
    tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)
  File ""gensim/models/word2vec_inner.pyx"", line 497, in gensim.models.word2vec_inner.train_batch_sg
    cdef REAL_t *syn0 = <REAL_t *>(np.PyArray_DATA(model.wv.vectors))
AttributeError: 'Word2VecKeyedVectors' object has no attribute 'vectors'

Exception in thread Thread-11:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 164, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 771, in _do_train_job
    tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)
  File ""gensim/models/word2vec_inner.pyx"", line 497, in gensim.models.word2vec_inner.train_batch_sg
    cdef REAL_t *syn0 = <REAL_t *>(np.PyArray_DATA(model.wv.vectors))
AttributeError: 'Word2VecKeyedVectors' object has no attribute 'vectors'

Exception in thread Thread-16:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 164, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 771, in _do_train_job
    tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)
  File ""gensim/models/word2vec_inner.pyx"", line 497, in gensim.models.word2vec_inner.train_batch_sg
    cdef REAL_t *syn0 = <REAL_t *>(np.PyArray_DATA(model.wv.vectors))
AttributeError: 'Word2VecKeyedVectors' object has no attribute 'vectors'

Exception in thread Thread-8:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 164, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 771, in _do_train_job
    tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)
  File ""gensim/models/word2vec_inner.pyx"", line 497, in gensim.models.word2vec_inner.train_batch_sg
    cdef REAL_t *syn0 = <REAL_t *>(np.PyArray_DATA(model.wv.vectors))
AttributeError: 'Word2VecKeyedVectors' object has no attribute 'vectors'

Exception in thread Thread-13:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 164, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 771, in _do_train_job
    tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)
  File ""gensim/models/word2vec_inner.pyx"", line 497, in gensim.models.word2vec_inner.train_batch_sg
    cdef REAL_t *syn0 = <REAL_t *>(np.PyArray_DATA(model.wv.vectors))
AttributeError: 'Word2VecKeyedVectors' object has no attribute 'vectors'

Exception in thread Thread-12:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 164, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 771, in _do_train_job
    tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)
  File ""gensim/models/word2vec_inner.pyx"", line 497, in gensim.models.word2vec_inner.train_batch_sg
    cdef REAL_t *syn0 = <REAL_t *>(np.PyArray_DATA(model.wv.vectors))
AttributeError: 'Word2VecKeyedVectors' object has no attribute 'vectors'

Exception in thread Thread-14:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 164, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 771, in _do_train_job
    tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)
  File ""gensim/models/word2vec_inner.pyx"", line 497, in gensim.models.word2vec_inner.train_batch_sg
    cdef REAL_t *syn0 = <REAL_t *>(np.PyArray_DATA(model.wv.vectors))
AttributeError: 'Word2VecKeyedVectors' object has no attribute 'vectors'

Exception in thread Thread-9:
Traceback (most recent call last):
  File ""/usr/lib/python2.7/threading.py"", line 801, in __bootstrap_inner
    self.run()
  File ""/usr/lib/python2.7/threading.py"", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/base_any2vec.py"", line 164, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""/home/ubuntu/workspace/machine_learning_tools-recommendations/mpozzer_env/local/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 771, in _do_train_job
    tally += train_batch_sg(self, sentences, alpha, work, self.compute_loss)
  File ""gensim/models/word2vec_inner.pyx"", line 497, in gensim.models.word2vec_inner.train_batch_sg
    cdef REAL_t *syn0 = <REAL_t *>(np.PyArray_DATA(model.wv.vectors))
AttributeError: 'Word2VecKeyedVectors' object has no attribute 'vectors'
```

#### Versions
Linux-4.4.0-1062-aws-x86_64-with-Ubuntu-16.04-xenial
('Python', '2.7.12 (default, Dec  4 2017, 14:50:18) \n[GCC 5.4.0 20160609]')
('NumPy', '1.15.1')
('SciPy', '0.19.1')
('gensim', '3.5.0')
('FAST_VERSION', 1)
"
307,https://github.com/RaRe-Technologies/gensim/issues/2183,2183,[],closed,2018-09-13 05:51:08+00:00,,Mmap not working as expected with KeyedVectors,"#### Description
Mmap not working as expected when loading KeyedVectors in two different processes. We are working on MAC 10.12.6 , and Python 3.6. We have tried loading the keyedVectors from file using mmap option as mentioned in the documentation: https://radimrehurek.com/gensim/models/keyedvectors.html

#### Steps/Code/Corpus to Reproduce
import os
import psutil
from gensim.models import KeyedVectors
import time
import numpy as np
def memory_usage_psutil():
    import psutil
    process = psutil.Process(os.getpid())
    print (""PID: "", os.getpid())
    mem = process.memory_info()[0] / float(2 ** 20)
    return mem

model=KeyedVectors.load(""/Users/coviam/Documents/GloveData/output.kv"", mmap='r')
print(""Memory consumption in MB : %s"",memory_usage_psutil())
print(""Done"")
time.sleep(100)

#### Expected Results
Memory should have been shared between the two processes and not doubled.

#### Actual Results
For Two separate processes loading .kv file :
Both process have 289M of memory (no sharing) in ‘r’ mode

#### Versions
NumPy 1.15.0
SciPy 1.1.0
gensim 3.5.0
FAST_VERSION 0"
308,https://github.com/RaRe-Technologies/gensim/issues/2184,2184,[],closed,2018-09-13 19:33:25+00:00,,Support Azure Blob Storage for gensim model save API,"Azure blobs have URL of the format https://<blobname>.core.azurewebsites.net/<blob container name>/blob_file

API's like
corpus.dictionary.save(azure_blob_url) (or)
ldamodel.save(azure_blob_url) fail with a NotImplementedError saying 'wb' mode not supported for https.

So it is just not possible to save these models in Azure Blobs!
"
309,https://github.com/RaRe-Technologies/gensim/issues/2185,2185,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-09-14 08:17:38+00:00,,Create a TF-IDF model from wikipedia,"I realized there is an inconsistency when it comes to manipulating datasets from your official source when it comes to your code. For example, at first I tried to use the ""text8"" which is a sample of wikipedia with `api.load` and everything worked perfect, then I wanted to escalate to a 16GB dump of wikipedia. The code follows:

```
dataset=api.load(""text8"")
dct = Dictionary(dataset)  # fit dictionary
corpus = [dct.doc2bow(line) for line in dataset]  # convert corpus to BoW format
model = TfidfModel(corpus)  # fit model
######### validate model
vector = model[corpus[0]]  # apply model to the first corpus document
sortvec = sorted(vector,reverse=True, key = lambda x: x[1]) #sort by TF-IDF descending
x = [item[0] for item in sortvec] #take the indices Descending on TF-IDF probability
cnt=0
y={}
##########passing to a dictionary the pairs corresponding to the indices above
for a in x:
    y[cnt] = dct[a];
    cnt+=1
first15pairs = y.values()[:15] #get top 15 words with highest probabilities from dictionary
d = [[s.encode('ascii','ignore')] for s in first15pairs]
print d
```

from this code I train the TF-IDF model with a small dataset and then manipulate it and take the top 15 words with highest frequencies. Everything works fine. When I change the dataset:
`dataset=api.load(""wiki-english-20171001"")` it downloads the huge dataset in 4 parts, I assume it creates the dct and corpus normally but when it comes to fitting the model it fails. it does nothing and the rest of the variables remain empty. After that I came across with another object called ""WikiCorpus"" I tried to write code with that as follows: 
```
wiki = WikiCorpus('data/enwiki-20170101-pages-articles-multistream.xml.bz2', lemmatize=False)
tfidf = TfidfModel(wiki)
```
but an error appears. I digged deeper into that error and found out that python 2 and multistream data is not supported (on official website). So my question is, is there an easy way to train the model the way I want it?"
310,https://github.com/RaRe-Technologies/gensim/issues/2187,2187,[],closed,2018-09-15 20:08:27+00:00,,Load Pre-trained word2vec vectors,"Hi,

I have heard a lot about gensim, but now when I am trying to use it, for probably the simplest task, i.e loading pre-trained embeddings, I am stuck for hours.

Consider:

```
from gensim.models import KeyedVectors
# Load vectors directly from the file
model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)
# Access vectors for specific words with a keyed lookup:
vector = model['simple']
```

```
python word2vec.pyTraceback (most recent call last):  File ""word2vec.py"", line 3, in <module>
    model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)
  File ""/home/andy/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py"", line 1436, in load_word2vec_format    limit=limit, datatype=datatype)
  File ""/home/andy/anaconda3/lib/python3.6/site-packages/gensim/models/utils_any2vec.py"", line 178, in _load_word2vec_format
    result.vectors = zeros((vocab_size, vector_size), dtype=datatype)
MemoryError
```

Could gensim be used to load word2vec pre-trained embeddings released by google? How could I do so?

Cheers!"
311,https://github.com/RaRe-Technologies/gensim/issues/2188,2188,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}]",closed,2018-09-16 19:48:35+00:00,,FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated,"#### Description
```
/usr/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.
  if np.issubdtype(vec.dtype, np.int):
```

#### Steps/Code/Corpus to Reproduce

```
from gensim.test.utils import common_texts
from gensim.models import Word2Vec

model = Word2Vec(common_texts, size=100, window=5, min_count=1, workers=4)
print(model.wv.most_similar('human'))
```

#### Expected Results
No warning.

#### Actual Results
`FutureWarning`.

#### Versions
```
Linux-4.14.68-1-MANJARO-x86_64-with-arch-Manjaro-Linux
Python 3.7.0 (default, Jul 15 2018, 10:44:58) 
[GCC 8.1.1 20180531]
NumPy 1.15.1
SciPy 1.1.0
gensim 3.5.0
FAST_VERSION 0
```

#### Possible fix

Replace the offending line with

```
if np.issubdtype(vec.dtype, np.signedinteger) or np.issubdtype(vec.dtype, np.unsignedinteger):
```

Based on [Numpy docs](https://docs.scipy.org/doc/numpy-1.15.1/reference/arrays.dtypes.html?highlight=signedinteger#specifying-and-constructing-data-types). I haven't researched the issue thoroughly though and I'm not sure whether this is a proper fix."
312,https://github.com/RaRe-Technologies/gensim/issues/2189,2189,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 708430967, 'node_id': 'MDU6TGFiZWw3MDg0MzA5Njc=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/performance', 'name': 'performance', 'color': 'd93f0b', 'default': False, 'description': 'Issue related to performance (in HW meaning)'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}]",closed,2018-09-19 14:55:18+00:00,,Phraser requires unnecessary memory,"Currently, `Phraser` objects (= the trimmed-down version of the full bigram finder `Phrases`) contains the actual bigrams in an internal attribute called [phrasegrams](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/phrases.py#L775). This is the biggest and most memory-intense part of a `Phraser` object.

`phrasegrams` is a dict of `{tuple of strings => (frequency [int], score [float])}`. But the `int` (the frequency count of that particular bigram) is unused. This means we're constructing that int, plus the wrapping tuple, for no good reason, inflating the necessary RAM. See also [mailing list discussion](https://groups.google.com/forum/#!topic/gensim/vsWXxUzuK6s).

Task:
* Drop the `int` from Phraser values, leaving only the `float`.
* And while at it, rename (deprecate) the `.vocab` attribute of Phrases to something more appropriate, for example `bigram_counts`.

"
313,https://github.com/RaRe-Technologies/gensim/issues/2190,2190,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}]",open,2018-09-20 08:39:25+00:00,,Allow reserved IDs for `token2id` in Dictionary,"The dictionary now stard indexing words at 0, which may be unwanted for several applications. E.g. in my application, I want the first word to have index 1, and reserve 0 for padding. Similarly, one may want to reserve certain IDs for unknown tokens, special delimiter tokens, etc, that will remain unaffected by, e.g. `filter_extremes` and `compactify`. What I propose, is to be able to supply reserved IDs in Dictionary that will remain unaffected by adding new documents and using different methods on Dictionary."
314,https://github.com/RaRe-Technologies/gensim/issues/2193,2193,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-09-22 05:00:51+00:00,,Get some numpy error when running doc2vec,"Hi i get some numpy error on linux server(amazon ec2 service)
#### tested pc
os : window
python : 3.7
pip : 18.0
numpy : 1.15.1
gensim : 3.5.0
scipy : 1.1.0

#### dev server(has error)
os : linux
instance type : t2.large
python : 3.6
anaconda-client : 1.7.2
anaconda-navigator : 1.8.7
anaconda-project : 0.8.2
numpy : 1.15.1
gensim : 3.5.0
scipy : 1.1.0

i was reinstalled dev server's numpy,gensim and scipy. but disabled to fix it.


doc2vec config
```
config= {
    'dm': 1,  
    'dbow_words': 1,  
    'window': 4,  
    'vector_size': 200,  
    'alpha': 0.025,  
    'sample': 1e-4,
    'seed': 1234,
    'min_count': 3,  
    'min_alpha': 0.025,  
    'workers': multiprocessing.cpu_count(),  
    'hs': 1,  
    'negative': 5,  
    'epochs': 10  
}
model = Doc2Vec(**config)
```
error message
```
Traceback (most recent call last):
  File ""/opt/conda/lib/python3.6/threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""/opt/conda/lib/python3.6/threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/user/.local/lib/python3.6/site-packages/gensim/models/base_any2vec.py"", line 164, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""/home/user/.local/lib/python3.6/site-packages/gensim/models/doc2vec.py"", line 660, in _do_train_job
    doctag_vectors=doctag_vectors, doctag_locks=doctag_locks
  File ""gensim/models/doc2vec_inner.pyx"", line 535, in gensim.models.doc2vec_inner.train_document_dm
```"
315,https://github.com/RaRe-Technologies/gensim/issues/2198,2198,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-09-23 22:13:13+00:00,,"Version 3.6.0 doesn't install files gensim/models/doc2vec_corpusfile.so, gensim/models/fasttext_corpusfile.so, gensim/models/word2vec_corpusfile.so","It writes these names into the plist files for the ```--record``` option (```setup.py install --record {plist}```), but doesn't actually install them:
```
===> Checking for items in pkg-plist which are not in STAGEDIR
Error: Missing: %%PYTHON_SITELIBDIR%%/gensim/models/doc2vec_corpusfile.so
Error: Missing: %%PYTHON_SITELIBDIR%%/gensim/models/fasttext_corpusfile.so
Error: Missing: %%PYTHON_SITELIBDIR%%/gensim/models/word2vec_corpusfile.so
```
"
316,https://github.com/RaRe-Technologies/gensim/issues/2199,2199,[],closed,2018-09-24 16:30:51+00:00,,How to pick the number of topics with Umass measure?,"I am trying to use Umass measure to pick the best number of topics, but I do not know what Umass exactly means? About the coherence score, is it the bigger, the better, or just the opposite? Below is the output of my test with Umass measure. How many topics should I pick?
![image](https://user-images.githubusercontent.com/43496800/45965139-3e52bf00-c05a-11e8-9b23-4e4d9684475a.png)
"
317,https://github.com/RaRe-Technologies/gensim/issues/2201,2201,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2018-09-29 14:32:03+00:00,,Unable to load KeyedVectors models created with gensim==3.2.0: AttributeError: Can't get attribute 'EuclideanKeyedVectors',"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description

Hi there,

I can't seem to be able to load trimmed `KeyedVectors` models created with gensim 3.2.0 with any newer version of gensim (3.3.0 - 3.6.0) because:

```
AttributeError: Can't get attribute 'EuclideanKeyedVectors' on <module 'gensim.models.keyedvectors' from '/usr/local/lib/python3.7/site-packages/gensim/models/keyedvectors.py'>
```

#### Steps/Code/Corpus to Reproduce

To replicate:

1) Create a model with gensim==3.2.0, convert it to `KeyedVectors` and then save it:

```shell
pip3.7 install -qU gensim==3.2.0
```

```python
from gensim.models import Word2Vec
from gensim.test.utils import common_texts

model = Word2Vec(common_texts, size=100, window=5, min_count=1, workers=4)
trimmed_model = model.wv
trimmed_model.save('test.word2vec')
```

2) Try loading the model with gensim>=3.2.0:

```shell
pip3.7 install -qU gensim==3.6.0	# same with 3.3.0, 3.4.0 and 3.5.0 too
```

```python
from gensim.models import KeyedVectors

word_vectors = KeyedVectors.load('test.word2vec')
```

#### Expected Results

Model should get loaded and be functional.


#### Actual Results

`KeyedVectors.load()` fails with:

```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.7/site-packages/gensim/models/keyedvectors.py"", line 212, in load
    return super(BaseKeyedVectors, cls).load(fname_or_handle, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/gensim/utils.py"", line 422, in load
    obj = unpickle(fname)
  File ""/usr/local/lib/python3.7/site-packages/gensim/utils.py"", line 1361, in unpickle
    return _pickle.load(f, encoding='latin1')
AttributeError: Can't get attribute 'EuclideanKeyedVectors' on <module 'gensim.models.keyedvectors' from '/usr/local/lib/python3.7/site-packages/gensim/models/keyedvectors.py'>
```


#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->

```
>>> import platform; print(platform.platform())
Darwin-18.0.0-x86_64-i386-64bit
>>> import sys; print(""Python"", sys.version)
Python 3.7.0 (default, Sep 18 2018, 18:47:08) 
[Clang 10.0.0 (clang-1000.10.43.1)]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.15.2
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.1.0
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.6.0
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 0
```


<!-- Thanks for contributing! -->

"
318,https://github.com/RaRe-Technologies/gensim/issues/2203,2203,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}]",closed,2018-10-01 12:48:01+00:00,,Wrong return types in docstrings for wv.evaluate_word_analogies and wv.evaluate_word_pairs,"This is the documented return type for `KeyedVectors.evaluate_word_analogies`:
https://github.com/RaRe-Technologies/gensim/blob/6a4424d3e465dea0afcddc4f4e2410cf0f52dba1/gensim/models/keyedvectors.py#L1070

The dicts in the second element of the return tuple have as values either a string or a list of 4-tuples. For instance:
```
{
    'section': 'family',
    'correct': [('he', 'she', 'dad', 'mom'), ...],
    'incorrect': [('man', 'woman', 'groom', 'bride'), ...]
}
```
So I believe the return value of `evaluate_word_analogies` is actually `Tuple[float, List[Dict[str, Union[str, List[Tuple[str, str, str, str]]]]]` (in PEP-484 style annotation).

Then, in `KeyedVectors.evaluate_word_pairs`, the documented return type is:
https://github.com/RaRe-Technologies/gensim/blob/6a4424d3e465dea0afcddc4f4e2410cf0f52dba1/gensim/models/keyedvectors.py#L1284

Here, the second and third elements of the return tuple are actually pairs of floats, since they are the values returned from `scipy.stats.pearsonr` and `spearmanr`, which return both the correlation and a p-value. I don't know whether the p-value should be discarded or the documented return type be updated to `(float, (float, float), (float, float))`."
319,https://github.com/RaRe-Technologies/gensim/issues/2204,2204,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-10-02 08:42:51+00:00,,GUnicorn + Flask + Gensim -> Error: dictionary changed size during iteration,"#### Description
I'm trying to create a microservice for certain functions based on previously built models. To avoid blowing up the RAM I am trying to run the app with `--preload` on gunicorn, since I don't write but only read the models I figured this shouldn't be a problem but as soon as I try to even load gensim the app crashes.

#### Steps/Code/Corpus to Reproduce
```python
import flask
from gensim.models import KeyedVectors, Word2Vec

app = flask.Flask(__name__)

@app.route('/')
def index():
    return """"
```


#### Expected Results
```
$ gunicorn mem_test:app --workers 2
[2018-10-02 10:39:19 +0200] [27406] [INFO] Starting gunicorn 19.9.0
[2018-10-02 10:39:19 +0200] [27406] [INFO] Listening at: http://127.0.0.1:8000 (27406)
[2018-10-02 10:39:19 +0200] [27406] [INFO] Using worker: sync
[2018-10-02 10:39:19 +0200] [27418] [INFO] Booting worker with pid: 27418
[2018-10-02 10:39:19 +0200] [27419] [INFO] Booting worker with pid: 27419
```

#### Actual Results
```
$ gunicorn mem_test:app --workers 2 --preload
[2018-10-02 10:36:17 +0200] [24018] [INFO] Starting gunicorn 19.9.0

Error: dictionary changed size during iteration
```

#### Versions
```
$ python3.6 
Python 3.6.6 (default, Jun 28 2018, 04:42:43) 
[GCC 5.4.0 20160609] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import platform; print(platform.platform())
Linux-4.8.0-58-generic-x86_64-with-Ubuntu-16.04-xenial
>>> import sys; print(""Python"", sys.version)
Python 3.6.6 (default, Jun 28 2018, 04:42:43) 
[GCC 5.4.0 20160609]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.14.2
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.0.1
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.5.0
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1
```"
320,https://github.com/RaRe-Technologies/gensim/issues/2209,2209,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 1584013467, 'node_id': 'MDU6TGFiZWwxNTg0MDEzNDY3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/conda', 'name': 'conda', 'color': 'c9ef58', 'default': False, 'description': ''}]",open,2018-10-03 12:57:57+00:00,,LdaSeqModel not replicable at 5th or 6th decimal despite fixed Python hash seed and random.state,"I've estimated both the LDA model and DTM on a dataset of 1173 texts (the LDA is used as input for DTM), and I get different results in the 4th, 5th and 6th decimal for the word probabilities when I run the DTM model on three different computers. In the code the Python hash seed is disabled (i.e., PYTHONHASHSEED=0), and the random.state is fixed as well. Moreover, all the packages of Anaconda are exactly the same on each of the three computers and all the version numbers are exactly the same and updated to the latest versions, so there really shouldn't be any difference. 

The way the DTM model is estimated is:

```python
ldaseq = ldaseqmodel.LdaSeqModel(corpus=CBcorpus_1997to2016_pruned, id2word=dictionary_pruned, time_slice=time_slice,
                                 num_topics=3, lda_model=ldamodel, random_state=np.random.RandomState(10))
```

The current idea that Radim, Bhargav (who wrote the code for this model) and I have is that it might be due to floating point approximation, and that this accumulates due to the many iterations in the model. Could someone please take a look to see where the problem might be? 

Thanks!

Myrthe van Dieijen

<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
TODO: change commented example
<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce
<!--
Example:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->

#### Expected Results
<!-- Example: Expected shape of (100,2).-->

#### Actual Results
<!-- Example: Actual shape of (100,5). 

Please paste or specifically describe the actual output or traceback. -->

#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->


<!-- Thanks for contributing! -->

"
321,https://github.com/RaRe-Technologies/gensim/issues/2213,2213,[],closed,2018-10-04 20:00:11+00:00,,Phrases not working correctly with both the scoring methods,"

#### Description
gensim.models.phrases not working correctly with either of the scoring methods

#### Steps/Code/Corpus to Reproduce

Example:
``` 
from gensim.test.utils import datapath
from gensim.models.word2vec import Text8Corpus
from gensim.models.phrases import Phrases, Phraser

sentences = Text8Corpus(datapath('testcorpus.txt'))
phrases = Phrases(sentences, min_count=2, threshold=10)
#phrases = Phrases(sentences, min_count=2, threshold=0.2, scoring='npmi')
phrases.vocab 
```

#### Expected Results
Bigrams with min count of 2

#### Actual Results
Bigrams with count 1 are part of the vocabulary
![screen shot 2018-10-04 at 3 54 12 pm](https://user-images.githubusercontent.com/16194274/46499330-cd47a000-c7ed-11e8-97ee-24666e2282e8.png)


#### Versions
```
Darwin-18.0.0-x86_64-i386-64bit
(u'Python', '2.7.15 |Anaconda, Inc.| (default, May  1 2018, 18:37:05) \n[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]')
(u'NumPy', '1.14.3')
(u'SciPy', '1.1.0')
(u'gensim', '3.6.0')
(u'FAST_VERSION', 1)
```


<!-- Thanks for contributing! -->

"
322,https://github.com/RaRe-Technologies/gensim/issues/2216,2216,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-10-06 13:04:22+00:00,,zipfile.BadZipFile: File is not a zip file,"```import gensim ```

caused this error all of sudden after upgrading...

zipfile.BadZipFile: File is not a zip file

installed via pip once and via conda forge once and neither of them worked.

any help will be appreciated.
"
323,https://github.com/RaRe-Technologies/gensim/issues/2218,2218,[],closed,2018-10-08 22:03:31+00:00,,Doc2Vec not optimal CPU utilization on high number of cores with all-in-memory corpus,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description

I know that there are a few related issues currently open or closed, but couldn't find specific information for the case where all corpus is loaded to memory, sorry if I missed something.

When I'm trying to run Doc2Vec with an all-in-memory corpus on a 64 CPU machine with `workers=40`, I see partial CPU usage.

Main process uses ~%400 CPU, and there are 40 other processes using CPU ~%10 each. This in total corresponds to a usage of 8 cores in full.

This limitation is breaking for me because I want to train document embeddings on a corpus with ~25M documents, training of just 1 epoch would take 1 day with current speed.

<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce
```
import gensim
from gensim.models.doc2vec import Doc2Vec, TaggedDocument

model = Doc2Vec(vector_size=300, window=15, max_vocab_size=None, min_count=5, hs=0, negative=5, ns_exponent=0.75, sample=10e-5)

# tagged_docs is a list of TaggedDocument instances loaded in memory, not an iterator or generator
model.build_vocab(tagged_docs, progress_per=10000)
model.workers = 40
model.train(tagged_docs, total_examples=len(tagged_docs), epochs=1)
```

#### Expected Results
<!-- Example: Expected shape of (100,2).-->
I expect near ideal CPU utilization.
#### Actual Results
It seems to be using only 8 of the cores in full.

```
2018-10-08 17:42:26,205 : INFO : training on a 30200106 raw words (16766153 effective words) took 62.0s, 270407 effective words/s
```

#### Versions
Linux-3.10.0-862.11.6.el7.x86_64-x86_64-with-redhat-7.5-Maipo
Python 3.6.6 | packaged by conda-forge | (default, Jul 26 2018, 09:53:17) 
[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)]
NumPy 1.15.2
SciPy 1.1.0
gensim 3.6.0
FAST_VERSION 1

<!-- Thanks for contributing! -->

"
324,https://github.com/RaRe-Technologies/gensim/issues/2219,2219,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}]",closed,2018-10-09 18:58:07+00:00,,"Stopword ""fifty"" misspelled ""fify"". ","<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description

The word ""fifty"" isn't in `gensim.parsing.preprocessing.STOPWORDS` frozenset, while the word ""fify"" is. 

#### Steps/Code/Corpus to Reproduce

See expected and actual results below:

#### Expected Results
```
>>> import gensim.parsing.preprocessing
>>> ""fifty"" in gensim.parsing.preprocessing.STOPWORDS
True
>>> ""fify"" in gensim.parsing.preprocessing.STOPWORDS
False
```

```
>>> print(""\n"".join(sorted(gensim.parsing.preprocessing.STOPWORDS)))
...
except
few
fifteen
fifty
fill
find
fire
...
```

#### Actual Results
```
>>> import gensim.parsing.preprocessing
>>> ""fifty"" in gensim.parsing.preprocessing.STOPWORDS
False
>>> ""fify"" in gensim.parsing.preprocessing.STOPWORDS
True
```

```
>>> print(""\n"".join(sorted(gensim.parsing.preprocessing.STOPWORDS)))
...
except
few
fifteen
fify
fill
find
fire
...
```

#### Versions

""fify"" is present on line 48 of [gensim.parsing.preprocessing.py](https://github.com/RaRe-Technologies/gensim/blob/4543646d3fe3496e11bc935e72cbf9b18504442e/gensim/parsing/preprocessing.py)

```
>>> import platform; print(platform.platform())
Linux-4.15.0-36-generic-x86_64-with-Ubuntu-16.04-xenial
>>> import sys; print(""Python"", sys.version)
('Python', '2.7.12 (default, Dec  4 2017, 14:50:18) \n[GCC 5.4.0 20160609]')
>>> import numpy; print(""NumPy"", numpy.__version__)
('NumPy', '1.14.2')
>>> import scipy; print(""SciPy"", scipy.__version__)
('SciPy', '1.0.1')
>>> import gensim; print(""gensim"", gensim.__version__)
('gensim', '3.4.0')
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
('FAST_VERSION', 1)
```


<!-- Thanks for contributing! -->


"
325,https://github.com/RaRe-Technologies/gensim/issues/2221,2221,[],closed,2018-10-09 21:11:54+00:00,,where is Gensim CBOW_mean implemented in the original implementation?,"Hi,

I was looking at the original word2vec implementation here at: https://code.google.com/archive/p/word2vec/source/default/source
The part o the code I'm talking about is: (Where CBOW is being trained)
![originalwv](https://user-images.githubusercontent.com/43973925/46698706-c782fd80-cbe5-11e8-940f-1810c800bf52.png)

However I couldn't find any lines corresponding to:
![gensimwv](https://user-images.githubusercontent.com/43973925/46698904-44ae7280-cbe6-11e8-8b24-43703bb7e93f.png)

Which is in the gensim code.  Can anyone please help me understand which part is this analogous to?

I really appreciate your time.

"
326,https://github.com/RaRe-Technologies/gensim/issues/2222,2222,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-10-10 16:39:10+00:00,,effect worker thread on loss in word2vec sgns,"Im trying to train a gensim(3.6.0) sgns model and in the process, I measure the loss during which I'm calculating as

loss = model.running_training_loss / model.corpus_count, 

however, I noticed that if I change my worker thread I get different losses keeping all other parameters same. Especially if I keep my worker thread a 1 I get a really high loss and If I increase the number of threads I get less loss. An instance

thread  loss
worker=1  20.40519721
worker=10   2.714875407
worker=16  1.239528453
what could be the reason behind it ..?"
327,https://github.com/RaRe-Technologies/gensim/issues/2223,2223,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}]",closed,2018-10-11 18:22:09+00:00,,LdaMulticore parameter alpha: 'auto' not supported but documentation says it is,"When using the value 'auto' for parameter ""alpha"" for LdaMulticore, the following exception is raised:
```
NotImplementedError: auto-tuning alpha not implemented in multicore LDA; use plain LdaModel.
```
(ldamulticore.py, line 146)

However the documentation string of the `__init__` states that ""auto"" is supported.

This may be a copy/paste error, but is there any chance to see auto get supported for the Multicore version as well? 

#### Versions
```
Linux-4.15.0-35-generic-x86_64-with-debian-buster-sid
Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 13 2017, 12:02:49) 
[GCC 7.2.0]
NumPy 1.14.2
SciPy 1.0.0
gensim 3.4.0
FAST_VERSION 1
```

However, the exception code is still present in the latest master as well, I think. "
328,https://github.com/RaRe-Technologies/gensim/issues/2224,2224,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-10-12 01:00:41+00:00,,Cannot add entity-value to keyedvectors,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
TODO: change commented example
<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce
<!--
Example:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->

#### Expected Results
<!-- Example: Expected shape of (100,2).-->

#### Actual Results
<!-- Example: Actual shape of (100,5). 

Please paste or specifically describe the actual output or traceback. -->

#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->


<!-- Thanks for contributing! -->

"
329,https://github.com/RaRe-Technologies/gensim/issues/2228,2228,"[{'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}]",closed,2018-10-14 20:31:50+00:00,,`pyemd` import check is misplaced,"Gensim only checks whether `pyemd` in installed once, on module load:
https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/keyedvectors.py#L755

All other calls to `wmdistance` will automatically fail, even if the `pyemd` module has been installed in the meanwhile.

This is unnecessary and annoying. Python is a dynamic language, we can import the module when needed (= where the check is actually happening, in `wmdistance`), not at the top.

Plus let's fix the `werein` typo in `At least one of the documents had no words that werein the vocabulary` and the non-Pythonic `len(document1) == 0` while at it. The code could use some style clean up."
330,https://github.com/RaRe-Technologies/gensim/issues/2230,2230,[],closed,2018-10-15 19:29:50+00:00,,The keep_tokens parameter for Dictionary.filter_extremes does not work properly,"The documentation of the `filter_extremes` method of `gensim.corpora.Dictionary` states for the `keep_tokens` parameter: ""Iterable of tokens that **must** stay in dictionary after filtering."" 

However, if filtering by the `keep_n` parameter is applied, those tokens can still get removed. 

This is due to the code around line 358 in gensim/corpora/dictionary.py where the ids are first sorted by document frequency in reverse order and then the first `keep_n` of those indices are taken. However, if the tokens listed in `keep_tokens` are rare and not within the `keep_n` most frequent ones, they get removed by this. 

The expected behaviour would be that the tokens listed in `keep_tokens` never get removed."
331,https://github.com/RaRe-Technologies/gensim/issues/2235,2235,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",closed,2018-10-18 07:49:16+00:00,,FastText save & callbacks suspicious behavior,"<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
TODO: FastText model does not learn anything from the text corpus. 

#### Steps/Code/Corpus to Reproduce


```python
import os
import logging

from gensim.models import FastText
from gensim.models.callbacks import CallbackAny2Vec

class EpochSaver(CallbackAny2Vec):
    '''Callback to save model after each epoch and show training parameters '''

    def __init__(self, savedir):
        self.savedir = savedir
        self.epoch = 0
        os.makedirs(self.savedir, exist_ok=True)

    def on_epoch_end(self, model):
        savepath = os.path.join(self.savedir, ""model_fastText_web_kw_sm{}_epoch.gz"".format(self.epoch))
        model.save(savepath)
        print(
            ""Epoch saved: {}"".format(self.epoch + 1),
            ""Start next epoch ... "", sep=""\n""
            )
        if os.path.isfile(os.path.join(self.savedir, ""model_fastText_web_kw_sm{}_epoch.gz"".format(self.epoch - 1))):
            print(""Previous model deleted "")
            os.remove(os.path.join(self.savedir, ""model_fastText_web_kw_sm{}_epoch.gz"".format(self.epoch - 1)))
        self.epoch += 1

class SentenceIter:
    def __iter__(self):
        with open(""data/eng_tweets/20_news_groups_dataset.txt"", ""r"") as f:
            for line in f:
                yield line[:-1].split("" "")

if __name__ == ""__main__"":

   logging.basicConfig(
   format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO
   )

   num_workers = os.cpu_count()
   model = FastText(
        SentenceIter(),
        sg=1,
        size=100,
        window=3,
        min_count=5,
        workers=num_workers,
        iter=5,
        negative=20
        callbacks=[EpochSaver(""./checkpoints/fasttext_eng_tweets"")]
    )
```

#### Expected Results 

I expect to find in model.most_similar(""word"") something closer in meaning but found just a trash. 
I took an open-source dataset  from sklearn.datasets  - fetch_20newsgroups. 

#### Actual Results

![image](https://user-images.githubusercontent.com/33403645/47139525-ad6fac00-d2c4-11e8-9747-e384678ebb40.png)

And it changes very slightly from epoch to epoch, It can change slightly an order of this words, or change their similarity. But nothing changes during training. Nothing learns. 

Also, what is important: 

1. If I try to make a fasttext model from command line, I mean using this command: 
` ./fasttext skipgram -input data.txt -output model`  (https://github.com/facebookresearch/fastText) It shows good results, for example for apple we would receive: apples, apple's and so on.  

2. Also If I change my model from FastText to Word2Vec - I can learn. Results are good. 

3. Also If I don't use my EpochSaver, but just load and save model on each epoch manuall, for example:

```python
for epoch in range(N_epochs):
    train model 
    save model 
```

And then load your model before the next epoch starts, you can also receive good results. 

So, the problem can be in EpochSaver, but can you explain please, why in Word2Vec's case it works, but here - don't. 

#### Versions

Linux-4.15.0-24-generic-x86_64-with-Ubuntu-16.04-xenial
Python 3.5.2 (default, Nov 23 2017, 16:37:01) 
[GCC 5.4.0 20160609]
NumPy 1.14.5
SciPy 1.1.0
gensim 3.6.0
FAST_VERSION 1

<!-- Thanks for contributing! -->

"
332,https://github.com/RaRe-Technologies/gensim/issues/2236,2236,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",open,2018-10-18 17:17:22+00:00,,Documentation: LdaModel.get_document_topics imprecise,"Web documentation says:

""minimum_probability (float) – Topics with an assigned probability lower than this threshold will be discarded."" 

Documentation string from my gensim version () says:

""minimum_probability (float): Ignore topics with probability below this value
        (None by default). If set to None, a value of 1e-8 is used to prevent 0s.""

This sounds as if setting this parameter to 0.0 would be a guarantee to always get back as many tuples as there are topics in the model, but this is not the case: the code still enforces the minimum of 1e-8. 

I am also not sure what the point of this is: if the parameter is set to 0.0, why not allow the user to get back the full topic distribution? I would tend to make the method work as described, rather than change the description. "
333,https://github.com/RaRe-Technologies/gensim/issues/2237,2237,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-10-19 05:06:55+00:00,,3.6.0 doesn't record the file list correctly,"The plist that it records using the ```--record``` option is wrong:
```
===> Checking for items in pkg-plist which are not in STAGEDIR
Error: Missing: %%PYTHON_SITELIBDIR%%/gensim/models/doc2vec_corpusfile.so
Error: Missing: %%PYTHON_SITELIBDIR%%/gensim/models/fasttext_corpusfile.so
Error: Missing: %%PYTHON_SITELIBDIR%%/gensim/models/word2vec_corpusfile.so
```

Found in the FreeBSD port."
334,https://github.com/RaRe-Technologies/gensim/issues/2238,2238,[],closed,2018-10-21 18:27:13+00:00,,error with the Dictionary attiribute of corpora,"Traceback (most recent call last):
  File ""topic_modelling.py"", line 11, in <module>
    dictionary = corpora.Dictionary(doc_clean)
AttributeError: module 'corpora' has no attribute 'Dictionary'
"
335,https://github.com/RaRe-Technologies/gensim/issues/2241,2241,[],closed,2018-10-25 11:34:58+00:00,,Seems like list of VERY BIG lists caused TypeError  problem,"#### Description
Seems like list of VERY BIG lists caused this problem

#### Steps/Code/Corpus to Reproduce
```
import csv
import pandas as pd
import gensim
import pickle
from gensim import corpora, models, similarities

from gensim.models import CoherenceModel
from pprint import pprint  # pretty-printer
from collections import defaultdict

dirname = './'
if __name__ ==""__main__"":
   texts = []

   with open( dirname+'texts.list','rb') as f: <<< I attached tests.zip file
      texts = pickle.load(f)

#   pprint(texts)
#   for text in texts:
#       print(text)
   dictionary = corpora.Dictionary(texts) <<< error

   n_items = len(dictionary)
```

#### Expected Results
make dictionary with out Type error

#### Actual Results
$ python bug.py > texts.out
Traceback (most recent call last):
  File ""bug.py"", line 26, in <module>
    dictionary = corpora.Dictionary(texts)
  File ""/home/smpark/miniconda3/lib/python3.7/site-packages/gensim/corpora/dictionary.py"", line 83, in __init__
    self.add_documents(documents, prune_at=prune_at)
  File ""/home/smpark/miniconda3/lib/python3.7/site-packages/gensim/corpora/dictionary.py"", line 202, in add_documents
    self.doc2bow(document, allow_update=True)  # ignore the result, here we only care about updating token ids
  File ""/home/smpark/miniconda3/lib/python3.7/site-packages/gensim/corpora/dictionary.py"", line 245, in doc2bow
    counter[w if isinstance(w, unicode) else unicode(w, 'utf-8')] += 1
TypeError: decoding to str: need a bytes-like object, float found

#### Versions
$ python version.py
Linux-4.15.0-36-generic-x86_64-with-debian-buster-sid
Python 3.7.0 (default, Jun 28 2018, 13:15:42) 
[GCC 7.2.0]
NumPy 1.15.2
SciPy 1.1.0
gensim 3.6.0
FAST_VERSION 1

[texts.zip](https://github.com/RaRe-Technologies/gensim/files/2514632/texts.zip)

"
336,https://github.com/RaRe-Technologies/gensim/issues/2244,2244,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2018-10-27 19:34:31+00:00,,Documentation: Unclear documentation for PoincareRelations,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
The [documentation](https://radimrehurek.com/gensim/models/poincare.html#gensim.models.poincare.PoincareRelations) for `PoincareRelations` specifies that the input should be a file with one relation per line. In case the relation is assymetric (as is the case with hypernymy) it is not clear whether the pairs should be
a. (u, v) where u is a v ex. u = cat, v = mammal
b. (u, v) where v is a u ex. u = mammal, v = cat 

This maybe clear to people working in this area, but a bit confusing to people just starting with `PoincareModel`. 

Thanks!"
337,https://github.com/RaRe-Technologies/gensim/issues/2246,2246,[],closed,2018-10-31 17:41:26+00:00,,"indptr, indices, and data in stochastic_svd","When I try to run stochastic_svd (from models.lsimodel.py) on its own, I get ""has no attribute"" error messages with regard to indptr, indices, and data (lines 926-927 and 958-960). It works fine when I run the LSI model as a whole. Where are these defined?

I realize this is a question and not an issue; tried posting on the Google group with nothing yet. Think it might be a bit technical for that forum, so thanks in advance if you can help here."
338,https://github.com/RaRe-Technologies/gensim/issues/2253,2253,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}]",closed,2018-11-01 22:20:27+00:00,,Dockerfile doesn't build,"#### Description
dockerfile doesn't build

#### Steps/Code/Corpus to Reproduce
cd docker
docker build .

#### Expected Results
build comples succesfully

#### Actual Results
```
Get:18 http://archive.ubuntu.com/ubuntu xenial-backports/universe amd64 Packages [8532 B]
Fetched 15.5 MB in 1s (10.1 MB/s)
Reading package lists...
Reading package lists...
Building dependency tree...
Reading state information...
E: Version '1.17.1-1ubuntu1.3' for 'wget' was not found
E: Version '2.23-0ubuntu9' for 'locales' was not found
The command '/bin/sh -c apt-get update     && apt-get install -y     ant=1.9.6-1ubuntu1     cmake=3.5.1-1ubuntu3     default-jdk=2:1.8-56ubuntu2     g++=4:5.3.1-1ubuntu1     git=1:2.7.4-0ubuntu1     libboost-all-dev=1.58.0.1ubuntu1     libgsl-dev=2.1+dfsg-2     mercurial=3.7.3-1ubuntu1     python3=3.5.1-3     python3-pip=8.1.1-2ubuntu0.4     python3-setuptools=20.7.0-1     python=2.7.11-1     python-pip=8.1.1-2ubuntu0.4     python-setuptools=20.7.0-1     unzip=6.0-20ubuntu1     wget=1.17.1-1ubuntu1.3     subversion=1.9.3-2ubuntu1.1     locales=2.23-0ubuntu9     libopenblas-dev=0.2.18-1ubuntu1     libboost-program-options-dev=1.58.0.1ubuntu1     zlib1g-dev=1:1.2.8.dfsg-2ubuntu4.1' returned a non-zero code: 100
```


#### Versions
develop branch @ 20181101_2219"
339,https://github.com/RaRe-Technologies/gensim/issues/2255,2255,[],closed,2018-11-02 01:56:52+00:00,,How to save a dictionary for later using?,"#### Description
Is there any way to save a dictionary for later using?"
340,https://github.com/RaRe-Technologies/gensim/issues/2257,2257,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-11-04 09:54:02+00:00,,FastText Bug,"I want to iterate a file several times so I made a class called MyLineSentence. When I train it in FastText, I get an error and the code aborted. **However, when I just replace FastText with WordVec, it is OK. So I think it is a bug of FastText.**

Environment: Windows 10.

```python
class MyLineSentence:
	def __init__(self, path, iter=15):
		self.path = path
		self.iter = iter
	def __iter__(self):
		for i in range(self.iter):
			f = open(self.path, 'r', encoding='utf-8')
			for line in f:
				yield line[:-1].split('\t')[-1].split(' ')
			f.close()

from gensim.models.fasttext import FastText
from gensim.models import Word2Vec
class WordVec_FT_Model:
	def __init__(self, corpora_path = None, model_path = None):
		self.corpora_path = corpora_path
		self.model_path = model_path
		self.model = None
	def train(self):
		if self.corpora_path is None:
			return
		iter = 2
		corpora = MyLineSentence(self.corpora_path, iter=iter)
		# self.model = WordVec(size=50, sg=1, iter=1, min_count=1, workers=1) # This is OK
		self.model = FastText(size=50, sg=1, iter=1, min_count=1, workers=1) # This makes an error
		print('building vocab...')
		self.model.build_vocab(corpora)
		print('build over.')
		corpora = MyLineSentence(self.corpora_path, iter=iter)
		print('training...')
		self.model.train(corpora, total_examples=self.model.corpus_count, epochs=self.model.iter)
```"
341,https://github.com/RaRe-Technologies/gensim/issues/2258,2258,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",closed,2018-11-05 16:10:29+00:00,,Integer overflow during `FastText` training with `corpus_file`,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description

<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->
`model = FastText(corpus_file=""sentences_norm.txt.gz"", workers=14, iter=5, size=200, sg=1, hs=1)`

with the following sizes 

```
2018-11-05 16:57:52,809 : INFO : collected 6532860 word types from a corpus of 4728738902 raw words and 238627116 sentences
2018-11-05 16:57:52,809 : INFO : Loading a fresh vocabulary
2018-11-05 16:58:00,788 : INFO : effective_min_count=5 retains 1887156 unique words (28% of original 6532860, drops 4645704)
2018-11-05 16:58:00,788 : INFO : effective_min_count=5 leaves 4721157112 word corpus (99% of original 4728738902, drops 7581790)
2018-11-05 16:58:07,437 : INFO : deleting the raw counts dictionary of 6532860 items
2018-11-05 16:58:07,615 : INFO : sample=0.001 downsamples 26 most-common words
2018-11-05 16:58:07,615 : INFO : downsampling leaves estimated 3749158657 word corpus (79.4% of prior 4721157112)
2018-11-05 16:58:11,281 : INFO : constructing a huffman tree from 1887156 words
2018-11-05 16:59:36,077 : INFO : built huffman tree with maximum node depth 30
2018-11-05 17:00:17,300 : INFO : estimated required memory for 1887156 words, 1929637 buckets and 200 dimensions: 7871448352 bytes
2018-11-05 17:00:17,398 : INFO : resetting layer weights
2018-11-05 17:01:43,333 : INFO : Total number of ngrams is 1929637
2018-11-05 17:02:11,990 : INFO : training model with 14 workers on 1887156 vocabulary and 200 features, using sg=1 hs=1 sample=0.001 negative=5 window=5
```

yields 

```
Exception in thread Thread-2120:
Traceback (most recent call last):
  File ""/home/joelkuiper/anaconda3/lib/python3.6/threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""/home/joelkuiper/anaconda3/lib/python3.6/threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/joelkuiper/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py"", line 175, in _worker_loop_corpusfile
    total_examples=total_examples, total_words=total_words, **kwargs)
  File ""/home/joelkuiper/anaconda3/lib/python3.6/site-packages/gensim/models/fasttext.py"", line 561, in _do_train_epoch
    total_examples, total_words, work, neu1)
  File ""gensim/models/fasttext_corpusfile.pyx"", line 126, in gensim.models.fasttext_corpusfile.train_epoch_sg
OverflowError: value too large to convert to int
```` 

on all workers. Note that the sg and hs parameters seem to have no relation to this, also happens without them. 

### Steps to reproduce
`model = FastText(corpus_file=""sentences_norm.txt.gz"", workers=14, iter=5,size=200)`

#### Expected Results
Should train the model

#### Actual Results
Exception thrown, no further output. 

```
Traceback (most recent call last):
  File ""/home/joelkuiper/anaconda3/lib/python3.6/threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""/home/joelkuiper/anaconda3/lib/python3.6/threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/joelkuiper/anaconda3/lib/python3.6/site-packages/gensim/models/base_any2vec.py"", line 175, in _worker_loop_corpusfile
    total_examples=total_examples, total_words=total_words, **kwargs)
  File ""/home/joelkuiper/anaconda3/lib/python3.6/site-packages/gensim/models/fasttext.py"", line 561, in _do_train_epoch
    total_examples, total_words, work, neu1)
  File ""gensim/models/fasttext_corpusfile.pyx"", line 126, in gensim.models.fasttext_corpusfile.train_epoch_sg
OverflowError: value too large to convert to int
```

#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->

Python 3.6.6 |Anaconda, Inc.| (default, Oct  9 2018, 12:34:16) 
[GCC 7.3.0]
NumPy 1.15.3
SciPy 1.1.0
gensim 3.6.0

On Ubuntu 16.04

**edit** seems to work fine when passing in a `LineSentence` object
<!-- Thanks for contributing! -->

"
342,https://github.com/RaRe-Technologies/gensim/issues/2260,2260,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2018-11-06 10:43:21+00:00,,doc2vec/word2vec/fasttext models do not appear to improve if similarities checked mid-training epochs,"<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
I am training a doc2vec model on a large corpus. I need to observe the model for more detailed statistics for my supervisor/boss.
The problem is similar to the problem below where I just slightly modified the [Doc2Vec Tutorial on the Lee Dataset](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-lee.ipynb). The model does not improve its recommendations for the` most_similar method`.

#### Steps/Code/Corpus to Reproduce
```python
import gensim
import os
import smart_open
import gensim.models.callbacks


# Set file names for train and test data
test_data_dir = '{}'.format(os.sep).join([gensim.__path__[0], 'test', 'test_data'])
lee_train_file = test_data_dir + os.sep + 'lee_background.cor'
lee_test_file = test_data_dir + os.sep + 'lee.cor'


def read_corpus(fname, tokens_only=False):
    with smart_open.smart_open(fname, encoding=""iso-8859-1"") as f:
        for i, line in enumerate(f):
            if tokens_only:
                yield gensim.utils.simple_preprocess(line)
            else:
                # For training data, add tags
                yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(line), [i])


train_corpus = list(read_corpus(lee_train_file))
test_corpus = list(read_corpus(lee_test_file, tokens_only=True))

results_new = {i: None for i, doc in enumerate(train_corpus)}
results_old = results_new.copy()


class TrainProgressEvaluation(gensim.models.callbacks.CallbackAny2Vec):

    def __init__(self, test_set, results_new, results_old):
        self.test_set = test_set
        self.results_new = results_new
        self.results_old = results_old
        self.epoch = 0

    def on_epoch_end(self, model):
        self.epoch += 1
        print(f""epoch {self.epoch} end"")

    def on_batch_begin(self, model):
        for num, sample in enumerate(self.test_set):
            recs = model.docvecs.most_similar(num)
            # for the first call results_new[num] is None
            self.results_old[num] = results_new[num] or recs
            self.results_new[num] = recs
            for i in range(len(recs)):
                if not self.results_old[num][i][0] == self.results_new[num][i][0] or not self.results_old[num][i][1] == self.results_new[num][i][1]:
                    print(f""Sample {num} has changed."")
                    print(f""Old tag {self.results_old[num][i][0]}. New tag {self.results_new[num][i][0]}"")
                    print(f""Old distance {self.results_old[num][i][1]}. New distance {self.results_new[num][i][1]}"")


model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40, workers=4)
model.build_vocab(train_corpus)
model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs,
            callbacks=(TrainProgressEvaluation(train_corpus, results_new, results_old),))


```

#### Expected Results
I expect to see many improvements in either recommendation or distance.

#### Actual Results
Consol Output with four workers:
It surprises me that only the first sample in the training_corpus receives some updates. I don't understand it.

```
Sample 0 has changed.
/usr/local/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.
Old tag 116. New tag 30
  if np.issubdtype(vec.dtype, np.int):
Old distance 0.5557072162628174. New distance 0.4648822546005249
Sample 0 has changed.
Old tag 42. New tag 224
Old distance 0.48946425318717957. New distance 0.3621359169483185
Sample 0 has changed.
Old tag 51. New tag 96
Old distance 0.4082771837711334. New distance 0.31921446323394775
Sample 0 has changed.
Old tag 90. New tag 77
Old distance 0.3731566369533539. New distance 0.3184990882873535
Sample 0 has changed.
Old tag 128. New tag 45
Old distance 0.34601616859436035. New distance 0.30474674701690674Sample 0 has changed.
Old tag 30. New tag 116
Old distance 0.4648822546005249. New distance 0.5557072162628174
Sample 0 has changed.
Old tag 224. New tag 42
Old distance 0.3621359169483185. New distance 0.48946425318717957
Sample 0 has changed.
Old tag 96. New tag 51
Old distance 0.31921446323394775. New distance 0.4082771837711334
Sample 0 has changed.
Old tag 77. New tag 90
Sample 0 has changed.
Old tag 46. New tag 234
Old distance 0.3005654215812683. New distance 0.3441653251647949
Old distance 0.3184990882873535. New distance 0.3731566369533539
Sample 0 has changed.
Old tag 45. New tag 128
Old distance 0.30474674701690674. New distance 0.34601616859436035
Sample 0 has changed.
Old tag 46. New tag 234
Old distance 0.3005654215812683. New distance 0.3441653251647949
Sample 0 has changed.
Sample 0 has changed.
Old tag 111. New tag 76
Old tag 111. New tag 76
Old distance 0.280322402715683. New distance 0.32334667444229126
Old distance 0.280322402715683. New distance 0.32334667444229126
Sample 0 has changed.
Old tag 221. New tag 49

Old distance 0.2779023051261902. New distance 0.27320006489753723
Sample 0 has changed.
Old tag 52. New tag 4
Old distance 0.27472415566444397. New distance 0.27205419540405273
Sample 0 has changed.
Old tag 221. New tag 49
Old distance 0.2779023051261902. New distance 0.27320006489753723
Sample 0 has changed.
Sample 0 has changed.
Old tag 205. New tag 149
Old distance 0.26930660009384155. New distance 0.2699446976184845
Old tag 52. New tag 4
Old distance 0.27472415566444397. New distance 0.27205419540405273
Sample 0 has changed.
Old tag 205. New tag 149
Old distance 0.26930660009384155. New distance 0.2699446976184845
Sample 0 has changed.
Old tag 116. New tag 30
Old distance 0.5557072162628174. New distance 0.4648822546005249
Sample 0 has changed.
Old tag 42. New tag 224
Old distance 0.48946425318717957. New distance 0.3621359169483185
Sample 0 has changed.
Old tag 51. New tag 96
Old distance 0.4082771837711334. New distance 0.31921446323394775
Sample 0 has changed.
Old tag 90. New tag 77
Old distance 0.3731566369533539. New distance 0.3184990882873535
Sample 0 has changed.
Old tag 128. New tag 45
Old distance 0.34601616859436035. New distance 0.30474674701690674
Sample 0 has changed.
Old tag 234. New tag 46
Old distance 0.3441653251647949. New distance 0.3005654215812683
Sample 0 has changed.
Old tag 76. New tag 111
Old distance 0.32334667444229126. New distance 0.280322402715683
Sample 0 has changed.
Old tag 49. New tag 221
Old distance 0.27320006489753723. New distance 0.2779023051261902
Sample 0 has changed.
Old tag 4. New tag 52
Old distance 0.27205419540405273. New distance 0.27472415566444397
Sample 0 has changed.
Old tag 149. New tag 205
Old distance 0.2699446976184845. New distance 0.26930660009384155
epoch 1 end
epoch 1 end
epoch 2 end
epoch 3 end
epoch 4 end
....
```

So I debug the model and there are no improvements anymore:
```
/usr/local/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.
  if np.issubdtype(vec.dtype, np.int):
epoch 1 end
epoch 2 end
....
```

I try it with 1 worker only:
```
/usr/local/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.
  if np.issubdtype(vec.dtype, np.int):
epoch 1 end
epoch 2 end
epoch 3 end
....
```

What's happening here and how can I see during training how my doc2vec model improves? Because it is also not possible to see the training_error for doc2vec [#999](https://github.com/RaRe-Technologies/gensim/issues/999).
Further experimenting reveals that docvecs.vectors_docs are of course updated between each call of `batch_end`. But `most_similiar` always returns the same suggestion.

#### Versions
Darwin-17.5.0-x86_64-i386-64bit
Python 3.7.0 (default, Jun 29 2018, 20:13:13) 
[Clang 9.1.0 (clang-902.0.39.2)]
NumPy 1.15.0
SciPy 1.1.0
gensim 3.5.0
FAST_VERSION 0

"
343,https://github.com/RaRe-Technologies/gensim/issues/2265,2265,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2018-11-14 23:21:28+00:00,,LDA Diff and Convergence metrics: inefficient memory consumption and file size,"#### Description
The current implementation of the DiffMetric and ConvergenceMetric callbacks has some severe drawbacks with respect to memory consumption and file size when persisting an LdaModel.

**Details:** The two callback metrics call the LdaModel.diff() method which requires a second model as an argument. Therefore, the callbacks make a deep copy of the model when initializing the callbacks and also at each time they are called (refere to Callback.set_model() and Callback.on_epoch_end()). With a deep copy you not only copy the model's dictionary, you also make a copy of any other callback the model points to. Running both the DiffMetric and the ConvergenceMetric during training over several epochs you inherit quite a bit of recursion and redundancy.

#### Steps/Code/Corpus to Reproduce
You can easily see the issue when watching memory consumption growing over time during training, but also when serializing the model after training. Run the following tutorial notebook:
[https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/Training_visualizations.ipynb](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/Training_visualizations.ipynb)
After training save the model with and without callbacks and compare the file sizes:

```
model.save('model_with_cb')
# file size: 2.9 GB <- not ok

model.callbacks = None
model.save('model_without_cb')
# file size: 595.2 kB <- ok
```

#### Possible solutions
A workaround would be to set ldamodel.callbacks to None before saving the model. However, if you plan to update the model you'll have to remember to initialize new callbacks. Still, the memory consumption remains an issue during training. It would be better to avoid making a deep copy of the model in the first place.

Internally the LdaModel.diff() method only needs access to the previous topics, not to the entire model. Thus, it would be sufficient to backup just the previous topics instead of the entire model. In order to do so the diff method might need some re-writing, though.

#### Versions
Linux-4.13.0-38-generic-x86_64-with-debian-stretch-sid
Python 3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) 
[GCC 7.2.0]
NumPy 1.14.3
SciPy 1.0.1
gensim 3.5.0
FAST_VERSION 1"
344,https://github.com/RaRe-Technologies/gensim/issues/2266,2266,[],closed,2018-11-15 12:52:55+00:00,,How to handle word out of vocabulary in word2vec?,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
How to handle word out of vocabulary while using word Word2vec keyed vector approach?

"
345,https://github.com/RaRe-Technologies/gensim/issues/2268,2268,[],closed,2018-11-16 09:51:34+00:00,,Word2VecKeyedVectors (& maybe other KeyedVectors) give AttributeError if you try to add() ,"Hi there,

excuses for cross posting with your news group!
Thank you for the superb gensim-module which we find extremely helpful for our text analytics projects!

#### Description
We stumbled upon an issue when we load the pre-trained google news word vectors: 
we are unable to add random word vectors to the map because the ""add""-method is not provided. 

#### Steps/Code/Corpus to Reproduce
`import pysvn`
`import numpy as np`
`import gensim`
`# assuming that GoogleNews-vectors-negative300.bin is extracted to local disk drive:`
`# URL: https://github.com/mmihaltz/word2vec-GoogleNews-vectors/blob/master/GoogleNews-vectors-negative300.bin.gz`
`# local path: D:/training-data/word2vec/GoogleNews-vectors-negative300.bin`
`googleNewsModel = gensim.models.KeyedVectors.load_word2vec_format('D:/training-data/word2vec/GoogleNews-vectors-negative300.bin', binary=True) `
`googleNewsModel.add(list('unknown word'), list(np.random.random(300))) `

#### Expected Results
New token, vector are added to the model.

#### Actual Results
`returns error: AttributeError: 'Word2VecKeyedVectors' object has no attribute 'add' `

Traceback (most recent call last):

  File ""<ipython-input-1-f0d2181562f3>"", line 1, in <module>
    runfile('C:/Users/hansch/../gensim_issue.py', wdir='C:/Users/hansch/../eurolex')

  File ""C:\Users\hansch\AppData\Local\conda\conda\envs\gpupy36gensim\lib\site-packages\spyder_kernels\customize\spydercustomize.py"", line 668, in runfile
    execfile(filename, namespace)

  File ""C:\Users\hansch\AppData\Local\conda\conda\envs\gpupy36gensim\lib\site-packages\spyder_kernels\customize\spydercustomize.py"", line 108, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File ""C:/Users/hansch/../gensim_issue.py"", line 11, in <module>
    googleNewsModel.add(list('unknown word'), list(np.random.random(300))) # add the token and the random wordvector to the google News word vectors

AttributeError: 'Word2VecKeyedVectors' object has no attribute 'add'



#### Versions
windows server 2012
python 3.6
gensim 3.6.0




"
346,https://github.com/RaRe-Technologies/gensim/issues/2270,2270,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2018-11-20 16:14:27+00:00,,DeprecationWarning: numpy sum :: np.sum(generator) is deprecated - LDA,"**Warning:**
score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)
/usr/local/lib/python2.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.from_iter(generator)) or the python sum builtin instead.
  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)

#### Versions
import platform; print(platform.platform())
Linux-4.16.0-x86_64-with-Ubuntu-18.04-bionic
import sys; print(""Python"", sys.version)
('Python', '2.7.15rc1 (default, Nov 12 2018, 14:31:15) \n[GCC 7.3.0]')
import numpy; print(""NumPy"", numpy.__version__)
('NumPy', '1.15.4')
import scipy; print(""SciPy"", scipy.__version__)
('SciPy', '1.1.0')
import gensim; print(""gensim"", gensim.__version__)
('gensim', '3.6.0')
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
('FAST_VERSION', 1)


"
347,https://github.com/RaRe-Technologies/gensim/issues/2272,2272,[],closed,2018-11-21 07:06:50+00:00,,questions about self.vocabulary,"![image](https://user-images.githubusercontent.com/19839217/48824010-e7d5d880-ed9d-11e8-982d-102c5e80da75.png)
In the script base_any2vec.py, the class BaseWordEmbeddingsModel has a mthed named ""build_vocab"" (as the picture showing above). I just wonder why the instance self has the attribute ""vocabulary"". I can't find the place where it is introduced in. It appears as the function of the class Word2VecVocab in the script word2vec.py. However ""word2vec.py"" is somewhat child script of the ""base_any2vec.py"". Anyone can explain this?

"
348,https://github.com/RaRe-Technologies/gensim/issues/2276,2276,[],closed,2018-11-23 16:01:23+00:00,,`FastText.wv.word_vec` word vectors with Polish character are different than the Facebook's,"#### Description
Facebook's and Gensim's word vectors are different for words with Polish characters.

#### Steps to Reproduce

Example (I'm using Polish common crawl vectors):
```
wget https://s3-us-west-1.amazonaws.com/fasttext-vectors/word-vectors-v2/cc.pl.300.bin.gz 
unzip cc.pl.300.bin.gz 
```

Gensim's (1)
```
from gensim.models import FastText
m = FastText.load_fasttext_format('cc.pl.300.bin')
print(m['głowa'][:10])
```
Facebook's (2)
```
from fastText import load_model
m_fb = load_model('cc.pl.300.bin')
print(m_fb.get_word_vector('głowa')[:10])
```

Oh, and 'głowa' is present in both vocabularies
```
print('głowa' in m.wv.vocab)
print('głowa' in m_fb.get_words())
```

Seems like an encoding issue (?)

#### Expected Results
Values in both vectors (1), (2) are different.

#### Actual Results
Values in  (1), (2) differ.

#### Versions
```
gensim 3.6.0
fasttext 0.8.22
```


"
349,https://github.com/RaRe-Technologies/gensim/issues/2277,2277,[],closed,2018-11-24 15:18:36+00:00,," assert self.projection.u is not None, ""decomposition not initialized yet"" AttributeError: 'NoneType' object has no attribute 'u'"," I aim to implement lsa similarity based on wikipedia to find the similarity among my questions and answers. I wrote the coed below but it gives me this error recently when I started run it on hpc. It works without error on my pc  with gensim 0.3.4 but with the same version of gensim I get the below error on hpc. Any help is appreciated.


`#load the corpora created in the previous notebook
tfidf_corpus = gensim.corpora.MmCorpus('./data/wiki_tfidf.mm')
lsi_corpus = gensim.corpora.MmCorpus('./data/wiki_lsa.mm')
#print(tfidf_corpus)
#print(lsi_corpus)

# load the models too
id2word_wiki = gensim.corpora.Dictionary.load('./data/wiki.dictionary')
#lda_model = gensim.models.LdaModel.load('./data/lda_wiki.model')
tfidf_model = gensim.models.TfidfModel.load('./data/tfidf_wiki.model')
lsi_model = gensim.models.LsiModel.load('./data/lsi_wiki.model')

index = Similarity('./data/wiki_index', lsi_corpus, num_features=lsi_corpus.num_terms)
#print(index)

# store to disk
index.save('./data/wiki_index.index')

# load back = same index
index = Similarity.load('./data/wiki_index.index')
#print(index)
docs_bow = (id2word.doc2bow(tokenize(document)) for document in index_documents)
docs_tfidf = tfidf_model[docs_bow]
docs_lsi = lsi_model[docs_tfidf]`




error:
  File ""lsa-final1.py"", line 226, in <module>
    docs_lsi = lsi_model[docs_tfidf]
  File ""/root/anaconda3/envs/my_env/lib/python3.7/site-packages/gensim/models/lsimodel.py"", line 564, in __getitem__
    assert self.projection.u is not None, ""decomposition not initialized yet""
AttributeError: 'NoneType' object has no attribute 'u'
"
350,https://github.com/RaRe-Technologies/gensim/issues/2278,2278,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-11-24 15:33:05+00:00,,"assert self.projection.u is not None, ""decomposition not initialized yet""","I aim to implement lsa similarity based on wikipedia to find the similarity among my questions and answers. I wrote the coed below but it gives me this error recently when I started run it on hpc. Any helpis appreciated. I do not get any error when run this program on my pc with the same version of gensim 3.4.0

`# load the corpora created in the previous notebook
tfidf_corpus = gensim.corpora.MmCorpus('./data/wiki_tfidf.mm')
lsi_corpus = gensim.corpora.MmCorpus('./data/wiki_lsa.mm')
#print(tfidf_corpus)
#print(lsi_corpus)

# load the models too
id2word_wiki = gensim.corpora.Dictionary.load('./data/wiki.dictionary')
#lda_model = gensim.models.LdaModel.load('./data/lda_wiki.model')
tfidf_model = gensim.models.TfidfModel.load('./data/tfidf_wiki.model')
lsi_model = gensim.models.LsiModel.load('./data/lsi_wiki.model')

index = Similarity('./data/wiki_index', lsi_corpus, num_features=lsi_corpus.num_terms)
#print(index)

# store to disk
index.save('./data/wiki_index.index')

# load back = same index
index = Similarity.load('./data/wiki_index.index')
#print(index)
 docs_bow = (id2word.doc2bow(tokenize(document)) for document in index_documents)
 docs_tfidf = tfidf_model[docs_bow]
 docs_lsi = lsi_model[docs_tfidf]`


error:
  File ""lsa-final1.py"", line 226, in <module>
    docs_lsi = lsi_model[docs_tfidf]
  File ""/root/anaconda3/envs/my_env/lib/python3.7/site-packages/gensim/models/lsimodel.py"", line 564, in __getitem__
    assert self.projection.u is not None, ""decomposition not initialized yet""
AttributeError: 'NoneType' object has no attribute 'u'"
351,https://github.com/RaRe-Technologies/gensim/issues/2279,2279,[],closed,2018-11-26 11:40:11+00:00,,LDA get topic words return only id's,"Hi,
I am trying to get the words from the topic models, and I only get the id's and values:

```
from gensim.test.utils import common_texts
from gensim.corpora.dictionary import Dictionary
from gensim.models import LdaModel
from gensim.test.utils import datapath

common_dictionary = Dictionary(common_texts)
common_corpus = [common_dictionary.doc2bow(text) for text in common_texts]

lda = LdaModel(common_corpus, num_topics=10)
temp_file = datapath(""model"")
lda.save(temp_file)

lda = LdaModel.load(temp_file)
other_texts = [['computer', 'time', 'graph'],['survey', 'response', 'eps'],['human', 'system', 'computer']]
other_corpus = [common_dictionary.doc2bow(text) for text in other_texts]
unseen_doc = other_corpus[0]
vector = lda[unseen_doc]

print(lda.print_topics())

x=lda.show_topics(num_topics=12, num_words=5,formatted=False)
topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in x]

#Below Code Prints Topics and Words
for topic,words in topics_words:
    print(str(topic)+ ""::""+ str(words))
print()

#Below Code Prints Only Words 
for topic,words in topics_words:
    print("" "".join(words))-->
```
Output:
```
[(0, '0.206*""11"" + 0.206*""10"" + 0.108*""9"" + 0.108*""3"" + 0.108*""6"" + 0.108*""7"" + 0.108*""4"" + 0.010*""5"" + 0.010*""0"" + 0.010*""1""'), (1, '0.083*""9"" + 0.083*""10"" + 0.083*""7"" + 0.083*""5"" + 0.083*""1"" + 0.083*""8"" + 0.083*""6"" + 0.083*""2"" + 0.083*""0"" + 0.083*""4""'), (2, '0.083*""9"" + 0.083*""10"" + 0.083*""5"" + 0.083*""7"" + 0.083*""0"" + 0.083*""3"" + 0.083*""11"" + 0.083*""1"" + 0.083*""4"" + 0.083*""8""'), (3, '0.262*""1"" + 0.262*""2"" + 0.262*""0"" + 0.024*""9"" + 0.024*""10"" + 0.024*""7"" + 0.024*""5"" + 0.024*""6"" + 0.024*""4"" + 0.024*""11""'), (4, '0.083*""9"" + 0.083*""10"" + 0.083*""7"" + 0.083*""5"" + 0.083*""1"" + 0.083*""2"" + 0.083*""11"" + 0.083*""6"" + 0.083*""0"" + 0.083*""8""'), (5, '0.277*""5"" + 0.187*""8"" + 0.098*""2"" + 0.098*""7"" + 0.098*""1"" + 0.098*""10"" + 0.098*""9"" + 0.009*""4"" + 0.009*""0"" + 0.009*""6""'), (6, '0.083*""9"" + 0.083*""10"" + 0.083*""5"" + 0.083*""7"" + 0.083*""0"" + 0.083*""8"" + 0.083*""2"" + 0.083*""1"" + 0.083*""11"" + 0.083*""6""'), (7, '0.153*""4"" + 0.153*""3"" + 0.153*""5"" + 0.153*""6"" + 0.153*""7"" + 0.153*""0"" + 0.014*""9"" + 0.014*""10"" + 0.014*""11"" + 0.014*""2""'), (8, '0.500*""9"" + 0.045*""10"" + 0.045*""7"" + 0.045*""5"" + 0.045*""0"" + 0.045*""4"" + 0.045*""2"" + 0.045*""1"" + 0.045*""11"" + 0.045*""6""'), (9, '0.083*""9"" + 0.083*""10"" + 0.083*""7"" + 0.083*""0"" + 0.083*""2"" + 0.083*""11"" + 0.083*""4"" + 0.083*""6"" + 0.083*""1"" + 0.083*""5""')]
0::['11', '10', '9', '3', '6']
1::['9', '10', '7', '5', '1']
2::['9', '10', '5', '7', '0']
3::['1', '2', '0', '9', '10']
4::['9', '10', '7', '5', '1']
5::['5', '8', '2', '7', '1']
6::['9', '10', '5', '7', '0']
7::['4', '3', '5', '6', '7']
8::['9', '10', '7', '5', '0']
9::['9', '10', '7', '0', '2']

11 10 9 3 6
9 10 7 5 1
9 10 5 7 0
1 2 0 9 10
9 10 7 5 1
5 8 2 7 1
9 10 5 7 0
4 3 5 6 7
9 10 7 5 0
9 10 7 0 2
```
Python: 3.5.2
Linux-4.15.0-39-generic-x86_64-with-Ubuntu-16.04-xenial
[GCC 5.4.0 20160609]
NumPy 1.15.4
gensim 3.6.0
FAST_VERSION 1

Thanks.

"
352,https://github.com/RaRe-Technologies/gensim/issues/2280,2280,[],closed,2018-11-27 02:18:04+00:00,,What does total_examples actually use for?,"Hello,

As I know, in the previous version of Gensim, using `total_example` was not compulsory but in the latest version, it should be declared explicitly.
I am interested to know what it means and how I should reach the appropriate value.
Is it a figure of rows in the raw or the pre-processed dataset?

Thanks in advance 
"
353,https://github.com/RaRe-Technologies/gensim/issues/2283,2283,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2018-12-03 21:26:45+00:00,,SECURITY: api.load() recklessly downloads & runs arbitrary python code,"The `api.load()` utility will grab fresh Python code, in the form  of an `__init__.py` file inside the Github project `gensim-data` download area, and then run it at the user's machine. 

This form of dynamic code loading & execution:

* violates user expectations: requesting a dataset should not run arbitrary new code that was never explicitly installed on the user's machine. Further, there's no indication in the `api.load()` docs that this could occur.
* creates a severe security risk: if a bad-faith actor obtains the ability to edit the `gensim-data` Github ""releases"" files, they can cause arbitrary new code to run on gensim users' machine, when those users use `api.load()`. The users wold think, ""I'm still using this old, assumed-safe-through-widespread-use gensim-X.Y.Z version"" – but they'd be running arbitrary all-new code from over the network. It's hard to tell who has `gensim-data` project rights. It's also not clear that anyone would quickly notice edits/changes there.

Further, these `__init__.py` files in the `gensim-data` releases aren't even in version-control – instead, they're uploaded as 'assets' via the Github releases interface. (There's no file-size need to do this; the `__init__.py` I reviewed, for `wiki-english-20171001` at <https://github.com/RaRe-Technologies/gensim-data/releases/download/wiki-english-20171001/__init__.py>, is just a tiny shim and I imagine most other such files are, as well. It's code, it should be versioned.)

That they are not in version-control makes them hard to review through normal means (such as browsing the Github website), and raises the possibility they could be changed to something malicious, and then back again, without anyone noticing or it being visible in any persistent logs. 

Recommendations: 

The `api.load()` mechanism should be immediately redesigned to not load any new code over the network – and the developer guidelines for gensim & associated projects should make it clear such dynamic loading of code outside normal package-installation processes (like `pip`) is unacceptable. 

If supporting new datasets requires dataset-specific code, that code should go through normal collaboration/version-control/release procedures, waiting for a new `pip`-installable `gensim` (or other new supporting project) explicit release before running on users' computers. 

ATTN: @menshikh-iv @piskvorky @chaitaliSaini "
354,https://github.com/RaRe-Technologies/gensim/issues/2285,2285,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 1602257032, 'node_id': 'MDU6TGFiZWwxNjAyMjU3MDMy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20HIGH', 'name': 'impact HIGH', 'color': 'b60205', 'default': False, 'description': 'Show-stopper for affected users'}]",open,2018-12-06 17:20:26+00:00,,Puzzling deprecated warnings,"I am using word vectors with gensim 3.4.0 and I am genuinely puzzled by the warnings I get when I try to load and use embeddings created with possibly older versions of gensim.
All of the models get loaded using `gensim.models.KeyedVectors.load(file, mmap='r')`

When I create a completely new instance using `model=gensim.models.Word2Vec()`:
* the model does not have a `vectors` or `vectors_norm` attribute and doing  `""x"" in model` shows ""DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.\_\_contains\_\_() instead).""
* `model.wv.syn0` informs about "" DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).""

So it looks as if I SHOULD always use model.wv and model.wv.vectors

But when I load glove embeddings that have been created probably with an older version of gensim:
* when I do `model.wv.vectors` I get: ""DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).""

So this tells me I should NOT use wv. The model does have model.vectors while others do not even have that attribute. Some have model.wv.syn0 or model.syn0 while still others dont. 

I cannot figure out what the correct way is to make my code always work, and work with all models and not show conflicting deprecation messages ...

"
355,https://github.com/RaRe-Technologies/gensim/issues/2286,2286,[],closed,2018-12-06 18:13:58+00:00,,DtmModel error,"#### Description
When running DtmModel on a dataset of size 1.5M documents, after about 1 hour it raises this error:

```
subprocess.CalledProcessError: Command '['/efs/data/jpb/Qatalog/dtm/dtm/main', '--ntopics=10', '--model=dtm', '--mode=fit', '--initialize_lda=true', '--corpus_prefix=/tmp/2beb46_train', '--outname=/tmp/2beb46_train_out', '--alpha=0.01', '--lda_max_em_iter=10', '--lda_sequence_min_iter=6', '--lda_sequence_max_iter=10', '--top_chain_var=0.005', '--rng_seed=0']' died with <Signals.SIGABRT: 6>.
```

This same DtmModel works on smaller datasets I've tried.

#### Versions
```
import platform; print(platform.platform())
Linux-4.4.0-1072-aws-x86_64-with-debian-stretch-sid
import sys; print(""Python"", sys.version)
Python 3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56)[GCC 7.2.0]
import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.15.4
import scipy; print(""SciPy"", scipy.__version__)
│SciPy 1.1.0
import gensim; print(""gensim"", gensim.__version__)
gensim 3.6.0
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1
```

Thanks for your help

"
356,https://github.com/RaRe-Technologies/gensim/issues/2287,2287,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-12-07 01:25:15+00:00,,Saving a Doc2Vec model failed.error says that the model is not UTF-8 encoded,"I am failing to save a trained Doc2Vec model that analyses Tweets.When i save it and try to open the content of the model it says that :saving is disabled and that the model is not UTF-8 encoded.Any idea about the error?
 **i create the model as follows:**
_model_ug_dbow = Doc2Vec(dm=0, size=100, negative=5, min_count=2, workers=2, alpha=0.065, min_alpha=0.065)_

**training:**

for epoch in range(30):
    model_ug_dbow.train(utils.shuffle([x for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)
    model_ug_dbow.alpha -= 0.002
    model_ug_dbow.min_alpha = model_ug_dbow.alpha

**Saving:**
_model_ug_dbow.save('d2v_model_ug_dbow.doc2vec')_
"
357,https://github.com/RaRe-Technologies/gensim/issues/2289,2289,[],closed,2018-12-07 10:49:39+00:00,,Flake8 Errors: W605 and W504,"I have cloned the repository in my ubuntu machine according to the steps provided [here](https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md).<br>
I run the flake8 test and getting these errors: **W605** and **W504**
Here is the screenshot of the log :
![log](https://user-images.githubusercontent.com/39291744/49643804-af402b00-fa3c-11e8-9572-f4edd123646f.png)<br>
These errors are occurring in the files:
[gensim/utils.py](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/utils.py)
[gensim/topic_coherence/direct_confirmation_measure.py](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/topic_coherence/direct_confirmation_measure.py) 
[gensim/topic_coherence/segmentation.py](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/topic_coherence/segmentation.py)
[gensim/summarization/mz_entropy.py](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/summarization/mz_entropy.py)
[gensim/corpora/wikicorpus.py](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/corpora/wikicorpus.py)
[gensim/test/test_matutils.py](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/test/test_matutils.py)
[gensim/test/test_doc2vec.py](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/test/test_doc2vec.py)
[gensim/models/word2vec.py](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/word2vec.py)
[gensim/models/atmodel.py](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/atmodel.py)
[gensim/models/coherencemodel.py](gensim/models/coherencemodel.py)
[gensim/models/ldamulticore.py](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/ldamulticore.py)
[gensim/models/phrases.py](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/phrases.py)

I think these errors are the main reason why **every [PR's](https://github.com/RaRe-Technologies/gensim/pulls)** is failing in one check( _Travis CI build is failed_).
I would like to work on this.
"
358,https://github.com/RaRe-Technologies/gensim/issues/2291,2291,[],closed,2018-12-09 16:42:37+00:00,,CoherenceModel with coherence='c_v' restarts Python,"#### Description
CoherenceModel with coherence='c_v' crashes

 on Windows when attempting to evaluate get_coherence().

Attempted to play around with freeze_support() as it seems like a forking issue, but doesn't seem to solve it. 

PS. Will be gone for the week, please allow for a bit of time for me to respond to queries.

<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce
<!--
Example:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->
(https://github.com/RaRe-Technologies/gensim/files/2660747/be5c63b4eb44f9d24906fb68a2608a6a-52d47e58268f41e8ef822208610be2192f91d065.zip)


Simplified sample of code as above.

#### Expected Results
<!-- Example: Expected shape of (100,2).-->
Value of coherence.

#### Actual Results
<!-- Example: Actual shape of (100,5). 
Please paste or specifically describe the actual output or traceback. -->
`RuntimeError:
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The ""freeze_support()"" line can be omitted if the program
        is not going to be frozen to produce an executable.`


#### Versions
<!--
Please run the following snippet and paste the output below.
-->
Windows-10-10.0.17134-SP0
Python 3.7.1 (v3.7.1:260ec2c36a, Oct 20 2018, 14:57:15) [MSC v.1915 64 bit (AMD64)]
NumPy 1.15.4
SciPy 1.1.0
C:\Users\kokho\AppData\Local\Programs\Python\Python37\lib\site-packages\gensim\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial
  warnings.warn(""detected Windows; aliasing chunkize to chunkize_serial"")
gensim 3.6.0
FAST_VERSION 0

<!-- Thanks for contributing! -->

"
359,https://github.com/RaRe-Technologies/gensim/issues/2293,2293,[],closed,2018-12-12 00:04:23+00:00,,How to give weights to different words and also how to add global context while training ,"I have to give importance to a few words while training. In skipgram model, I use the central word to predict the neighbouring words. I also want to predict the global context like a theme word in every single window size. 

Is there a way to do it  ?"
360,https://github.com/RaRe-Technologies/gensim/issues/2294,2294,[],closed,2018-12-14 02:19:26+00:00,,using  skip-gram of word2vec,"Hello,
        I want to predict context words given a word using skip-gram algorithm.
        I check gensim doc about [word2vec ](https://radimrehurek.com/gensim/models/word2vec.html),  but I can't find the API about predicting context words.
        Does the API exist?

"
361,https://github.com/RaRe-Technologies/gensim/issues/2295,2295,[],closed,2018-12-14 08:17:47+00:00,,Deprecation Warning while performing topic modelling,"I trying to use LDA model in gensim. I am getting mentioned, I recently installed the gensim package.
```
/.local/lib/python3.5/site-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.from_iter(generator)) or the python sum builtin instead.
  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)
```
"
362,https://github.com/RaRe-Technologies/gensim/issues/2301,2301,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2018-12-18 16:10:52+00:00,,Found a broken link in Tutorials.md,"In tutorials.md, link to the __America's_ Next topic Model Slides_ is **broken.** This is the [link](https://speakerdeck.com/tmylk/americas-next-topic-model?slide=6).
It should be replaced by the correct one."
363,https://github.com/RaRe-Technologies/gensim/issues/2304,2304,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2018-12-20 07:17:06+00:00,,ValueError: too many values to unpack (expected 3),"Please help me to resolve the issue.



![image](https://user-images.githubusercontent.com/3966230/50269735-405bcc80-0455-11e9-8bc3-dd62c84dd5ee.png)
"
364,https://github.com/RaRe-Technologies/gensim/issues/2305,2305,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}, {'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",closed,2018-12-21 15:09:33+00:00,,Save gensim model in binary format .bin with ngrams,"I'm able to save the model in binary format without ngrams (.vec like object) so is not possible to query oov words, is there a way to save the model in binary format with ngrams and open it?
(if I try to load a bin model generated with facebook fastText gives me following expection: Supervised fastText models are not supported, even if the model got unsupervised training."
365,https://github.com/RaRe-Technologies/gensim/issues/2306,2306,[],closed,2018-12-23 06:21:50+00:00,,get_document_topics returns and empty list ,"I trained the lda model and want to get topic distribution for a new document. However, for some documents the get_document_topics function returns and empty list and I get this warning: 

/home/anaconda2/lib/python2.7/site-packages/gensim/models/ldamodel.py:676: RuntimeWarning: overflow encountered in divide
  gammad = self.alpha + expElogthetad * np.dot(cts / phinorm, expElogbetad.T)

This is the way I call the function:

>  topic_vector = [ x[1] for x in self.ldamodel.get_document_topics(new_doc_bow , minimum_probability= 0.0, per_word_topics=False)]

"
366,https://github.com/RaRe-Technologies/gensim/issues/2309,2309,[],closed,2018-12-25 12:42:58+00:00,,Can't import gensim in Windows,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description

<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

I have a problem importing gensim, I use Anaconda in Windows (separate virtualenv), find below the traceback and the dependencies versions.

#### Steps/Code/Corpus to Reproduce
<!--
Example:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->
`import gensim`

#### Actual Results
<!-- Example: Actual shape of (100,5). 

Please paste or specifically describe the actual output or traceback. -->

```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\hatem\Anaconda3\envs\crashsim\lib\site-packages\gensim\__init__.py"", line 5, in <module>
    from gensim import parsing, corpora, matutils, interfaces, models, similarities, summarization, utils  # noqa:F401
  File ""C:\Users\hatem\Anaconda3\envs\crashsim\lib\site-packages\gensim\models\__init__.py"", line 15, in <module>
    from .doc2vec import Doc2Vec  # noqa:F401
  File ""C:\Users\hatem\Anaconda3\envs\crashsim\lib\site-packages\gensim\models\doc2vec.py"", line 86, in <module>
    from gensim.models.doc2vec_inner import train_document_dbow, train_document_dm, train_document_dm_concat
  File ""__init__.pxd"", line 872, in init gensim.models.doc2vec_inner
ValueError: numpy.ufunc has the wrong size, try recompiling. Expected 192, got 216
```

#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->
Windows-10-10.0.15063-SP0
Python 3.7.1 
NumPy 1.15.4
SciPy 1.2.0
gensim 3.6.0
<!-- Thanks for contributing! -->

"
367,https://github.com/RaRe-Technologies/gensim/issues/2310,2310,[],closed,2018-12-25 23:00:33+00:00,,Document pretrained word embeddings,"#### Description
Documentation doesn't seem to contain information on pretrained models - I can't find any information on them other than getting keys from 

`gensim.downloader.models.keys()`

Is there a reason to not contain this information in documentation?

If there is no such reason, then wouldn't it be beneficial to document these models?

I'd be happy to help with adding this information. But where should we put it?  I think [downloader documentation](**url**) would be the correct place."
368,https://github.com/RaRe-Technologies/gensim/issues/2311,2311,[],closed,2018-12-27 13:21:45+00:00,,Get text embeddings using LDA ,"Im pretty new to NLP and I've ran an LDA model using bag of words embeddings and it gives me an output of the topics and the important words related to those topics. I wanted to know if there is a way to get the document embeddings out of the LDA model to further use them elsewhere. Say for finding out similar documents. 
Any help would be much appreciated. Thanks"
369,https://github.com/RaRe-Technologies/gensim/issues/2312,2312,"[{'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}, {'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",closed,2018-12-29 00:44:11+00:00,,Poor separation of concerns in fasttext design,"The architecture consists of several classes:

- FastTextKeyedVectors (embeddings)
- FastTextTrainables (neural network)
- FastText (the actual model)

The [separation of concerns](https://en.wikipedia.org/wiki/Separation_of_concerns) between the classes is poor. For example, the FastTextTrainables neural network knows far too much about the implementation details of FastTextKeyedVectors embeddings. Here is a concrete example (full code [here](https://github.com/RaRe-Technologies/gensim/blob/ce403d38373be6c3254417f5fac6c41a38fd5dd1/gensim/models/fasttext.py#L996)):

```python
            wv.vectors_vocab = empty((len(wv.vocab), wv.vector_size), dtype=REAL)
            self.vectors_vocab_lockf = ones((len(wv.vocab), wv.vector_size), dtype=REAL)

            wv.vectors_ngrams = empty((self.bucket, wv.vector_size), dtype=REAL)
            self.vectors_ngrams_lockf = ones((self.bucket, wv.vector_size), dtype=REAL)

            wv.hash2index = {}
            wv.buckets_word = {}
            ngram_indices = []
            for word, vocab in wv.vocab.items():
                buckets = []
                for ngram in _compute_ngrams(word, wv.min_n, wv.max_n):
                    ngram_hash = _ft_hash(ngram) % self.bucket
                    if ngram_hash not in wv.hash2index:
                        wv.hash2index[ngram_hash] = len(ngram_indices)
                        ngram_indices.append(ngram_hash)
                    buckets.append(wv.hash2index[ngram_hash])
                wv.buckets_word[vocab.index] = np.array(buckets, dtype=np.uint32)
            wv.num_ngram_vectors = len(ngram_indices)
```

The above code is part of the FastTextTrainables, but it's writing to attributes of FastTextKeyedVectors. It knows about what the attributes of FastTextKeyedVectors are, and how they are related.

Ideally, such code should be in the FastTextKeyedVectors class. In practice, this may not be as simple, because there may be code common to both classes there. Identifying such areas (concerns), splitting them, and separating the concerns would improve the fasttext design significantly."
370,https://github.com/RaRe-Technologies/gensim/issues/2315,2315,"[{'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",closed,2019-01-03 07:55:06+00:00,,Poor reproducibility of out-of-vocab word vectors after loading native model,"See this unit test for reproduction:

https://github.com/mpenkov/gensim/blob/0d30caeb8c6d165d63c050de4bf32a0eab241d48/gensim/test/test_fasttext.py#L891

The test passes only if the tolerance is very high (0.1). For lower tolerance values (e.g. 0.01 and below), the test fails."
371,https://github.com/RaRe-Technologies/gensim/issues/2316,2316,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2019-01-07 01:08:40+00:00,,No documentation for how tags assigned in Doc2Vec w/corpus_file,"Although the new `corpus_file` mode ostensibly works with `Doc2Vec`, there's no documentation about how per-document `tags` are set in that mode. Is it still possible to set string tags, or more than one tag per document? (Or are documents just given the single tag for their line number in the file?)

At the very least, the docs for the `corpus_file` parameter in the class documentation – https://radimrehurek.com/gensim/models/doc2vec.html#gensim.models.doc2vec.Doc2Vec – should mention how tags are assigned in this mode."
372,https://github.com/RaRe-Technologies/gensim/issues/2317,2317,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-01-07 08:01:11+00:00,,"LSI worker getting ""stuck""","#### Description

When building an LsiModel in distributed mode, one of the workers gets ""stuck"" while orthonormalizing the action matrix. This stalls the whole process of building the model, as the dispatcher hangs on ""reached the end of input; now waiting for all remaining jobs to finish"". 

#### Steps/Code/Corpus to Reproduce

```
lsi_model = LsiModel(
        id2word=bow,
        num_topics=300,
        chunksize=5000,
        distributed=True
    )
lsi_model.add_documents(corpus)
```

LSI dispatcher and workers are initialized in separate bash script. I have tried with the number of LSI workers set to 16 and 8.

Gensim version: 3.6.0
Pyro4 version: 4.63

#### Expected Results
Process should run to completion

#### Actual Results

Main script output:
```
[2019-01-06 04:04:09,862] [23465] [gensim.models.lsimodel] [INFO] {add_documents:462} updating model with new documents
[2019-01-06 04:04:09,862] [23465] [gensim.models.lsimodel] [INFO] {add_documents:485} initializing 8 workers
[2019-01-06 04:05:12,131] [23465] [gensim.models.lsimodel] [INFO] {add_documents:488} preparing a new chunk of documents
[2019-01-06 04:05:12,135] [23465] [gensim.models.lsimodel] [DEBUG] {add_documents:492} converting corpus to csc format
[2019-01-06 04:05:12,497] [23465] [gensim.models.lsimodel] [DEBUG] {add_documents:499} creating job #0
[2019-01-06 04:05:12,541] [23465] [gensim.models.lsimodel] [INFO] {add_documents:503} dispatched documents up to #5000
[2019-01-06 04:06:46,191] [23465] [gensim.models.lsimodel] [INFO] {add_documents:488} preparing a new chunk of documents
[2019-01-06 04:06:46,200] [23465] [gensim.models.lsimodel] [DEBUG] {add_documents:492} converting corpus to csc format
[2019-01-06 04:06:46,618] [23465] [gensim.models.lsimodel] [DEBUG] {add_documents:499} creating job #1
[2019-01-06 04:06:46,682] [23465] [gensim.models.lsimodel] [INFO] {add_documents:503} dispatched documents up to #10000
[2019-01-06 04:08:11,839] [23465] [gensim.models.lsimodel] [INFO] {add_documents:488} preparing a new chunk of documents
[2019-01-06 04:08:11,843] [23465] [gensim.models.lsimodel] [DEBUG] {add_documents:492} converting corpus to csc format
[2019-01-06 04:08:12,561] [23465] [gensim.models.lsimodel] [DEBUG] {add_documents:499} creating job #2
[2019-01-06 04:08:12,786] [23465] [gensim.models.lsimodel] [INFO] {add_documents:503} dispatched documents up to #15000
[2019-01-06 04:09:48,217] [23465] [gensim.models.lsimodel] [INFO] {add_documents:488} preparing a new chunk of documents
[2019-01-06 04:09:48,230] [23465] [gensim.models.lsimodel] [DEBUG] {add_documents:492} converting corpus to csc format
[2019-01-06 04:09:48,700] [23465] [gensim.models.lsimodel] [DEBUG] {add_documents:499} creating job #3
[2019-01-06 04:09:48,786] [23465] [gensim.models.lsimodel] [INFO] {add_documents:503} dispatched documents up to #20000
[2019-01-06 04:09:48,938] [23465] [gensim.models.lsimodel] [INFO] {add_documents:518} reached the end of input; now waiting for all remaining jobs to finish
```

Output of LSI worker that is stuck:
```
2019-01-06 04:04:09,867 - INFO - resetting worker #1
2019-01-06 04:06:46,705 - INFO - worker #1 received job #208
2019-01-06 04:06:46,705 - INFO - updating model with new documents
2019-01-06 04:06:46,705 - INFO - using 100 extra samples and 2 power iterations
2019-01-06 04:06:46,705 - INFO - 1st phase: constructing (500000, 400) action matrix
2019-01-06 04:06:48,402 - INFO - orthonormalizing (500000, 400) action matrix
```

CPU for that LSI worker has been ~100% for >24 hours.

#### Versions

Linux-4.10.0-38-generic-x86_64-with-Ubuntu-16.04-xenial
Python 3.5.2 (default, Nov 23 2017, 16:37:01) 
[GCC 5.4.0 20160609]
NumPy 1.15.2
SciPy 1.1.0
gensim 3.6.0
FAST_VERSION 1


<!-- Thanks for contributing! -->

"
373,https://github.com/RaRe-Technologies/gensim/issues/2324,2324,[],closed,2019-01-09 10:19:42+00:00,,similar doc tags from new documents,"There is `model.docvecs.most_similar('doctorwho')` to obtain similar docs. Is there any way to retrieve similar docs (doc tags) for a new document? Or is the `TODO: Accept vectors of out-of-training-set docs, as if from inference.` indicating that exactly this is not possible yet? Is there a way to do that manually?"
374,https://github.com/RaRe-Technologies/gensim/issues/2325,2325,[],closed,2019-01-10 06:07:46+00:00,,Unimportant 'Warning' in phrases.py,"Upon 1st use of `PhrasesTransformation.__getitem__()`, there's a UserWarning issued ""For a faster implementation, use the gensim.models.phrases.Phraser class"". See:

https://github.com/RaRe-Technologies/gensim/blob/7fca36f3eb0df70e5f823e2fb4852193b4ad7393/gensim/models/phrases.py#L655

It's kind of excessive/alarming to display a ""warning"" to deliver a low-severity usage recommendation - thus leading to user inquiries like this at SO: https://stackoverflow.com/questions/54112456/warnings-in-gensim-phrasestransformer

I suggest no ""warning"" here, as there's nothing wrong or especially concerning. Subtle efficiency tips should go elsewhere.

"
375,https://github.com/RaRe-Technologies/gensim/issues/2329,2329,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",closed,2019-01-11 11:36:35+00:00,,Roll back optimization that trims empty buckets,"Our implementation diverges from Facebook's because we trim buckets that have no ngrams assigned to them, saving memory and training time. We should roll back this optimization because it introduces divergent behavior and makes the code more complex.

See https://github.com/RaRe-Technologies/gensim/pull/2313#issue-241664476 and https://github.com/RaRe-Technologies/gensim/pull/2313#issuecomment-453492981 for more details"
376,https://github.com/RaRe-Technologies/gensim/issues/2330,2330,[],closed,2019-01-12 18:14:05+00:00,,Transfer Learning word2vec,"Hey there,

I am confused about the comment from here: https://datascience.stackexchange.com/questions/10695/how-to-initialize-a-new-word2vec-model-with-pre-trained-model-weights

Is it possible to use pretrained vectors like from fasttext to train new on custom data?

From the accepted answer it seems so?"
377,https://github.com/RaRe-Technologies/gensim/issues/2332,2332,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",closed,2019-01-14 08:13:17+00:00,,replace 'sum(time_slice) == num_topics' to 'sum(time_slice) == num_documents',"https://github.com/RaRe-Technologies/gensim/blob/355ecc68a6ccb07f38418e8c80784b70aac84442/gensim/models/ldaseqmodel.py#L75

As the comments said 'Number of documents in each time-slice', maybe the num_documents is the true meaning for sum(time_slice) ??"
378,https://github.com/RaRe-Technologies/gensim/issues/2333,2333,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",open,2019-01-15 00:16:39+00:00,,FastText segfaults during training of skipgram model,"Given a data file:

```$ cat bug/data-example.txt 
Path: cantaloupe.srv.cs.cmu.edu!magnesium.club.cc.cmu.edu!news.sei.cmu.edu!cis.ohio-state.edu!pacific.mps.ohio-state.edu!zaphod.mps.ohio-state.edu!sol.ctr.columbia.edu!destroyer!cs.ubc.ca!mala.bc.ca!oneb!jc
Newsgroups: sci.med
Subject: Broken rib
Message-ID: <D0ZB3B1w164w@oneb.almanac.bc.ca>
From: jc@oneb.almanac.bc.ca
Date: Tue, 20 Apr 93 17:52:00 PDT
Organization: The Old Frog's Almanac, Nanaimo, B.C.
Keywords: advice needed
Summary: long term problems?
Lines: 17

Hello,  I am not sure if this is the right conference to ask this
question, however, Here I go..  I am a commercial fisherman and I 
fell about 3 weeks ago down into the hold of the boat and broke or
cracked a rib and wrenched and bruised my back and left arm.
  My question,  I have been to a doctor and was told that it was 
best to do nothing and it would heal up with no long term effect, and 
indeed I am about 60 % better, however, the work I do is very 
hard and I am still not able to go back to work.  The thing that worries me
is the movement or ""clunking"" I feel and hear back there when I move
```

the following code segfaults:

```python
import codecs                                                                                                                                                                                                 
import logging                                                                                                                                                                                                
import os                                                                                                                                                                                                     
import os.path as P                                                                                                                                                                                           
                                                                                                                                                                                                              
from gensim.models import FastText

class SentenceIter:
    def __init__(self, filename):
        self.filename = filename

    def __iter__(self):
        curr_dir = P.dirname(P.abspath(__file__))
        with codecs.open(P.join(curr_dir, self.filename), ""r"", 'utf-8', errors='replace') as fin:
            for line in fin:
                words_bad = line[:-1].split("" "")  # Yielding this causes a segfault
                words_good = line.rstrip().split(' ')  # Yielding this is OK
                logging.debug('words_bad: %r', words_bad)
                logging.debug('words_good: %r', words_good)
                logging.debug('---')
                yield words_good


def main():
   logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)

   num_workers = os.cpu_count()
   model = FastText(
        SentenceIter(""data-example.txt""),  # This works when the iterator yields words_good
        sg=1,
        size=100,
        window=3,
        min_count=5,
        workers=num_workers,
        iter=5,
        negative=20,
    )


if __name__ == ""__main__"":
    main()
```

The result is the same for the develop branch and the 3.6.0 release.

Setting sg=0 in the constructor avoids the segfault, so the problem could be skipgram-related.

Running in gdb gives the following output:

```Thread 18 ""python"" received signal SIGSEGV, Segmentation fault.
[Switching to Thread 0x7fffe7eb5700 (LWP 11302)]
__pyx_f_6gensim_6models_14fasttext_inner_fasttext_fast_sentence_sg_neg (__pyx_v_negative=<optimized out>, __pyx_v_cum_table=0x11b5560, __pyx_v_cum_table_len=5, __pyx_v_syn0_vocab=<optimized out>, 
    __pyx_v_syn0_ngrams=0x17fbfd0, __pyx_v_syn1neg=0x17f7340, __pyx_v_size=<optimized out>, __pyx_v_word_index=4, __pyx_v_word2_index=0, __pyx_v_subwords_index=0x165ea80, __pyx_v_subwords_len=0, 
    __pyx_v_alpha=0.0200200006, __pyx_v_work=0x7fffb0001200, __pyx_v_l1=0x7fffb8001000, __pyx_v_next_random=223366870975522, __pyx_v_word_locks_vocab=0x17f8dc0, __pyx_v_word_locks_ngrams=0x17f95a0)
    at ./gensim/models/fasttext_inner.c:2333
2333        __pyx_v_g = ((__pyx_v_label - __pyx_v_f) * __pyx_v_alpha);
(gdb) p __pyx_v_g
$1 = -1.28037043e+32
(gdb) p __pyx_v_label
$2 = 1
(gdb) p __pyx_v_f
Cannot access memory at address 0x7ffdd5ddd7c0
(gdb) p __pyx_v_alpha
$3 = 0.0200200006
(gdb)
```"
379,https://github.com/RaRe-Technologies/gensim/issues/2336,2336,[],closed,2019-01-16 17:04:48+00:00,,Module not callable,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
TODO: change commented example
<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce
<!--
Example:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->

#### Expected Results
<!-- Example: Expected shape of (100,2).-->

#### Actual Results
<!-- Example: Actual shape of (100,5). 

Please paste or specifically describe the actual output or traceback. -->

#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->


<!-- Thanks for contributing! -->

"
380,https://github.com/RaRe-Technologies/gensim/issues/2337,2337,[],closed,2019-01-16 17:10:46+00:00,,module not callable,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
TODO: change commented example
<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce
<!--
Example:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->

#### Expected Results
<!-- Example: Expected shape of (100,2).-->

#### Actual Results
<!-- Example: Actual shape of (100,5). 

Please paste or specifically describe the actual output or traceback. -->

#### Versions
<!--

Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->


<!-- Thanks for contributing! -->

Linux-4.15.0-43-generic-x86_64-with-debian-buster-sid
Python 3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) 
[GCC 7.2.0]
NumPy 1.15.0
SciPy 1.1.0
gensim 3.4.0
FAST_VERSION 1
i use python 3.7 on linux 18.04LTS with the latest gensim version
but i am getting error while tying
dictionary.save(os.path(TEMP_FOLDER,""deerwester.dict""))
the error message is 
TypeError                                 Traceback (most recent call last)
<ipython-input-8-2ce297631a51> in <module>()
----> 1 dictionary.save(os.path(TEMP_FOLDER,""deerwester.dict""))

TypeError: 'module' object is not callable
"
381,https://github.com/RaRe-Technologies/gensim/issues/2338,2338,[],closed,2019-01-16 17:43:04+00:00,,Documentation issue: mistyped,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
TODO: change commented example
<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce
<!--
Example:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->

#### Expected Results
<!-- Example: Expected shape of (100,2).-->

#### Actual Results
<!-- Example: Actual shape of (100,5). 

Please paste or specifically describe the actual output or traceback. -->

#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->


<!-- Thanks for contributing! -->
Linux-4.15.0-43-generic-x86_64-with-debian-buster-sid
Python 3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) 
[GCC 7.2.0]
NumPy 1.15.0
SciPy 1.1.0
gensim 3.4.0
FAST_VERSION 1
in the notebook, http://localhost:8889/notebooks/docs/notebooks/Corpora_and_Vector_Spaces.ipynb
there is typo, in "".As the token_id is 0 for ""human"" and 2 for ""computer"", the new document “Human computer interaction” will be transformed to [(0, 1), (2, 1)]. The words ""computer"" and ""human"" exist in the dictionary and appear once. Thus, they become (0, 1), (2, 1) respectively in the sparse vector. ""

the id for""computer"" is 0. Hence,it should be transformed to [(0,1),(1,1)] .
"
382,https://github.com/RaRe-Technologies/gensim/issues/2341,2341,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",closed,2019-01-19 19:32:06+00:00,,fastText  fixes in 3.7 break compatibility with old models,"Recent fixes to Gensim's fastText implementation introduced in #2313 are great. Unfortunately, they also break compatibility with fastText models trained by older Gensim versions - if the models are stored as a KeyedVectors() object. One can load such a model, but as soon as you try to do anything useful (like `most_similar()`, etc), it fails, because the `compatible_hash` attribute is missing.
If this attribute is added manually after the loading, everything goes fine.

#### Steps/Code/Corpus to Reproduce
```
import gensim

model = gensim.models.KeyedVectors.load(ANY_KEYED_VECTORS_FASTTEXT_MODEL)
model.most_similar(positive=ANY_WORD)
```
#### Expected Results
The `compatible_hash` attribute is automatically assigned the False value on load, and the model works as before.

#### Actual Results
```
/usr/local/lib/python3.5/dist-packages/gensim/models/keyedvectors.py in word_vec(self, word, use_norm)
   2057 
   2058         """"""
-> 2059         hash_fn = _ft_hash if self.compatible_hash else _ft_hash_broken
   2060 
   2061         if word in self.vocab:

AttributeError: 'FastTextKeyedVectors' object has no attribute 'compatible_hash'

```

#### Versions
Linux-4.15.0-43-generic-x86_64-with-LinuxMint-18.3-sylvia
Python 3.5.2 (default, Nov 12 2018, 13:43:14) 
[GCC 5.4.0 20160609]
NumPy 1.14.5
SciPy 1.1.0
gensim 3.7.0
FAST_VERSION 1"
383,https://github.com/RaRe-Technologies/gensim/issues/2342,2342,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2019-01-20 02:17:11+00:00,,there is no log  when i use word2vec by corpus_file,"I use the corpus_file in word2vec for speed boosting, but there is no log on the terminal, so I don't know when it will be done.
gemsim: 3.7.0"
384,https://github.com/RaRe-Technologies/gensim/issues/2343,2343,[],closed,2019-01-20 11:18:53+00:00,,GSOC 19,"Hello, I am wondering if gensim is going to apply for GSOC ? I have a great interest in NLP and topic modelling and want to do project with gensim this year since your last years project have caught my attention.
Please guide me.
Regards
David 
"
385,https://github.com/RaRe-Technologies/gensim/issues/2348,2348,[],closed,2019-01-22 04:00:55+00:00,,Sign of lsi_vector,"Linux-4.15.0-43-generic-x86_64-with-debian-buster-sid
Python 3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) 
[GCC 7.2.0]
NumPy 1.15.0
SciPy 1.1.0
gensim 3.4.0
FAST_VERSION 1

The notebook is on Similarity_Queries

The original notebook-log of lsi 2nd dim:
2019-01-22 08:49:18,871 : INFO : topic #1(2.542): 0.623*""graph"" + 0.490*""trees"" + 0.451*""minors"" + 0.274*""survey"" + -0.167*""system"" + -0.141*""eps"" + -0.113*""human"" + 0.107*""response"" + 0.107*""time"" + -0.072*""interface""

My notebook-log of lsi 2nd dim:
2019-01-22 08:50:27,166 : INFO : topic #1(2.542): -0.623*""graph"" + -0.490*""trees"" + -0.451*""minors"" + -0.274*""survey"" + 0.167*""system"" + 0.141*""eps"" + 0.113*""human"" + -0.107*""response"" + -0.107*""time"" + 0.072*""interface""

that is why the vector is affected.
the original notebook-log of lsi vector is:
[(0, -0.4618210045327156), (1, -0.07002766527899992)]

while I get the complete opposite:
[(0, 0.46182100453271535), (1, 0.07002766527900031)]

I understand that because the 2nd dim of lsi_vec is complete opposite of my vec. But,it doesn't affect the cosine similarity sims,how?"
386,https://github.com/RaRe-Technologies/gensim/issues/2350,2350,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",closed,2019-01-24 13:00:42+00:00,,impossible to load into gensim the fastText model trained with pretrained_vectors,"#### Description
When using using fastText model, trained itself with the pretrained vectors,  impossible to load the model with gensim.models.FastText.load_fasttext_format

#### Steps/Code/Corpus to Reproduce
First we make glove into word2vec format with gensim.
Keep ""glove.6B.50d.txt"" in local
```py
from gensim.scripts.glove2word2vec import glove2word2vec
from gensim.models import KeyedVectors
_ = glove2word2vec(""glove.6B.50d.txt"", ""w2v_from_glove.6B.50d.txt"")
```

Then use any sample text TEXT_FOR_WE_FILENAME, e.g.,
https://raw.githubusercontent.com/bbejeck/hadoop-algorithms/master/src/shakespeare.txt
(keep ""shakespeare.txt"" in local)
and train with pretrained vectors from ""w2v_from_glove.6B.50d.txt"" on the text:
```py
TEXT_FOR_WE_FILENAME = shakespeare.txt
PRETRAINED_VECTOR_DIM = 50
PRETRAINED_FILE =  ""w2v_from_glove.6B.50d.txt""
import fastText
model_pre = fastText.train_unsupervised(TEXT_FOR_WE_FILENAME, model='skipgram', dim=PRETRAINED_VECTOR_DIM, pretrainedVectors=PRETRAINED_FILE)
model_pre.save_model(""fasttext_model.bin"")
```

Error comes when trying to load this new fasttext model into gensim (while it is possible to load it into
the original fastText
```py
import fastText
from gensim.models import FastText as ge_ft
FASTTEXT_MODEL_BIN = ""fasttext_model.bin""
#this works
ft_model = fastText.load_model(FASTTEXT_MODEL_BIN)
ft_model.get_word_vector(""additional"")

#this one does not: 
ge_model = ge_ft.load_fasttext_format(FASTTEXT_MODEL_BIN)

```
Output:
```
AssertionError: unexpected number of vectors
---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
<command-3269280551404242> in <module>()
      1 #gensim FastText (having  some different features)
----> 2 ge_model = ge_ft.load_fasttext_format(FASTTEXT_MODEL_BIN)

/databricks/python/lib/python3.5/site-packages/gensim/models/fasttext.py in load_fasttext_format(cls, model_file, encoding)
    778 
    779         """"""
--> 780         return _load_fasttext_format(model_file, encoding=encoding)
    781 
    782     def load_binary_data(self, encoding='utf8'):

/databricks/python/lib/python3.5/site-packages/gensim/models/fasttext.py in _load_fasttext_format(model_file, encoding)
   1005     model.num_original_vectors = m.vectors_ngrams.shape[0]
   1006 
-> 1007     model.wv.init_post_load(m.vectors_ngrams)
   1008     model.trainables.init_post_load(model, m.hidden_output)
   1009 

/databricks/python/lib/python3.5/site-packages/gensim/models/keyedvectors.py in init_post_load(self, vectors, match_gensim)
   2189         """"""
   2190         vocab_words = len(self.vocab)
-> 2191         assert vectors.shape[0] == vocab_words + self.bucket, 'unexpected number of vectors'
   2192         assert vectors.shape[1] == self.vector_size, 'unexpected vector dimensionality'
   2193 

AssertionError: unexpected number of vectors
```

#### Versions
Linux-4.15.0-1036-azure-x86_64-with-Ubuntu-16.04-xenial
Python 3.5.2 (default, Nov 23 2017, 16:37:01) 
[GCC 5.4.0 20160609]
NumPy 1.15.3
SciPy 0.18.1
gensim 3.7.0, FAST_VERSION 0
fasttext 0.8.22
"
387,https://github.com/RaRe-Technologies/gensim/issues/2351,2351,[],closed,2019-01-25 10:45:36+00:00,,cosine similarity is not giving 1 for two same input documents,"https://groups.google.com/forum/#!topic/gensim/YiMDDtLCI7o

Any similarity to a document by itself should be 1. It seems to me it is something wrong with cosine similarity in gensim, because I do not get 1.

def cossim(texts):
    dictionary = corpora.Dictionary(texts)
    corpus = [dictionary.doc2bow(text) for text in texts]
    tfidf = TfidfModel(corpus, dictionary, normalize=True)
    index = MatrixSimilarity(tfidf[corpus], num_features=len(dictionary))
    simmatrix = index[corpus]
    return simmatrix

Input text in the form of 2d list of words is [here](https://groups.google.com/group/gensim/attach/6bb39f0def72f/input_2d_text_list.txt?part=0.1&authuser=0). The cosine similarity scores for these five documents I'v got from above code are:

[[0.4484578  0.03050137 0.01659208 0.03342406 0.11152142]
 [0.01370624 0.31444198 0.1637049  0.14261982 0.05780634]
 [0.00734405 0.16124928 0.38912225 0.14186516 0.03908984]
 [0.01621059 0.15392897 0.1554464  0.34419927 0.06053988]
 [0.07290775 0.08409916 0.05773569 0.08160509 0.3643248 ]]


Numbers in diagonal should be all 1, but they are not."
388,https://github.com/RaRe-Technologies/gensim/issues/2352,2352,[],closed,2019-01-25 11:05:53+00:00,,veclen documentation,"Linux-4.15.0-43-generic-x86_64-with-debian-buster-sid
Python 3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) 
[GCC 7.2.0]
NumPy 1.15.0
SciPy 1.1.0
gensim 3.4.0
FAST_VERSION 1


def unitvec(vec, norm='l2', return_norm=False):
    """"""Scale a vector to unit length.

    Parameters
    ----------
    vec : {numpy.ndarray, scipy.sparse, list of (int, float)}
        Input vector in any format
    norm : {'l1', 'l2'}, optional
        Metric to normalize in.
    return_norm : bool, optional
        Return the length of vector `vec`, in addition to the normalized vector itself?

    Returns
    -------
    numpy.ndarray, scipy.sparse, list of (int, float)}
        Normalized vector in same format as `vec`.
    float
        Length of `vec` before normalization, if `return_norm` is set.

    Notes
    -----
    Zero-vector will be unchanged.

    """"""
    if norm not in ('l1', 'l2'):
        raise ValueError(""'%s' is not a supported norm. Currently supported norms are 'l1' and 'l2'."" % norm)

    if scipy.sparse.issparse(vec):
        vec = vec.tocsr()
        if norm == 'l1':
            veclen = np.sum(np.abs(vec.data))
        if norm == 'l2':
            veclen = np.sqrt(np.sum(vec.data ** 2))
        if veclen > 0.0:
            if np.issubdtype(vec.dtype, np.integer):
                vec = vec.astype(np.float)
            vec /= veclen
            if return_norm:
                return vec, veclen
            else:
                return vec
        else:
            if return_norm:
                return vec, 1.
            else:
                return vec

    if isinstance(vec, np.ndarray):
        if norm == 'l1':
            veclen = np.sum(np.abs(vec))
        if norm == 'l2':
            veclen = blas_nrm2(vec)
        if veclen > 0.0:
            if np.issubdtype(vec.dtype, np.integer):
                vec = vec.astype(np.float)
            if return_norm:
                return blas_scal(1.0 / veclen, vec).astype(vec.dtype), veclen
            else:
                return blas_scal(1.0 / veclen, vec).astype(vec.dtype)
        else:
            if return_norm:
                return vec, 1
            else:
                return vec

    try:
        first = next(iter(vec))  # is there at least one element?
    except StopIteration:
        return vec

    if isinstance(first, (tuple, list)) and len(first) == 2:  # gensim sparse format
        if norm == 'l1':
            length = float(sum(abs(val) for _, val in vec))
        if norm == 'l2':
            length = 1.0 * math.sqrt(sum(val ** 2 for _, val in vec))
        assert length > 0.0, ""sparse documents must not contain any explicit zero entries""
        if return_norm:
            return ret_normalized_vec(vec, length), length
        else:
            return ret_normalized_vec(vec, length)
    else:
        raise ValueError(""unknown input type"")


Here the veclen vector is unknown as not written in comments.What is veclen and what is its format?"
389,https://github.com/RaRe-Technologies/gensim/issues/2354,2354,[],closed,2019-01-25 13:41:20+00:00,,Feature Suggestion: Add new parameter that gives topic distribution among all the words,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
TODO: change commented example
<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce
<!--
Example:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->

#### Expected Results
<!-- Example: Expected shape of (100,2).-->

#### Actual Results
<!-- Example: Actual shape of (100,5). 

Please paste or specifically describe the actual output or traceback. -->

#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->


<!-- Thanks for contributing! -->
Complete topic vectors is important for clearer analysis.

"
390,https://github.com/RaRe-Technologies/gensim/issues/2355,2355,[],closed,2019-01-25 15:45:18+00:00,,Documentation: Unclear Explanation,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
TODO: change commented example
<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce
<!--
Example:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->

#### Expected Results
<!-- Example: Expected shape of (100,2).-->

#### Actual Results
<!-- Example: Actual shape of (100,5). 

Please paste or specifically describe the actual output or traceback. -->

#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->


<!-- Thanks for contributing! -->

https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ#q3-how-do-you-calculate-the-matrix-v-in-lsi-space 
Question 4.

"
391,https://github.com/RaRe-Technologies/gensim/issues/2362,2362,[],closed,2019-01-30 00:15:28+00:00,,WikiCorpus lumps many paragraphs into one,"<!--
If your issue is a usage or a general question, please submit it here instead:
- Mailing List: https://groups.google.com/forum/#!forum/gensim
For more information, see Recipes&FAQ: https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ
-->

<!-- Instructions For Filing a Bug: https://github.com/RaRe-Technologies/gensim/blob/develop/CONTRIBUTING.md -->

#### Description
TODO: change commented example
<!-- Example: Vocabulary size is not what I expected when training Word2Vec. -->

#### Steps/Code/Corpus to Reproduce
<!--
Example:
```
from gensim.models import word2vec

sentences = ['human', 'machine']
model = word2vec.Word2Vec(sentences)
print(model.syn0.shape) 
```
If the code is too long, feel free to put it in a public gist and link
it in the issue: https://gist.github.com
-->

#### Expected Results
<!-- Example: Expected shape of (100,2).-->

#### Actual Results
<!-- Example: Actual shape of (100,5). 

Please paste or specifically describe the actual output or traceback. -->

#### Versions
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->


<!-- Thanks for contributing! -->

"
392,https://github.com/RaRe-Technologies/gensim/issues/2368,2368,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",open,2019-02-01 00:54:43+00:00,,FastText.save() can't pickle _thread.lock,"#### Description
I can't save the Gensim model because I get an exception. The data is streamed in.

#### Steps/Code/Corpus to Reproduce
https://gist.github.com/RXminuS/aecaf4656bad55b0e3008987f322f34e

#### Expected Results
The model to be saved

#### Actual Results
Exception thrown

```
Traceback (most recent call last):
  File ""/usr/local/anaconda3/envs/donnanlp/lib/python3.7/site-packages/gensim/utils.py"", line 692, in save
    _pickle.dump(self, fname_or_handle, protocol=pickle_protocol)
TypeError: file must have a 'write' attribute

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""scripts/train_gensim.py"", line 263, in <module>
    file_friendly_logging=args.file_friendly_logging, force=args.force)
  File ""scripts/train_gensim.py"", line 179, in main
    start_alpha=0.025, end_alpha=0.0001)
  File ""/usr/local/anaconda3/envs/donnanlp/lib/python3.7/site-packages/gensim/models/fasttext.py"", line 710, in train
    queue_factor=queue_factor, report_delay=report_delay, callbacks=callbacks)
  File ""/usr/local/anaconda3/envs/donnanlp/lib/python3.7/site-packages/gensim/models/base_any2vec.py"", line 1081, in train
    **kwargs)
  File ""/usr/local/anaconda3/envs/donnanlp/lib/python3.7/site-packages/gensim/models/base_any2vec.py"", line 563, in train
    callback.on_epoch_end(self)
  File ""scripts/train_gensim.py"", line 108, in on_epoch_end
    f""_model.{self._global_step}.gensim""), separately=[])
  File ""/usr/local/anaconda3/envs/donnanlp/lib/python3.7/site-packages/gensim/models/fasttext.py"", line 813, in save
    super(FastText, self).save(*args, **kwargs)
  File ""/usr/local/anaconda3/envs/donnanlp/lib/python3.7/site-packages/gensim/models/base_any2vec.py"", line 621, in save
    super(BaseAny2VecModel, self).save(fname_or_handle, **kwargs)
  File ""/usr/local/anaconda3/envs/donnanlp/lib/python3.7/site-packages/gensim/utils.py"", line 695, in save
    self._smart_save(fname_or_handle, separately, sep_limit, ignore, pickle_protocol=pickle_protocol)
  File ""/usr/local/anaconda3/envs/donnanlp/lib/python3.7/site-packages/gensim/utils.py"", line 549, in _smart_save
    pickle(self, fname, protocol=pickle_protocol)
  File ""/usr/local/anaconda3/envs/donnanlp/lib/python3.7/site-packages/gensim/utils.py"", line 1364, in pickle
    _pickle.dump(obj, fout, protocol=protocol)
TypeError: can't pickle _thread.lock objects
```

#### Versions
```
Python 3.7.1 (default, Dec 14 2018, 13:28:58) 
[Clang 4.0.1 (tags/RELEASE_401/final)] :: Anaconda, Inc. on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import platform; print(platform.platform())
Darwin-18.2.0-x86_64-i386-64bit
>>> import sys; print(""Python"", sys.version)
Python 3.7.1 (default, Dec 14 2018, 13:28:58) 
[Clang 4.0.1 (tags/RELEASE_401/final)]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.15.4
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.2.0
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.7.0
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1
>>> 
```

"
393,https://github.com/RaRe-Technologies/gensim/issues/2369,2369,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-02-02 21:43:55+00:00,,Doesn't install the file _utils_any2vec.so,"This file is written to plist by ```--record {plist}```, but isn't actually installed:
```
===> Checking for items in pkg-plist which are not in STAGEDIR
Error: Missing: %%PYTHON_SITELIBDIR%%/gensim/models/_utils_any2vec.so
===> Error: Plist issues found. 
```

gensim-3.7.1"
394,https://github.com/RaRe-Technologies/gensim/issues/2372,2372,"[{'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",closed,2019-02-05 01:53:02+00:00,,Loading the English wikipedia model hangs indefinitely when low on RAM,"Initially reported [here](https://github.com/RaRe-Technologies/gensim/issues/2350#issuecomment-460293018) by @akutuzov.

<copypasta>

This is yet another regression after the [fastText code refactoring](https://github.com/RaRe-Technologies/gensim/pull/2313) in Gensim 3.7 (another one was fixed in #2341).
Indeed, Gensim 3.6 loads pre-trained fastText models without any trouble. Below are examples with the Wikipedia model from https://fasttext.cc/, but the same stuff happens with any models trained using native fastText.
```
import gensim
gensim.__version__
'3.6.0'
import logging
logging.basicConfig(format='%(asctime)s : %(levelname)s : (message)s', level=logging.INFO)
model = gensim.models.fasttext.FastText.load_fasttext_format('wiki_en')
2019-01-24 16:23:47,740 : INFO : loading 2519370 words for fastText model from wiki.en.bin
2019-01-24 16:29:54,820 : INFO : loading weights for 2519370 words for fastText model from wiki.en.bin
2019-01-24 16:37:43,068 : INFO : loaded (2519370, 300) weight matrix for fastText model from wiki.en.bin 
model
<gensim.models.fasttext.FastText at 0x7f8e98e2c320>
```
However, Gensim 3.7 is doing weird things here (retraining the model instead of loading it?):
```
import gensim
gensim.__version__
'3.7.0'
import logging
logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)
model = gensim.models.fasttext.FastText.load_fasttext_format('wiki.en')
2019-01-24 16:25:50,816 : INFO : loading 2519370 words for fastTextmodel from wiki.en.bin
2019-01-24 16:30:14,701 : INFO : resetting layer weights
2019-01-24 16:30:14,702 : INFO : Total number of ngrams is 0
2019-01-24 16:30:14,702 : INFO : Updating model with new vocabulary
2019-01-24 16:30:40,839 : INFO : New added 2519370 unique words (50% of original 5038740) and increased the count of 2519370 pre-existing words (50% of original 5038740)
2019-01-24 16:31:02,325 : INFO : deleting the raw counts dictionary of 2519370 items
2019-01-24 16:31:02,325 : INFO : sample=0.0001 downsamples 650 most-common words
2019-01-24 16:31:02,326 : INFO : downsampling leaves estimated 4076481917 word corpus (103.2% of prior 3949186974)
```
After it went like this for an hour, I killed the process.

Gensim 3.7.1 does the same, nothing changed. I'm sorry, but it seems that fastText refactoring in 3.7 was extremely badly tested, with so many things broken :-(

</copypasta>"
395,https://github.com/RaRe-Technologies/gensim/issues/2374,2374,[],closed,2019-02-06 10:35:42+00:00,,Support for async iterators as Corpus,"It would be interesting to support asynchronous iterators for usage as a Corpus in all the transforms. 
This is especially interesting in case the corpus is stored on a remote device/database.

More precisely, I mean enabling the usage of such a corpus:
```python
class AsyncCorpus:
    def __aiter__(self):
        return self

    async def __anext__(self):
        data = await self.fetch_data()
        if data:
            return data
        else:
            raise StopAsyncIteration

    async def fetch_data(self):
        ...
```

as:

```python
tfidf_model = gensim.models.TfidfModel(corpus)
```

or 

```python
tfidf_corpus = tfidf_model[corpus]
```

where corpus is an `AsyncCorpus`

A possibility would be to transform the asynchronous iterator into a synchronous one, as suggested [here](https://stackoverflow.com/a/52548704). "
396,https://github.com/RaRe-Technologies/gensim/issues/2375,2375,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}]",closed,2019-02-06 15:17:25+00:00,,Off-by-one counting error in TFIDF,"Building a TFIDF model outputs this in the log:

```
INFO - 2019-02-06 16:09:54,670 - resulting dictionary: Dictionary(10000 unique tokens: [u'writings', u'foul', u'prefix', u'woods', u'hanging']...)
INFO - 2019-02-06 16:10:01,718 - collecting document frequencies
INFO - 2019-02-06 16:10:01,718 - PROGRESS: processing document #0
INFO - 2019-02-06 16:10:02,162 - calculating IDF weights for 1701 documents and 9999 features (2220559 matrix non-zeros)
```

Note the ""9999 features"", despite the dictionary having 10000 features. (any dictionary and any number of features -- the actual values don't matter, it's always off-by-one).

This seems to be a bug introduced in [this refactoring](https://github.com/RaRe-Technologies/gensim/commit/af01bc702f7ad48ed9ecacb256d9f6f7da6d3bc4#diff-896942304f9417b1b8842823b19d7431R128).

Not sure if this is an isolated problem or what other places are affected by similar ""optimizations""."
397,https://github.com/RaRe-Technologies/gensim/issues/2377,2377,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",closed,2019-02-07 19:45:51+00:00,,FastText segfaults for some ngram ranges,"hey,

I feel something is bad with my text data. I used common crawl for text data and even without any preprocesing (to dismiss as error source) the fasttext model stops during training and just exists without any messages. That is only for some ngram ranges like:

```
model=FastText(sentences,min_n=4)
print(model)
```
In this case no modell summary is printed and the model was not built but there is no message at all.

Giving as paramater instead just `min_n=2, max_n=4` the model is built and works fine.

I used my text data and the sentence iterator like here

```
>>> from gensim.utils import tokenize
>>> import smart_open
>>>
>>>
>>> class MyIter(object):
...     def __iter__(self):
...         path = datapath('crime-and-punishment.txt')
...         with smart_open.smart_open(path, 'r', encoding='utf-8') as fin:
...             for line in fin:
...                 yield list(tokenize(line))

```

with above fasttext statement. 


Might this comes from bad encoding like `\xad`? How to find out what is bad in my data?"
398,https://github.com/RaRe-Technologies/gensim/issues/2378,2378,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",closed,2019-02-09 12:49:09+00:00,,loading fastText model trained with pretrained_vectors still fails (see: #2350),"## Description
Loading pretrained `fastext_model.bin` with `gensim.models.fasttext.FastText.load_fasttext_format('wiki-news-300d-1M-subword.bin')` fails with `AssertionError: unexpected number of vectors` despite fix for #2350.

## Steps/Code/Corpus to Reproduce
first install `develop` branch with: `pip install --upgrade git+git://github.com/RaRe-Technologies/gensim@develop`, then:
```python
#dependencies 
import requests, zipfile, io
from gensim.models.fasttext import FastText

#download model
ft_url = 'https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki-news-300d-1M-subword.bin.zip'
r = requests.get(ft_url)
z = zipfile.ZipFile(io.BytesIO(r.content))
z.extractall()

#attempt load
mod = FastText.load_fasttext_format('wiki-news-300d-1M-subword.bin')
```

#### Expected Results
Loaded model.

#### Actual Results
```
---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
<ipython-input-29-a054256d6f88> in <module>
      1 #load model
      2 from gensim.models.fasttext import FastText
----> 3 mod = FastText.load_fasttext_format('wiki-news-300d-1M-subword.bin')
      4 # from gensim.models import KeyedVectors
      5 # wv = KeyedVectors.load_word2vec_format('wiki-news-300d-1M-subword.vec')

/anaconda3/envs/tensor_env/lib/python3.7/site-packages/gensim/models/fasttext.py in load_fasttext_format(cls, model_file, encoding, full_model)
   1012 
   1013         """"""
-> 1014         return _load_fasttext_format(model_file, encoding=encoding, full_model=full_model)
   1015 
   1016     def load_binary_data(self, encoding='utf8'):

/anaconda3/envs/tensor_env/lib/python3.7/site-packages/gensim/models/fasttext.py in _load_fasttext_format(model_file, encoding, full_model)
   1270     #
   1271     # We explicitly set min_count=1 regardless of the model's parameters to
-> 1272     # ignore the trim rule when building the vocabulary.  We do this in order
   1273     # to support loading native models that were trained with pretrained vectors.
   1274     # Such models will contain vectors for _all_ encountered words, not only

/anaconda3/envs/tensor_env/lib/python3.7/site-packages/gensim/models/keyedvectors.py in init_post_load(self, vectors, match_gensim)
   2205         """"""
   2206         vocab_words = len(self.vocab)
-> 2207         assert vectors.shape[0] == vocab_words + self.bucket, 'unexpected number of vectors'
   2208         assert vectors.shape[1] == self.vector_size, 'unexpected vector dimensionality'
   2209 

AssertionError: unexpected number of vectors
```

## Versions
Darwin-18.2.0-x86_64-i386-64bit
Python 3.7.2 (default, Dec 29 2018, 00:00:04) 
[Clang 4.0.1 (tags/RELEASE_401/final)]
NumPy 1.16.1
SciPy 1.2.0
gensim 3.7.1
FAST_VERSION 1

#### thanks for your work! 

"
399,https://github.com/RaRe-Technologies/gensim/issues/2379,2379,[],closed,2019-02-11 06:27:01+00:00,,crashed when using LdaMulticore in sub-subprocess,"ENV:  Unbuntu 16.0.4
python version: 3.6.3

subProcess:
    Process ForkPoolWorker-1:1:
    Process ForkPoolWorker-1:2:
    Process ForkPoolWorker-1:4:
    Process ForkPoolWorker-1:3:

when call LdaMulticore using 4 workers in sub-subprocess, It crashed with:

Traceback:
**Traceback (most recent call last):
  File ""xxx/python3.6/multiprocessing/queues.py"", line 241, in _feed
    obj = _ForkingPickler.dumps(obj)
  File ""xxx/python3.6/multiprocessing/reduction.py"", line 51, in dumps
    cls(buf, protocol).dump(obj)
_pickle.PicklingError: Can't pickle <function __RandomState_ctor at 0x7f30e93e1f28>: it's not the same object as numpy.random.__RandomState_ctor**

When I look at the code of LdaMulticore, I feel the local variable  [job_queue, result_queue] cause this problem.

Did any One who have see the same problem.


"
400,https://github.com/RaRe-Technologies/gensim/issues/2380,2380,[],closed,2019-02-12 15:38:31+00:00,,an implementation bug in summarizer,"#### Steps/Code/Corpus to Reproduce
If debugging the following piece of code, and get ino the function [`_set_graph_edge_weights`](https://github.com/RaRe-Technologies/gensim/blob/70fa23378da277f60a4cd566375f09d389f08ddb/gensim/summarization/summarizer.py#L74).
`documents` is a variable using BoW representation, however, `_bm25_weights` expects a list of list of plain tokens. If `BoW` is used, `(1, 2)` and `(1, 3)` are treated as different words. Actually, they are the same words which just have different counts in different documents. 

```
from gensim.summarization.summarizer import summarize

text = '''Rice Pudding - Poem by Alan Alexander Milne
What is the matter with Mary Jane?
She's crying with all her might and main,
And she won't eat her dinner - rice pudding again -
What is the matter with Mary Jane?
What is the matter with Mary Jane?
I've promised her dolls and a daisy-chain,
And a book about animals - all in vain -
What is the matter with Mary Jane?
What is the matter with Mary Jane?
She's perfectly well, and she hasn't a pain;
But, look at her, now she's beginning again! -
What is the matter with Mary Jane?
What is the matter with Mary Jane?
I've promised her sweets and a ride in the train,
And I've begged her to stop for a bit and explain -
What is the matter with Mary Jane?
What is the matter with Mary Jane?
She's perfectly well and she hasn't a pain,
And it's lovely rice pudding for dinner again!
What is the matter with Mary Jane?'''

print(summarize(text))
```

#### Versions
3.7.1
<!--
Please run the following snippet and paste the output below.
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
-->


<!-- Thanks for contributing! -->

"
401,https://github.com/RaRe-Technologies/gensim/issues/2383,2383,[],closed,2019-02-14 16:54:10+00:00,,Different result everytime with Word2Vec,"Hi,
I am trying out Gensim Word2Vec with a very small and experimental data. It returns the ""most_similar"" values for my item i.e. ""breast cancer"" in this case. But every time I print, I get different values for the same item(s) which is evident on the picture I have attached.

What's the reason?

Prabhat


![gensim_erratic](https://user-images.githubusercontent.com/7250780/52802882-cdfb1780-30a6-11e9-83a5-bf9b4f793a8b.png)
"
402,https://github.com/RaRe-Technologies/gensim/issues/2384,2384,[],closed,2019-02-14 17:30:20+00:00,,Readme incorrectly states that HDP implementation is parallel,"The readme currently (on master) states:

> Efficient multicore implementations of popular algorithms, such as online Latent Semantic Analysis (LSA/LSI/SVD), Latent Dirichlet Allocation (LDA), Random Projections (RP), Hierarchical Dirichlet Process (HDP) or word2vec deep learning.

However, the HDP model is single core (and it looks like RP is as well, though I'm less familiar with the technique) and this is misleading.
"
403,https://github.com/RaRe-Technologies/gensim/issues/2385,2385,[],closed,2019-02-15 07:38:48+00:00,,Updating vocab words to lowercase,Is there any way to update the words in vocab to lowercase?
404,https://github.com/RaRe-Technologies/gensim/issues/2388,2388,[],closed,2019-02-17 16:28:30+00:00,,Using labeled fasttext data format for domain specific data,"Hi,

I have (multi) labeled my domain specific data as suggested by FastText. The samples are below:
----
__label__disorder __label__8197001 acrodermatitis
__label__procedure __label__390416006 serum flecainide level
__label__procedure __label__309626003 child referral - school psychologist
__label__finding __label__2663001 palpatory proteinuria
__label__disorder __label__210526006 degloving injury, axilla
__label__disorder __label__6347003 disruption of cesarean wound in the puerperium
__label__specimen __label__258518003 scrotal swab
__label__procedure __label__391570004 m2 mitochondrial antibody (enzyme immunoassay) level
----

Regards

Prabhat"
405,https://github.com/RaRe-Technologies/gensim/issues/2389,2389,[],open,2019-02-19 13:31:31+00:00,,HdpModel doesn't return all topic,"#### Problem description

HdpModel doesn't return all topic when calling show_topics(num_topics=-1). It was changed in c3d2299b74d30b54659ba3274b6f79253a33ff93. Perhaps it was intentional, then you should update the documentation.

#### Steps/code/corpus to reproduce
``` python
>>> from gensim.test.utils import common_corpus, common_dictionary
>>> from gensim.models import HdpModel
>>> hdp = HdpModel(common_corpus, common_dictionary)
>>> print(len(hdp.show_topics(num_topics=20, num_words=10)))
20
>>> print(len(hdp.show_topics(num_topics=-1, num_words=10)))
0

```

#### Versions
Linux-4.15.0-45-generic-x86_64-with-Ubuntu-18.04-bionic
Python 3.6.7 (default, Oct 22 2018, 11:32:17) 
[GCC 8.2.0]
NumPy 1.16.1
SciPy 1.2.1
gensim 3.7.0
FAST_VERSION 1
"
406,https://github.com/RaRe-Technologies/gensim/issues/2393,2393,[],closed,2019-02-25 16:12:59+00:00,,Exception when importing gensim,"I tried to load gensim in my code. Often it works fine. Today, I get the following exception:

```
Traceback (most recent call last):
  File ""/project/6008168/tamouze/just.py"", line 2, in <module>
    import gensim
  File ""/project/6008168/tamouze/Python_directory/ENV2.7_new/lib/python2.7/site-packages/gensim/__init__.py"", line 5, in <module>
    from gensim import parsing, corpora, matutils, interfaces, models, similarities, summarization, utils  # noqa:F401
  File ""/project/6008168/tamouze/Python_directory/ENV2.7_new/lib/python2.7/site-packages/gensim/parsing/__init__.py"", line 4, in <module>
    from .preprocessing import (remove_stopwords, strip_punctuation, strip_punctuation2,  # noqa:F401
  File ""/project/6008168/tamouze/Python_directory/ENV2.7_new/lib/python2.7/site-packages/gensim/parsing/preprocessing.py"", line 40, in <module>
    from gensim import utils
  File ""/project/6008168/tamouze/Python_directory/ENV2.7_new/lib/python2.7/site-packages/gensim/utils.py"", line 44, in <module>
    from smart_open import smart_open
  File ""/project/6008168/tamouze/Python_directory/ENV2.7_new/lib/python2.7/site-packages/smart_open/__init__.py"", line 1, in <module>
    from .smart_open_lib import *
  File ""/project/6008168/tamouze/Python_directory/ENV2.7_new/lib/python2.7/site-packages/smart_open/smart_open_lib.py"", line 29, in <module>
    import requests
  File ""/project/6008168/tamouze/Python_directory/ENV2.7_new/lib/python2.7/site-packages/requests/__init__.py"", line 97, in <module>
    from . import utils
  File ""/project/6008168/tamouze/Python_directory/ENV2.7_new/lib/python2.7/site-packages/requests/utils.py"", line 26, in <module>
    from ._internal_utils import to_native_string
ImportError: cannot import name to_native_string
```

my code : 
```
from __future__ import print_function
import gensim
from gensim.models.fasttext import FastText as FT_gensim
```
Can you please help in identified why i get this exception?
Im uisng gensim 3.4.0 and python 2.7.14"
407,https://github.com/RaRe-Technologies/gensim/issues/2394,2394,[],open,2019-02-25 20:31:02+00:00,,`Doc2Vec.save()` is saving a `vectors_docs_norm` property unnecessarily,"Per a [report on the project list](https://groups.google.com/d/msg/gensim/WwALx45eCoQ/Pesi4TeeBAAJ), saving a `Doc2Vec` model is generating a `.vectors_docs_norm.npy` file on disk. Previously & generally, the properties which cache the unit-normed vectors haven't been saved, because they are generated when needed. "
408,https://github.com/RaRe-Technologies/gensim/issues/2395,2395,[],closed,2019-02-26 14:46:35+00:00,,gensim 3.7.1 on databricks installed in Databrick Runtime version 4.2 (no workers) but not working,"gensim 3.7.1 on databricks installed in Databrick Runtime version 4.2 (no workers) but not working. The error is below:
```
%sh
lscpu
```
```
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                4
On-line CPU(s) list:   0-3
Thread(s) per core:    1
Core(s) per socket:    4
Socket(s):             1
NUMA node(s):          1
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 79
Model name:            Intel(R) Xeon(R) CPU E5-2673 v4 @ 2.30GHz
Stepping:              1
CPU MHz:               2294.685
BogoMIPS:              4589.37
Hypervisor vendor:     Microsoft
Virtualization type:   full
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              51200K
NUMA node0 CPU(s):     0-3
Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt
```


Python:

```import sys
sys.version_info
```
```
Out[25]: sys.version_info(major=3, minor=5, micro=2, releaselevel='final', serial=0)
```


Pip:
```
%sh 
/databricks/python3/bin/python3 -m pip freeze
```
```
alabaster==0.7.12
ansi2html==1.1.1
azure-common==1.1.18
azure-nspkg==3.0.2
azure-storage-blob==1.1.0
azure-storage-common==1.1.0
azure-storage-nspkg==3.1.0
Babel==2.6.0
backports.shutil-get-terminal-size==1.0.0
boto==2.42.0
boto3==1.4.1
botocore==1.4.70
brewer2mpl==1.4.1
bz2file==0.98
certifi==2016.2.28
cffi==1.7.0
chardet==2.3.0
colorama==0.3.7
configobj==5.0.6
cryptography==1.5
cycler==0.10.0
Cython==0.24.1
decorator==4.0.10
dill==0.2.9
docutils==0.14
EMD-signal==0.2.6
enum34==1.1.6
et-xmlfile==1.0.1
freetype-py==1.0.2
funcsigs==1.0.2
fusepy==2.0.4
gensim==3.7.1
ggplot==0.6.8
html5lib==0.999
idna==2.1
imagesize==1.1.0
ipaddress==1.0.16
ipython==2.2.0
ipython-genutils==0.1.0
jdcal==1.2
Jinja2==2.8
jmespath==0.9.0
llvmlite==0.13.0
lxml==3.6.4
MarkupSafe==0.23
matplotlib==1.5.3
mpld3==0.2
msgpack-python==0.4.7
multiprocess==0.70.7
ndg-httpsclient==0.3.3
numba==0.28.1
numpy==1.16.1
numpydoc==0.8.0
openpyxl==2.3.2
packaging==19.0
pandas==0.24.1
pathlib2==2.1.0
pathos==0.2.3
patsy==0.4.1
pexpect==4.0.1
pickleshare==0.7.4
Pillow==3.3.1
pkg-resources==0.0.0
ply==3.9
pox==0.2.5
ppft==1.6.4.9
prompt-toolkit==1.0.7
psycopg2==2.6.2
ptyprocess==0.5.1
py4j==0.10.3
pyarrow==0.8.0
pyasn1==0.1.9
pycparser==2.14
pycurl==7.43.0
Pygments==2.1.3
pygobject==3.20.0
pyOpenSSL==16.0.0
pyparsing==2.2.0
pypng==0.0.18
python-apt==1.1.0b1+ubuntu0.16.4.1
python-dateutil==2.5.3
python-geohash==0.8.5
pytz==2016.6.1
requests==2.11.1
s3transfer==0.1.9
scikit-learn==0.18.1
scipy==1.2.1
scour==0.32
seaborn==0.7.1
simplejson==3.8.2
singledispatch==3.4.0.3
six==1.10.0
smart-open==1.8.0
snowballstemmer==1.2.1
Sphinx==2.0.0b1
sphinxcontrib-applehelp==1.0.1
sphinxcontrib-devhelp==1.0.1
sphinxcontrib-htmlhelp==1.0.1
sphinxcontrib-jsmath==1.0.1
sphinxcontrib-qthelp==1.0.2
sphinxcontrib-serializinghtml==1.1.1
ssh-import-id==5.5
statsmodels==0.8.0
traitlets==4.3.0
unattended-upgrades==0.1
urllib3==1.19.1
virtualenv==15.0.1
wcwidth==0.1.7
```


Error:
```
%sh 
/databricks/python3/bin/python3 -m pip install gensim==3.7.1
```
```Collecting gensim==3.7.1
  Downloading https://files.pythonhosted.org/packages/74/51/4afe96105fe8884cad58535203ddf70b20b313119af257198f5ce13e0300/gensim-3.7.1-cp35-cp35m-manylinux1_x86_64.whl (24.2MB)
Requirement already satisfied: numpy>=1.11.3 in /[REDACTED]/python3/lib/python3.5/site-packages (from gensim==3.7.1) (1.16.1)
Requirement already satisfied: six>=1.5.0 in /usr/lib/python3/dist-packages (from gensim==3.7.1) (1.10.0)
Collecting smart-open>=1.7.0 (from gensim==3.7.1)
  Downloading https://files.pythonhosted.org/packages/ff/c8/de7dcf34d4b5f2ae94fe1055e0d6418fb97a63c9dc3428edd264704983a2/smart_open-1.8.0.tar.gz (40kB)
Requirement already satisfied: scipy>=0.18.1 in /[REDACTED]/python3/lib/python3.5/site-packages (from gensim==3.7.1) (1.2.1)
Requirement already satisfied: boto>=2.32 in /[REDACTED]/python3/lib/python3.5/site-packages (from smart-open>=1.7.0->gensim==3.7.1) (2.42.0)
Collecting bz2file (from smart-open>=1.7.0->gensim==3.7.1)
  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz
Requirement already satisfied: requests in /[REDACTED]/python3/lib/python3.5/site-packages (from smart-open>=1.7.0->gensim==3.7.1) (2.11.1)
Requirement already satisfied: boto3 in /[REDACTED]/python3/lib/python3.5/site-packages (from smart-open>=1.7.0->gensim==3.7.1) (1.4.1)
Requirement already satisfied: botocore<1.5.0,>=1.4.1 in /[REDACTED]/python3/lib/python3.5/site-packages (from boto3->smart-open>=1.7.0->gensim==3.7.1) (1.4.70)
Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /[REDACTED]/python3/lib/python3.5/site-packages (from boto3->smart-open>=1.7.0->gensim==3.7.1) (0.9.0)
Requirement already satisfied: s3transfer<0.2.0,>=0.1.0 in /[REDACTED]/python3/lib/python3.5/site-packages (from boto3->smart-open>=1.7.0->gensim==3.7.1) (0.1.9)
Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /[REDACTED]/python3/lib/python3.5/site-packages (from botocore<1.5.0,>=1.4.1->boto3->smart-open>=1.7.0->gensim==3.7.1) (2.5.3)
Requirement already satisfied: docutils>=0.10 in /[REDACTED]/python3/lib/python3.5/site-packages (from botocore<1.5.0,>=1.4.1->boto3->smart-open>=1.7.0->gensim==3.7.1) (0.14)
Building wheels for collected packages: smart-open, bz2file
  Building wheel for smart-open (setup.py): started
  Building wheel for smart-open (setup.py): finished with status 'done'
  Stored in directory: /root/.cache/pip/wheels/f7/a6/ff/9ab5842c14e50e95a06a4675b0b4a689c9cab6064dac2b01d0
  Building wheel for bz2file (setup.py): started
  Building wheel for bz2file (setup.py): finished with status 'done'
  Stored in directory: /root/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9
Successfully built smart-open bz2file
Installing collected packages: bz2file, smart-open, gensim
Successfully installed bz2file-0.98 gensim-3.7.1 smart-open-1.8.0
```

Error when importing:
```
import gensim
```

```
---------------------------------------------------------------------------
OSError                                   Traceback (most recent call last)
<command-1185133677875717> in <module>()
----> 1 import gensim

/[REDACTED]/python/lib/python3.5/site-packages/gensim/__init__.py in <module>()
      3 """"""
      4 
----> 5 from gensim import parsing, corpora, matutils, interfaces, models, similarities, summarization, utils  # noqa:F401
      6 import logging
      7 

/[REDACTED]/python/lib/python3.5/site-packages/gensim/corpora/__init__.py in <module>()
      4 
      5 # bring corpus classes directly into package namespace, to save some typing
----> 6 from .indexedcorpus import IndexedCorpus  # noqa:F401 must appear before the other classes
      7 
      8 from .mmcorpus import MmCorpus  # noqa:F401

/[REDACTED]/python/lib/python3.5/site-packages/gensim/corpora/indexedcorpus.py in <module>()
     13 import numpy
     14 
---> 15 from gensim import interfaces, utils
     16 
     17 logger = logging.getLogger(__name__)

/[REDACTED]/python/lib/python3.5/site-packages/gensim/interfaces.py in <module>()
     19 import logging
     20 
---> 21 from gensim import utils, matutils
     22 from six.moves import range
     23 

/[REDACTED]/python/lib/python3.5/site-packages/gensim/matutils.py in <module>()
     19 import numpy as np
     20 import scipy.sparse
---> 21 from scipy.stats import entropy
     22 import scipy.linalg
     23 from scipy.linalg.lapack import get_lapack_funcs

/[REDACTED]/python/lib/python3.5/site-packages/scipy/stats/__init__.py in <module>()
    365 from __future__ import division, print_function, absolute_import
    366 
--> 367 from .stats import *
    368 from .distributions import *
    369 from .morestats import *

/[REDACTED]/python/lib/python3.5/site-packages/scipy/stats/stats.py in <module>()
    170 from scipy._lib._version import NumpyVersion
    171 from scipy._lib._util import _lazywhere
--> 172 import scipy.special as special
    173 from . import distributions
    174 from . import mstats_basic

/[REDACTED]/python/lib/python3.5/site-packages/scipy/special/__init__.py in <module>()
    641 from ._ufuncs import *
    642 
--> 643 from .basic import *
    644 from ._logsumexp import logsumexp, softmax
    645 from . import specfun

/[REDACTED]/python/lib/python3.5/site-packages/scipy/special/basic.py in <module>()
     17                       poch, binom, hyp0f1)
     18 from . import specfun
---> 19 from . import orthogonal
     20 from ._comb import _comb_int
     21 

/[REDACTED]/python/lib/python3.5/site-packages/scipy/special/orthogonal.py in <module>()
     81 from numpy import (exp, inf, pi, sqrt, floor, sin, cos, around, int,
     82                    hstack, arccos, arange)
---> 83 from scipy import linalg
     84 from scipy.special import airy
     85 

/[REDACTED]/python/lib/python3.5/site-packages/scipy/linalg/__init__.py in <module>()
    210 __all__ = [s for s in dir() if not s.startswith('_')]
    211 
--> 212 from numpy.dual import register_func
    213 for k in ['norm', 'inv', 'svd', 'solve', 'det', 'eig', 'eigh', 'eigvals',
    214           'eigvalsh', 'lstsq', 'cholesky']:

/[REDACTED]/python/lib/python3.5/importlib/_bootstrap.py in _find_and_load(name, import_)

/[REDACTED]/python/lib/python3.5/importlib/_bootstrap.py in _find_and_load_unlocked(name, import_)

/[REDACTED]/python/lib/python3.5/importlib/_bootstrap.py in _find_spec(name, path, target)

/[REDACTED]/python/lib/python3.5/importlib/_bootstrap_external.py in find_spec(cls, fullname, path, target)

/[REDACTED]/python/lib/python3.5/importlib/_bootstrap_external.py in _get_spec(cls, fullname, path, target)

/[REDACTED]/python/lib/python3.5/importlib/_bootstrap_external.py in find_spec(self, fullname, target)

/[REDACTED]/python/lib/python3.5/importlib/_bootstrap_external.py in _fill_cache(self)

OSError: [Errno 116] Stale file handle: '/[REDACTED]/python/lib/python3.5/site-packages/numpy'
```

It is most certainly Databricks problem"
409,https://github.com/RaRe-Technologies/gensim/issues/2396,2396,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 1602279836, 'node_id': 'MDU6TGFiZWwxNjAyMjc5ODM2', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20MEDIUM', 'name': 'reach MEDIUM', 'color': 'ef7a1a', 'default': False, 'description': 'Affects a significant number of users'}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}]",open,2019-02-26 18:23:37+00:00,,Arrays not separated correctly during `save()`,"#### Problem description

When storing Gensim objects via `.save()`, arrays are not being stored separately correctly according to the `sep_limit` parameter.

This is because of a bug either [here](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/utils.py#L593), where the separation limit is compared against the array's number of (non-zero) elements, or in the documentatuion, which says `In bytes`.

Issue was discovered by @anotherbugmaster in https://github.com/RaRe-Technologies/gensim/pull/2371#issuecomment-467510439

This bug doesn't affect functionality, it's very minor. We'll just be storing fewer sparse arrays separately, once fixed.

#### Steps/code/corpus to reproduce

```python
import scipy.sparse
import numpy
import gensim

x = gensim.utils.SaveLoad()
x.sparse = scipy.sparse.csr_matrix(numpy.random.rand(100, 100))  # <= 10000 nnz
x.save('/tmp/x.pkl', sep_limit=10001)  # store separately arrays of >=10001 bytes
```

**Expected output**: ~120 KB of sparse arrays stored separately, because larger than `sep_limit=10001` bytes.

```
2019-02-26 19:19:17,590 : INFO : saving SaveLoad object under /tmp/x.pkl, separately None
2019-02-26 19:19:17,590 : INFO : storing scipy.sparse array 'sparse' under /tmp/x.pkl.sparse.npy
2019-02-26 19:19:17,592 : INFO : saved /tmp/x.pkl
```

**Actual output**: sparse attribute isn't stored separately:

```
2019-02-26 19:18:09,105 : INFO : saving SaveLoad object under /tmp/x.pkl, separately None
2019-02-26 19:18:09,106 : INFO : saved /tmp/x.pkl
```

#### Versions

Darwin-15.6.0-x86_64-i386-64bit
('Python', '2.7.10 (default, Oct 23 2015, 19:19:21) \n[GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.59.5)]')
('NumPy', '1.12.0')
('SciPy', '0.19.1')
('gensim', '3.7.1')
('FAST_VERSION', 0)
"
410,https://github.com/RaRe-Technologies/gensim/issues/2398,2398,[],closed,2019-02-28 09:27:46+00:00,,Similarity class does not use constant memory,"I am using the Similarity class to query a corpus (2.5M docs, features reduced to 300 using LSI). It gave me 77 shards, each ~57MB which looks ok, however when I query the index it loads everything (full 4GB) into memory, which is exactly what I wanted to avoid. The documentation states the Similarity class runs with constant memory, but that is not what happens. I used default values for chunk and shard sizes, which are 256 and 32768. The documentation states

> shardsize should be chosen so that a shardsize x chunksize matrix of floats fits comfortably into main memory.

That would be 32 MB. Why is it using 4 GB instead?

Tested on:
Windows-2012ServerR2-6.3.9600-SP0
Python 3.6.4, AMD64
NumPy 1.16.2
SciPy 1.2.1
gensim 3.7.1 (also didn't work before updating with neither 3.6.0 nor 3.4.0)

"
411,https://github.com/RaRe-Technologies/gensim/issues/2400,2400,[],closed,2019-03-04 10:39:12+00:00,,Similarity object gone after computer restart,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description
I'm trying to load a saved similarity object from disk.
Whenever I'm trying to load the object after I restarted the computer, the loaded object is failing to work.
I believe the problem is that maybe the tmp/ folder is cleaned when the computer restarts.

What are you trying to achieve? What is the expected result? What are you seeing instead?
I'm trying to use the Similarity index that was saved on the disk.

#### Steps/code/corpus to reproduce
I get the following traceback when calling:
index = similarities.Similarity.load(""path to .index file"") 
index.similarity_by_id(0) // Arbitrary check that the index is working as needed.

FileNotFoundError                         Traceback (most recent call last)
<ipython-input-302-400050246fc0> in <module>
----> 1 index.similarity_by_id(0)

~/.local/lib/python3.6/site-packages/gensim/similarities/docsim.py in similarity_by_id(self, docpos)
    622 
    623         """"""
--> 624         query = self.vector_by_id(docpos)
    625         norm, self.norm = self.norm, False
    626         result = self[query]

~/.local/lib/python3.6/site-packages/gensim/similarities/docsim.py in vector_by_id(self, docpos)
    593         if not self.shards or docpos < 0 or docpos >= pos:
    594             raise ValueError(""invalid document position: %s (must be 0 <= x < %s)"" % (docpos, len(self)))
--> 595         result = shard.get_document_id(docpos - pos + len(shard))
    596         return result
    597 

~/.local/lib/python3.6/site-packages/gensim/similarities/docsim.py in get_document_id(self, pos)
    186         """"""
    187         assert 0 <= pos < len(self), ""requested position out of range""
--> 188         return self.get_index().index[pos]
    189 
    190     def __getitem__(self, query):

~/.local/lib/python3.6/site-packages/gensim/similarities/docsim.py in get_index(self)
    162         if not hasattr(self, 'index'):
    163             logger.debug(""mmaping index from %s"", self.fullname())
--> 164             self.index = self.cls.load(self.fullname(), mmap='r')
    165         return self.index
    166 

~/.local/lib/python3.6/site-packages/gensim/utils.py in load(cls, fname, mmap)
    424         compress, subname = SaveLoad._adapt_by_suffix(fname)
    425 
--> 426         obj = unpickle(fname)
    427         obj._load_specials(fname, mmap, compress, subname)
    428         logger.info(""loaded %s"", fname)

~/.local/lib/python3.6/site-packages/gensim/utils.py in unpickle(fname)
   1379 
   1380     """"""
-> 1381     with smart_open(fname, 'rb') as f:
   1382         # Because of loading from S3 load can't be used (missing readline in smart_open)
   1383         if sys.version_info > (3, 0):

~/.local/lib/python3.6/site-packages/smart_open/smart_open_lib.py in smart_open(uri, mode, **kw)
    179         raise TypeError('mode should be a string')
    180 
--> 181     fobj = _shortcut_open(uri, mode, **kw)
    182     if fobj is not None:
    183         return fobj

~/.local/lib/python3.6/site-packages/smart_open/smart_open_lib.py in _shortcut_open(uri, mode, **kw)
    299     #
    300     if six.PY3:
--> 301         return open(parsed_uri.uri_path, mode, buffering=buffering, **open_kwargs)
    302     elif not open_kwargs:
    303         return open(parsed_uri.uri_path, mode, buffering=buffering)

FileNotFoundError: [Errno 2] No such file or directory: '.shrd.0'


Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform()) - Linux-4.15.0-45-generic-x86_64-with-Ubuntu-18.04-bionic
import sys; print(""Python"", sys.version) - Python 3.6.7 (default, Oct 22 2018, 11:32:17)  [GCC 8.2.0]
import numpy; print(""NumPy"", numpy.__version__) - NumPy 1.16.1
import scipy; print(""SciPy"", scipy.__version__) - SciPy 1.2.1
import gensim; print(""gensim"", gensim.__version__) - gensim 3.7.1
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION) - FAST_VERSION 1
```
"
412,https://github.com/RaRe-Technologies/gensim/issues/2401,2401,[],closed,2019-03-05 01:52:52+00:00,,how to use gensim at centos 6 ,"First of all, i want to transform word into vector via gensim, to calculate text similarity between two short paragraph. i can successfully install gensim package at centos6 system with python 3. However, to run my program, i have problem with ""import gensim"". Keep on getting notice of ""No module named _ssl"". Has anyone encounter this problem? Really need some help, thank you! 


```
"
413,https://github.com/RaRe-Technologies/gensim/issues/2402,2402,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}]",closed,2019-03-06 09:20:25+00:00,,AssertionError: unexpected number of vectors when loading Korean FB model,"Hi,

I downloaded pretrained word vector file (.bin) from facebook 
(https://fasttext.cc/docs/en/crawl-vectors.html)
However, when I tried to use this model it happens to make error.

    from gensim.models import FastText
    fasttext_model = FastText.load_fasttext_format('cc.ko.300.bin', encoding='utf8')

    UnicodeDecodeError: 'utf-8' codec can't decode byte 0xed in position 0: invalid continuation byte

But weird thing is that it operates well when I use old version bin file (https://fasttext.cc/docs/en/pretrained-vectors.html)

So I tried to find the solution and found that this problem had happend and solved.

The issue was made through facebook fasttext issue
(https://github.com/facebookresearch/fastText/issues/715)
And they fixed it by
(https://github.com/facebookresearch/fastText/commit/e13484bcb261cda51d33c4940ab5e207aba3ee79)

So, I think gensim load_fasttext_format function had this UnicodeDecodeError because of above problem.

Can you help me to find and solve this problem?

------------------------------------------


I tried changing
word = word_bytes.decode(encoding, errors='replace')
word = word_bytes.decode(encoding, errors='ignore')
in gensim\models\_fasttext_bin.py , line 177
But both made same error
    File ""C:\Users\User\PycharmProjects\ksenticnet\venv\lib\site-packages\gensim\models\keyedvectors.py"", line 2207, in init_post_load
    assert vectors.shape[0] == vocab_words + self.bucket, 'unexpected number of vectors'
AssertionError: unexpected number of vectors

#### Versions
Windows-10-10.0.17134-SP0
Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)]
NumPy 1.16.2
SciPy 1.2.1
gensim 3.7.1
FAST_VERSION 0

"
414,https://github.com/RaRe-Technologies/gensim/issues/2403,2403,[],open,2019-03-06 22:45:20+00:00,,`sklearn_api.D2VTransformer` input should match other sklearn text preprocessing,"Hi all,

Thanks for the great tool, I've been using gensim for years and I love it.

One thing that would be a huge convenience and take literally 2 seconds to implement would be extend `sklearn_api.D2VTransformer` to handle doc-inputs that are strings.

Currently, the module expects each doc to be a list of strings. I understand that users might want to chunk string for various purposes (clustering noun phrases), but this precludes a valuable use-case for this model. 

Consider the common supervised model-comparison:

```
p_1 = Pipeline([('cv', CountVectorizer()), ('clf', clf)]) 
p_2 = Pipeline([('tfidf', TfidfVectorizer()), ('clf', clf)]) 
p_3 = Pipeline([('d2v', D2VTransformer()), ('clf', clf)])

for p in [p_1, p_2, p_3]:
    ## compare accuracies...
```

Right now, this will fail, because `cv` and `tfidf` do `fit_transform` on a list of strings, while `d2v` does `fit_transform` on a list of lists of strings.

This would entail a very simple change to these lines of code:

https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/sklearn_api/d2vmodel.py#L198-L199

to first check if doc.split() correctly processes, otherwise wrapping in a list as is currently there.

I'm happy to make the change, but please let me know if there's a compelling reason to keep the current behavior.

Alex"
415,https://github.com/RaRe-Technologies/gensim/issues/2407,2407,"[{'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2019-03-07 09:08:43+00:00,,Filename overwrite in `FastText.load_fasttext_format`,"I download FB pretrained common-crawl model using https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz from https://fasttext.cc/docs/en/crawl-vectors.html page.
When I try to load it, I get an error

**Code:**
```python
from gensim.models import FastText

ft_cc = FastText.load_fasttext_format(""models/cc.en.300.bin.gz"", full_model=False)
```

**Stacktrace:**
```
---------------------------------------------------------------------------
FileNotFoundError                         Traceback (most recent call last)
<timed exec> in <module>

~/.local/lib/python3.6/site-packages/gensim/models/fasttext.py in load_fasttext_format(cls, model_file, encoding, full_model)
   1012 
   1013         """"""
-> 1014         return _load_fasttext_format(model_file, encoding=encoding, full_model=full_model)
   1015 
   1016     def load_binary_data(self, encoding='utf8'):

~/.local/lib/python3.6/site-packages/gensim/models/fasttext.py in _load_fasttext_format(model_file, encoding, full_model)
   1245     if not model_file.endswith('.bin'):
   1246         model_file += '.bin'
-> 1247     with smart_open(model_file, 'rb') as fin:
   1248         m = gensim.models._fasttext_bin.load(fin, encoding=encoding, full_model=full_model)
   1249 

~/.local/lib/python3.6/site-packages/smart_open/smart_open_lib.py in smart_open(uri, mode, **kw)
    179         raise TypeError('mode should be a string')
    180 
--> 181     fobj = _shortcut_open(uri, mode, **kw)
    182     if fobj is not None:
    183         return fobj

~/.local/lib/python3.6/site-packages/smart_open/smart_open_lib.py in _shortcut_open(uri, mode, **kw)
    299     #
    300     if six.PY3:
--> 301         return open(parsed_uri.uri_path, mode, buffering=buffering, **open_kwargs)
    302     elif not open_kwargs:
    303         return open(parsed_uri.uri_path, mode, buffering=buffering)

FileNotFoundError: [Errno 2] No such file or directory: 'models/cc.en.300.bin.gz.bin'
```

Problem in filename overwriting that happens
https://github.com/RaRe-Technologies/gensim/blob/cebc9dbeacddf7689c35aadb8854ae850d4561d2/gensim/models/fasttext.py#L1302-L1303

To avoid that, I should `gunzip` model file first (that's definitely not a thing that user expect).

**Versions:**
no matters, all python & gensim version affected, including last release."
416,https://github.com/RaRe-Technologies/gensim/issues/2409,2409,[],open,2019-03-09 15:53:16+00:00,,poincare_distance_heatmap error: no attribute 'poincare_dists',"#### Problem description

I am trying to use ``poincare_distance_heatmap`` . However, it encounters an ``AttributeError:  type object 'PoincareKeyedVectors' has no attribute 'poincare_dists'``

```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-493-db8d99e53005> in <module>()
----> 1 poincare_distance_heatmap((0, 0))

~/Applications/anaconda/lib/python3.5/site-packages/gensim/viz/poincare.py in poincare_distance_heatmap(origin_point, x_range, y_range, num_points)
    144 
    145     origin_point = np.array(origin_point)
--> 146     all_distances = PoincareKeyedVectors.poincare_dists(origin_point, all_points)
    147 
    148     distances = go.Scatter(

AttributeError: type object 'PoincareKeyedVectors' has no attribute 'poincare_dists'
```

#### Steps/code/corpus to reproduce
```python
from gensim.test.utils import datapath
from gensim.viz.poincare import poincare_distance_heatmap
from gensim.models.poincare import PoincareModel, PoincareRelations

relations = PoincareRelations(file_path=datapath('poincare_hypernyms_large.tsv'))
model = PoincareModel(train_data=relations)
model.train(epochs=50)

poincare_distance_heatmap((0, 0))
```

#### Versions

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```

```
Darwin-14.5.0-x86_64-i386-64bit
Python 3.5.4 |Anaconda custom (x86_64)| (default, Nov  8 2017, 18:11:28) 
[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]
NumPy 1.14.3
SciPy 1.1.0
gensim 3.7.1
FAST_VERSION 1
```
"
417,https://github.com/RaRe-Technologies/gensim/issues/2412,2412,[],closed,2019-03-13 05:22:04+00:00,,Regarding Google Season of Docs,"Hello all, 
I wanted to know that are you going to participate in the upcoming Google Season of docs?"
418,https://github.com/RaRe-Technologies/gensim/issues/2413,2413,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}]",open,2019-03-13 15:22:18+00:00,,Feature proposal: model trimming,"**Problem:** In production, gensim models typically used as ""text embedding tool"" for any kind of upstream models (for the target supervised task). In production, it's very important to use as less as possible resources (esp. RAM).  Unfortunately, huge gensim models consume too much of RAM even if we use it only for inference (no more training).

**Idea:** Decrease RAM usage, based on 2 simple things
- cutting out some information (attributes) from model that don't used for inference (i.e. we still can use inference, but no more training)
- ""downgrade"" matrices dtype, like `float64` -> `float32`.

**Implementation draft:**
I propose to add an function `trim_model` to `gensim.utils` (instead of adding some methods for models), this implementation can be easily extended to other models if needed and don't overcomplicate existing models (because this is fully separate)

This is just a first draft, comments are welcome
```python
import warnings

from gensim.models import TfidfModel, LdaModel, LsiModel
from gensim.models.lsimodel import Projection

import numpy as np


def trim_model(model, dtype=None):
    """"""Reduce amount of memory used by model.

    This function mutates passed `model`: delete/cast/null attributes,
    after this operation, you can't update your model, but model size is significantly less.
    
    model: {:class:`~gensim.models.tfidf.TfidfModel`, :class:`~gensim.models.ldamodel.LdaModel`, 
            :class:`~gensim.models.lsimodel.LsiModel`}
        Supported gensim model.
    dtype: np.dtype
        Datatype used for casting attributes, if None - don't cast attributes.

    """"""
    attr2remove = []  # delete this attributes from model
    attr2null = []  # null this attributes, i.e. model.X = None (required for save/load compatibility)
    attr2cast = []  # cast attributes to lower type

    if isinstance(model, TfidfModel):
        attr2remove.append(""id2word"")
        attr2cast.append(""idfs"")
        
    elif isinstance(model, LdaModel):
        if dtype:
            model.dtype = dtype

        attr2null.extend([""state"", ""id2word""])
        attr2cast.extend([""alpha"", ""eta"", ""expElogbeta""])
    
    elif isinstance(model, LsiModel):
        if dtype:
            model.dtype = dtype
        attr2remove.append(""id2word"")
        attr2cast.append(""projection"")
    else:
        raise RuntimeError(""model {} not supported yet"".format(model))
        
        
    for attr in attr2remove:
        if not hasattr(model, attr):
            warnings.warn(""Model {} have no attribute {} marked to delete"".format(model, attr))
            continue
        delattr(model, attr)
    
    for attr in attr2cast:
        if dtype is None:
            continue  # don't cast without explicit type passing

        if not hasattr(model, attr):
            warnings.warn(""Model {} have no attribute {} marked to cast"".format(model, attr))
            continue

        attr_mat = getattr(model, attr)

        if isinstance(attr_mat, dict):
            for k, v in attr_mat.items():
                attr_mat[k] = dtype(v)

        elif isinstance(attr_mat, np.ndarray):
            setattr(model, attr, attr_mat.astype(dtype))
            
        elif isinstance(attr_mat, Projection):  # special case for LSI internal attributes, internal means model.a.b
            setattr(attr_mat, ""u"", attr_mat.u.astype(dtype))
            setattr(attr_mat, ""s"", attr_mat.s.astype(dtype))
            setattr(model, attr, attr_mat)
            
    for attr in attr2null:
        if not hasattr(model, attr):
            warnings.warn(""Model {} have no attribute {} marked to nullify"".format(model, attr))
            continue
            
        setattr(model, attr, None)
```

**Benchmark:**
That's results I received on my production models (I measurement model size on disk for simplicity, measurements for RAM is comparable).
Original model dtype is `np.float64`, `dtype=None` mean that we don't cast data types (stay it as is).


| Model | Original size, MB| Trimmed (dtype=None), MB | Trimmed (dtype=np.float32), MB|
|-------|------------------|-----------------------------|----------------------------------|
| `TfidfModel` | 85.05 | 50.67, **x1.678**|  46.59,  **x1.825**|
| `LdaModel` | 6518.85 | 3242.96, **x2.010**| 1619.86, **x4.024**|
| `LsiModel` | 3258.23 | 3233.25, **x1.007**| 1616.63, **x2.015** |"
419,https://github.com/RaRe-Technologies/gensim/issues/2414,2414,[],closed,2019-03-13 15:28:59+00:00,,LdaMulticore not working so well with corpus in tf_idf form.,"First of all, I want to say that  I am not very good English. I hope that you guys can bear with me.

Like I said, I transformed my corpus to tf_idf form and used it with ldamulticore but it took much longer to process than with normal corpus. Can anyone help me with this issue ?"
420,https://github.com/RaRe-Technologies/gensim/issues/2415,2415,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",closed,2019-03-13 15:58:39+00:00,,Inference issue using FB pretrained model if word have no ngrams,"**Problem:** `FastText` in gensim and official version still produce different output on FB pretrained model (issue with oov word **without ngrams**).


**Prepare data:**
```bash
curl https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz --output cc.en.300.bin.gz
gunzip cc.en.300.bin.gz
```

**Code:**
```python
from gensim.models import FastText
from fastText import load_model
import numpy as np

fname = ""cc.en.300.bin""

fb_model = load_model(fname)
gensim_model = FastText.load_fasttext_format(fname)

word = ""`""  # you can't generate subwords from this word

assert len(fb_model.get_subwords(word)[0]) == 0  # really, no subwords

fb_vector = fb_model.get_word_vector(""`"")  # fb_vector exist, though no subwords and not in vocab
np.testing.assert_allclose(fb_vector, np.zeros(fb_vector.shape[0]))  # and fb vector is zero vector

gensim_vector = gensim_model[""`""]  # raise an exception
```
```python
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
<ipython-input-13-243ea594a1c4> in <module>
      8 np.testing.assert_allclose(fb_vector, np.zeros(fb_vector.shape[0]))
      9 
---> 10 gensim_vector = gensim_model[""`""]

~/.local/lib/python3.6/site-packages/gensim/utils.py in new_func1(*args, **kwargs)
   1445                     stacklevel=2
   1446                 )
-> 1447                 return func(*args, **kwargs)
   1448 
   1449             return new_func1

~/.local/lib/python3.6/site-packages/gensim/models/fasttext.py in __getitem__(self, words)
    926 
    927         """"""
--> 928         return self.wv.__getitem__(words)
    929 
    930     @deprecated(""Method will be removed in 4.0.0, use self.wv.__contains__() instead"")

~/.local/lib/python3.6/site-packages/gensim/models/keyedvectors.py in __getitem__(self, entities)
    345         if isinstance(entities, string_types):
    346             # allow calls like trained_model['office'], as a shorthand for trained_model[['office']]
--> 347             return self.get_vector(entities)
    348 
    349         return vstack([self.get_vector(entity) for entity in entities])

~/.local/lib/python3.6/site-packages/gensim/models/keyedvectors.py in get_vector(self, word)
    463 
    464     def get_vector(self, word):
--> 465         return self.word_vec(word)
    466 
    467     def words_closer_than(self, w1, w2):

~/.local/lib/python3.6/site-packages/gensim/models/keyedvectors.py in word_vec(self, word, use_norm)
   2096                 return word_vec / max(1, ngrams_found)
   2097             else:  # No ngrams of the word are present in self.ngrams
-> 2098                 raise KeyError('all ngrams for word %s absent from model' % word)
   2099 
   2100     def init_sims(self, replace=False):

KeyError: 'all ngrams for word ` absent from model'

```

Exception is correct, but behaviour is wrong (should return zero vector as FB implementation. instead of raising an exception).
BTW - when we load & use FB model - we shouldn't raise an exception at all.
"
421,https://github.com/RaRe-Technologies/gensim/issues/2416,2416,"[{'id': 175642, 'node_id': 'MDU6TGFiZWwxNzU2NDI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/wishlist', 'name': 'wishlist', 'color': 'd7e102', 'default': False, 'description': 'Feature request'}]",closed,2019-03-15 08:44:37+00:00,,gensim.downloader should accept custom directory for downloading embeddings,"#### Problem description

I am trying to use gensim.downloader for download embeddings. However, it is creating a directory in my home folder where there is not enough space. I would like to specify a custom folder so that the embeddings get downloaded there. 

#### Steps/code/corpus to reproduce

Fill up your C drive and use gensim.downloader to download one of the embeddings. 

#### Versions

Please provide the output of:

```python
import gensim.downloader as api
dataset = api.load(""text8"")
```
"
422,https://github.com/RaRe-Technologies/gensim/issues/2418,2418,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}, {'id': 1602334472, 'node_id': 'MDU6TGFiZWwxNjAyMzM0NDcy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20MEDIUM', 'name': 'impact MEDIUM', 'color': '7af49f', 'default': False, 'description': 'Big annoyance for affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",open,2019-03-15 11:51:25+00:00,,Zero probabilities in LDA model,"#### Problem description

A user reported ""empty"" topics (all probabilities zero), during LdaModel training:
https://groups.google.com/forum/#!topic/gensim/LuPD2VSouSQ

Apparently some of the recent optimizations in #1656 (and maybe elsewhere?) introduced numeric instabilities.

#### Steps/code/corpus to reproduce

Unknown. Probably related to large data size: large vocabulary in combination with large number of topics, leading to float32 under/overflows.

User reported that changing the `dtype` back to float64 helped and the ""empty topics"" problem went away.

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
"
423,https://github.com/RaRe-Technologies/gensim/issues/2422,2422,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-03-19 10:58:37+00:00,,gensim/word2vec: TypeError: 'int' object is not iterable,"#### Problem description

I'm trying to establish the embedding layr and the  weights which will be shown in the code bellow
 using my training input which is in the form of  a lists of tokenized questions plus the vocabulary ( i loaded my data using pandas) 
also i made sure to eliminate all integers from my data .

#### Steps/code/corpus to reproduce

```python  
embedding_weights = train_word2vec(
    X_train, vocab['w2idx'], 
    num_features=embedding_dim, 
    min_word_count=min_word_count, 
    context=context)
input_shape = (sequence_length,)
model_input = Input(shape=input_shape)
layer = Embedding(
    len(vocab['idx2w']),
    embedding_dim,
    input_length=sequence_length,
    name=""embedding""
)(model_input)
layer = Dropout(dropout_prob[0])(layer)`
```

and this is the error i keep on getting

```
  File ""<ipython-input-13-76e01a83efc1>"", line 3, in <module>
    min_word_count=min_word_count, context=context)
  File ""C:\Users\ACER\Pod_Dsgn_Chatbot\Wor2vec.py"", line 43, in train_word2vec
    for key, word in vocabulary_inv.items()}
  File ""C:\Users\ACER\Pod_Dsgn_Chatbot\Wor2vec.py"", line 43, in <dictcomp>
    for key, word in vocabulary_inv.items()}
  File ""C:\Users\ACER\Anaconda3\envs\py37\lib\site-packages\gensim\utils.py"", line 1398, in new_func1
    return func(*args, **kwargs)
  File ""C:\Users\ACER\Anaconda3\envs\py37\lib\site-packages\gensim\models\word2vec.py"", line 821, in __getitem__
    return self.wv.__getitem__(words)
  File ""C:\Users\ACER\Anaconda3\envs\py37\lib\site-packages\gensim\models\keyedvectors.py"", line 171, in __getitem__
    return vstack([self.get_vector(entity) for entity in entities])
TypeError: 'int' object is not iterable`
```

#### Versions

```python 3.6.8
 platform version: '1.0.8'
 sys version:'3.6.8 |Anaconda custom (64-bit)| (default, Feb 11 2019, 15:03:47) [MSC v.1915 64 bit (AMD64)]'
 numpy version: '1.15.4'
scipy version: '1.2.0'
 gensim version: '3.4.0'
FAST_VERSION 1
```
"
424,https://github.com/RaRe-Technologies/gensim/issues/2424,2424,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",closed,2019-03-20 05:57:24+00:00,,tutorials fail doctests,"If you run ""python -m doctest docs/src/tut1.rst"" you get a ton of output. Most of the problems are because of incorrect formatting, e.g.

```python
>>> x = [1,
>>>      2]
```

should really be:

```python
>>> x = [1,
...      2]
```

For whatever reason, it doesn't look like the tutorials were ever tested with doctest. There's no reason for it to be this way, so we should make them doctest-compatible in the future."
425,https://github.com/RaRe-Technologies/gensim/issues/2425,2425,[],closed,2019-03-20 16:07:58+00:00,,DOC@VEC Memory Error,"<!--
Haveing issues when running DOC2VEC model on my dataset

Version:

Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]
NumPy 1.14.3
SciPy 1.1.0
gensim 3.5.0
FAST_VERSION 1
```
---------------------------------------------------------------------------
`max_epochs = 100
vec_size = 20
alpha = 0.025
# -------------------------------------------------------------------------------------

documents = [TaggedDocument(queries, [int(upi_id)]) for upi_id, queries in dict_queries_union.items()]
model = Doc2Vec(size=vec_size, alpha=alpha, min_alpha=0.00025, min_count=1, dm=1)
model.build_vocab(documents)
`

`MemoryError`                               Traceback (most recent call last)
<ipython-input-82-56270494d133> in <module>()
----> 1 model.build_vocab(documents)

C:\Anaconda3\lib\site-packages\gensim\models\doc2vec.py in build_vocab(self, documents, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)
   1040         report_values['memory'] = self.estimate_memory(vocab_size=report_values['num_retained_words'])
   1041         self.trainables.prepare_weights(
-> 1042             self.hs, self.negative, self.wv, self.docvecs, update=update)
   1043 
   1044     def build_vocab_from_freq(self, word_freq, keep_raw_vocab=False, corpus_count=None, trim_rule=None, update=False):

C:\Anaconda3\lib\site-packages\gensim\models\doc2vec.py in prepare_weights(self, hs, negative, wv, docvecs, update)
   1290         # set initial input/projection and hidden weights
   1291         if not update:
-> 1292             self.reset_weights(hs, negative, wv, docvecs)
   1293         else:
   1294             self.update_weights(hs, negative, wv)

C:\Anaconda3\lib\site-packages\gensim\models\doc2vec.py in reset_weights(self, hs, negative, wv, docvecs, vocabulary)
   1296     def reset_weights(self, hs, negative, wv, docvecs, vocabulary=None):
   1297         super(Doc2VecTrainables, self).reset_weights(hs, negative, wv)
-> 1298         self.reset_doc_weights(docvecs)
   1299 
   1300     def reset_doc_weights(self, docvecs):

C:\Anaconda3\lib\site-packages\gensim\models\doc2vec.py in reset_doc_weights(self, docvecs)
   1309             self.vectors_docs_lockf.fill(1.0)
   1310         else:
-> 1311             docvecs.vectors_docs = empty((length, docvecs.vector_size), dtype=REAL)
   1312             self.vectors_docs_lockf = ones((length,), dtype=REAL)  # zeros suppress learning
   1313 

MemoryError:"
426,https://github.com/RaRe-Technologies/gensim/issues/2426,2426,[],closed,2019-03-22 05:22:58+00:00,,How to customize a model (beyond doc2vec)?,"#### Problem description

Hello guys,
I want to customize a model beyond doc2vec.

In doc2vec, the probality model for predicting a center word is p(word_center|doc_tag, word_context).

Based on it,  I want to build a model p(word_center|doc_tag,word_attribute,word_context). The word_attribute of word_center may be Place, Name, etc. so that we can add human knowledge on words. 

So how can I implement such a model in gensim?
"
427,https://github.com/RaRe-Technologies/gensim/issues/2427,2427,[],closed,2019-03-23 18:23:32+00:00,,Error after loading KeyedVectors and using similarity queries,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? 
I am training a Word2Vec model, then splitting the word vectors into two groups (original vocabulary, selected words from the vocabulary) and storing them in two KeyedVectors files. After that I load the two KeyedVectors files and try to query for similarity based on words and vectors. 

What is the expected result?
Before storing and loading I can query both KeyedVectors with ""most_similar"" and ""similar_by_vector"". After restoring, I expect to be able to query the vectors pools as before. 

 What are you seeing instead?
I am able to query the original word vectors set, but not the one I've generated by restricting the original vocabulary (even if I could do it before).

#### Steps/code/corpus to reproduce
1. To train the model
```
import pickle
from gensim.models.word2vec import PathLineSentences
from gensim.models import KeyedVectors
from gensim.models import Word2Vec
import copy

sentences = PathLineSentences('./wiki_00_processed.txt')
model = Word2Vec(
        sentences,
        size=150,
        window=10,
        min_count=1,
        workers=10)
model.train(sentences, total_examples=model.corpus_count, epochs=10)
```

2. To split the vocabulary
``` 
def restrict_w2v(w2v_original, restricted_word_set):
    new_vectors = []
    new_vocab = {}
    new_index2entity = []
    new_vectors_norm = []
    w2v = copy.deepcopy(w2v_original) 
    
    for i in range(len(w2v.vocab)):
        word = w2v.index2entity[i]
        vec = w2v.vectors[i]
        vocab = w2v.vocab[word]
        vec_norm = w2v.vectors_norm[i]
        if word in restricted_word_set:
            vocab.index = len(new_index2entity)
            new_index2entity.append(word)
            new_vocab[word] = vocab
            new_vectors.append(vec)
            new_vectors_norm.append(vec_norm)

    w2v.vocab = new_vocab
    w2v.vectors = new_vectors
    w2v.index2entity = new_index2entity
    w2v.index2word = new_index2entity
    w2v.vectors_norm = new_vectors_norm
    return w2v

with open(""wiki_entities_00.txt"", ""rb"") as fp:  
    all_entities = pickle.load(fp)

word_vectors_all = model.wv
kb_word_vectors = restrict_w2v(word_vectors_all, all_entities)
```

3. Query before and after loading
```
test_vec = word_vectors_all['canada]
kb_word_vectors.similar_by_vector(test_vec) # works
kb_word_vectors.save(""kb_vocab_vecs_entities.kv"")
kb_vectors_restored = KeyedVectors.load(""kb_vocab_vecs_entities.kv"", mmap='r')
kb_vectors_restored.similar_by_vector(test_vec) # does not work
```

```
Error:
TypeError                                 Traceback (most recent call last)
<ipython-input-145-9a2fbad26fa8> in <module>
----> 1 kb_vectors_test.similar_by_vector(jazz_vec)

~/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py in similar_by_vector(self, vector, topn, restrict_vocab)
    607 
    608         """"""
--> 609         return self.most_similar(positive=[vector], topn=topn, restrict_vocab=restrict_vocab)
    610 
    611     @deprecated(

~/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py in most_similar(self, positive, negative, topn, restrict_vocab, indexer)
    520             negative = []
    521 
--> 522         self.init_sims()
    523 
    524         if isinstance(positive, string_types) and not negative:

~/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py in init_sims(self, replace)
   1330         if getattr(self, 'vectors_norm', None) is None or replace:
   1331             logger.info(""precomputing L2-norms of word weight vectors"")
-> 1332             self.vectors_norm = _l2_norm(self.vectors, replace=replace)
   1333 
   1334     def relative_cosine_similarity(self, wa, wb, topn=10):

~/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py in _l2_norm(m, replace)
   2344 
   2345     """"""
-> 2346     dist = sqrt((m ** 2).sum(-1))[..., newaxis]
   2347     if replace:
   2348         m /= dist

TypeError: unsupported operand type(s) for ** or pow(): 'list' and 'int'
```
Data Sets:
[wiki_00_processed.txt](https://github.com/RaRe-Technologies/gensim/files/2999667/wiki_00_processed.txt)
[wiki_entities_00.txt](https://github.com/RaRe-Technologies/gensim/files/2999668/wiki_entities_00.txt)


#### Versions

Please provide the output of:

```python 3.7.1
import platform; print(platform.platform())
Linux-4.18.0-16-generic-x86_64-with-debian-buster-sid

import sys; print(""Python"", sys.version)
Python 3.7.1 (default, Dec 14 2018, 19:28:38) 
[GCC 7.3.0]

import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.16.2

import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.1.0

import gensim; print(""gensim"", gensim.__version__)
gensim 3.7.1

from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1

```
"
428,https://github.com/RaRe-Technologies/gensim/issues/2429,2429,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}, {'id': 1602257032, 'node_id': 'MDU6TGFiZWwxNjAyMjU3MDMy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20HIGH', 'name': 'impact HIGH', 'color': 'b60205', 'default': False, 'description': 'Show-stopper for affected users'}, {'id': 1602279836, 'node_id': 'MDU6TGFiZWwxNjAyMjc5ODM2', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20MEDIUM', 'name': 'reach MEDIUM', 'color': 'ef7a1a', 'default': False, 'description': 'Affects a significant number of users'}]",open,2019-04-02 00:10:18+00:00,,Cannot call most_similar on Doc2VecKeyedVectors,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I am trying to build my own Doc2VecKeyedVectors from a subset of vectors of my model, and then perform most_similar() on the result.

When calling most_similar(), I get the following error (see full trace in ""steps to reproduce section""):

AttributeError: 'list' object has no attribute 'shape'

I noticed that the new Doc2VecKeyedVectors object I created has an empty list value for its vector_docs attributes, which I believe should be a (non-empty) np.ndarray instead of a list.  

#### Steps/code/corpus to reproduce
Minimal reproduceable sample:

```python
full_model_keyedvecs = model.docvecs # a pretrained model of type gensim.models.doc2vec.Doc2Vec
relevant_ids = [...] # insert list of indices used to build TaggedDocuments
relevant_vectors = [full_model_keyedvecs.vectors_docs[i, :] for i in relevant_ids]
relevant_vectors = np.array(relevant_vectors)
keyed_vecs = gensim.models.keyedvectors.Doc2VecKeyedVectors(vector_size=300, mapfile_path=None)
keyed_vecs.add(entities=relevant_ids, weights=relevant_vectors, replace=False)

--> at this point, I have successfully added the subset of keyed vectors, as I know by examining the size of keyed_vecs.vectors.shape
assert keyed_vecs.vectors.shape[0] == len(relevant_ids)

in_training_doc_id = 222 # an id I know is in relevant_ids
```

--> the following line causes the error
```python
sims = keyed_vecs.most_similar(positive=[in_training_doc_id], topn=500)
```

Full stack trace:
```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-229-1c2b6021aae3> in <module>
---> 11 keyed_vecs.most_similar(positive=[630608])

~\AppData\Local\Continuum\miniconda3\envs\amlenv36\lib\site-packages\gensim\models\keyedvectors.py in most_similar(self, positive, negative, topn, clip_start, clip_end, indexer)
   1623             negative = []
   1624 
-> 1625         self.init_sims()
   1626         clip_end = clip_end or len(self.vectors_docs_norm)
   1627 

~\AppData\Local\Continuum\miniconda3\envs\amlenv36\lib\site-packages\gensim\models\keyedvectors.py in init_sims(self, replace)
   1584                         mode='w+', shape=self.vectors_docs.shape)
   1585                 else:
-> 1586                     self.vectors_docs_norm = empty(self.vectors_docs.shape, dtype=REAL)
   1587                 np_divide(
   1588                     self.vectors_docs, sqrt((self.vectors_docs ** 2).sum(-1))[..., newaxis], self.vectors_docs_norm)

AttributeError: 'list' object has no attribute 'shape'
```

---------------------------------------------------------------------------


#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
Python 3.6.7 |Anaconda custom (64-bit)| (default, Dec 10 2018, 20:35:02) [MSC v.1915 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import platform; print(platform.platform())
Windows-10-10.0.17763-SP0
>>> import sys; print(""Python"", sys.version)
Python 3.6.7 |Anaconda custom (64-bit)| (default, Dec 10 2018, 20:35:02) [MSC v.1915 64 bit (AMD64)]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.15.4
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.1.0
>>> import gensim; print(""gensim"", gensim.__version__)
[…]\AppData\Local\Continuum\miniconda3\envs\amlenv36\lib\site-packages\gensim\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial
  warnings.warn(""detected Windows; aliasing chunkize to chunkize_serial"")
gensim 3.5.0
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1
>>>
"
429,https://github.com/RaRe-Technologies/gensim/issues/2430,2430,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-04-02 00:31:27+00:00,,Error when import gensim,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description
Error when `import gensim`

What are you trying to achieve? What is the expected result? What are you seeing instead?
Just want to import gensim

#### Steps/code/corpus to reproduce
I just run the following code
```
import gensim
```
Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

```
Traceback (most recent call last):
  File ""Doc2Vec.py"", line 7, in <module>
    import gensim
  File ""/usr/local/lib/python3.6/dist-packages/gensim/__init__.py"", line 5, in <module>
    from gensim import parsing, corpora, matutils, interfaces, models, similarities, summarization, utils  # noqa:F401
  File ""/usr/local/lib/python3.6/dist-packages/gensim/parsing/__init__.py"", line 4, in <module>
    from .preprocessing import (remove_stopwords, strip_punctuation, strip_punctuation2,  # noqa:F401
  File ""/usr/local/lib/python3.6/dist-packages/gensim/parsing/preprocessing.py"", line 42, in <module>
    from gensim import utils
  File ""/usr/local/lib/python3.6/dist-packages/gensim/utils.py"", line 45, in <module>
    from smart_open import smart_open
  File ""/usr/local/lib/python3.6/dist-packages/smart_open/__init__.py"", line 1, in <module>
    from .smart_open_lib import *
  File ""/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py"", line 45, in <module>
    from boto.compat import BytesIO, urlsplit, six
  File ""/usr/lib/python3/dist-packages/boto/__init__.py"", line 1216, in <module>
    boto.plugin.load_plugins(config)
  File ""/usr/lib/python3/dist-packages/boto/plugin.py"", line 92, in load_plugins
    for file in glob.glob(os.path.join(directory, '*.py')):
  File ""/usr/lib/python3.6/posixpath.py"", line 80, in join
    a = os.fspath(a)
TypeError: expected str, bytes or os.PathLike object, not NoneType
```

#### Versions
Python 3.6.8

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```

```Python 3.6.8 (default, Dec 24 2018, 19:24:27)
[GCC 5.4.0 20160609] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import platform; print(platform.platform())
Linux-4.13.0-1012-gcp-x86_64-with-Ubuntu-16.04-xenial
>>> import sys; print(""Python"", sys.version)
Python 3.6.8 (default, Dec 24 2018, 19:24:27)
[GCC 5.4.0 20160609]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.16.2
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.2.1
>>> import gensim; print(""gensim"", gensim.__version__)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.6/dist-packages/gensim/__init__.py"", line 5, in <module>
    from gensim import parsing, corpora, matutils, interfaces, models, similarities, summarization, utils  # noqa:F401
  File ""/usr/local/lib/python3.6/dist-packages/gensim/parsing/__init__.py"", line 4, in <module>
    from .preprocessing import (remove_stopwords, strip_punctuation, strip_punctuation2,  # noqa:F401
  File ""/usr/local/lib/python3.6/dist-packages/gensim/parsing/preprocessing.py"", line 42, in <module>
    from gensim import utils
  File ""/usr/local/lib/python3.6/dist-packages/gensim/utils.py"", line 45, in <module>
    from smart_open import smart_open
  File ""/usr/local/lib/python3.6/dist-packages/smart_open/__init__.py"", line 1, in <module>
    from .smart_open_lib import *
  File ""/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py"", line 45, in <module>
    from boto.compat import BytesIO, urlsplit, six
  File ""/usr/lib/python3/dist-packages/boto/__init__.py"", line 1216, in <module>
    boto.plugin.load_plugins(config)
  File ""/usr/lib/python3/dist-packages/boto/plugin.py"", line 92, in load_plugins
    for file in glob.glob(os.path.join(directory, '*.py')):
  File ""/usr/lib/python3.6/posixpath.py"", line 80, in join
    a = os.fspath(a)
TypeError: expected str, bytes or os.PathLike object, not NoneType
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.6/dist-packages/gensim/__init__.py"", line 5, in <module>
    from gensim import parsing, corpora, matutils, interfaces, models, similarities, summarization, utils  # noqa:F401
  File ""/usr/local/lib/python3.6/dist-packages/gensim/parsing/__init__.py"", line 4, in <module>
    from .preprocessing import (remove_stopwords, strip_punctuation, strip_punctuation2,  # noqa:F401
  File ""/usr/local/lib/python3.6/dist-packages/gensim/parsing/preprocessing.py"", line 42, in <module>
    from gensim import utils
  File ""/usr/local/lib/python3.6/dist-packages/gensim/utils.py"", line 45, in <module>
    from smart_open import smart_open
  File ""/usr/local/lib/python3.6/dist-packages/smart_open/__init__.py"", line 1, in <module>
    from .smart_open_lib import *
  File ""/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py"", line 46, in <module>
    import boto.s3.key
  File ""/usr/lib/python3/dist-packages/boto/s3/key.py"", line 33, in <module>
    import boto.utils
  File ""/usr/lib/python3/dist-packages/boto/__init__.py"", line 1216, in <module>
    boto.plugin.load_plugins(config)
AttributeError: module 'boto' has no attribute 'plugin'```"
430,https://github.com/RaRe-Technologies/gensim/issues/2431,2431,[],open,2019-04-02 12:26:05+00:00,,parameter topN=False is not working in similar_by_vector.,"
#### Problem description
parameter topN=False is not working in similar_by_vector. I got empty list when set topN=False.

#### Steps/code/corpus to reproduce

```Python
       full_node2vec_model = Word2VecKeyedVectors.load(node2vec_path)
        vector=full_node2vec_model[""1""]
        result=full_node2vec_model.similar_by_vector(vector=vector,topn=10)
        print(result)

        result = full_node2vec_model.similar_by_vector(vector=vector, topn=False)
        print(result)
```
### Problem
code in similar_by_vector just call most_similar.
```
        return self.most_similar(positive=[vector], topn=topn, restrict_vocab=restrict_vocab)
```

most_similar returns [] when TopN=False
```
        if topn is not None and topn < 1:
            return []
```


#### Versions

```
Windows-10-10.0.17134-SP0
Python 3.6.7 |Anaconda, Inc.| (default, Oct 28 2018, 19:44:12) [MSC v.1915 64 bit (AMD64)]
NumPy 1.15.4
SciPy 1.1.0
gensim 3.7.1
FAST_VERSION 1
```
"
431,https://github.com/RaRe-Technologies/gensim/issues/2432,2432,"[{'id': 1584013467, 'node_id': 'MDU6TGFiZWwxNTg0MDEzNDY3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/conda', 'name': 'conda', 'color': 'c9ef58', 'default': False, 'description': ''}]",open,2019-04-03 19:25:16+00:00,,Deprecation warning in matutils,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

`matutils.corpus2dense` triggers the following deprecation warning 

```
 /opt/conda/lib/python3.6/site-packages/gensim/matutils.py:503: FutureWarning: arrays to stack must be passed as a ""sequence"" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
  result = np.column_stack(sparse2full(doc, num_terms) for doc in corpus)
```

#### Steps/code/corpus to reproduce

See [this Kaggle kernel](https://www.kaggle.com/petebleackley/the-grammar-of-truth-and-lies) for an example"
432,https://github.com/RaRe-Technologies/gensim/issues/2434,2434,[],closed,2019-04-04 12:13:11+00:00,,BM25 does not support generator as corpus,"``__init__`` method in BM25 class takes a ""list of list of str"" as corpus instead of a generator. More precisely, this is what it looks like right now:

```
def __init__(self, corpus):
        """"""
        Parameters
        ----------
        corpus : list of list of str
            Given corpus.
        """"""
        self.corpus_size = len(corpus)
        self.avgdl = 0
        self.doc_freqs = []
        self.idf = {}
        self.doc_len = []
        self._initialize(corpus)
```
As we know, considering a generator instead of a list would be great to handle large collections of documents that do not fit in memory."
433,https://github.com/RaRe-Technologies/gensim/issues/2435,2435,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-04-04 15:23:52+00:00,,AssertionError: expected to reach EOF when loading full FastText model,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I am trying to fine-tune a pretrained FastText using gensim. I use the weights from the official Facebook implementation. Partial loading works fine, but full model loading results in AssertionError.

#### Steps/code/corpus to reproduce

```python
import gensim
model = gensim.models.FastText.load_fasttext_format('cc.en.300.bin', full_model=True) 
```

results in
```
---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
<ipython-input-16-1896fcc1d1cb> in <module>
----> 1 model = gensim.models.FastText.load_fasttext_format('cc.en.300.bin', full_model=True)

~/.anaconda3/envs/qs3.6/lib/python3.6/site-packages/gensim/models/fasttext.py in load_fasttext_format(cls, model_file, encoding, full_model)
   1012 
   1013         """"""
-> 1014         return _load_fasttext_format(model_file, encoding=encoding, full_model=full_model)
   1015 
   1016     def load_binary_data(self, encoding='utf8'):

~/.anaconda3/envs/qs3.6/lib/python3.6/site-packages/gensim/models/fasttext.py in _load_fasttext_format(model_file, encoding, full_model)
   1246         model_file += '.bin'
   1247     with smart_open(model_file, 'rb') as fin:
-> 1248         m = gensim.models._fasttext_bin.load(fin, encoding=encoding, full_model=full_model)
   1249 
   1250     model = FastText(

~/.anaconda3/envs/qs3.6/lib/python3.6/site-packages/gensim/models/_fasttext_bin.py in load(fin, encoding, full_model)
    264     else:
    265         hidden_output = _load_matrix(fin, new_format=new_format)
--> 266         assert fin.read() == b'', 'expected to reach EOF'
    267 
    268     model.update(vectors_ngrams=vectors_ngrams, hidden_output=hidden_output)

AssertionError: expected to reach EOF
```

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
```
Linux-4.4.0-139-generic-x86_64-with-debian-stretch-sid
Python 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) 
[GCC 7.3.0]
NumPy 1.16.2
SciPy 1.2.1
gensim 3.7.1
FAST_VERSION 1
```"
434,https://github.com/RaRe-Technologies/gensim/issues/2436,2436,[],closed,2019-04-07 19:42:50+00:00,,Error: -1073741819 (0xC0000005) and computer restarted,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

This issue is about a bug that I found and I think it is important as it restarted my PC.
The problem appears when I use similarities.SparseMatrixSimilarity and the parameter num_features is smaller than the number of elements in the corpus dictionary. 
At the beggining, my computer restarted after I had executed my code and a blue screen appears showing a problem with rzpnk.sys (a driver) , I tried it twice and my computer also restarted. I decided to uninstall the program related to that driver so the driver was deleted, then I executed again the code and I obtained: 
**""Process finished with exit code -1073741819 (0xC0000005)""**
I've been reading on the Internet that this could be caused by an invalid memory access...
Finally I changed my code and assigned num_features the size of the corpus dictionary, so now it works. 

#### Steps/code/corpus to reproduce
```python
dct = Dictionary(documents)
corpus = [dct.doc2bow(line) for line in documents]
model = TfidfModel(corpus)
index = similarities.SparseMatrixSimilarity(model[corpus], num_features=12)
#In this case it returns exit code -1073741819 (0xC0000005)
#The correct code is: 
index = similarities.SparseMatrixSimilarity(model[corpus], num_features=len(dct ))
```
#### Versions

Windows-10-10.0.17134-SP0
Python 3.6.8 |Anaconda, Inc.| (default, Feb 21 2019, 18:30:04) [MSC v.1916 64 bit (AMD64)]
NumPy 1.16.2
SciPy 1.2.1
gensim 3.7.1
FAST_VERSION 0"
435,https://github.com/RaRe-Technologies/gensim/issues/2437,2437,[],closed,2019-04-08 08:58:46+00:00,,Is preprocessing required when training a word2vec model?,Should I pre process the data (including removal of stopwords) before training a word2vec model in gensim for better results?
436,https://github.com/RaRe-Technologies/gensim/issues/2438,2438,[],closed,2019-04-08 09:45:21+00:00,,lemmatize: StopIteration error in Python 3.7,"#### Problem description

Trying to run simple lemmatization as described in the documentation. Getting:
`
RuntimeError: generator raised StopIteration`

#### Steps/code/corpus to reproduce

```
from gensim.utils import lemmatize
lemmatize('Hello World! How is it going?! Nonexistentword, 21')
```

#### Versions

```python
Darwin-17.7.0-x86_64-i386-64bit
Python 3.7.2 (default, Dec 29 2018, 00:00:04) 
[Clang 4.0.1 (tags/RELEASE_401/final)]
NumPy 1.16.2
SciPy 1.2.1
gensim 3.7.1
FAST_VERSION 1
```
"
437,https://github.com/RaRe-Technologies/gensim/issues/2439,2439,[],closed,2019-04-08 12:06:08+00:00,,eps = DTYPE_TO_EPS[self.dtype]，KeyError: dtype('float32'),"## Problem description

Hi，There. I was using gensim LDA to train a model in Linux,I has serialized the lda model to my computer.But when I load the model on windows 10, I got this error:
```
Traceback (most recent call last):
  File ""D:\Program Files\JetBrains\PyCharm 2018.1.2\helpers\pydev\pydevd.py"", line 1664, in <module>
    main()
  File ""D:\Program Files\JetBrains\PyCharm 2018.1.2\helpers\pydev\pydevd.py"", line 1658, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File ""D:\Program Files\JetBrains\PyCharm 2018.1.2\helpers\pydev\pydevd.py"", line 1068, in run
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""D:\Program Files\JetBrains\PyCharm 2018.1.2\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""E:/PycharmProject/LdaProject/lda_predict.py"", line 18, in <module>
    lda_topic = model[doc_bow]
  File ""C:\Program Files\Anaconda3\lib\site-packages\gensim\models\ldamodel.py"", line 1187, in __getitem__
    return self.get_document_topics(bow, eps, self.minimum_phi_value, self.per_word_topics)
  File ""C:\Program Files\Anaconda3\lib\site-packages\gensim\models\ldamodel.py"", line 1024, in get_document_topics
    gamma, phis = self.inference([bow], collect_sstats=per_word_topics)
  File ""C:\Program Files\Anaconda3\lib\site-packages\gensim\models\ldamodel.py"", line 513, in inference
    eps = DTYPE_TO_EPS[self.dtype]
KeyError: dtype('float32')
```
However，when I debug to this function,my dtype is ""float32"" indeed.
Please help me.

## Steps/code/corpus to reproduce
### predict new data
```
model = models.LdaModel.load('E:/PycharmProject/ldadata/model/lda_model.pkl',mmap='r')
dictionary = corpora.Dictionary.load(""E:/PycharmProject/ldadata/model/id2word.dict"")

query = input(""input:"")
doc_bow = dictionary.doc2bow(jieba.cut(query,cut_all=False))
lda_topic = model[doc_bow]
for index, score in sorted(lda_topic, key=lambda tup: -1*tup[1]):
    print (""Score: {}\t Topic: {}"".format(score, lda_topic.print_topic(index, 20)))
```

## Versions

```
Linux version:  centos7
gensim version: 3.3.0
numpy version: 1.15.0
windows :win10
Python version: 3.5.2
```


"
438,https://github.com/RaRe-Technologies/gensim/issues/2440,2440,[],closed,2019-04-09 08:50:46+00:00,,Does gensim implement inverted index ?,"I have many documents , in order to improve performance , I want get the relevent subset documents before calculating cosine distance based on their vectors ( learned from other models ). I want to know whether gensim implements inverted index to help me get the relevent documents ？ "
439,https://github.com/RaRe-Technologies/gensim/issues/2441,2441,[],open,2019-04-10 00:16:57+00:00,,Loading KeyedVectors for large split model w/ missing files,"Hey there!

So, on one of our servers - after having run for quite a while - a W2V model that we attempted to save with model.save(...) did not manage to fit to persistent storage completely.
As such, we managed to get the modelxyz.**wv.vectors.npy** file and part of the syn0neg one.
Is there a way to still extract the KeyedVectors from the wv.vectors.npy file (as I assume that's the one containing the KeyedVectors-relevant data) or does the training have to go through again? The file is in the order of magnitude of 102GB if that is of any help.
I've been trying with KeyedVectors.load() (as well as with load_word2vec_format(path) w/ binary=True and binary=False - which didn't seem like it would make much sense considering we saved with model.save(path)) - unfortunately to no avail.
Suggestions welcome! I've been thinking of ways to trick the W2V model by giving it a default empty one and just ""linking"" the KeyedVectors to it as such.

Wishing a great night!

#### Steps/code/corpus to reproduce
Loading KeyedVectors for large split model w/ missing files.
-> KeyedVectors.load()

model_wv = KeyedVectors.load('modelxxyz.**wv.vectors.npy**')
Leads to: `_pickle.UnpicklingError: STACK_GLOBAL requires str`"
440,https://github.com/RaRe-Technologies/gensim/issues/2442,2442,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-04-11 01:26:21+00:00,,Import nltk before gensim cause model.similarity() to fail,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description


#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
"
441,https://github.com/RaRe-Technologies/gensim/issues/2443,2443,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",open,2019-04-11 13:55:45+00:00,,Exploding Perplexity for big number of topics,"I am training LDA on a set of ~17500 Documents. Until 230 Topics, it works perfectly fine, but for everything above that, the perplexity score explodes.

(Perplexity was calucated by taking 2 ** (-1.0 * lda_model.log_perplexity(corpus))
 which results in 234599399490.052. Usually my perplexity is around 70-150.)

For the perplexity, I am not using a hold out set. It is calculated on the same corpus that was used for training. I can upload the lda model + corpus in the next few minutes."
442,https://github.com/RaRe-Technologies/gensim/issues/2444,2444,[],closed,2019-04-11 14:42:42+00:00,,Problem while passing wlocal function in tfidf model ,"#### Problem description
I tried to use math.sqrt function on term frequency when computing TF-IDF model as you declare in script documentation:

```
wlocals : function, optional
            Function for local weighting, default for `wlocal` is :func:`~gensim.utils.identity`
            (other options: :func:`math.sqrt`, :func:`math.log1p`, etc).
```
========================================
Gensim implementation:

```python
tf_array = self.wlocal(np.array(tf_array))
vector = [
   (termid, tf * self.idfs.get(termid))
   for termid, tf in zip(termid_array, tf_array) if abs(self.idfs.get(termid, 0.0)) > self.eps
]
```

Error:

```
  File ""/home/xmedved1/.local/lib/python3.6/site-packages/gensim/models/tfidfmodel.py"", line 432, in __getitem__
    tf_array = self.wlocal(np.array(tf_array))
TypeError: only size-1 arrays can be converted to Python scalars
```
======================================

Fix if I want to use  math.sqrt:

```python
tf_array = np.array(tf_array)
vector = [
    (termid, self.wlocal(tf) * self.idfs.get(termid))
    for termid, tf in zip(termid_array, tf_array) if abs(self.idfs.get(termid, 0.0)) > self.eps
]
```

==========================================
gensim version 3.7.2

==========================================
I don't know if this is a problem to fix, because in Gensim implementation I can do some normalization that includes all items in list (something like tf = n_i_j / sum(n_k_j) where i,k is token and i!=k and j is the document  –> this is not allowed in my fix). So I thing the problem is the documentation of wlocal parameter.

Best regards M
"
443,https://github.com/RaRe-Technologies/gensim/issues/2445,2445,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-04-14 03:33:30+00:00,,AttributeError: 'Word2Vec' object has no attribute 'sorted_vocab',"![image](https://user-images.githubusercontent.com/3667080/56087962-e4f09700-5ea8-11e9-9c79-3191e846a40e.png)

```python
model = Word2Vec.load(full_bin_name)
  File ""/Users/dreampie/miniconda/envs/python2/lib/python2.7/site-packages/gensim/models/word2vec.py"", line 979, in load
    return load_old_word2vec(*args, **kwargs)
  File ""/Users/dreampie/miniconda/envs/python2/lib/python2.7/site-packages/gensim/models/deprecated/word2vec.py"", line 171, in load_old_word2vec
    'sorted_vocab': old_model.sorted_vocab,
AttributeError: 'Word2Vec' object has no attribute 'sorted_vocab'
```

![image](https://user-images.githubusercontent.com/3667080/56087972-1a958000-5ea9-11e9-8580-5ffb4cc687c4.png)
"
444,https://github.com/RaRe-Technologies/gensim/issues/2446,2446,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",open,2019-04-15 01:37:24+00:00,,word2vec.ipynb broken,"```python
['/home/misha/git/gensim/docs/notebooks/../../gensim/test/test_data/lee_background.cor', '/home/misha/git/gensim/docs/notebooks/text8_50000000']

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
~/git/gensim/gensim/models/word2vec.py in __iter__(self)
   1430             # Things that don't have seek will trigger an exception
-> 1431             self.source.seek(0)
   1432             for line in itertools.islice(self.source, self.limit):

AttributeError: 'str' object has no attribute 'seek'

During handling of the above exception, another exception occurred:

FileNotFoundError                         Traceback (most recent call last)
<ipython-input-28-920db5b19105> in <module>
     20                 for i in range(3):
     21                     start_time = time.time()
---> 22                     w2v_model = gensim.models.Word2Vec(data, compute_loss=loss_flag, sg=sg_val, hs=hs_val, seed=seed_val)
     23                     time_taken_list.append(time.time() - start_time)
     24 

~/git/gensim/gensim/models/word2vec.py in __init__(self, sentences, corpus_file, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, max_final_vocab)
    781             callbacks=callbacks, batch_words=batch_words, trim_rule=trim_rule, sg=sg, alpha=alpha, window=window,
    782             seed=seed, hs=hs, negative=negative, cbow_mean=cbow_mean, min_alpha=min_alpha, compute_loss=compute_loss,
--> 783             fast_version=FAST_VERSION)
    784 
    785     def _do_train_epoch(self, corpus_file, thread_id, offset, cython_vocab, thread_private_mem, cur_epoch,

~/git/gensim/gensim/models/base_any2vec.py in __init__(self, sentences, corpus_file, workers, vector_size, epochs, callbacks, batch_words, trim_rule, sg, alpha, window, seed, hs, negative, ns_exponent, cbow_mean, min_alpha, compute_loss, fast_version, **kwargs)
    757                 raise TypeError(""You can't pass a generator as the sentences argument. Try a sequence."")
    758 
--> 759             self.build_vocab(sentences=sentences, corpus_file=corpus_file, trim_rule=trim_rule)
    760             self.train(
    761                 sentences=sentences, corpus_file=corpus_file, total_examples=self.corpus_count,

~/git/gensim/gensim/models/base_any2vec.py in build_vocab(self, sentences, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)
    934         """"""
    935         total_words, corpus_count = self.vocabulary.scan_vocab(
--> 936             sentences=sentences, corpus_file=corpus_file, progress_per=progress_per, trim_rule=trim_rule)
    937         self.corpus_count = corpus_count
    938         self.corpus_total_words = total_words

~/git/gensim/gensim/models/word2vec.py in scan_vocab(self, sentences, corpus_file, progress_per, workers, trim_rule)
   1589             sentences = LineSentence(corpus_file)
   1590 
-> 1591         total_words, corpus_count = self._scan_vocab(sentences, progress_per, trim_rule)
   1592 
   1593         logger.info(

~/git/gensim/gensim/models/word2vec.py in _scan_vocab(self, sentences, progress_per, trim_rule)
   1558         vocab = defaultdict(int)
   1559         checked_string_types = 0
-> 1560         for sentence_no, sentence in enumerate(sentences):
   1561             if not checked_string_types:
   1562                 if isinstance(sentence, string_types):

~/git/gensim/gensim/models/word2vec.py in __iter__(self)
   1438         except AttributeError:
   1439             # If it didn't work like a file, use it as a string filename
-> 1440             with utils.smart_open(self.source) as fin:
   1441                 for line in itertools.islice(fin, self.limit):
   1442                     line = utils.to_unicode(line).split()

~/envs/gensim/lib/python3.7/site-packages/smart_open-1.7.1-py3.7.egg/smart_open/smart_open_lib.py in smart_open(uri, mode, **kw)
    179         raise TypeError('mode should be a string')
    180 
--> 181     fobj = _shortcut_open(uri, mode, **kw)
    182     if fobj is not None:
    183         return fobj

~/envs/gensim/lib/python3.7/site-packages/smart_open-1.7.1-py3.7.egg/smart_open/smart_open_lib.py in _shortcut_open(uri, mode, **kw)
    299     #
    300     if six.PY3:
--> 301         return open(parsed_uri.uri_path, mode, buffering=buffering, **open_kwargs)
    302     elif not open_kwargs:
    303         return open(parsed_uri.uri_path, mode, buffering=buffering)

FileNotFoundError: [Errno 2] No such file or directory: '/home/misha/git/gensim/docs/notebooks/text8_50000000'
```"
445,https://github.com/RaRe-Technologies/gensim/issues/2447,2447,[],closed,2019-04-15 04:02:07+00:00,,"Get MemoryError while using ""model.wv.similar_by_vector"" method.","<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I have a word2vec model who's size is 15.5GB, and my computer has 24GB RAM, after I just loaded that model, the used RAM is about 12GB, but after I run 
```python
import gensim

file = r'/path/to/my/file/Tencent_AILab_ChineseEmbedding.txt'

word_model = gensim.models.KeyedVectors.load_word2vec_format(file, binary=False)

word_model.wv.similar_by_vector(word_model['稀饭'])
```
I got a memory error :(

I 'm using Pycharm, so I don't get full error log, just a big red ""MemoryError"".

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
Python 3.7.3 (default, Mar 27 2019, 22:11:17) 
[GCC 7.3.0] :: Anaconda, Inc. on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import platform; print(platform.platform())
Linux-4.18.0-17-generic-x86_64-with-debian-buster-sid
>>> import sys; print(""Python"", sys.version)
Python 3.7.3 (default, Mar 27 2019, 22:11:17) 
[GCC 7.3.0]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.16.2
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.2.1
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.4.0
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 0
"
446,https://github.com/RaRe-Technologies/gensim/issues/2448,2448,[],closed,2019-04-15 09:35:30+00:00,,bz2file dependency considered not neccessary?,"Python has built-in **bz2** module (https://docs.python.org/3/library/bz2.html), don't understand why does gensim depend on **bz2file** which is a old library (see https://pypi.org/project/bz2file/) without updates for a long time. Can I remove this dependency safely?
```
Installing collected packages: bz2file, jmespath, urllib3, botocore, s3transfer, boto3, smart-open, gensim
  Found existing installation: urllib3 1.24.1
    Uninstalling urllib3-1.24.1:
      Successfully uninstalled urllib3-1.24.1
Successfully installed boto3-1.9.130 botocore-1.12.130 bz2file-0.98 gensim-3.7.2 jmespath-0.9.4 s3transfer-0.2.0 smart-open-1.8.1 urllib3-1.22
```"
447,https://github.com/RaRe-Technologies/gensim/issues/2449,2449,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-04-17 15:06:19+00:00,,gensim package gives deprecation warning,"I am facing warning in my Kaggle kernel

```
/opt/conda/lib/python3.6/site-packages/gensim/similarities/docsim.py:528: FutureWarning: arrays to stack must be passed as a ""sequence"" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.
```

The error can be reproduced in Kaggle kernel below
https://www.kaggle.com/frissontek/recommendation-engine-for-career-village/
"
448,https://github.com/RaRe-Technologies/gensim/issues/2450,2450,[],closed,2019-04-18 04:00:34+00:00,,Can I directly input one-hot coding vectors not the raw sentences?,I just want to input one-hot coding vectors not the raw sentences directly. Thank you so much.
449,https://github.com/RaRe-Technologies/gensim/issues/2451,2451,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-04-18 08:16:52+00:00,,Some files there are not int master branch,"There are not some files for `gensim/gensim/example/dmlcz/gensim_xml.py`. These files there are in develop branch, but there are not in master branch. Please fix it (= ."
450,https://github.com/RaRe-Technologies/gensim/issues/2452,2452,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-04-19 09:03:31+00:00,,'utf-8' codec can't decode byte 0xd1 in position 97: unexpected end of data,"#### Problem description

Ok, I have the stated issue. Yes, it's in FAQ, I know. But I think it's different for me.
The thing is: on one machine it occurs, on another one it isn't. On the exact same data that was produced by original word2vec and that is 100% pure organic utf-8.
The machine that _doesn't have_ this problem (my local Gentoo laptop) is using build from `master` branch produced sometimes around 21.04.2018. The machine that _have_ the problem (cluster machine on CentOS) has Gensim installed from pip, version 3.7.2. Python version 3.6 on both of them.

#### Steps/code/corpus to reproduce

```
Traceback (most recent call last):
  File ""/home/scrambled/process_data.py"", line 172, in <module>
    w2v = load_bin_vec(w2v_file, vocab)
  File ""/home/scrambled/process_data.py"", line 102, in load_bin_vec
    model = KeyedVectors.load_word2vec_format(fname, binary=True)
  File ""/home/scrambled/.local/lib/python3.6/site-packages/gensim/models/keyedvectors.py"", line 1476, in load_word2vec_format
    limit=limit, datatype=datatype)
  File ""/home/scrambled/.local/lib/python3.6/site-packages/gensim/models/utils_any2vec.py"", line 382, in _load_word2vec_format
    word = utils.to_unicode(b''.join(word), encoding=encoding, errors=unicode_errors)
  File ""/home/scrambled/.local/lib/python3.6/site-packages/gensim/utils.py"", line 359, in any2unicode
    return unicode(text, encoding, errors=errors)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd1 in position 97: unexpected end of data
```

#### Versions

Machine that _do have_ the problem:

```
Linux-2.6.32-696.30.1.el6.x86_64-x86_64-with-redhat-6.10-Santiago
Python 3.6.8 (default, Apr 18 2019, 15:17:38) [GCC 5.5.0]
NumPy 1.16.2
SciPy 1.2.1
gensim 3.7.2
>>> FAST_VERSION 1
```

Machine that _don't_:
```
Linux-4.18.11-x86_64-Intel-R-_Core-TM-_i7-7700HQ_CPU_@_2.80GHz-with-gentoo-2.6
Python 3.6.5 (default, Apr 25 2018, 22:51:58) [GCC 7.2.0]
NumPy 1.16.1
SciPy 1.2.1
gensim 3.4.0
FAST_VERSION 0
```"
451,https://github.com/RaRe-Technologies/gensim/issues/2453,2453,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",closed,2019-04-19 12:52:05+00:00,,_rollback_optimization is not performed on some old FastText models,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

Model `araneum_none_fasttextskipgram_300_5_2018` from https://rusvectores.org/ru/models/
is loading incorrectly with `gensim.models.fasttext.FastText.load`
This method creates model with `compatible_hash = True` and `hash2index` param, so that ngram indexes are computed incorrectly. 

#### Steps/code/corpus to reproduce

```python

from gensim.models.fasttext import FastText

ft2 = FastText.load('./data/araneum_none_fasttextskipgram_300_5_2018.model')
ft2.wv.word_vec('слово123')
```

gives the following stacktrace

```
---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
<ipython-input-14-5fac1e42e24a> in <module>()
----> 1 ft2.wv.word_vec('слово123')

~/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py in word_vec(self, word, use_norm)
   2111                 return word_vec
   2112             for nh in ngram_hashes:
-> 2113                 word_vec += ngram_weights[nh]
   2114             return word_vec / len(ngram_hashes)
   2115 

IndexError: index 1369364 is out of bounds for axis 0 with size 27355
```
#### Versions

```
Linux-4.2.0-27-generic-x86_64-with-debian-jessie-sid
Python 3.6.8 |Anaconda 4.4.0 (64-bit)| (default, Dec 30 2018, 01:22:34) 
[GCC 7.3.0]
NumPy 1.16.0
SciPy 1.1.0
gensim 3.7.2
FAST_VERSION 1
```
"
452,https://github.com/RaRe-Technologies/gensim/issues/2455,2455,[],open,2019-04-20 08:15:14+00:00,,accuracy function for analogy test error,"#### Problem description
Analogy test for accuracy function does not work properly because of the typo (topn = False) on line 1187 in keyedvectors.py script.
(https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/keyedvectors.py)

#### Solution
There are 2 solutions regarding this matter: changing the typo in accuracy function or changing the most_smiliar function

1) Change accuracy function in gensim/models/keyedvectors.py script on line 1187
(https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/keyedvectors.py)
```python
sims = most_similar(self, positive=[b, c], negative=[a], topn=False, restrict_vocab=restrict_vocab)
==>
sims = most_similar(self, positive=[b, c], negative=[a], topn=None, restrict_vocab=restrict_vocab)
```
2) Change the most_similar function in gensim/models/keyedvectors.py script on line 514,556
(https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/keyedvectors.py)

```python
if topn is not None and topn < 1: ==> if not topn and topn<1:
```
AND
```python
if topn is None: ==> if not topn:
```


#### Versions

```python
Darwin-18.5.0-x86_64-i386-64bit
Python 3.6.8 |Anaconda, Inc.| (default, Dec 29 2018, 19:04:46) 
[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]
NumPy 1.16.2
SciPy 1.2.1
gensim 3.7.2
FAST_VERSION 0
```"
453,https://github.com/RaRe-Technologies/gensim/issues/2458,2458,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",open,2019-04-20 23:44:32+00:00,,explicitly specify encoding whenever opening text files,"When we call `smart_open.smart_open(..., 'r', ...)`, we should always include the encoding.

https://github.com/RaRe-Technologies/gensim/pull/2423#discussion_r277142330"
454,https://github.com/RaRe-Technologies/gensim/issues/2459,2459,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 175642, 'node_id': 'MDU6TGFiZWwxNzU2NDI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/wishlist', 'name': 'wishlist', 'color': 'd7e102', 'default': False, 'description': 'Feature request'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}]",open,2019-04-21 01:09:52+00:00,,"potential Doc2Vec feature: reverse inference, to synthesize doc/summary words","Motivated by the SO question: https://stackoverflow.com/questions/55768598/interpret-the-doc2vec-vectors-clusters-representation/55779049#55779049

`Doc2Vec` could plausibly have a function that's reverse-inference: take a doc-vector, return a (ranked) list of words most-predicted by that input vector. It'd work highly analogously to `Word2Vec.predict_output_word()`. Such a list of words *might* be useful as a sort-of summary or label for a doc-vector."
455,https://github.com/RaRe-Technologies/gensim/issues/2460,2460,"[{'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2019-04-22 04:01:55+00:00,,Passing nonsense (int) for `corpus_file` generates confusing OSError in get_offsets_and_start_doctags_for_corpusfile,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I am trying to train a doc2vec model over 1.35 million docs. Each line of the opened file corresponds to a doc and I am creating a TaggedDocument object from that. I am getting these errors which I cannot resolve. Note that the 1351747 below corresponds to the number of docs.
```
OSError: [Errno 9] Bad file descriptor: 1351747
```

This is my code:
```python
taggeddoc = []
f = open('EnglishT.txt')
for line in f:
    td = TaggedDocument(gensim.utils.to_unicode(str.encode(line)).split(),[str(index)])
    taggeddoc.append(td)
    index += 1
f.close()
print(len(taggeddoc))
model = gensim.models.doc2vec.Doc2Vec(vector_size=50, dm=0, dbow_words=0, workers=30, alpha=0.025, min_alpha=0.025)

model.build_vocab(taggeddoc)
# start training
for epoch in range(500):
    model.train(taggeddoc, model.corpus_count, epochs=model.iter)
    model.alpha -= 0.002  
    model.min_alpha = model.alpha 
```

Using Python3:
```
Traceback (most recent call last):
  File ""en_d2v.py"", line 25, in <module>
    model.train(taggeddoc, model.corpus_count, epochs=model.iter)
  File ""/home/junlp/.local/lib/python3.6/site-packages/gensim/models/doc2vec.py"", line 799, in train
    offsets, start_doctags = self._get_offsets_and_start_doctags_for_corpusfile(corpus_file, self.workers)
  File ""/home/junlp/.local/lib/python3.6/site-packages/gensim/models/doc2vec.py"", line 828, in _get_offsets_and_start_doctags_for_corpusfile
    corpus_file_size = os.path.getsize(corpus_file)
  File ""/usr/lib/python3.6/genericpath.py"", line 50, in getsize
    return os.stat(filename).st_size
OSError: [Errno 9] Bad file descriptor: 1351747
```

Using Python2
```
Traceback (most recent call last):
  File ""en_d2v.py"", line 32, in <module>
    model.train(taggeddoc, model.corpus_count, epochs=model.iter)
  File ""/home/junlp/.local/lib/python2.7/site-packages/gensim/models/doc2vec.py"", line 799, in train
    offsets, start_doctags = self._get_offsets_and_start_doctags_for_corpusfile(corpus_file, self.workers)
  File ""/home/junlp/.local/lib/python2.7/site-packages/gensim/models/doc2vec.py"", line 828, in _get_offsets_and_start_doctags_for_corpusfile
    corpus_file_size = os.path.getsize(corpus_file)
  File ""/usr/lib/python2.7/genericpath.py"", line 57, in getsize
    return os.stat(filename).st_size
TypeError: coercing to Unicode: need string or buffer, int found
```

#### Versions

Linux-4.15.0-46-generic-x86_64-with-Ubuntu-18.04-bionic
('Python', '2.7.15rc1 (default, Nov 12 2018, 14:31:15) \n[GCC 7.3.0]') 
('NumPy', '1.16.2')
('SciPy', '1.2.1')
No handlers could be found for logger ""smart_open.ssh""
('gensim', '3.7.2')
('FAST_VERSION', 1)

For Python3,
Python 3.6.7 (default, Oct 22 2018, 11:32:17)"
456,https://github.com/RaRe-Technologies/gensim/issues/2462,2462,[],open,2019-04-24 02:49:00+00:00,,DTM mode = ‘time’ ERROR,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description
My code runs well when the mode is the default 'fit',but I wanna use the 'time' mode to analysis the corpus through time to see the topics in different times.But the 'time'mode seems not work.

At first it's the error returned from the gensim.utils :""returned non-zero exit status 1"".

After I rewrite some code in utils.py,new errors occured that all the codes with the ""np.loadtxt"" in the dtmmodel dont work,actually all the txt are missing.

**Do I use the 'time' in a wrong way or what?Or the 'time' mode dont work at all?**
What are you trying to achieve? What is the expected result? What are you seeing instead?

#### Steps/code/corpus to reproduce
`model = DtmModel(path_to_dtm_binary,corpus = corpus,time_slices=[1] * len(corpus),id2word=dic,num_topics = num_topics,alpha = alpha,mode='fit')#this works well`

`dtm_time = DtmModel(path_to_dtm_binary,corpus = corpus,time_slices=[1] * len(corpus),id2word=dic,num_topics = num_topics,alpha = alpha,mode='time')`
#returns this error after I rewrite the code in utils.py.Before that,it returns the""returned non-zero exit status 1"",which was the function:check_output error

OSError: C:\Users\Mamba\AppData\Local\Temp\ecbee0_train_out/lda-seq/gam.dat not found.



#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
Windows-10-10.0.17763-SP0
import sys; print(""Python"", sys.version)
Python 3.7.1 (default, Dec 10 2018, 22:54:23) [MSC v.1915 64 bit (AMD64)]
import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.16.2
import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.2.1
import gensim; print(""gensim"", gensim.__version__)
gensim 3.4.0
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1
```
"
457,https://github.com/RaRe-Technologies/gensim/issues/2463,2463,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}]",open,2019-04-24 12:57:25+00:00,,Coherence RuntimeWarnings : divide by zero encountered in double_scalars AND invalid value encountered in double_scalars,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

For my intership, I'm trying to evaluate the quality of different LDA models using both perplexity and coherence. I used a loop and generated each model. However, I encounter a problem when the loop reaches **parameter_value=15**. The coherence score seems to be stored as nan for the models 15, 20, 25 and 30... I tried fixing this issue by changind the parameters in **.LdaModel()** but it only makes the warning appear for further models. **Instead of having a warning for parameter_value=15, I get it for parameter_value=30**.

Can someone please help me ?

#### Problem encountered : warning
```warning
starting pass for parameter_value = 30.000
Elapsed time: 1.6870347789972584
Perplexity score: -13.63168019880968
C:\Users\straw\Anaconda3\lib\site-packages\gensim\topic_coherence\direct_confirmation_measure.py:204: RuntimeWarning: divide by zero encountered in double_scalars
  m_lr_i = np.log(numerator / denominator)
C:\Users\straw\Anaconda3\lib\site-packages\gensim\topic_coherence\indirect_confirmation_measure.py:323: RuntimeWarning: invalid value encountered in double_scalars
  return cv1.T.dot(cv2)[0, 0] / (_magnitude(cv1) * _magnitude(cv2))
Coherence Score: nan
```

#### Steps/code

```python

grid_flt = defaultdict(list)

 # num topics
parameter_list=[2, 5, 10, 15, 20, 25, 30]


for parameter_value in parameter_list:
    print(""starting pass for parameter_value = %.3f"" % parameter_value)
    start_time = timeit.default_timer()
    # run model
    ldamodel_train_flt = gensim.models.ldamodel.LdaModel(corpus=doc_term_matrix_train_flt, id2word = dictionary_train_flt, num_topics = parameter_value, passes=25, per_word_topics=True)

    # show elapsed time for model
    elapsed = timeit.default_timer() - start_time
    print(""Elapsed time: %s"" % elapsed)
    
    # Compute perplexity
    perplex =  ldamodel_train_flt.log_perplexity(doc_term_matrix_test_flt)
    print(""Perplexity score: %s"" % perplex)
    grid_flt[parameter_value].append(perplex)
    
    # Compute Coherence Score
    coherence_model_lda = gensim.models.coherencemodel.CoherenceModel(model=ldamodel_train_flt, texts=list_of_docs_flt_test, dictionary=dictionary_train_flt, coherence='c_v')
    coherence_lda = coherence_model_lda.get_coherence()
    print(""Coherence Score: %s"" % coherence_lda)
    grid_flt[parameter_value].append(coherence_lda)
```
#### Versions

```console
Windows-10-10.0.17134-SP0
Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]
NumPy 1.16.2
SciPy 1.1.0
gensim 3.7.2
FAST_VERSION -1
```"
458,https://github.com/RaRe-Technologies/gensim/issues/2464,2464,[],closed,2019-04-25 20:40:14+00:00,,Lemmatizer fails for some words,"**The problem**

```python
from gensim import utils

print (utils.lemmatize('smile')) # other words include 'her', 'smooth'
print (utils.lemmatize('arrived')) #other words include 'ears', 'tattoos', 'campaigning'
```

The first command ('smile') returns an empty array. 
The second command ('arrived') returns unlemmatized word. 
Many other words work just fine. 


**Version info:**
Windows-10-10.0.17134-SP0
Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)]
NumPy 1.16.3
SciPy 1.2.1
c:\Program Files\Python36\lib\site-packages\smart_open\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress
  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')
gensim 3.7.2
FAST_VERSION -1"
459,https://github.com/RaRe-Technologies/gensim/issues/2465,2465,[],open,2019-04-28 04:23:06+00:00,,NMF test code raises deprecation warnings,"Running test_nmf.py under nosetests gives the following:

```
.../home/misha/git/gensim/gensim/test/test_nmf.py:139: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  self.assertTrue(np.issubdtype(v, float))
/home/misha/git/gensim/gensim/test/test_nmf.py:150: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  self.assertTrue(np.issubdtype(v, float))
./home/misha/git/gensim/gensim/test/test_nmf.py:130: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  self.assertTrue(np.issubdtype(v, float))
...../home/misha/git/gensim/gensim/test/test_nmf.py:157: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  self.assertTrue(np.issubdtype(probability, float))
/home/misha/git/gensim/gensim/test/test_nmf.py:163: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  self.assertTrue(np.issubdtype(probability, float))
./home/misha/git/gensim/gensim/test/test_nmf.py:123: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  self.assertTrue(np.issubdtype(v, float))
........
----------------------------------------------------------------------
Ran 18 tests in 62.843s

OK
```

We should fix these warnings to avoid bad behavior in the future, once the deprecations kick in."
460,https://github.com/RaRe-Technologies/gensim/issues/2467,2467,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-04-29 00:07:43+00:00,,type object 'gensim._matutils.array' has no attribute '__reduce_cython__',"getting the following error:
AttributeError                            Traceback (most recent call last)
<ipython-input-13-6d3fc7c83071> in <module>()
      1 # Gensim
----> 2 import gensim, spacy, logging, warnings
      3 import gensim.corpora as corpora
      4 from gensim.utils import lemmatize, simple_preprocess
      5 from gensim.models import CoherenceModel

~\Anaconda3\lib\site-packages\gensim\__init__.py in <module>()
      3 """"""
      4 
----> 5 from gensim import parsing, corpora, matutils, interfaces, models, similarities, summarization, utils  # noqa:F401
      6 import logging
      7 

~\Anaconda3\lib\site-packages\gensim\corpora\__init__.py in <module>()
      4 
      5 # bring corpus classes directly into package namespace, to save some typing
----> 6 from .indexedcorpus import IndexedCorpus  # noqa:F401 must appear before the other classes
      7 
      8 from .mmcorpus import MmCorpus  # noqa:F401

~\Anaconda3\lib\site-packages\gensim\corpora\indexedcorpus.py in <module>()
     13 import numpy
     14 
---> 15 from gensim import interfaces, utils
     16 
     17 logger = logging.getLogger(__name__)

~\Anaconda3\lib\site-packages\gensim\interfaces.py in <module>()
     19 import logging
     20 
---> 21 from gensim import utils, matutils
     22 from six.moves import range
     23 

~\Anaconda3\lib\site-packages\gensim\matutils.py in <module>()
   1089 try:
   1090     # try to load fast, cythonized code if possible
-> 1091     from gensim._matutils import logsumexp, mean_absolute_difference, dirichlet_expectation
   1092 
   1093 except ImportError:

~\Anaconda3\lib\site-packages\gensim\_matutils.cp36-win_amd64.pyd in init gensim._matutils()

AttributeError: type object 'gensim._matutils.array' has no attribute '__reduce_cython__'
"
461,https://github.com/RaRe-Technologies/gensim/issues/2468,2468,"[{'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",open,2019-04-29 13:35:11+00:00,,Loading BioWordVec fails with gensim (3.7.2) fastText interface,"While using [FBs fastText Python lib ](https://github.com/facebookresearch/fastText/tree/master/python) the [BioWordVec](https://ftp.ncbi.nlm.nih.gov/pub/lu/Suppl/BioSentVec/BioWordVec_PubMed_MIMICIII_d200.bin) embeddings are loaded successfully and work as advertised (i.e. they produce representation of both in- and out-of-vocab words). 

This works on both a MacBook Pro (late 2018, 16Gbs of RAM with OS X Mojave 10.14.4) and on a Linux server (CentOS 7) with 64GBs of RAM. The loading takes 100ish seconds and uses some swap memory (but is quite efficient when it comes to virt/RAM memory). 

The code which successfully executes this performance is:

```python
import fastText as fasttext
ftModel = fasttext.load_model(path/to/model/+'BioWordVec_PubMed_MIMICIII_d200.bin')
```

to load the model and either 
ftModel.get_word_vector(word) to get the word representation or 
ftModel.get_input_vector(word_ID) to get a representation of word with said ID. 


When I try to load the same model with gensims fastText interface , either with load_facebook_model() or load_facebook_vectors(), the code:
1. fails to load the model on the Mac; the process exists as all memory get eaten away
2. successfully loads on the CentOS server, but only after more than 30 mins and uses 35(ish) GB of Virt and RAM memory. 

The said model was trained with FBs fastText tool, as seen on their [repo](https://github.com/ncbi-nlp/BioSentVec#biowordvec-biomedical-word-embeddings-with-fasttext) : 
_We applied fastText to compute 200-dimensional word embeddings._

Both the Mac and the CentOS server have the same libs (and their versions) installed:

Python 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34)
[GCC 7.3.0]
NumPy 1.16.2
SciPy 1.1.0
gensim 3.7.2
FAST_VERSION 1"
462,https://github.com/RaRe-Technologies/gensim/issues/2470,2470,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-05-01 04:36:38+00:00,,models.Doc2Vec retruned model.docvecs size is smaller than input docs,"
models.Doc2Vec retruned model.docvecs size is smaller than input docs

model = models.Doc2Vec(docs,alpha=0.025,min_alpha=0.025,min_count=2,vector_size=30,workers=4,epochs=50)

docs size 2849, 
model.docvecs size 2749 

"
463,https://github.com/RaRe-Technologies/gensim/issues/2471,2471,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-05-01 07:55:18+00:00,,Persistense on disk fails,"Hello!

I can't get back the model I have saved. 
When I do that:
`from gensim.test.utils import get_tmpfile`
 `fname = get_tmpfile(""fasttext.model"")`   
 `model.save(fname)`   
 `print(model.wv[""afgadfgd""])`   

saving works and word vector is printed but when I load the model with   
`model = FastText.load(fname)`    
and try:    
`print(model.wv[""afgadfgd""])`
it fails with an error:    
`AttributeError: 'FastTextKeyedVectors' object has no attribute 'vectors_ngrams'`

Could you please look into that?

```Linux-4.18.0-17-generic-x86_64-with-debian-buster-sid
Python 3.7.2 (default, Dec 29 2018, 06:19:36) 
[GCC 7.3.0]
NumPy 1.16.3
SciPy 1.2.1
gensim 3.7.2
FAST_VERSION 1
```
"
464,https://github.com/RaRe-Technologies/gensim/issues/2473,2473,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}]",closed,2019-05-03 18:37:13+00:00,,Using the load_facebook_model method produces ValueError on array reshaping,"I am trying to load in the English, pre-trained, bin model from [FastText](https://fasttext.cc/docs/en/crawl-vectors.html), but am getting a ValueError.

Versions:
```
Windows-10-10.0.17134-SP0
Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)]
NumPy 1.16.2
SciPy 1.2.1
gensim 3.7.2
FAST_VERSION 0
```

I am running the following line: 
`model_fast = gensim.models.fasttext.load_facebook_model('cc.en.300.bin.gz')`

However, I get this error:
```
ValueError                                Traceback (most recent call last)
<ipython-input-7-615bb517a8f5> in <module>
----> 1 model_fast = gensim.models.fasttext.load_facebook_model('cc.en.300.bin.gz')

c:\users\david\desktop\bennet~1\bennet~1\bert_t~1\env\lib\site-packages\gensim\models\fasttext.py in load_facebook_model(path, encoding)
   1241 
   1242     """"""
-> 1243     return _load_fasttext_format(path, encoding=encoding, full_model=True)
   1244 
   1245 

c:\users\david\desktop\bennet~1\bennet~1\bert_t~1\env\lib\site-packages\gensim\models\fasttext.py in _load_fasttext_format(model_file, encoding, full_model)
   1321     """"""
   1322     with smart_open(model_file, 'rb') as fin:
-> 1323         m = gensim.models._fasttext_bin.load(fin, encoding=encoding, full_model=full_model)
   1324 
   1325     model = FastText(

c:\users\david\desktop\bennet~1\bennet~1\bert_t~1\env\lib\site-packages\gensim\models\_fasttext_bin.py in load(fin, encoding, full_model)
    272     model.update(raw_vocab=raw_vocab, vocab_size=vocab_size, nwords=nwords)
    273 
--> 274     vectors_ngrams = _load_matrix(fin, new_format=new_format)
    275 
    276     if not full_model:

c:\users\david\desktop\bennet~1\bennet~1\bert_t~1\env\lib\site-packages\gensim\models\_fasttext_bin.py in _load_matrix(fin, new_format)
    235 
    236     matrix = np.fromfile(fin, dtype=dtype, count=num_vectors * dim)
--> 237     matrix = matrix.reshape((num_vectors, dim))
    238     return matrix
    239 

ValueError: cannot reshape array of size 1116604308 into shape (4000000,300)
```"
465,https://github.com/RaRe-Technologies/gensim/issues/2474,2474,"[{'id': 175642, 'node_id': 'MDU6TGFiZWwxNzU2NDI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/wishlist', 'name': 'wishlist', 'color': 'd7e102', 'default': False, 'description': 'Feature request'}]",open,2019-05-04 11:18:49+00:00,,Automated closing / locking of stale tickets,"I suggest adding Github bots to the Gensim repo to:

1. Automatically comment on `need info` label, to point the user to our check-list from the issue template of what we need in reports (notably a reproducible example + SW versions), and warn them the issue will be closed otherwise.
2. Automatically warn (post a comment) about future closing of a ticket if the ticket has a ""need info"" tag and no activity for 1 week.
3. Close the ticket if there's no activity for 2 weeks.
4. Lock the ticket if there's no activity for 1 month (to prevent people hijacking old tickets).

I found some bots that reportedly do that, e.g. [stale bot](https://github.com/apps/stale), [lock bot](https://github.com/apps/lock).

But we have to be careful about permissions requested by these 3rd party tools. I don't have much trust in external tools, and requesting the bot any sort of access to our private repos would be an immediate show-stopper."
466,https://github.com/RaRe-Technologies/gensim/issues/2477,2477,[],closed,2019-05-05 15:18:43+00:00,,mismatched field names,"Some places in the code use   self._lines_are_documents
while others use  self.lines_are_documents   (no underscore)

https://github.com/RaRe-Technologies/gensim/blob/40792c611ff6d0385fadc6de1f03d9ae22261351/gensim/corpora/textcorpus.py#L512

https://github.com/RaRe-Technologies/gensim/blob/40792c611ff6d0385fadc6de1f03d9ae22261351/gensim/corpora/textcorpus.py#L592

https://github.com/RaRe-Technologies/gensim/blob/40792c611ff6d0385fadc6de1f03d9ae22261351/gensim/corpora/textcorpus.py#L517"
467,https://github.com/RaRe-Technologies/gensim/issues/2483,2483,[],closed,2019-05-08 13:51:36+00:00,,Fasttext - Different order of subwords change similarity ,"Hi,

I just found that different order of subwords in a OOV-word gives different results.

My example is

sub1sub2 (OOV)

with sub1 and sub2 subwords which are in vocab.

So 

`print(model.wv.similarity(""sub1sub2"",""sub2sub1""))`

should yield `1`, right?

I get for my model depending on the words 80 or even just 60%?

Since for OOVs the vector is just the sum of subwords, why does the order change the result?

gensim: 3.6.0"
468,https://github.com/RaRe-Technologies/gensim/issues/2484,2484,[],closed,2019-05-08 19:09:35+00:00,,Parameters equivalence in Word2vec,"Hello, I would like to understand better the difference between the ""iter"" and ""epoch"" parameters in the Word2vec algorithm. 

Does the epoch parameter have an equivalent to the Mikolov's implementation? 

Actually, I haven't seen any mention to the Epoch parameter in the Mikolov job, so how could I replicate it? Would be enough an execution like Gensim.Word2vec(iter = 5, epoch = 5) Mikolov.Word2vec(iter = 5) to run the same for these two parameters?"
469,https://github.com/RaRe-Technologies/gensim/issues/2486,2486,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-05-09 00:43:10+00:00,, Error reporting for loading model files,Error loading model file. Details are attached.
470,https://github.com/RaRe-Technologies/gensim/issues/2487,2487,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-05-09 02:27:27+00:00,,Error reporting for loading model files," Once running to model =  Doc2Vec. load (model_path) , an error is reported.
Specific error reporting information: _pickle. unpicking Error: invalid load key' xca'
Error reporting environment:
Linux-4,15-1032-x86_64-with-debian-stretch-sid
GCC 5.4.0 20160609
Python3.6.5
Gensim=3.7.3
Numpy=1.15.1
Scipy=1.1.0
FAST_VERSION 1"
471,https://github.com/RaRe-Technologies/gensim/issues/2488,2488,[],closed,2019-05-09 12:05:32+00:00,,"Hi，I wanna know how to retain the information of ""title tag"" when processing the corpus.xml into plain corpus.txt","I have a entity set， and I wanna extract entity-related page information from Wikipedia, but when the corpus.xml is processed into a corpus.txt, title information is filtered out, so I can't link my entity to the information in Wikipedia corpus. I want to know how to keep ""title tag"" information. I would appreciate it if you can help me.(Thank you so much!!!)"
472,https://github.com/RaRe-Technologies/gensim/issues/2489,2489,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}]",open,2019-05-10 09:28:30+00:00,,Document how to get complete document distribution from LDA,"Document how to to get full document distribution from LDA, that would help in those cases where you are implementing your own distance algorithm and you need full  distribution. Personally I set  minimum_probability=0.0 but there might be other ways."
473,https://github.com/RaRe-Technologies/gensim/issues/2490,2490,[],closed,2019-05-11 03:29:07+00:00,,Sent2Vec not importing,"Hi, I tried to use Sent2Vec with Gensim 3.7.3, but the import isn't working. Is it part of the latest release? 
"
474,https://github.com/RaRe-Technologies/gensim/issues/2492,2492,[],closed,2019-05-11 19:06:58+00:00,,Error using Gensim with Flask API,"I am trying to build a python API for the first time. Trying to build an API end point to summarize using flask rest and gensim libraries. Any suggestions?

Code: 
```
import flask
from flask import json
from flask import request
from flask_restful import Resource, Api, reqparse
from gensim.summarization.summarizer import summarize

app = flask.Flask(__name__)
app.config[""DEBUG""] = True

@app.route('/', methods=['GET'])
def home():
    return ""<p>This is a test GET End point</p>""

@app.route('/', methods = ['POST'])
def api_message():
        return summarize(request.data)  
app.run()
```

Expected output:

```
 * Serving Flask app ""TextSummarizerAPI"" (lazy loading)
 * Environment: production
   WARNING: Do not use the development server in a production environment.
   Use a production WSGI server instead.
 * Debug mode: on
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 295-630-739
 * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit) 
```

Actual output:
```

Traceback (most recent call last):
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\flask\app.py"", line 2309, in __call__
    return self.wsgi_app(environ, start_response)
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\flask\app.py"", line 2295, in wsgi_app
    response = self.handle_exception(e)
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\flask\app.py"", line 1741, in handle_exception
    reraise(exc_type, exc_value, tb)
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\flask\_compat.py"", line 35, in reraise
    raise value
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\flask\app.py"", line 2292, in wsgi_app
    response = self.full_dispatch_request()
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\flask\app.py"", line 1815, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\flask\app.py"", line 1718, in handle_user_exception
    reraise(exc_type, exc_value, tb)
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\flask\_compat.py"", line 35, in reraise
    raise value
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\flask\app.py"", line 1813, in full_dispatch_request
    rv = self.dispatch_request()
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\flask\app.py"", line 1799, in dispatch_request
    return self.view_functions[rule.endpoint](**req.view_args)
  File ""C:\Blog Code\TextSummarizer\TextSummarizer\TextSummarizer\PythonAPI\TextSummarizerAPI.py"", line 18, in api_message
    return summarize(request.data)
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\gensim\summarization\summarizer.py"", line 419, in summarize
    sentences = _clean_text_by_sentences(text)
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\gensim\summarization\textcleaner.py"", line 248, in clean_text_by_sentences
    original_sentences = split_sentences(text)
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\gensim\summarization\textcleaner.py"", line 77, in split_sentences
    processed = replace_abbreviations(text)
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\gensim\summarization\textcleaner.py"", line 102, in replace_abbreviations
    return replace_with_separator(text, SEPARATOR, [AB_SENIOR, AB_ACRONYM])
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\gensim\summarization\textcleaner.py"", line 148, in replace_with_separator
    result = regex.sub(replacement, result)
TypeError: cannot use a string pattern on a bytes-like object
127.0.0.1 - - [11/May/2019 11:57:05] ""POST / HTTP/1.1"" 500 -
Traceback (most recent call last):
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\flask\app.py"", line 2309, in __call__
    return self.wsgi_app(environ, start_response)
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\flask\app.py"", line 2295, in wsgi_app
    response = self.handle_exception(e)
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\flask\app.py"", line 1741, in handle_exception
    reraise(exc_type, exc_value, tb)
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\flask\_compat.py"", line 35, in reraise
    raise value
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\flask\app.py"", line 2292, in wsgi_app
    response = self.full_dispatch_request()
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\flask\app.py"", line 1815, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\flask\app.py"", line 1718, in handle_user_exception
    reraise(exc_type, exc_value, tb)
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\flask\_compat.py"", line 35, in reraise
    raise value
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\flask\app.py"", line 1813, in full_dispatch_request
    rv = self.dispatch_request()
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\flask\app.py"", line 1799, in dispatch_request
    return self.view_functions[rule.endpoint](**req.view_args)
  File ""C:\Blog Code\TextSummarizer\TextSummarizer\TextSummarizer\PythonAPI\TextSummarizerAPI.py"", line 18, in api_message
    return summarize(request.data)
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\gensim\summarization\summarizer.py"", line 419, in summarize
    sentences = _clean_text_by_sentences(text)
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\gensim\summarization\textcleaner.py"", line 248, in clean_text_by_sentences
    original_sentences = split_sentences(text)
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\gensim\summarization\textcleaner.py"", line 77, in split_sentences
    processed = replace_abbreviations(text)
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\gensim\summarization\textcleaner.py"", line 102, in replace_abbreviations
    return replace_with_separator(text, SEPARATOR, [AB_SENIOR, AB_ACRONYM])
  File ""C:\Users\aniru\AppData\Local\Programs\Python\Python37-32\lib\site-packages\gensim\summarization\textcleaner.py"", line 148, in replace_with_separator
    result = regex.sub(replacement, result)
TypeError: cannot use a string pattern on a bytes-like object
 * Detected change in 'C:\\Blog Code\\TextSummarizer\\TextSummarizer\\TextSummarizer\\PythonAPI\\TextSummarizerAPI.py', reloading
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 295-630-739
 * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)
```"
475,https://github.com/RaRe-Technologies/gensim/issues/2494,2494,[],closed,2019-05-15 11:15:49+00:00,,Get p(t|w) distribution,"#### Problem description

How can I get distribution `p(t|w)` from an already trained LDA model?
It's need for calulate the *core* of theme.

This is calculated by the formula: `p(t|w) = p(w|t) * p(t) / p(w)`
"
476,https://github.com/RaRe-Technologies/gensim/issues/2495,2495,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-05-16 18:12:58+00:00,,Provision for enriching just the vocabulary and not the documents,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I have a small list of sentences and I am trying to use that to create a document similarity based search. 
Gensim is correctly able to relate the search sentence with closest sentences in the corpus when the most of the words match . But when the input is the same question using a different set of words (synonyms or lexically similar word), it cannot get a match.

In creating the model there are two steps 
1. create_vocab
2. train

In the create_vocab i want to use a large corpus of created say from wikipedia + the training corpus, but the training is done only using the train corpus. 
I expect that by building the vocal of a large corpus it will enrich the word vector embeddings within the model . Then when try to infer the similarity for a new sentence which has synonyms for an existing sentence , it should be able to provide me with the correct match from the train corpus. 

But unfortunately that is not happening, rather what is happening is we are getting answers from the large wikipedia corpus. 

Is what i trying to do even makes sense and if so what is going wrong here.

#### Steps/code/corpus to reproduce

This is my vision 
lets say i have a set of sentences like 
```
[ ' the new rates are effective from this monday', 'If the customer has opted into new rate and wants to remain on their custom rate card, then it will be evaluated on a case by case basis at the SLT level based on a developed exception framework If the customer has opted out of all new rate payment plans, and wants to remain on their custom Singles Card, then they may do so; these exceptions will continue to operate as they do today through DPIC and PIC evaluations', 'Company remains committed to transparent pricing, and also to serving our customer’s needs. The introduction of new rate is in response to directional shifts in the marketplace by our customers. Customers will have the choice of staying on rate cards with transparent pricing or opting in to new rate for more granular pricing', ..........]
```

now if the question is asked
what was the reason for such deviating modification 

it should show me the 3rd sentence to be most similar , it is not doing that but showing some other sentences with very low confidence score.  I believe that is because it does know know that **deviating modification**  and **directional shift** are very close phrases. By introducing a large vocab i expect that knowledge to be imparted to the model thus resulting better results. 

I am using the following code to train  the model
```python
train_corpus = # some small list
vocab_corpus = train_corpus + # huge wikipedia corpus
model = gensim.models.doc2vec.Doc2Vec(vector_size=100, alpha=0.025, min_count=2, min_alpha=0.025, dbow_words=1, dm_concat=1)
model.build_vocab(vocab_corpus)
# There was a huge optimization by running the training repeatedly with a decreasing alpha value. 
for epoch in range(4):
    model.train(train_corpus, total_examples=model.corpus_count, epochs=40)
    model.alpha -= 0.002  # decrease the learning rate
    model.min_alpha = model.alpha  # fix the learning rate, no decay
```

If what i am thinking is not possible , is there any way to enrich the lexical knowledge of the model by introducing synonyms or phrases or n-grams etc. 

#### Versions

Please provide the output of:

```python
Linux-4.15.0-48-generic-x86_64-with-debian-buster-sid
Python 3.7.1 (default, Dec 14 2018, 19:28:38) 
[GCC 7.3.0]
NumPy 1.15.4
SciPy 1.1.0
gensim 3.4.0
FAST_VERSION 1
```
"
477,https://github.com/RaRe-Technologies/gensim/issues/2496,2496,[],closed,2019-05-17 08:39:45+00:00,,SparseTermSimilarityMatrix - TypeError: 'numpy.float32' object is not iterable,"I am using gensim 3.7.3 and python3.6.

I am following the exact example of SoftCosineSimilarity at https://radimrehurek.com/gensim/similarities/docsim.html
but with my own dataset and embeddings trained on Fasttext.
Dictionary and WordEmbeddingSimilarityIndex are executed properly but then I get an error when trying SparseTermSimilarityMatrix. I found a similar issue, that was solved in the pull below, but I still seem to get this error. However, I tried the exact same code with Word2Vec and the gensim imported common_texts and it worked. Why it doesnt work in my case, is it related to FastText?

https://github.com/RaRe-Technologies/gensim/pull/2356

My code:
```
from gensim.models import FastText
from gensim.corpora import Dictionary
from gensim.models import WordEmbeddingSimilarityIndex
from gensim.similarities import SoftCosineSimilarity, SparseTermSimilarityMatrix

model = FastText.load('fasttext_vector_100')
# this line works
model.wv.most_similar(positive=['test'], topn=2)
termsim_index = WordEmbeddingSimilarityIndex(model.wv)
# texts is similar to common_texts, list of lists of strings
dictionary = Dictionary(texts)
bow_corpus = [dictionary.doc2bow(document) for document in texts]
# it fails here
similarity_matrix = SparseTermSimilarityMatrix(termsim_index, dictionary)
```


```
TypeError                                 Traceback (most recent call last)
<ipython-input-129-c33cf3beaa3e> in <module>()
----> 1 similarity_matrix = SparseTermSimilarityMatrix(termsim_index, dictionary)  # construct similarity matrix

~\AppData\Local\Continuum\anaconda3\lib\site-packages\gensim\similarities\termsim.py in __init__(self, source, dictionary, tfidf, symmetric, positive_definite, nonzero_limit, dtype)
    232             most_similar = [
    233                 (dictionary.token2id[term], similarity)
--> 234                 for term, similarity in index.most_similar(t1, num_rows)
    235                 if term in dictionary.token2id]
    236 

~\AppData\Local\Continuum\anaconda3\lib\site-packages\gensim\similarities\termsim.py in <listcomp>(.0)
    231             num_rows = nonzero_limit - num_nonzero
    232             most_similar = [
--> 233                 (dictionary.token2id[term], similarity)
    234                 for term, similarity in index.most_similar(t1, num_rows)
    235                 if term in dictionary.token2id]

~\AppData\Local\Continuum\anaconda3\lib\site-packages\gensim\models\keyedvectors.py in most_similar(self, t1, topn)
   1418         else:
   1419             most_similar = self.keyedvectors.most_similar(positive=[t1], topn=topn, **self.kwargs)
-> 1420             for t2, similarity in most_similar:
   1421                 if similarity > self.threshold:
   1422                     yield (t2, similarity**self.exponent)

TypeError: 'numpy.float32' object is not iterable

```"
478,https://github.com/RaRe-Technologies/gensim/issues/2498,2498,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-05-20 12:57:40+00:00,,ModuleNotFoundError: No module named 'gensim.models.word2vec_corpusfile' exception when using corpus_file parameter,"#### Problem description

I can run Doc2vec with documents parameter without problem but when set corpus_file parameter I am getting following exception:

```python
2019-05-20 15:39:47,719 INFO collecting all words and their counts
2019-05-20 15:39:47,719 WARNING this function is deprecated, use smart_open.open instead
2019-05-20 15:39:47,722 INFO PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2019-05-20 15:39:47,880 INFO PROGRESS: at example #10000, processed 166529 words (1052030/s), 12757 word types, 10000 tags
2019-05-20 15:39:47,994 INFO PROGRESS: at example #20000, processed 333710 words (1475171/s), 18969 word types, 20000 tags
2019-05-20 15:39:48,110 INFO PROGRESS: at example #30000, processed 497372 words (1413199/s), 23460 word types, 30000 tags
2019-05-20 15:39:48,232 INFO PROGRESS: at example #40000, processed 664500 words (1368097/s), 27517 word types, 40000 tags
2019-05-20 15:39:48,356 INFO PROGRESS: at example #50000, processed 831204 words (1351422/s), 31439 word types, 50000 tags
2019-05-20 15:39:48,474 INFO PROGRESS: at example #60000, processed 999270 words (1425773/s), 34971 word types, 60000 tags
2019-05-20 15:39:48,595 INFO PROGRESS: at example #70000, processed 1166581 words (1381434/s), 38029 word types, 70000 tags
2019-05-20 15:39:48,709 INFO PROGRESS: at example #80000, processed 1331917 words (1450900/s), 40998 word types, 80000 tags
2019-05-20 15:39:48,850 INFO PROGRESS: at example #90000, processed 1500483 words (1199681/s), 43763 word types, 90000 tags
2019-05-20 15:39:48,968 INFO PROGRESS: at example #100000, processed 1668223 words (1425485/s), 46284 word types, 100000 tags
2019-05-20 15:39:49,100 INFO PROGRESS: at example #110000, processed 1832073 words (1246089/s), 48598 word types, 110000 tags
2019-05-20 15:39:49,236 INFO PROGRESS: at example #120000, processed 1999604 words (1235473/s), 50894 word types, 120000 tags
2019-05-20 15:39:49,360 INFO PROGRESS: at example #130000, processed 2166458 words (1342288/s), 53063 word types, 130000 tags
2019-05-20 15:39:49,485 INFO PROGRESS: at example #140000, processed 2332035 words (1324079/s), 55163 word types, 140000 tags
2019-05-20 15:39:49,605 INFO PROGRESS: at example #150000, processed 2498794 words (1402007/s), 57258 word types, 150000 tags
2019-05-20 15:39:49,720 INFO PROGRESS: at example #160000, processed 2664993 words (1448274/s), 59151 word types, 160000 tags
2019-05-20 15:39:49,851 INFO PROGRESS: at example #170000, processed 2833858 words (1287963/s), 61142 word types, 170000 tags
2019-05-20 15:39:49,977 INFO PROGRESS: at example #180000, processed 3001865 words (1343356/s), 62966 word types, 180000 tags
2019-05-20 15:39:50,106 INFO PROGRESS: at example #190000, processed 3169739 words (1300939/s), 64843 word types, 190000 tags
2019-05-20 15:39:50,232 INFO collected 66527 word types and 200000 unique tags from a corpus of 200000 examples and 3335643 words
2019-05-20 15:39:50,233 INFO Loading a fresh vocabulary
2019-05-20 15:39:50,349 INFO effective_min_count=3 retains 26695 unique words (40% of original 66527, drops 39832)
2019-05-20 15:39:50,349 INFO effective_min_count=3 leaves 3286045 word corpus (98% of original 3335643, drops 49598)
2019-05-20 15:39:50,446 INFO deleting the raw counts dictionary of 66527 items
2019-05-20 15:39:50,448 INFO sample=0.001 downsamples 35 most-common words
2019-05-20 15:39:50,448 INFO downsampling leaves estimated 3004103 word corpus (91.4% of prior 3286045)
2019-05-20 15:39:50,547 INFO estimated required memory for 26695 words and 300 dimensions: 317415500 bytes
2019-05-20 15:39:50,547 INFO resetting layer weights
2019-05-20 15:39:54,690 WARNING this function is deprecated, use smart_open.open instead
2019-05-20 15:39:54,837 INFO training model with 4 workers on 26695 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
Traceback (most recent call last):
  File ""run.py"", line 76, in <module>
    run_ner_process()
  File ""run.py"", line 57, in run_ner_process
    doc2vec_test.doc2vec_create3()
  File ""C:\_XProject\similarity\doc2vec_test.py"", line 48, in doc2vec_create3
    model = Doc2Vec(corpus_file=file_name, dm=1, vector_size=300, window=5, min_count=3, workers=multiprocessing.cpu_count())
  File ""C:\_XProject\_envx\lib\site-packages\gensim\models\doc2vec.py"", line 620, in __init__
    end_alpha=self.min_alpha, callbacks=callbacks)
  File ""C:\_XProject\_envx\lib\site-packages\gensim\models\doc2vec.py"", line 814, in train
    queue_factor=queue_factor, report_delay=report_delay, callbacks=callbacks, **kwargs)
  File ""C:\_XProject\_envx\lib\site-packages\gensim\models\base_any2vec.py"", line 1081, in train
    **kwargs)
  File ""C:\_XProject\_envx\lib\site-packages\gensim\models\base_any2vec.py"", line 556, in train
    corpus_file, cur_epoch=cur_epoch, total_examples=total_examples, total_words=total_words, **kwargs)
  File ""C:\_XProject\_envx\lib\site-packages\gensim\models\base_any2vec.py"", line 405, in _train_epoch_corpusfile
    from gensim.models.word2vec_corpusfile import CythonVocab
ModuleNotFoundError: No module named 'gensim.models.word2vec_corpusfile'
```


#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

```python

import os
import multiprocessing
from collections import OrderedDict

from gensim import corpora
from gensim.models.doc2vec import Doc2Vec, TaggedDocument
from gensim.utils import save_as_line_sentence

TEMP_FOLDER=""""
    common_texts = [""Hırvatistan,diğer,şehir,hiçbir,aday,salt,zafer,el,et"".split("",""), 
    ""seçim,toplam,46 bin 325,aday,yarış"".split("",""), 
    ""AB,milletvekili,Makedonya,üyelik,müzakere,başla,çağrı"".split("","")]
#total 200.000 lines
save_as_line_sentence(common_texts, os.path.join(TEMP_FOLDER, 'corpus.txt'))
file_name = os.path.join(TEMP_FOLDER, 'corpus.txt')
model = Doc2Vec(corpus_file=file_name, dm=0, vector_size=10, window=5, min_count=3, workers=multiprocessing.cpu_count())
#model = Doc2Vec(corpus_file=file_name, epochs=5, vector_size=300, workers=multiprocessing.cpu_count())
model.save(os.path.join(TEMP_FOLDER, 'doc2vec_dm_1.model'))
```

corpus.txt file content after ""save_as_line_sentence"" (200.000 lines of tokenized sentences)
~~~
Hırvat yerel seçim ikinci tur kal
sonuç başta büyük şehir ol üzere açık fark bir zafer el et göster
seçim gözlemci seçim gün sandık merkez kampanya yasak del bil
...
~~~


#### Versions

Please provide the output of:

```python
>>> import platform; print(platform.platform())
Windows-10-10.0.16299-SP0
>>> import sys; print(""Python"", sys.version)
Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.16.3
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.2.1
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.7.3
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION -1
>>>
```
"
479,https://github.com/RaRe-Technologies/gensim/issues/2499,2499,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",open,2019-05-23 14:21:40+00:00,,MemoryError when using ldaseqmodel.doc_topics ,"I am trying to create a matrix/data frame with the topic distribution over documents for all documents, since these are needed to find what documents have the highest prevalence of a given topic. However, I get a MemoryError when I use ldaseqmodel.doc_topics(). 

I am using a list comprehension to get the topic distributions for each document. 

```python
prop = [ldaseq.doc_topics(n) for n in np.arange(start,end,1)]
```

I get the following error: 

```
 File ""/home/jnava/utilities/anaconda3/lib/python3.7/site-packages/gensim/models/ldaseqmodel.py"", line 575, in doc_topics
    doc_topic = np.copy(self.gammas)
 File ""/home/jnava/utilities/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py"", line 733, in copy
    return array(a, order=order, copy=True)
MemoryError 
```

I have broken up the task into chunks such that I am only doing a batch of n documents in a list comprehension, say n=500, instead of all documents in a single list comprehension. This works sometimes, but not with all data sets/models. 

I have also tried a for loop and get the same error. "
480,https://github.com/RaRe-Technologies/gensim/issues/2500,2500,[],closed,2019-05-24 18:42:56+00:00,,Mallet wrapper raises RuntimeError: invalid doc topics format when prefix path is passed,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I am loading a saved mallet wrapper model to generate topics for given text. I pass prefix when I train the model. When I load the model, I am getting runtimeerror raised by read_doctopics() in ldamallet.py module. 

#### Steps/code/corpus to reproduce
```python
import pandas as pd
import numpy as np
import re
import gensim
import gensim.corpora as corpora
from gensim.utils import simple_preprocess
from gensim.models import CoherenceModel
import os
import joblib

lemmatized_words = [['cold', 'spring',  'april',  'united',  'state',  'outstanding',  'potential',  become',  'world',  'leader',  'wind',  'energy'],  ['lag',  'china',  'european',  'union',  'china',  currently',  'lead',  'world',  'wind',  'power',  'country',  'project',  'percent',  'energy',  'market',  supply'],  ['renewable',  'energy',  'accord',  'wind',  'europe',  'report',  'wind',  'power',  'european',  union',  'generate',  'enough',  'electricity',  'support',  'percent',  'total',  'energy'], [ 'consumption',  french',  'president',  'emmanuel',  'macron',  'promise',  'france'], [ 'alone',  'would',  'triple',  'wind',  power',  'capacity',  'unite',  'state',  'produce',  'percent',  'total',  'electricity',  'wind',  'power',  fall',  china',  'catch',  'answer',  'may',  'seem',  'simple'],  ['instal',  'wind',  'farm',  'optimize',  performance',  'wind',  'turbine',  'already',  'create',  'job',  'strong',  'diverse',  'economy',  sustainable',  'future',  'come',  'generation',  'cloudvisit'],  ['invest',  'vision',  'develop',  'wind',  turbine',  'maintenance',  'software',  'make',  'future',  'possible',  'wind',  'growth',  'unite',  'state',  wind',  'energy',  'growing',  'hold',  'notable',  'potential',  'nation'],  ['first',  'utility',  'scale',  offshore',  'wind',  'energy',  'project',  'vineyard',  'wind',  'recently',  'award',  'year',  'contract',  provide',  'electricity',  'approximately',  'third',  'cost',  'renewable',  'cloudvisit'], ['wind',  'turbine',  maintenance',  'software',  'help',  'support',  'renewable',  'affordable',  'electricity',  'nationwide',  cloudvisit',  'wind',  'turbine',  'maintenance',  'software',  'enable',  'remote',  'inspection',  'wind',  farm',  'inspector']]

def find_optimum_model(lemmatized_words):
    id2word = corpora.Dictionary(lemmatized_words)
    all_corpus = [id2word.doc2bow(text) for text in lemmatized_words]

    def compute_coherence_values(dictionary, all_corpus, texts, limit, start=2, step=3):
        coherence_values = []
        model_list = []

        #For two lines below update with your path to new_mallet
        os.environ.update({'MALLET_HOME':r'C:\\users\\axk0er8\\Sentiment_Analysis_Working\\new_mallet\\mallet-2.0.8'})
        mallet_path = r'C:\\users\\axk0er8\\Sentiment_Analysis_Working\\new_mallet\\mallet-2.0.8\\bin\\mallet.bat'
        prefix_path = r'C:\\users\\axk0er8\\Sentiment_Analysis_Working\\NewsSentimentAnalysis\\mallet_temp\\'
        for num_topics in range(start, limit, step):
            model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=all_corpus, num_topics=num_topics, id2word=dictionary,
                                             prefix=prefix_path, random_seed=42)

            model_list.append(model)
            coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')
            coherence_values.append(coherencemodel.get_coherence())

        return model_list, coherence_values

    model_list, coherence_values = compute_coherence_values(dictionary=id2word, all_corpus=all_corpus,texts=lemmatized_words,start=2,
                                                            limit=40, step=6)
    model_values_df = pd.DataFrame({'model_list':model_list,'coherence_values':coherence_values})

    optimal_model = model_values_df.loc[model_values_df['coherence_values'].idxmax()]['model_list']

    joblib.dump(all_corpus,'corpus.pkl')
    joblib.dump(id2word,'id2word_dictionary_mallet.pkl')
    joblib.dump(optimal_model,'optimal_ldamallet_model.pkl')

def generate_dominant_topic(lemmatized_words):
    id2word = joblib.load('id2word_dictionary_mallet.pkl')
    new_corpus = [id2word.doc2bow(text) for text in lemmatized_words]
    optimal_model = joblib.load('optimal_ldamallet_model.pkl')


    def format_topics_sentences(ldamodel, new_corpus):
        sent_topics_df = pd.DataFrame()
        for i, row in enumerate(ldamodel[new_corpus]):
            row = sorted(row, key=lambda x: (x[1]), reverse=True)
            for j, (topic_num, prop_topic) in enumerate(row):
                if j == 0:
                    wp = ldamodel.show_topic(topic_num)
                    topic_keywords = "", "".join([word for word, prop in wp])
                    sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]),
                                                           ignore_index=True)
                else:
                    break
        sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']
        return (sent_topics_df)
    
    df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, new_corpus=new_corpus)
    return (df_topic_sent_keywords)


find_optimum_model(lemmatized_words)

generate_dominant_topic(lemmmatized_words)
```
Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-9-5a39311bf01f> in <module>
----> 1 generate_dominant_topic(lemmatized_words)

<ipython-input-2-fcbf87d7c75b> in generate_dominant_topic(lemmatized_words)
     55         return (sent_topics_df)
     56 
---> 57     df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, new_corpus=new_corpus)
     58     return (df_topic_sent_keywords)

<ipython-input-2-fcbf87d7c75b> in format_topics_sentences(ldamodel, new_corpus)
     42     def format_topics_sentences(ldamodel, new_corpus):
     43         sent_topics_df = pd.DataFrame()
---> 44         for i, row in enumerate(ldamodel[new_corpus]):
     45             row = sorted(row, key=lambda x: (x[1]), reverse=True)
     46             for j, (topic_num, prop_topic) in enumerate(row):

~\AppData\Local\Continuum\anaconda3\lib\site-packages\gensim\models\wrappers\ldamallet.py in __getitem__(self, bow, iterations)
    323         logger.info(""inferring topics with MALLET LDA '%s'"", cmd)
    324         check_output(args=cmd, shell=True)
--> 325         result = list(self.read_doctopics(self.fdoctopics() + '.infer'))
    326         return result if is_corpus else result[0]
    327 

~\AppData\Local\Continuum\anaconda3\lib\site-packages\gensim\models\wrappers\ldamallet.py in read_doctopics(self, fname, eps, renorm)
    562                                     count += 1
    563                     else:
--> 564                         raise RuntimeError(""invalid doc topics format at line %i in %s"" % (lineno + 1, fname))
    565 
    566                 if renorm:

RuntimeError: invalid doc topics format at line 2 in C:\\users\\axk0er8\\Sentiment_Analysis_Working\\NewsSentimentAnalysis\\mallet_temp\\doctopics.txt.infer

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
Windows-10-10.0.16299-SP0
Python 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]
NumPy 1.16.2
SciPy 1.2.1
gensim 3.7.3
FAST_VERSION -1"
481,https://github.com/RaRe-Technologies/gensim/issues/2501,2501,[],closed,2019-05-24 21:54:12+00:00,,All vectors in lsi_model[corpus_tfidf] are not of num_topics length passed to LsiModel,"I am using a combination of TF-IDF and LSI as shown in this [tutorial](https://radimrehurek.com/gensim/tut2.html) to arrive at `corpus_lsi = lsi[corpus_tfidf]`. I am then in need of unpacking this TransformedCorpus into a num_documents x num_topics matrix, but am unable to do so because not all of the individual vectors in `corpus_lsi` end up being the length of `num_topics` that I defined while using `models.LsiModel`.

I have opted to use 1000 topics but, 4 out of 5 times, each document vector does not have 1000 elements. Instead, 1 or 2 will be 999 or 998 elements in length. I attempted to resolve this by setting `num_topics` to 990 but the issue persists just the same at a lower value. I am unable to provide the dataset I am using, but below is the code I have written:

This works just fine:
```
id2word = corpora.Dictionary(text_dict)
texts = text_dict

# Term Document Frequency (bag of words)
corpus = [id2word.doc2bow(text) for text in texts]

# TF-IDF
tfidf = TfidfModel(corpus, smartirs='ntc')
corpus_tfidf = tfidf[corpus]

# LSI: 1000 Topics
lsi_model = LsiModel(corpus=corpus_tfidf, id2word=id2word,
                     num_topics=1000, decay=0.5)

corpus_lsi = lsi_model[corpus_tfidf]
```

Converting `corpus_lsi` to a matrix runs without error, but does not work as expected:
```
static_corpus_lsi = np.array([[j[1] for j in i] for i in corpus_lsi])
```

Most of the time, the result is that `static_corpus_lsi` is not of shape num_documents x 1000 as I expect them to be. Some document vectors are of length 1000 and 1 or 2 are of slightly less length.

Versions Info:
```
Linux-4.14.79+-x86_64-with-Ubuntu-18.04-bionic
('Python', '2.7.15rc1 (default, Nov 12 2018, 14:31:15) \n[GCC 7.3.0]')
('NumPy', '1.16.3')
('SciPy', '1.2.1')
('gensim', '3.6.0')
('FAST_VERSION', 1)
```
"
482,https://github.com/RaRe-Technologies/gensim/issues/2502,2502,"[{'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}, {'id': 1583467927, 'node_id': 'MDU6TGFiZWwxNTgzNDY3OTI3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/help%20wanted', 'name': 'help wanted', 'color': '1d76db', 'default': True, 'description': ''}]",closed,2019-05-28 05:23:27+00:00,,High RAM usage when loading FastText Model on Google Colab,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I want to load FastText pre-trained model using Gensim. I run this script in Google Colab with ~12GB RAM but it always crashes, with Colab's message: ""Your session crashed after using all available RAM.""

#### Steps/code/corpus to reproduce

```
# Download dan unzip model
!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz
!gunzip -k cc.en.300.bin.gz

# Install / Upgrade Gensim
!pip install --upgrade gensim

# Load model method 1 
from gensim.models.fasttext import FastText, load_facebook_vectors
model = load_facebook_vectors(""cc.en.300.bin.gz"")

# Load model method 2 
from gensim.models.fasttext import FastText
model = FastText.load_fasttext_format('cc.en.300.bin')
```

I didn't use both methods at the same time, I only use one of them. Then, I restart the runtime to clear the memory if I want to run another method. I use method 2 to avoid issue #2378. Both method crash Colab by using all available RAM. At first, I think the problem is the model but if I check the size each model, their size is far below 12GB:

```
cc.en.300.bin.gz     4.19 GB
cc.en.300.bin        6.74 GB
```

and if I load using FastText Python module, it works:

```
# Install FasText
!git clone https://github.com/facebookresearch/fastText.git
!pip install fastText/.
# Load model
import fastText
model = fastText.load_model(""cc.en.300.bin"")
```

#### Versions

Linux-4.14.79+-x86_64-with-Ubuntu-18.04-bionic
Python 3.6.7 (default, Oct 22 2018, 11:32:17) 
[GCC 8.2.0]
NumPy 1.16.3
SciPy 1.3.0
gensim 3.7.3
FAST_VERSION 1"
483,https://github.com/RaRe-Technologies/gensim/issues/2503,2503,[],open,2019-05-28 05:51:48+00:00,,Handling of max_probability in get_term_topics is counter-intuitive,"Context: Using the 20newsgroups dataset for training an LDA model.

```python
from gensim.corpora import Dictionary
from gensim.models import ldamodel
from gensim.parsing.preprocessing import preprocess_string
import gensim.downloader
import numpy

corpus = gensim.downloader.load(""20-newsgroups"")

# pick two distinct newsgroups
texts = [
    preprocess_string(text['data'])
    for text in corpus
    if text['topic'] in ('soc.religion.christian', 'talk.politics.guns')
]

dictionary = Dictionary(texts)
dictionary.filter_extremes(no_above=0.1, no_below=10)
corpus = [dictionary.doc2bow(text) for text in texts]

numpy.random.seed(1) # setting random seed to get the same results each time.
model = ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=2, alpha='asymmetric', passes=5)
```

The model distinguishes between the two topics reasonably well:

```python
>>> model.show_topics()
[(0,
  '0.007*""homosexu"" + 0.005*""paul"" + 0.004*""scriptur"" + 0.004*""hell"" + 0.004*""cathol"" + 0.004*""lord"" + 0.004*""belief"" + 0.003*""mari"" + 0.003*""heaven"" + 0.003*""natur""'),
 (1,
  '0.006*""firearm"" + 0.004*""batf"" + 0.004*""stratu"" + 0.004*""file"" + 0.004*""crime"" + 0.003*""koresh"" + 0.003*""crimin"" + 0.003*""handgun"" + 0.003*""amend"" + 0.003*""polic""')]
```

However, the get_term_topics function does not return any topics given an in-vocabulary term:

```python
model.get_term_topics('firearm')
```

From the topics list above, we can see that the coefficients are relatively low. So, a user may be tempted to decrease the minimum_probability parameter to 0 to skip thresholding:

```python
model.get_term_topics('firearm', minimum_probability=0)
```

Unfortunately, this does not return any topics either, because of [this code](https://github.com/RaRe-Technologies/gensim/blob/8741d1c674e505a2268bc9ef08e916f5c8a7e403/gensim/models/ldamodel.py#L1313):

```python
        if minimum_probability is None:
            minimum_probability = self.minimum_probability
        minimum_probability = max(minimum_probability, 1e-8)  # never allow zero values in sparse output
        if minimum_phi_value is None:
            minimum_phi_value = self.minimum_probability
        minimum_phi_value = max(minimum_phi_value, 1e-8)  # never allow zero values in sparse output
```

This behavior is preventing us from demonstrating the get_term_topics in our tutorials. Is it possible to review it? For example, if the user requests a zero minimum_probability, why don't we just respect that?"
484,https://github.com/RaRe-Technologies/gensim/issues/2504,2504,[],closed,2019-05-28 17:44:13+00:00,,Getting Segmentation fault: 11 while running cosine similarity function on a bunch of documents.,"I'm using gensim to perform cosine similarity on a bunch of documents getting the Segmentation fault: 11. Could you please help me to resolve this issue?

**Error Trace:**
```
2019-05-28 15:11:22,779 : INFO : creating sparse index
2019-05-28 15:11:22,779 : INFO : creating sparse matrix from corpus
2019-05-28 15:11:22,780 : INFO : PROGRESS: at document #0/546
2019-05-28 15:11:22,790 : INFO : created <546x430 sparse matrix of type '<class 'numpy.float32'>'
        with 2191 stored elements in Compressed Sparse Row format>
2019-05-28 15:11:22,791 : INFO : creating sparse shard #0
2019-05-28 15:11:22,791 : INFO : saving index shard to /var/folders/s_/jrkppgc11h97hmtcs00cy6bc0000gn/T/simserver93714a.0
2019-05-28 15:11:22,791 : INFO : saving SparseMatrixSimilarity object under /var/folders/s_/jrkppgc11h97hmtcs00cy6bc0000gn/T/simserver93714a.0, separately None
2019-05-28 15:11:22,794 : INFO : saved /var/folders/s_/jrkppgc11h97hmtcs00cy6bc0000gn/T/simserver93714a.0
2019-05-28 15:11:22,794 : INFO : loading SparseMatrixSimilarity object from /var/folders/s_/jrkppgc11h97hmtcs00cy6bc0000gn/T/simserver93714a.0
2019-05-28 15:11:22,794 : INFO : loaded /var/folders/s_/jrkppgc11h97hmtcs00cy6bc0000gn/T/simserver93714a.0
**Segmentation fault: 11**
```
**Code**
```
    def cosine_similarity(self,documents, query_docs=None, task='pairwise_similarity', metric_threshold=0.85, num_best=20):
        self.log('computing cosine similarity started')
        # Compute cosine similarity between the query_docs and the documents.
        dictionary = Dictionary(documents)
        corpus = [dictionary.doc2bow(doc) for doc in documents]
        # index_tmpfile = get_tmpfile(""index"")
        index = Similarity(output_prefix=None,corpus=corpus, num_best=num_best, num_features=len(dictionary))
        similarities = []
        if task == 'pairwise_similarity':
            self.log('computing pairwise_similarity')
            for sim in index:
                similarities.append(sim)
        elif task == 'batch_query':
            self.log('computing similarity using batch query')

            query_docs = [self.tfidf[self.dictionary.doc2bow(doc)] for doc in query_docs]
            for sim in index[query_docs]:
                similarities.append(sim)
        # filter results based on metric threshold
        filtered_results = []
        for ind_sim in similarities:
            filtered_results.append([item[0] for item in ind_sim if item[1] >= metric_threshold])
        self.log('computing cosine similarity completed')
        return filtered_results
```"
485,https://github.com/RaRe-Technologies/gensim/issues/2506,2506,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}, {'id': 1583467927, 'node_id': 'MDU6TGFiZWwxNTgzNDY3OTI3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/help%20wanted', 'name': 'help wanted', 'color': '1d76db', 'default': True, 'description': ''}, {'id': 1602334472, 'node_id': 'MDU6TGFiZWwxNjAyMzM0NDcy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20MEDIUM', 'name': 'impact MEDIUM', 'color': '7af49f', 'default': False, 'description': 'Big annoyance for affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",closed,2019-05-29 07:49:41+00:00,,LsiTransformer is giving a ValueError,"#### Problem description

I'm trying to use the class `gensim.sklearn_api.lsimodel.LsiTransformer` according to the documentation, but it results in a ValueError with the following stack trace:

```
Traceback (most recent call last):
  File ""/home/rob/code_projects/gensim_test/test.py"", line 14, in <module>
    corpus_lsi_space = lsi_model.fit_transform(tfidf_features)
  File ""/home/rob/venv/pex/gensim_test/lib/python3.6/site-packages/sklearn/base.py"", line 553, in fit_transform
    return self.fit(X, **fit_params).transform(X)
  File ""/home/rob/venv/pex/gensim_test/lib/python3.6/site-packages/gensim/sklearn_api/lsimodel.py"", line 133, in transform
    distribution = [matutils.sparse2full(self.gensim_model[doc], self.num_topics) for doc in docs]
  File ""/home/rob/venv/pex/gensim_test/lib/python3.6/site-packages/gensim/sklearn_api/lsimodel.py"", line 133, in <listcomp>
    distribution = [matutils.sparse2full(self.gensim_model[doc], self.num_topics) for doc in docs]
  File ""/home/rob/venv/pex/gensim_test/lib/python3.6/site-packages/gensim/models/lsimodel.py"", line 583, in __getitem__
    vec = matutils.corpus2csc(bow, num_terms=self.num_terms, dtype=self.projection.u.dtype)
  File ""/home/rob/venv/pex/gensim_test/lib/python3.6/site-packages/gensim/matutils.py"", line 158, in corpus2csc
    doc_indices, doc_data = zip(*doc) if doc else ([], [])
  File ""/home/rob/venv/pex/gensim_test/lib/python3.6/site-packages/scipy/sparse/base.py"", line 287, in __bool__
    raise ValueError(""The truth value of an array with more than one ""
ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().
```

It could be that I'm misunderstanding something or that the documentation is wrong, but I'm pretty sure this is a bug.

#### Steps/code/corpus to reproduce

Here is a minimal example to reproduce the above stack trace:

```python
from sklearn.feature_extraction.text import TfidfVectorizer
from gensim.sklearn_api.lsimodel import LsiTransformer


docs = [
    'This is a doc with nothing special',
    'This is another doc with absolutely nothing special',
    'Here we go with another boring doc that has some generic words'
]

vectorizer = TfidfVectorizer()
tfidf_features = vectorizer.fit_transform(docs)
lsi_model = LsiTransformer(num_topics=5)
corpus_lsi_space = lsi_model.fit_transform(tfidf_features)
```

#### Versions

```python
Linux-4.15.0-50-generic-x86_64-with-Ubuntu-18.04-bionic
Python 3.6.7 (default, Oct 22 2018, 11:32:17) 
[GCC 8.2.0]
NumPy 1.16.4
SciPy 1.3.0
gensim 3.7.3
FAST_VERSION 1
```
"
486,https://github.com/RaRe-Technologies/gensim/issues/2507,2507,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-05-29 11:08:35+00:00,,Dictionary Error,"#### Problem description
I got this bug that didn't happen before. Basically, I want to compute coherence score for each topic I've gathered from different LDA models.

#### Steps/code/corpus to reproduce

```
data = pd.read_csv(""hasil_praproses_2.csv"")
texts = [doc.split() for doc in data['finals'].values.tolist()]

dictionary = Dictionary(texts)
dictionary.filter_extremes(no_below=5, no_above=0.9)
dictionary.compactify()
dictionary.save(""dictionary_unvised.dict"")
dictionary = Dictionary.load(""dictionary_unvised.dict"")
corpus = [dictionary.doc2bow(text) for text in texts]

from gensim.models.ldamodel import LdaModel
from gensim.models.coherencemodel import CoherenceModel

import logging
logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)
logging.root.level = logging.INFO

passes = 20
iterations = 800
n_topics = [5,6,7]

for n in n_topics:    
    lda = LdaModel(corpus,
                   num_topics=n,
                   id2word=dictionary,
                   passes=passes,
                   iterations=iterations,
                   random_state=7,
                   alpha='auto',
                   eta='auto')
    
    topic_bow = lda.show_topics(num_topics=n, num_words = 20, formatted=False)
    top = [[w[0] for w in topic] for num, topic in topic_bow]
    topics_list.append(top)

flat_topics = [topic for topics in topics_list for topic in topics]

cm = CoherenceModel(topics=flat_topics[0], corpus=corpus dictionary=dictionary, coherence='u_mass')
cm.get_coherence()
```
An example of one of the topics:
```
flat_topics[0]
['traffic', 'improve', 'good', 'work', 'growth', 'mopac', 'infrastructure', 'downtown', 'issue', 'public_transportation', 'affordable_housing', 'problem', 'traffic_flow', 'plan', 'traffic_congestion', 'planning', 'fix_traffic', 'transportation', 'major', 'business']
```

And I keep getting this error:
```
KeyError                                  Traceback (most recent call last)
~/anaconda3/lib/python3.6/site-packages/gensim/models/coherencemodel.py in _ensure_elements_are_ids(self, topic)
    342         try:
--> 343             return np.array([self.dictionary.token2id[token] for token in topic])
    344         except KeyError:  # might be a list of token ids already, but let's verify all in dict

~/anaconda3/lib/python3.6/site-packages/gensim/models/coherencemodel.py in <listcomp>(.0)
    342         try:
--> 343             return np.array([self.dictionary.token2id[token] for token in topic])
    344         except KeyError:  # might be a list of token ids already, but let's verify all in dict

KeyError: 't'

During handling of the above exception, another exception occurred:

KeyError                                  Traceback (most recent call last)
<ipython-input-30-8aee651e4ed2> in <module>()
      2                       corpus=corpus,
      3                       dictionary=dictionary,
----> 4                       coherence='u_mass')
      5 coba.get_coherence()

~/anaconda3/lib/python3.6/site-packages/gensim/models/coherencemodel.py in __init__(self, model, topics, texts, corpus, dictionary, window_size, keyed_vectors, coherence, topn, processes)
    215         self._accumulator = None
    216         self._topics = None
--> 217         self.topics = topics
    218 
    219         self.processes = processes if processes >= 1 else max(1, mp.cpu_count() - 1)

~/anaconda3/lib/python3.6/site-packages/gensim/models/coherencemodel.py in topics(self, topics)
    323             new_topics = []
    324             for topic in topics:
--> 325                 topic_token_ids = self._ensure_elements_are_ids(topic)
    326                 new_topics.append(topic_token_ids)
    327 

~/anaconda3/lib/python3.6/site-packages/gensim/models/coherencemodel.py in _ensure_elements_are_ids(self, topic)
    343             return np.array([self.dictionary.token2id[token] for token in topic])
    344         except KeyError:  # might be a list of token ids already, but let's verify all in dict
--> 345             topic = [self.dictionary.id2token[_id] for _id in topic]
    346             return np.array([self.dictionary.token2id[token] for token in topic])
    347 

~/anaconda3/lib/python3.6/site-packages/gensim/models/coherencemodel.py in <listcomp>(.0)
    343             return np.array([self.dictionary.token2id[token] for token in topic])
    344         except KeyError:  # might be a list of token ids already, but let's verify all in dict
--> 345             topic = [self.dictionary.id2token[_id] for _id in topic]
    346             return np.array([self.dictionary.token2id[token] for token in topic])
    347 

KeyError: 't'
```
#### Versions

Please provide the output of:

```
Linux-4.15.0-1032-gcp-x86_64-with-debian-stretch-sid
Python 3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) 
[GCC 7.2.0]
NumPy 1.14.3
SciPy 1.1.0
gensim 3.4.0
FAST_VERSION 1
```
"
487,https://github.com/RaRe-Technologies/gensim/issues/2508,2508,[],closed,2019-05-29 16:22:00+00:00,,FastText SkipGram Implementation Broken since 3.7.2,"The FastText implementation using skip-gram appears to be broken since 3.7.2. Below is the sample code I am using, which is almost identical to the example in the docs but with additional printed output. In v3.7.1, everything runs fine, but in subsequent versions, an IndexError occurs during train_sg_pair.

```python
# Sample Code
import sys
import gensim
from gensim.models import FastText
from gensim.test.utils import common_texts
print(f""Python {sys.version.split()[0]} | Gensim {gensim.__version__}"")

sim_word = ""computer""

print(""CBOW"")
cbow = FastText(size=4, window=3, min_count=1)
cbow.build_vocab(sentences=common_texts)
cbow.train(sentences=common_texts, total_examples=len(common_texts), epochs=10)
cbow_similarities = "" | "".join(
    [f""{word}: {sim:0.4f}"" for (word, sim) in cbow.most_similar(""computer"")]
)
print(f""{sim_word}:: {cbow_similarities}"")

print(""Skip-Gram"")
sg = FastText(size=4, window=3, min_count=1,
              sg=1)      # only difference!
sg.build_vocab(sentences=common_texts)
sg.train(sentences=common_texts, total_examples=len(common_texts), epochs=10)
sg_similarities = "" | "".join(
    [f""{word}: {sim:0.4f}"" for (word, sim) in sg.most_similar(""computer"")]
)
print(f""{sim_word}:: {sg_similarities}"")
```

# Works in 3.7.1

```
Python 3.7.3 | Gensim 3.7.1
CBOW
<input>:16: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).
computer:: graph: 0.6275 | time: 0.4795 | interface: 0.3012 | user: 0.1459 | trees: 0.0747 | system: -0.1502 | human: -0.2375 | survey: -0.3557 | response: -0.5107 | eps: -0.5126
Skip-Gram
<input>:27: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).
computer:: graph: 0.6274 | time: 0.4800 | interface: 0.3014 | user: 0.1466 | trees: 0.0741 | system: -0.1501 | human: -0.2371 | survey: -0.3564 | response: -0.5109 | eps: -0.5127
```

# Fails in 3.7.3

```
Python 3.7.3 | Gensim 3.7.3
CBOW
C:\Users\yzxs008\Documents\ml_env\lib\site-packages\gensim\models\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.
  ""C extension not loaded, training will be slow. ""
<input>:16: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).
computer:: human: 0.8081 | interface: 0.5414 | graph: 0.4632 | time: 0.3914 | survey: 0.0709 | eps: -0.1581 | minors: -0.1638 | trees: -0.2344 | user: -0.4144 | system: -0.4159
Skip-Gram
Exception in thread Thread-47:
Traceback (most recent call last):
  File ""C:\Users\yzxs008\AppData\Local\Programs\Python\Python37\lib\threading.py"", line 917, in _bootstrap_inner
    self.run()
  File ""C:\Users\yzxs008\AppData\Local\Programs\Python\Python37\lib\threading.py"", line 865, in run
    self._target(*self._args, **self._kwargs)
  File ""C:\Users\yzxs008\Documents\ml_env\lib\site-packages\gensim\models\base_any2vec.py"", line 211, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""C:\Users\yzxs008\Documents\ml_env\lib\site-packages\gensim\models\fasttext.py"", line 834, in _do_train_job
    tally += train_batch_sg(self, sentences, alpha, work, neu1)
  File ""C:\Users\yzxs008\Documents\ml_env\lib\site-packages\gensim\models\fasttext.py"", line 412, in train_batch_sg
    train_sg_pair(model, model.wv.index2word[word2.index], subwords_indices, alpha, is_ft=True)
  File ""C:\Users\yzxs008\Documents\ml_env\lib\site-packages\gensim\models\word2vec.py"", line 418, in train_sg_pair
    l1_ngrams = np_sum(context_vectors_ngrams[context_index[1:]], axis=0)
IndexError: too many indices for array
```"
488,https://github.com/RaRe-Technologies/gensim/issues/2509,2509,[],closed,2019-05-29 23:38:11+00:00,,Dictionary.filter_extremes does not work properly,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? What is the expected result? What are you seeing instead?

I am using this function to filter out low frequency and high frequency words. However, the result dictionary size does not match my expectation.
The word frequency and word count for the corpus is:
[(1, 1441563), (2, 211515), (3, 77050), (4, 38364), ...]
```
id2word = gensim.corpora.Dictionary(texts, prune_at=2e6)
id2word.filter_extremes(no_below=4, no_above=0.5, keep_n=None)
```
the removed word frequency and word count is
[(1, 1441563), (2, 211515), (3, 77050), (4, 9)]
I don't understand why there are 9 words that appear 4 times in the corpus are filtered out.

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

```python
import gensim, json


with open(bug_data_file, 'r', encoding='utf-8') as r:
    unique_texts = json.load(r)


def stat_list(item_list):
    dic = dict()
    for item in item_list:
        dic[item] = dic.get(item, 0) + 1
    return dic


def merge_count(to_dic, from_dic):
    for key, val in from_dic.items():
        to_dic[key] = to_dic.get(key, 0) + val

    
def stat_freq_count(vocab_freq):
    # return freq : # of words has this frequecy
    return stat_list(vocab_freq.values())


def stat_vocabulary_freq(texts):
    # compute the word frequency to facilitate vovabulary filtering
    vocab_freq = dict()
    for doc in texts:
        merge_count(vocab_freq, stat_list(doc))
    return vocab_freq


def _create_corpus_using(texts, id2word):
    # create corpus using the given dictionary
    # useful for creating corpus for subset of texts
    corpus = [id2word.doc2bow(text) for text in texts]
    filtered_corpus = list(item for item in corpus if item)
    print('raw text doc count:', len(texts), \
          'filtered:', len(filtered_corpus), \
          'ratio %.2f' % (len(filtered_corpus) / len(texts)))
    return filtered_corpus, id2word


def create_corpus(texts, filter_limit):
    # Create Dictionary
    # the vocabulary size should below  default keep_n=100k
    id2word = gensim.corpora.Dictionary(texts, prune_at=2e6)
    total = len(id2word)
    print('raw token count:', total)
    if filter_limit:
        no_below, no_above = filter_limit
        id2word.filter_extremes(no_below=no_below, no_above=no_above, keep_n=None)
        print('filter vocabulary with (no_below, no_above)', filter_limit)
        print('keep token count:', len(id2word), \
              'keep ratio %.2f' % (len(id2word) / total))
    # create corpus
    # Term Document Frequency
    return _create_corpus_using(texts, id2word)

### filter corpus
no_below = 4
no_above = 0.5
filtered_corpus, id2word = create_corpus(unique_texts, (no_below, no_above))

### before filtering
vocab_freq = stat_vocabulary_freq(unique_texts)
freq_count = stat_freq_count(vocab_freq)
sorted_fc = sorted(freq_count.items(), key=lambda x:x[0])
print('list of (word frequency, word count)')
print(sorted_fc)

### after filtering
print('expected vocabulary size:', sum(c for _, c in sorted_fc[no_below - 1:]))

chosen_vocab = set(id2word.values())
filtered_vf = dict()
for w, freq in vocab_freq.items():
    if w not in chosen_vocab:
        filtered_vf[w] = freq
sorted_fvf = sorted(stat_freq_count(filtered_vf).items(), key=lambda x:x[0])
print('list of (word frequency, word count)')
print(sorted_fvf)
filtered_w = list(v for v, f in filtered_vf.items() if f == 4)
print('filtered out word', filtered_w)
```

key message in the output
```
list of (word frequency, word count)
[(1, 1441563), (2, 211515), (3, 77050), (4, 38364), (5, 22585), ...]

raw token count: 1857642
filter vocabulary with (no_below, no_above) (4, 0.5)
keep token count: 127505 keep ratio 0.07

expected vocabulary size: 127514
list of (word frequency, word count)
[(1, 1441563), (2, 211515), (3, 77050), (4, 9)]
```

The result token count is 127505, however, I expect this number to be 127514 based on 4 and 0.5. The missing 9 words are all appeared 4 times in the corpus.

json file to the corpus is [here](https://drive.google.com/file/d/14FH4yu8aWyMiPS9xkNzSdac1FOHzditK/view?usp=sharing)

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```

Linux-4.4.0-130-generic-x86_64-with-debian-stretch-sid
Python 3.6.7 | packaged by conda-forge | (default, Feb 28 2019, 09:07:38) 
[GCC 7.3.0]
NumPy 1.16.2
SciPy 1.2.1
gensim 3.7.1
FAST_VERSION 0"
489,https://github.com/RaRe-Technologies/gensim/issues/2511,2511,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2019-05-30 04:48:32+00:00,,"Get rid of Python implementation of fastText, word2vec, doc2vec","We have Cython implementations for the above models, so that we fall back to Python when Cython is not available.

This is more hassle than it's worth, because:

1. The Python versions are too slow to be practical
2. We have to expend additional effort to test the Python versions (leading to bugs like this: https://github.com/RaRe-Technologies/gensim/issues/2508#issuecomment-497182316)
3. The Cython implementations are available most of the time. For people who don't have a compiler, we offer wheels.
"
490,https://github.com/RaRe-Technologies/gensim/issues/2512,2512,[],closed,2019-05-30 16:40:10+00:00,,Sparse Matrix is taking a huge memory while computing cosine similarity.,"**Sparse Matrix is taking a huge memory while computing cosine similarity and it's dead slow.**

**Memory Consumed : 17.93 GB**

Kindly help to resolve this issue.

**Code**

```
def cossim(documents, query_docs=None, task='pairwise_similarity', metric_threshold=0.85, num_best=20):
    logging.info('computing cosine similarity started')
    logging.info(
        'semantic matcher configuration :: task : {} metric_threshold: {} num_best: {}'.format(
            task, metric_threshold, num_best))
    # Compute cosine similarity between the query_docs and the documents.
    dictionary = Dictionary(documents)
    # dictionary.filter_extremes()
    tfidf = TfidfModel(dictionary=dictionary)
    corpus = [tfidf[dictionary.doc2bow(doc)] for doc in documents]
    # corpus = [dictionary.doc2bow(doc) for doc in documents]

    index_tmpfile = get_tmpfile(""index"")
    index = Similarity(output_prefix=index_tmpfile, corpus=corpus, num_best=num_best, num_features=len(dictionary),chunksize=2048)
    similarities = []
    if task == 'pairwise_similarity':
        logging.info('computing pairwise_similarity')
        for sim in index:
            similarities.append(sim)
    elif task == 'batch_query':
        logging.info('computing similarity using batch query')
        tfidf_query_docs = [tfidf[dictionary.doc2bow(doc)] for doc in query_docs]
        for sim in index[tfidf_query_docs]:
            similarities.append(sim)
    # filter results based on metric threshold
    filtered_results = []
    logging.info('filtering results based on metric threshold {}'.format(metric_threshold))
    for ind_sim in similarities:
        filtered_results.append([item[0] for item in ind_sim if item[1] >= metric_threshold])
    logging.info('computing cosine similarity completed')
```

**Log Trace:**

```
2019-05-30 22:00:32,133 : INFO : no.of records in the data set :: 4398258
2019-05-30 22:00:32,606 : INFO : no.of records in the data set after dropping null values :: 4166943
2019-05-30 22:00:33,279 : INFO : no.of records in the data set after dropping duplicate values :: 101926
2019-05-30 22:00:43,623 : INFO : no.of records in the normalized data set :: 101926
2019-05-30 22:00:43,855 : INFO : computing cosine similarity started
2019-05-30 22:00:43,855 : INFO : semantic matcher configuration :: task : batch_query metric_threshold: 0.85 num_best: 20
2019-05-30 22:00:43,855 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2019-05-30 22:00:43,941 : INFO : adding document #10000 to Dictionary(2019 unique tokens: ['bracket', 'frame', 'front', 'instal', 'licens']...)
2019-05-30 22:00:44,027 : INFO : adding document #20000 to Dictionary(2963 unique tokens: ['bracket', 'frame', 'front', 'instal', 'licens']...)
2019-05-30 22:00:44,109 : INFO : adding document #30000 to Dictionary(3591 unique tokens: ['bracket', 'frame', 'front', 'instal', 'licens']...)
2019-05-30 22:00:44,194 : INFO : adding document #40000 to Dictionary(4196 unique tokens: ['bracket', 'frame', 'front', 'instal', 'licens']...)
2019-05-30 22:00:44,278 : INFO : adding document #50000 to Dictionary(4807 unique tokens: ['bracket', 'frame', 'front', 'instal', 'licens']...)
2019-05-30 22:00:44,361 : INFO : adding document #60000 to Dictionary(5258 unique tokens: ['bracket', 'frame', 'front', 'instal', 'licens']...)
2019-05-30 22:00:44,439 : INFO : adding document #70000 to Dictionary(5658 unique tokens: ['bracket', 'frame', 'front', 'instal', 'licens']...)
2019-05-30 22:00:44,519 : INFO : adding document #80000 to Dictionary(6350 unique tokens: ['bracket', 'frame', 'front', 'instal', 'licens']...)
2019-05-30 22:00:44,601 : INFO : adding document #90000 to Dictionary(6953 unique tokens: ['bracket', 'frame', 'front', 'instal', 'licens']...)
2019-05-30 22:00:44,649 : INFO : built Dictionary(7160 unique tokens: ['bracket', 'frame', 'front', 'instal', 'licens']...) from 95908 documents (total 283699 corpus positions)
2019-05-30 22:00:47,942 : INFO : starting similarity index under /var/folders/s_/jrkppgc11h97hmtcs00cy6bc0000gn/T/index
2019-05-30 22:00:49,742 : INFO : PROGRESS: fresh_shard size=10000
2019-05-30 22:00:51,522 : INFO : PROGRESS: fresh_shard size=20000
2019-05-30 22:00:53,401 : INFO : PROGRESS: fresh_shard size=30000
2019-05-30 22:00:53,931 : INFO : creating sparse index
2019-05-30 22:00:53,931 : INFO : creating sparse matrix from corpus
2019-05-30 22:00:53,932 : INFO : PROGRESS: at document #0/32768
2019-05-30 22:00:54,087 : INFO : PROGRESS: at document #10000/32768
2019-05-30 22:00:54,237 : INFO : PROGRESS: at document #20000/32768
2019-05-30 22:00:54,383 : INFO : PROGRESS: at document #30000/32768
2019-05-30 22:00:54,429 : INFO : created <32768x7160 sparse matrix of type '<class 'numpy.float32'>'
        with 100075 stored elements in Compressed Sparse Row format>
2019-05-30 22:00:54,429 : INFO : creating sparse shard #0
2019-05-30 22:00:54,430 : INFO : saving index shard to /var/folders/s_/jrkppgc11h97hmtcs00cy6bc0000gn/T/index.0
2019-05-30 22:00:54,430 : INFO : saving SparseMatrixSimilarity object under /var/folders/s_/jrkppgc11h97hmtcs00cy6bc0000gn/T/index.0, separately None
2019-05-30 22:00:54,435 : INFO : saved /var/folders/s_/jrkppgc11h97hmtcs00cy6bc0000gn/T/index.0
2019-05-30 22:00:54,436 : INFO : loading SparseMatrixSimilarity object from /var/folders/s_/jrkppgc11h97hmtcs00cy6bc0000gn/T/index.0
2019-05-30 22:00:54,440 : INFO : loaded /var/folders/s_/jrkppgc11h97hmtcs00cy6bc0000gn/T/index.0
2019-05-30 22:00:54,485 : INFO : PROGRESS: fresh_shard size=0
2019-05-30 22:00:56,476 : INFO : PROGRESS: fresh_shard size=10000
2019-05-30 22:00:58,442 : INFO : PROGRESS: fresh_shard size=20000
2019-05-30 22:01:00,380 : INFO : PROGRESS: fresh_shard size=30000
2019-05-30 22:01:00,899 : INFO : creating sparse index
2019-05-30 22:01:00,899 : INFO : creating sparse matrix from corpus
2019-05-30 22:01:00,899 : INFO : PROGRESS: at document #0/32768
2019-05-30 22:01:01,047 : INFO : PROGRESS: at document #10000/32768
2019-05-30 22:01:01,186 : INFO : PROGRESS: at document #20000/32768
2019-05-30 22:01:01,325 : INFO : PROGRESS: at document #30000/32768
2019-05-30 22:01:01,368 : INFO : created <32768x7160 sparse matrix of type '<class 'numpy.float32'>'
        with 97181 stored elements in Compressed Sparse Row format>
2019-05-30 22:01:01,368 : INFO : creating sparse shard #1
2019-05-30 22:01:01,368 : INFO : saving index shard to /var/folders/s_/jrkppgc11h97hmtcs00cy6bc0000gn/T/index.1
2019-05-30 22:01:01,368 : INFO : saving SparseMatrixSimilarity object under /var/folders/s_/jrkppgc11h97hmtcs00cy6bc0000gn/T/index.1, separately None
2019-05-30 22:01:01,375 : INFO : saved /var/folders/s_/jrkppgc11h97hmtcs00cy6bc0000gn/T/index.1
2019-05-30 22:01:01,375 : INFO : loading SparseMatrixSimilarity object from /var/folders/s_/jrkppgc11h97hmtcs00cy6bc0000gn/T/index.1
2019-05-30 22:01:01,378 : INFO : loaded /var/folders/s_/jrkppgc11h97hmtcs00cy6bc0000gn/T/index.1
2019-05-30 22:01:01,424 : INFO : PROGRESS: fresh_shard size=0
2019-05-30 22:01:03,198 : INFO : PROGRESS: fresh_shard size=10000
2019-05-30 22:01:05,090 : INFO : PROGRESS: fresh_shard size=20000
2019-05-30 22:01:06,891 : INFO : PROGRESS: fresh_shard size=30000
2019-05-30 22:01:06,960 : INFO : computing similarity using batch query
2019-05-30 22:01:10,174 : INFO : creating sparse index
2019-05-30 22:01:10,174 : INFO : creating sparse matrix from corpus
2019-05-30 22:01:10,175 : INFO : PROGRESS: at document #0/30372
2019-05-30 22:01:10,303 : INFO : PROGRESS: at document #10000/30372
2019-05-30 22:01:10,447 : INFO : PROGRESS: at document #20000/30372
2019-05-30 22:01:10,580 : INFO : PROGRESS: at document #30000/30372
2019-05-30 22:01:10,589 : INFO : created <30372x7160 sparse matrix of type '<class 'numpy.float32'>'
        with 82365 stored elements in Compressed Sparse Row format>
2019-05-30 22:01:10,589 : INFO : creating sparse shard #2
2019-05-30 22:01:10,589 : INFO : saving index shard to /var/folders/s_/jrkppgc11h97hmtcs00cy6bc0000gn/T/index.2
2019-05-30 22:01:10,589 : INFO : saving SparseMatrixSimilarity object under /var/folders/s_/jrkppgc11h97hmtcs00cy6bc0000gn/T/index.2, separately None
2019-05-30 22:01:10,594 : INFO : saved /var/folders/s_/jrkppgc11h97hmtcs00cy6bc0000gn/T/index.2
2019-05-30 22:01:10,594 : INFO : loading SparseMatrixSimilarity object from /var/folders/s_/jrkppgc11h97hmtcs00cy6bc0000gn/T/index.2
2019-05-30 22:01:10,597 : INFO : loaded /var/folders/s_/jrkppgc11h97hmtcs00cy6bc0000gn/T/index.2

```
"
491,https://github.com/RaRe-Technologies/gensim/issues/2514,2514,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}]",closed,2019-05-31 12:05:05+00:00,,Threre is no support for online learning in poincare model,"gensim supports online learning via `build_vocab` in fasttex, word2vec or other models.
But there is not `build_vocab` in poincare model.
Don't we need this mehotd or is it impossible to implement this feature ?
"
492,https://github.com/RaRe-Technologies/gensim/issues/2515,2515,[],open,2019-05-31 12:20:28+00:00,,poincare model does not work when workers > 1,"The document says `workers` (int, optional) – Number of threads to use for training the model.
https://radimrehurek.com/gensim/models/poincare.html
But there is no implementation for multi-threads in poincare model.
https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/poincare.py#L594"
493,https://github.com/RaRe-Technologies/gensim/issues/2517,2517,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-06-02 17:28:26+00:00,,gensim.models.Phraser score_item method returns a tuple instead of a float in gensim 3.7.3,"## Problem description

The gensim.models.Phraser score_item method returns a tuple instead of a float.
In gensim 3.4.0, the content of the score_item method of the Phraser class was:

```python

def score_item(self, worda, wordb, components, scorer):
        """"""score is retained from original dataset
        """"""
        try:
            return self.phrasegrams[tuple(components)][1]
        except KeyError:
            return -1
```

In gensim 3.7.3, the content of the score_item method of the Phraser class is:

```python

    def score_item(self, worda, wordb, components, scorer):
        """"""Score a bigram.

        Parameters
        ----------
        worda : str
            First word for comparison.
        wordb : str
            Second word for comparison.
        components : generator
            Contain phrases.
        scorer : {'default', 'npmi'}
            NOT USED.

        Returns
        -------
        float
            Score for given bi-gram, if bi-gram not presented in dictionary - return -1.

        """"""
        try:
            return self.phrasegrams[tuple(components)]
        except KeyError:
            return -1
```

The **[1]** of the line `return self.phrasegrams[tuple(components)][1]` disappeared.

I don't know if this has an explanation, but without that [1], the method returns a tuple instead of a float. The pythondoc comment of the method in gensim 3.7.3 says that it should return a float, so I think this is a bug.

I had a Phraser model stored on disk that was working fine in gensim 3.4.0, but now fails in gensim 3.7.3, raising the following Exception in the analyze_sentence method, which is the one that compares the score returned by score_item, and the threshold:

```codeblock
...
.../lib/python3.6/site-packages/gensim/models/phrases.py"", line 169, in analyze_sentence
    if score > threshold:
TypeError: '>' not supported between instances of 'tuple' and 'int'
```

The code of the analyze_sentence method contains:

```python
def analyze_sentence(self, sentence, threshold, common_terms, scorer):
    <more code ...>
    score = self.score_item(
                    worda=last_uncommon,
                    wordb=word,
                    components=chain,
                    scorer=scorer,
                )
                if score > threshold:
                    <more code ...>
    <more code ...>
```

Here we can see that, if the score_item method returns a tuple, the score variable will contain a tuple, and the expression `score > threshold` will fail.

This exception only gets raised when the 2 words passed to the score_item function generate a bigram. This is because, if the words doesn't generate a bigram, `self.phrasegrams[tuple(components)]` raises a KeyError exception, and the score_item method returns -1 instead of a tuple.

#### Solution
Add again the [1] to the `return self.phrasegrams[tuple(components)]` line of the score_item method, this way:

```python
    def score_item(self, worda, wordb, components, scorer):
        """"""Score a bigram.

        Parameters
        ----------
        worda : str
            First word for comparison.
        wordb : str
            Second word for comparison.
        components : generator
            Contain phrases.
        scorer : {'default', 'npmi'}
            NOT USED.

        Returns
        -------
        float
            Score for given bi-gram, if bi-gram not presented in dictionary - return -1.

        """"""
        try:
            return self.phrasegrams[tuple(components)][1]
        except KeyError:
            return -1
```"
494,https://github.com/RaRe-Technologies/gensim/issues/2519,2519,"[{'id': 1338770061, 'node_id': 'MDU6TGFiZWwxMzM4NzcwMDYx', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/stale', 'name': 'stale', 'color': 'bc4c01', 'default': False, 'description': 'Waiting for author to complete contribution, no recent effort'}, {'id': 1584013467, 'node_id': 'MDU6TGFiZWwxNTg0MDEzNDY3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/conda', 'name': 'conda', 'color': 'c9ef58', 'default': False, 'description': ''}]",open,2019-06-03 10:41:39+00:00,,Segmentation Fault after repeated Word2Vec vocabulary-updates,"#### Problem description

Hello, I'm new on gensim and I try to implement a (simple) W2V on my sentences. I cut out my sentences in batch of 10000 sentences, for each batch I apply the model with updating the vocab. Nevertheless, after 2 iterations I had a segmentation default error. 

#### Steps to reproduce

```python
def from_df_to_text(TEXTS, nlp=None):
    if not nlp:
        nlp = spacy.blank('es')
   
    TEXTS_NLP = nlp.tokenizer.pipe(TEXTS_LIST, n_threads = 7)
    
    return TEXTS_NLP`

def from_texts_to_token(TEXTS_LIST):
    for text in TEXTS_LIST:
        for word in text:
            yield str(word)

def new_batch(TEXTS, j, nlp=None):
    
    k, texts = 0, []
    
    for text in TEXTS:
        if k > j - 1:
            break
        texts.append(text.replace('\n',''))
        k += 1
    
    if not nlp:
        nlp = spacy.blank('es')
    
    texts = nlp.tokenizer.pipe(texts, n_threads = 7) 
    
    texts = [[str(token) for token in text] for text in texts]

    return(texts)

n_batch = 10000 ## number of texts to put on the W2V algorithm

emb_size=512
lr_init=0.025
window_size=4 
min_count_words=5 
max_vocab_size=None 
sample=0.0001 
seed=1  
workers=25 
lr_fin=0.0001
sg=1 
hs=0
negative=20
ns_exponent=0.75 
cbow_mean=1
iters=1
null_word=1
trim_rule=None
sorted_vocab=1
batch_words=128
callbacks=() 
max_final_vocab=None

TEXTS_NLP = from_df_to_text(TEXTS_, nlp=None)
TEXTS = from_texts_to_token(TEXTS_NLP)

model_W2V = gensim.models.Word2Vec(size=emb_size, alpha=lr_init, window=window_size, min_count=5,
                                   max_vocab_size=None, sample=sample, seed=seed, workers=workers, 
                                   min_alpha=lr_fin, sg=sg, hs=hs, negative=5, ns_exponent=ns_exponent,
                                   cbow_mean=cbow_mean,  iter=iters, 
                                   null_word=null_word, trim_rule=trim_rule, sorted_vocab=sorted_vocab, batch_words=batch_words,
                                   compute_loss=compute_loss, callbacks=callbacks, max_final_vocab=max_final_vocab)

loop_size = int(6185537 / n_batch) + 1 ### Number of phrase which are not in catalan

logger = logging.getLogger(__name__)

for i in range(loop_size):
    sentences = new_batch(TEXTS_, n_batch)
    if i != 0:
        update=True
    else:
        logger.info('initialize vocabulary')
        update=False
        
    model_W2V.build_vocab(sentences, update=update)
    model_W2V.train(sentences, total_examples = n_batch, epochs =  model_W2V.epochs)
    logger.info('Advancement: {}%'.format(round(100 * (i+1) / loop_size, 3)))
```

#### Logs

```Logs
019-06-03 10:40:15,208 : INFO : initialize vocabulary
2019-06-03 10:40:15,211 : INFO : collecting all words and their counts
2019-06-03 10:40:15,214 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2019-06-03 10:40:15,319 : INFO : collected 57928 word types from a corpus of 561742 raw words and 10000 sentences
2019-06-03 10:40:15,320 : INFO : Loading a fresh vocabulary
2019-06-03 10:40:15,353 : INFO : effective_min_count=5 retains 10273 unique words (17% of original 57928, drops 47655)
2019-06-03 10:40:15,354 : INFO : effective_min_count=5 leaves 493158 word corpus (87% of original 561742, drops 68584)
2019-06-03 10:40:15,380 : INFO : deleting the raw counts dictionary of 57928 items
2019-06-03 10:40:15,382 : INFO : sample=0.0001 downsamples 373 most-common words
2019-06-03 10:40:15,383 : INFO : downsampling leaves estimated 257490 word corpus (52.2% of prior 493158)
2019-06-03 10:40:15,403 : INFO : estimated required memory for 10273 words and 512 dimensions: 47214708 bytes
2019-06-03 10:40:15,404 : INFO : resetting layer weights
2019-06-03 10:40:15,564 : INFO : training model with 25 workers on 10274 vocabulary and 512 features, using sg=1 hs=0 sample=0.0001 negative=5 window=4
2019-06-03 10:40:16,580 : INFO : EPOCH 1 - PROGRESS: at 93.82% examples, 239000 words/s, in_qsize 47, out_qsize 2
2019-06-03 10:40:16,635 : DEBUG : job loop exiting, total 4407 jobs
2019-06-03 10:40:16,642 : DEBUG : worker exiting, processed 171 jobs
2019-06-03 10:40:16,642 : INFO : worker thread finished; awaiting finish of 24 more threads
2019-06-03 10:40:16,642 : DEBUG : worker exiting, processed 176 jobs
2019-06-03 10:40:16,643 : DEBUG : worker exiting, processed 184 jobs
2019-06-03 10:40:16,643 : DEBUG : worker exiting, processed 168 jobs
2019-06-03 10:40:16,643 : DEBUG : worker exiting, processed 178 jobs
2019-06-03 10:40:16,643 : DEBUG : worker exiting, processed 174 jobs
2019-06-03 10:40:16,643 : DEBUG : worker exiting, processed 172 jobs
2019-06-03 10:40:16,644 : DEBUG : worker exiting, processed 184 jobs
2019-06-03 10:40:16,644 : INFO : worker thread finished; awaiting finish of 23 more threads
2019-06-03 10:40:16,644 : DEBUG : worker exiting, processed 174 jobs
2019-06-03 10:40:16,644 : DEBUG : worker exiting, processed 177 jobs
2019-06-03 10:40:16,644 : DEBUG : worker exiting, processed 179 jobs
2019-06-03 10:40:16,646 : DEBUG : worker exiting, processed 181 jobs
2019-06-03 10:40:16,647 : DEBUG : worker exiting, processed 182 jobs
2019-06-03 10:40:16,648 : DEBUG : worker exiting, processed 176 jobs
2019-06-03 10:40:16,648 : DEBUG : worker exiting, processed 170 jobs
2019-06-03 10:40:16,649 : DEBUG : worker exiting, processed 179 jobs
2019-06-03 10:40:16,650 : DEBUG : worker exiting, processed 175 jobs
2019-06-03 10:40:16,650 : DEBUG : worker exiting, processed 178 jobs
2019-06-03 10:40:16,651 : DEBUG : worker exiting, processed 176 jobs
2019-06-03 10:40:16,651 : DEBUG : worker exiting, processed 179 jobs
2019-06-03 10:40:16,651 : DEBUG : worker exiting, processed 169 jobs
2019-06-03 10:40:16,651 : DEBUG : worker exiting, processed 178 jobs
2019-06-03 10:40:16,652 : DEBUG : worker exiting, processed 173 jobs
2019-06-03 10:40:16,652 : DEBUG : worker exiting, processed 172 jobs
2019-06-03 10:40:16,652 : DEBUG : worker exiting, processed 182 jobs
2019-06-03 10:40:16,654 : INFO : worker thread finished; awaiting finish of 22 more threads
2019-06-03 10:40:16,667 : INFO : worker thread finished; awaiting finish of 21 more threads
2019-06-03 10:40:16,667 : INFO : worker thread finished; awaiting finish of 20 more threads
2019-06-03 10:40:16,667 : INFO : worker thread finished; awaiting finish of 19 more threads
2019-06-03 10:40:16,668 : INFO : worker thread finished; awaiting finish of 18 more threads
2019-06-03 10:40:16,668 : INFO : worker thread finished; awaiting finish of 17 more threads
2019-06-03 10:40:16,669 : INFO : worker thread finished; awaiting finish of 16 more threads
2019-06-03 10:40:16,669 : INFO : worker thread finished; awaiting finish of 15 more threads
2019-06-03 10:40:16,669 : INFO : worker thread finished; awaiting finish of 14 more threads
2019-06-03 10:40:16,670 : INFO : worker thread finished; awaiting finish of 13 more threads
2019-06-03 10:40:16,670 : INFO : worker thread finished; awaiting finish of 12 more threads
2019-06-03 10:40:16,671 : INFO : worker thread finished; awaiting finish of 11 more threads
2019-06-03 10:40:16,671 : INFO : worker thread finished; awaiting finish of 10 more threads
2019-06-03 10:40:16,671 : INFO : worker thread finished; awaiting finish of 9 more threads
2019-06-03 10:40:16,672 : INFO : worker thread finished; awaiting finish of 8 more threads
2019-06-03 10:40:16,672 : INFO : worker thread finished; awaiting finish of 7 more threads
2019-06-03 10:40:16,673 : INFO : worker thread finished; awaiting finish of 6 more threads
2019-06-03 10:40:16,673 : INFO : worker thread finished; awaiting finish of 5 more threads
2019-06-03 10:40:16,673 : INFO : worker thread finished; awaiting finish of 4 more threads
2019-06-03 10:40:16,674 : INFO : worker thread finished; awaiting finish of 3 more threads
2019-06-03 10:40:16,674 : INFO : worker thread finished; awaiting finish of 2 more threads
2019-06-03 10:40:16,675 : INFO : worker thread finished; awaiting finish of 1 more threads
2019-06-03 10:40:16,675 : INFO : worker thread finished; awaiting finish of 0 more threads
2019-06-03 10:40:16,675 : INFO : EPOCH - 1 : training on 561742 raw words (257712 effective words) took 1.1s, 235149 effective words/s
2019-06-03 10:40:16,676 : INFO : training on a 561742 raw words (257712 effective words) took 1.1s, 231956 effective words/s
2019-06-03 10:40:16,676 : INFO : Advancement: 0.162%
2019-06-03 10:40:25,207 : INFO : collecting all words and their counts
2019-06-03 10:40:25,210 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2019-06-03 10:40:25,336 : INFO : collected 62772 word types from a corpus of 610078 raw words and 10000 sentences
2019-06-03 10:40:25,338 : INFO : Updating model with new vocabulary
2019-06-03 10:40:25,377 : INFO : New added 11111 unique words (15% of original 73883) and increased the count of 11111 pre-existing words (15% of original 73883)
2019-06-03 10:40:25,438 : INFO : deleting the raw counts dictionary of 62772 items
2019-06-03 10:40:25,440 : INFO : sample=0.0001 downsamples 766 most-common words
2019-06-03 10:40:25,441 : INFO : downsampling leaves estimated 565566 word corpus (105.6% of prior 535425)
2019-06-03 10:40:25,460 : INFO : estimated required memory for 22222 words and 512 dimensions: 102132312 bytes
2019-06-03 10:40:25,461 : INFO : updating layer weights
2019-06-03 10:40:25,553 : WARNING : Effective 'alpha' higher than previous training cycles
2019-06-03 10:40:25,554 : INFO : training model with 25 workers on 14246 vocabulary and 512 features, using sg=1 hs=0 sample=0.0001 negative=5 window=4
2019-06-03 10:40:26,569 : INFO : EPOCH 1 - PROGRESS: at 86.30% examples, 248658 words/s, in_qsize 48, out_qsize 1
2019-06-03 10:40:26,703 : DEBUG : job loop exiting, total 4631 jobs
2019-06-03 10:40:26,709 : DEBUG : worker exiting, processed 185 jobs
2019-06-03 10:40:26,709 : DEBUG : worker exiting, processed 179 jobs
2019-06-03 10:40:26,709 : DEBUG : worker exiting, processed 179 jobs
2019-06-03 10:40:26,710 : INFO : worker thread finished; awaiting finish of 24 more threads
2019-06-03 10:40:26,710 : DEBUG : worker exiting, processed 188 jobs
2019-06-03 10:40:26,710 : DEBUG : worker exiting, processed 185 jobs
2019-06-03 10:40:26,711 : DEBUG : worker exiting, processed 178 jobs
2019-06-03 10:40:26,711 : DEBUG : worker exiting, processed 188 jobs
2019-06-03 10:40:26,712 : DEBUG : worker exiting, processed 179 jobs
2019-06-03 10:40:26,712 : DEBUG : worker exiting, processed 193 jobs
2019-06-03 10:40:26,712 : DEBUG : worker exiting, processed 187 jobs
2019-06-03 10:40:26,714 : DEBUG : worker exiting, processed 184 jobs
2019-06-03 10:40:26,715 : INFO : worker thread finished; awaiting finish of 23 more threads
2019-06-03 10:40:26,715 : DEBUG : worker exiting, processed 184 jobs
2019-06-03 10:40:26,716 : DEBUG : worker exiting, processed 178 jobs
2019-06-03 10:40:26,716 : DEBUG : worker exiting, processed 183 jobs
2019-06-03 10:40:26,717 : DEBUG : worker exiting, processed 177 jobs
2019-06-03 10:40:26,717 : DEBUG : worker exiting, processed 192 jobs
2019-06-03 10:40:26,717 : DEBUG : worker exiting, processed 195 jobs
2019-06-03 10:40:26,717 : DEBUG : worker exiting, processed 187 jobs
2019-06-03 10:40:26,718 : DEBUG : worker exiting, processed 197 jobs
2019-06-03 10:40:26,719 : DEBUG : worker exiting, processed 181 jobs
2019-06-03 10:40:26,719 : DEBUG : worker exiting, processed 192 jobs
2019-06-03 10:40:26,719 : DEBUG : worker exiting, processed 185 jobs
2019-06-03 10:40:26,719 : DEBUG : worker exiting, processed 186 jobs
2019-06-03 10:40:26,719 : DEBUG : worker exiting, processed 182 jobs
2019-06-03 10:40:26,720 : DEBUG : worker exiting, processed 187 jobs
2019-06-03 10:40:26,723 : INFO : worker thread finished; awaiting finish of 22 more threads
2019-06-03 10:40:26,734 : INFO : worker thread finished; awaiting finish of 21 more threads
2019-06-03 10:40:26,734 : INFO : worker thread finished; awaiting finish of 20 more threads
2019-06-03 10:40:26,735 : INFO : worker thread finished; awaiting finish of 19 more threads
2019-06-03 10:40:26,735 : INFO : worker thread finished; awaiting finish of 18 more threads
2019-06-03 10:40:26,736 : INFO : worker thread finished; awaiting finish of 17 more threads
2019-06-03 10:40:26,736 : INFO : worker thread finished; awaiting finish of 16 more threads
2019-06-03 10:40:26,736 : INFO : worker thread finished; awaiting finish of 15 more threads
2019-06-03 10:40:26,737 : INFO : worker thread finished; awaiting finish of 14 more threads
2019-06-03 10:40:26,738 : INFO : worker thread finished; awaiting finish of 13 more threads
2019-06-03 10:40:26,739 : INFO : worker thread finished; awaiting finish of 12 more threads
2019-06-03 10:40:26,739 : INFO : worker thread finished; awaiting finish of 11 more threads
2019-06-03 10:40:26,739 : INFO : worker thread finished; awaiting finish of 10 more threads
2019-06-03 10:40:26,740 : INFO : worker thread finished; awaiting finish of 9 more threads
2019-06-03 10:40:26,740 : INFO : worker thread finished; awaiting finish of 8 more threads
2019-06-03 10:40:26,741 : INFO : worker thread finished; awaiting finish of 7 more threads
2019-06-03 10:40:26,741 : INFO : worker thread finished; awaiting finish of 6 more threads
2019-06-03 10:40:26,742 : INFO : worker thread finished; awaiting finish of 5 more threads
2019-06-03 10:40:26,742 : INFO : worker thread finished; awaiting finish of 4 more threads
2019-06-03 10:40:26,742 : INFO : worker thread finished; awaiting finish of 3 more threads
2019-06-03 10:40:26,743 : INFO : worker thread finished; awaiting finish of 2 more threads
2019-06-03 10:40:26,743 : INFO : worker thread finished; awaiting finish of 1 more threads
2019-06-03 10:40:26,744 : INFO : worker thread finished; awaiting finish of 0 more threads
2019-06-03 10:40:26,744 : INFO : EPOCH - 1 : training on 610078 raw words (287644 effective words) took 1.2s, 244753 effective words/s
2019-06-03 10:40:26,744 : INFO : training on a 610078 raw words (287644 effective words) took 1.2s, 241781 effective words/s
2019-06-03 10:40:26,745 : INFO : Advancement: 0.323%
2019-06-03 10:40:36,138 : INFO : collecting all words and their counts
2019-06-03 10:40:36,139 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2019-06-03 10:40:36,295 : INFO : collected 63969 word types from a corpus of 659711 raw words and 10000 sentences
2019-06-03 10:40:36,296 : INFO : Updating model with new vocabulary
2019-06-03 10:40:36,345 : INFO : New added 11934 unique words (15% of original 75903) and increased the count of 11934 pre-existing words (15% of original 75903)
2019-06-03 10:40:36,412 : INFO : deleting the raw counts dictionary of 63969 items
2019-06-03 10:40:36,415 : INFO : sample=0.0001 downsamples 736 most-common words
2019-06-03 10:40:36,415 : INFO : downsampling leaves estimated 623638 word corpus (106.7% of prior 584748)
2019-06-03 10:40:36,441 : INFO : estimated required memory for 23868 words and 512 dimensions: 109697328 bytes
2019-06-03 10:40:36,442 : INFO : updating layer weights
2019-06-03 10:40:36,537 : WARNING : Effective 'alpha' higher than previous training cycles
2019-06-03 10:40:36,538 : INFO : training model with 25 workers on 17646 vocabulary and 512 features, using sg=1 hs=0 sample=0.0001 negative=5 window=4
2019-06-03 10:40:37,555 : INFO : EPOCH 1 - PROGRESS: at 85.47% examples, 266849 words/s, in_qsize 48, out_qsize 1
2019-06-03 10:40:37,716 : DEBUG : job loop exiting, total 4948 jobs
2019-06-03 10:40:37,724 : DEBUG : worker exiting, processed 207 jobs
2019-06-03 10:40:37,724 : DEBUG : worker exiting, processed 186 jobs
2019-06-03 10:40:37,724 : DEBUG : worker exiting, processed 196 jobs
2019-06-03 10:40:37,724 : DEBUG : worker exiting, processed 200 jobs
2019-06-03 10:40:37,724 : DEBUG : worker exiting, processed 200 jobs
2019-06-03 10:40:37,724 : DEBUG : worker exiting, processed 192 jobs
2019-06-03 10:40:37,725 : DEBUG : worker exiting, processed 204 jobs
2019-06-03 10:40:37,725 : DEBUG : worker exiting, processed 199 jobs
2019-06-03 10:40:37,725 : INFO : worker thread finished; awaiting finish of 24 more threads
2019-06-03 10:40:37,725 : DEBUG : worker exiting, processed 194 jobs
2019-06-03 10:40:37,726 : DEBUG : worker exiting, processed 202 jobs
2019-06-03 10:40:37,726 : DEBUG : worker exiting, processed 208 jobs
2019-06-03 10:40:37,726 : DEBUG : worker exiting, processed 195 jobs
2019-06-03 10:40:37,727 : DEBUG : worker exiting, processed 202 jobs
2019-06-03 10:40:37,727 : DEBUG : worker exiting, processed 191 jobs
2019-06-03 10:40:37,728 : DEBUG : worker exiting, processed 195 jobs
2019-06-03 10:40:37,729 : DEBUG : worker exiting, processed 200 jobs
2019-06-03 10:40:37,731 : DEBUG : worker exiting, processed 201 jobs
2019-06-03 10:40:37,731 : DEBUG : worker exiting, processed 198 jobs
2019-06-03 10:40:37,732 : DEBUG : worker exiting, processed 202 jobs
2019-06-03 10:40:37,732 : DEBUG : worker exiting, processed 197 jobs
2019-06-03 10:40:37,732 : DEBUG : worker exiting, processed 192 jobs
2019-06-03 10:40:37,732 : DEBUG : worker exiting, processed 198 jobs
2019-06-03 10:40:37,732 : DEBUG : worker exiting, processed 201 jobs
2019-06-03 10:40:37,733 : DEBUG : worker exiting, processed 195 jobs
2019-06-03 10:40:37,734 : DEBUG : worker exiting, processed 193 jobs
2019-06-03 10:40:37,734 : INFO : worker thread finished; awaiting finish of 23 more threads
2019-06-03 10:40:37,744 : INFO : worker thread finished; awaiting finish of 22 more threads
2019-06-03 10:40:37,745 : INFO : worker thread finished; awaiting finish of 21 more threads
2019-06-03 10:40:37,745 : INFO : worker thread finished; awaiting finish of 20 more threads
2019-06-03 10:40:37,746 : INFO : worker thread finished; awaiting finish of 19 more threads
2019-06-03 10:40:37,746 : INFO : worker thread finished; awaiting finish of 18 more threads
2019-06-03 10:40:37,746 : INFO : worker thread finished; awaiting finish of 17 more threads
2019-06-03 10:40:37,747 : INFO : worker thread finished; awaiting finish of 16 more threads
2019-06-03 10:40:37,747 : INFO : worker thread finished; awaiting finish of 15 more threads
2019-06-03 10:40:37,748 : INFO : worker thread finished; awaiting finish of 14 more threads
2019-06-03 10:40:37,748 : INFO : worker thread finished; awaiting finish of 13 more threads
2019-06-03 10:40:37,748 : INFO : worker thread finished; awaiting finish of 12 more threads
2019-06-03 10:40:37,749 : INFO : worker thread finished; awaiting finish of 11 more threads
2019-06-03 10:40:37,749 : INFO : worker thread finished; awaiting finish of 10 more threads
2019-06-03 10:40:37,750 : INFO : worker thread finished; awaiting finish of 9 more threads
2019-06-03 10:40:37,750 : INFO : worker thread finished; awaiting finish of 8 more threads
2019-06-03 10:40:37,750 : INFO : worker thread finished; awaiting finish of 7 more threads
2019-06-03 10:40:37,751 : INFO : worker thread finished; awaiting finish of 6 more threads
2019-06-03 10:40:37,751 : INFO : worker thread finished; awaiting finish of 5 more threads
2019-06-03 10:40:37,752 : INFO : worker thread finished; awaiting finish of 4 more threads
2019-06-03 10:40:37,752 : INFO : worker thread finished; awaiting finish of 3 more threads
2019-06-03 10:40:37,753 : INFO : worker thread finished; awaiting finish of 2 more threads
2019-06-03 10:40:37,753 : INFO : worker thread finished; awaiting finish of 1 more threads
2019-06-03 10:40:37,753 : INFO : worker thread finished; awaiting finish of 0 more threads
2019-06-03 10:40:37,754 : INFO : EPOCH - 1 : training on 659711 raw words (320472 effective words) took 1.2s, 267206 effective words/s
2019-06-03 10:40:37,754 : INFO : training on a 659711 raw words (320472 effective words) took 1.2s, 263723 effective words/s
2019-06-03 10:40:37,755 : INFO : Advancement: 0.485%
2019-06-03 10:40:46,407 : INFO : collecting all words and their counts
2019-06-03 10:40:46,408 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2019-06-03 10:40:46,540 : INFO : collected 62797 word types from a corpus of 624413 raw words and 10000 sentences
2019-06-03 10:40:46,541 : INFO : Updating model with new vocabulary
2019-06-03 10:40:46,577 : INFO : New added 11404 unique words (15% of original 74201) and increased the count of 11404 pre-existing words (15% of original 74201)
2019-06-03 10:40:46,641 : INFO : deleting the raw counts dictionary of 62797 items
2019-06-03 10:40:46,643 : INFO : sample=0.0001 downsamples 754 most-common words
2019-06-03 10:40:46,644 : INFO : downsampling leaves estimated 582383 word corpus (106.0% of prior 549589)
2019-06-03 10:40:46,671 : INFO : estimated required memory for 22808 words and 512 dimensions: 104825568 bytes
2019-06-03 10:40:46,672 : INFO : updating layer weights
2019-06-03 10:40:46,760 : WARNING : Effective 'alpha' higher than previous training cycles
2019-06-03 10:40:46,761 : INFO : training model with 25 workers on 20087 vocabulary and 512 features, using sg=1 hs=0 sample=0.0001 negative=5 window=4
```

And here happens the segmentation error. I don't really understand what is going on...

#### Versions

I'm in fresh conda environment, and here are the versions

```python
Linux-4.9.0-7-amd64-x86_64-with-debian-buster-sid
Python 3.6.7 | packaged by conda-forge | (default, Feb 28 2019, 09:07:38) 
[GCC 7.3.0]
NumPy 1.16.4
SciPy 1.3.0
spacy 2.1.4
gensim 3.7.3
FAST_VERSION 1
```
"
495,https://github.com/RaRe-Technologies/gensim/issues/2520,2520,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",closed,2019-06-03 11:59:00+00:00,,Bug in models.phraser.original_scorer,"#### Problem description

There seems to be a bug in models.phraser.original_scorer. `min_count` is defined as ""Minimum collocation count threshold"", which is a bit ambiguous, but this argument actually corresponds to `Phrases.min_count`, which is defined as:

```
min_count : float, optional
            Ignore all words and bigrams with total collected count lower than this value.
```
Given this definition, line 692 is seemingly incorrect:

```
return (bigram_count - min_count) / worda_count / wordb_count * len_vocab
```

When bigram_count == min_count, this will return zero, meaning that either the definition of min_count is wrong, or this formula is incorrect.

#### Versions

I'm using gensim 3.7.3, but this issue seems to go back all the way to the original commit of the phrases module back in 0.10.3.
"
496,https://github.com/RaRe-Technologies/gensim/issues/2521,2521,[],closed,2019-06-07 12:26:08+00:00,,Increasing Perplexity with number of topics,"In order to evaluate the best number of topics for my dataset, I split the set into testset and trainingset (25%, 75%, 18k documents alltogether). But somehow my perplexity keeps increasing on the testset. I don't know exactly why.

You can see the perplexity here: https://imgur.com/FE9KF2Z

Corpus can be found here: http://uploaded.net/file/nkru8zi7

I split the corpus the following way (using sklearn)
corpus_train, corpus_test = train_test_split(corpus, test_size=0.25)

Then I apply LDA on the train_set. Then get the perplexity using

perplexity = 2 ** (-1.0 * lda_model.log_perplexity(corpus_test))

on the testset.

I do a new split for every number of topic (So I don't have one split and use it for every number of topics, but do a new split everytime before applying lda)

Any suggestions?"
497,https://github.com/RaRe-Technologies/gensim/issues/2522,2522,[],closed,2019-06-09 02:57:41+00:00,,LdaMallet load_document_topics() fails.,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

**Trying: ** When I use method `load_document_topics()` in a trained LdaMallet model today, I got the following Error:

```python
RuntimeError                              Traceback (most recent call last)
<ipython-input-138-6d106e31d9f6> in <module>
      1 tot = []
----> 2 for w in model.load_document_topics():
      3     tot.append(list(map(lambda x:x[1], sorted(w))))

d:\code\git\gensim\gensim\models\wrappers\ldamallet.py in read_doctopics(self, fname, eps, renorm)
    560                                     count += 1
    561                     else:
--> 562                         raise RuntimeError(""invalid doc topics format at line %i in %s"" % (lineno + 1, fname))
    563 
    564                 if renorm:

RuntimeError: invalid doc topics format at line 2946 in ./model\r20_n20doctopics.txt
```

* ` ./model\r20_n20` is the prefix.

I have checked the file and find something wrong with the second columns, like:

```python 
0 0 0.2 0.3 0.5 
1    0.3 0.2 0.5
2 1 0.2 0.1 0.7

...
```

#### Versions


```python
Windows-10-10.0.15063-SP0
Python 3.6.6 (v3.6.6:4cf1f54eb7, Jun 27 2018, 03:37:03) [MSC v.1900 64 bit (AMD64)]
NumPy 1.16.2
SciPy 1.1.0
gensim 3.7.3
FAST_VERSION 0
```
"
498,https://github.com/RaRe-Technologies/gensim/issues/2523,2523,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",open,2019-06-10 12:37:46+00:00,,bug in gensim.summarization.mz_entropy.mz_keywords,"**Problem statement:**

It seems to be a bug if the text is too short and number of words is lower than blocksize. In my case the values were: `n_words (232.0) ` and `blocksize (1024)`.

**Log:**

```
gensim\summarization\mz_entropy.py:127: RuntimeWarning: invalid value encountered in double_scalars
  - __log_combinations(n_words, blocksize)
```

**Dirty solution:**

Override `blocksize` value from the default `1024` to something lower:

`mz_keywords(text, blocksize=128)`

"
499,https://github.com/RaRe-Technologies/gensim/issues/2524,2524,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-06-13 06:37:39+00:00,,Could see unknown logs while running Cosine Similarity,"I could see some unknown logs about tokens being added to `dictionay` while running `Cosine Similarity` using `Gensim`. Could you please help me understand, why I see these logs?



**My Code:**

```python
def cossim(documents, query_docs=None, task='pairwise_similarity', metric_threshold=0.85, num_best=20, **kwargs):
    try:
        dictionary = Dictionary(documents)
        tfidf = TfidfModel(dictionary=dictionary)
        corpus = [dictionary.doc2bow(doc) for doc in documents]
        features_rep='bow'
        if len(dictionary) > 1000 and len(dictionary) <=2000:
            corpus = [tfidf[doc] for doc in corpus]
            features_rep='tfidf'
        elif len(dictionary) > 2000:
            model = LsiModel(corpus, id2word=dictionary, num_topics=200)
            corpus = [model[tfidf[doc]] for doc in corpus]
            features_rep = 'lsi'
        index_tmpfile = get_tmpfile(""index"")
        index = Similarity(output_prefix=index_tmpfile, corpus=corpus, num_best=num_best, num_features=len(dictionary),
                           chunksize=256)
        similarities = []
        if task == 'pairwise_similarity':
            start_time = time.time()
            
            for sim in index:
                similarities.append(sim)
            
        elif task == 'batch_query':
            start_time = time.time()
            query_docs_features = [dictionary.doc2bow(doc) for doc in query_docs]
            if features_rep=='tfidf':
                query_docs_features = [tfidf[doc] for doc in query_docs_features]
            elif features_rep=='lsi':
                query_docs_features = [model[tfidf[doc]] for doc in query_docs_features]
            for sim in index[query_docs_features]:
                similarities.append(sim)
        filtered_results = []
        for ind_sim in similarities:
            filtered_results.append([item[0] for item in ind_sim if item[1] >= metric_threshold])
        if query_docs is not None:
            matched_docs, unmatched_docs, matching_stats = stats(documents, query_docs, filtered_results)
            return matched_docs, unmatched_docs
        else:
            return filtered_results
    except Exception:
        logging.error(
            ""Exception has occurred while performing Cosine Similarity. {}"".format(traceback.format_exc()))
```




> I don't have any of these `['computer', 'human', 'interface', 'response', 'survey']` tokens in my current dictionary, not sure why I see these in the logs

**The Unknown Log that I see:**

```
2019-06-13 11:23:55,556 : INFO : 'pattern' package found; tag filters are available for English
2019-06-13 11:23:55,564 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2019-06-13 11:23:55,564 : INFO : built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)
```"
500,https://github.com/RaRe-Technologies/gensim/issues/2525,2525,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-06-13 09:51:41+00:00,,Unable to run gensims Distributed LSI,"#### Problem description

`Unable to run gensims Distributed LSI`

#### Steps/code/corpus to reproduce
```
from gensim.corpora import Dictionary
from gensim.models import TfidfModel, LsiModel
from gensim.similarities import Similarity
from gensim.test.utils import get_tmpfile
import sys
import time, traceback
import logging
logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)

documents=['simple document','trying to reproduce lsi error','example document']
documents=[doc.split(' ') for doc in documents]    
dictionary = Dictionary(documents)
tfidf = TfidfModel(dictionary=dictionary)
corpus = [dictionary.doc2bow(doc) for doc in documents]
model = LsiModel(corpus, id2word=dictionary,num_topics=200,distributed=True)
```

#### Log Trace:

```
2019-06-13 15:15:40,268 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2019-06-13 15:15:40,269 : INFO : built Dictionary(11 unique tokens: ['document', 'simple', 'error', 'lsi', 'reproduce']...) from 5 documents (total 17 corpus positions)
2019-06-13 15:15:40,292 : INFO : looking for dispatcher at PYRONAME:gensim.lsi_dispatcher
2019-06-13 15:15:42,414 : ERROR : failed to initialize distributed LSI (Failed to locate the nameserver)
---------------------------------------------------------------------------
ConnectionRefusedError                    Traceback (most recent call last)
~/anaconda3/lib/python3.6/site-packages/Pyro4/core.py in connect_and_handshake(conn)
    514                                                nodelay=config.SOCK_NODELAY,
--> 515                                                sslContext=sslContext)
    516                 conn = socketutil.SocketConnection(sock, uri.object)

~/anaconda3/lib/python3.6/site-packages/Pyro4/socketutil.py in createSocket(bind, connect, reuseaddr, keepalive, timeout, noinherit, ipv6, nodelay, sslContext)
    306         try:
--> 307             sock.connect(connect)
    308         except socket.error:

ConnectionRefusedError: [Errno 61] Connection refused

The above exception was the direct cause of the following exception:

CommunicationError                        Traceback (most recent call last)
~/anaconda3/lib/python3.6/site-packages/Pyro4/core.py in _locateNS(host, port, broadcast, hmac_key)
   2004     try:
-> 2005         proxy._pyroBind()
   2006         log.debug(""located NS"")

~/anaconda3/lib/python3.6/site-packages/Pyro4/core.py in _pyroBind(self)
    407         """"""
--> 408         return self.__pyroCreateConnection(True)
    409 

~/anaconda3/lib/python3.6/site-packages/Pyro4/core.py in __pyroCreateConnection(self, replaceUri, connected_socket)
    595             else:
--> 596                 connect_and_handshake(conn)
    597             if config.METADATA:

~/anaconda3/lib/python3.6/site-packages/Pyro4/core.py in connect_and_handshake(conn)
    548                         ce.__cause__ = x
--> 549                     raise ce
    550             else:

CommunicationError: cannot connect to ('localhost', 9090): [Errno 61] Connection refused

The above exception was the direct cause of the following exception:

NamingError                               Traceback (most recent call last)
~/anaconda3/lib/python3.6/site-packages/gensim/models/lsimodel.py in __init__(self, corpus, num_topics, id2word, chunksize, decay, distributed, onepass, power_iters, extra_samples, dtype)
    431                 logger.info(""looking for dispatcher at %s"", str(dispatcher._pyroUri))
--> 432                 dispatcher.initialize(
    433                     id2word=self.id2word, num_topics=num_topics, chunksize=chunksize, decay=decay,

~/anaconda3/lib/python3.6/site-packages/Pyro4/core.py in __getattr__(self, name)
    274             if not self._pyroMethods and not self._pyroAttrs:
--> 275                 self._pyroGetMetadata()
    276         if name in self._pyroAttrs:

~/anaconda3/lib/python3.6/site-packages/Pyro4/core.py in _pyroGetMetadata(self, objectId, known_metadata)
    614             try:
--> 615                 self.__pyroCreateConnection()
    616             except errors.PyroError:

~/anaconda3/lib/python3.6/site-packages/Pyro4/core.py in __pyroCreateConnection(self, replaceUri, connected_socket)
    587             else:
--> 588                 uri = _resolve(self._pyroUri, self._pyroHmacKey)
    589             # socket connection (normal or Unix domain socket)

~/anaconda3/lib/python3.6/site-packages/Pyro4/core.py in _resolve(uri, hmac_key)
   1909     if uri.protocol == ""PYRONAME"":
-> 1910         with _locateNS(uri.host, uri.port, hmac_key=hmac_key) as nameserver:
   1911             return nameserver.lookup(uri.object)

~/anaconda3/lib/python3.6/site-packages/Pyro4/core.py in _locateNS(host, port, broadcast, hmac_key)
   2011             e.__cause__ = x
-> 2012         raise e
   2013 

NamingError: Failed to locate the nameserver

During handling of the above exception, another exception occurred:

RuntimeError                              Traceback (most recent call last)
<ipython-input-5-d3777d1d3a97> in <module>()
     24 tfidf = TfidfModel(dictionary=dictionary)
     25 corpus = [dictionary.doc2bow(doc) for doc in documents]
---> 26 model = LsiModel(corpus, id2word=dictionary,num_topics=200,distributed=True)
     27 corpus = [model[tfidf[doc]] for doc in corpus]
     28 index_tmpfile = get_tmpfile(""index"")

~/anaconda3/lib/python3.6/site-packages/gensim/models/lsimodel.py in __init__(self, corpus, num_topics, id2word, chunksize, decay, distributed, onepass, power_iters, extra_samples, dtype)
    440                 # distributed version was specifically requested, so this is an error state
    441                 logger.error(""failed to initialize distributed LSI (%s)"", err)
--> 442                 raise RuntimeError(""failed to initialize distributed LSI (%s)"" % err)
    443 
    444         if corpus is not None:

RuntimeError: failed to initialize distributed LSI (Failed to locate the nameserver)
```

#### Versions
```
Python 3.6.4
NumPy 1.15.4
SciPy 1.1.0
gensim 3.7.1
FAST_VERSION 1
```"
501,https://github.com/RaRe-Technologies/gensim/issues/2526,2526,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-06-13 17:19:20+00:00,,Word2Vec Threading problem,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

Hi, I am trying to train a word2vec model with gensim.
But, it seems to have a problem.
Training fails when I put more than 2000 sentences into model.


#### Steps/code/corpus to reproduce
![Screen Shot 2019-06-13 at 1 19 04 PM](https://user-images.githubusercontent.com/10040328/59453419-d9084f00-8ddd-11e9-99f9-65f68210186c.png)


#### Versions

Please provide the output of:

```python
Linux-4.4.0-143-generic-x86_64-with-Ubuntu-16.04-xenial
Python 3.5.2 (default, Nov 12 2018, 13:43:14) 
[GCC 5.4.0 20160609]
NumPy 1.16.2
SciPy 1.2.1
gensim 3.7.2
FAST_VERSION 1
```

"
502,https://github.com/RaRe-Technologies/gensim/issues/2527,2527,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-06-14 12:13:19+00:00,,test the topic changing over time with CSV format,"I am trying to implement gensim.models.wrappers import DtmModel to test the topic changing over time.

My testing file is Amazon review file with CSV format, which include reviews, ratings, date and title.

I am trying to replicate the page https://radimrehurek.com/gensim/models/wrappers/dtmmodel.html to find the topic changing over time, but fail to create time_slices. Is any one can help me? thank you very much.

<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? What is the expected result? What are you seeing instead?

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
"
503,https://github.com/RaRe-Technologies/gensim/issues/2529,2529,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-06-15 01:06:42+00:00,,Error while loading French binary model,"I download pretrained fasttext models of English and French from https://fasttext.cc/docs/en/pretrained-vectors.html. When I use load_facebook_model() function to load the data, `wiki.en.bin` goes well but `wiki.fr.bin` cannot be loaded. The error is 
```
Traceback (most recent call last):
 File ""<stdin>"", line 1, in <module>
 File ""/home/qihe/r-1694068/build/scsar-word-embeddings/venv/lib/python3.6/site-packages/gensim/models/fasttext.py"", line 1299, in l
oad_facebook_vectors
   model_wrapper = _load_fasttext_format(path, encoding=encoding, full_model=False)
 File ""/home/qihe/r-1694068/build/scsar-word-embeddings/venv/lib/python3.6/site-packages/gensim/models/fasttext.py"", line 1323, in _
load_fasttext_format
   m = gensim.models._fasttext_bin.load(fin, encoding=encoding, full_model=full_model)
 File ""/home/qihe/r-1694068/build/scsar-word-embeddings/venv/lib/python3.6/site-packages/gensim/models/_fasttext_bin.py"", line 271,
in load
   raw_vocab, vocab_size, nwords = _load_vocab(fin, new_format, encoding=encoding)
 File ""/home/qihe/r-1694068/build/scsar-word-embeddings/venv/lib/python3.6/site-packages/gensim/models/_fasttext_bin.py"", line 167,
in _load_vocab
   raise NotImplementedError(""Supervised fastText models are not supported"")
NotImplementedError: Supervised fastText models are not supported
```
I do not think only the French model is supervised. Is there any bug? If it is not a bug in gensim, I guess there is some problem in the model. With a closer look, I find that the value of `nwords` and the size of vocabulary is 1152450, while the size of vectors  is 1152449. I am not sure what is the reason of this mismatch. @cpuhrsch

System: RHEL 7
Gensim: 3.7.2

Some related issue: https://github.com/facebookresearch/fastText/issues/218
"
504,https://github.com/RaRe-Technologies/gensim/issues/2531,2531,[],closed,2019-06-17 10:28:32+00:00,,MmWriter raises UserWarning on __init__,"#### Problem description

When using MmCorpus, the MmWriter class raises a UserWarning on `__init__` because it is using a deprecated function of smart_open.

#### Steps/code/corpus to reproduce

```python
MmCorpus.serialize('corpus.mm', some_corpus)

[2019-06-17 13:20:19,741] [INFO] {save_corpus:122} storing corpus in Matrix Market format to corpus.mm
/home/rob/venv/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function
  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL
```

#### Versions

```
Linux-4.15.0-51-generic-x86_64-with-Ubuntu-18.04-bionic
Python 3.6.7 (default, Oct 22 2018, 11:32:17) 
[GCC 8.2.0]
NumPy 1.16.3
SciPy 1.3.0
gensim 3.7.3
FAST_VERSION 1
```"
505,https://github.com/RaRe-Technologies/gensim/issues/2532,2532,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}, {'id': 1602334472, 'node_id': 'MDU6TGFiZWwxNjAyMzM0NDcy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20MEDIUM', 'name': 'impact MEDIUM', 'color': '7af49f', 'default': False, 'description': 'Big annoyance for affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",open,2019-06-18 03:16:47+00:00,,"WordEmbeddingsKeyedVectors.add() doesn't clear `vectors_norm`, causing `IndexError` on later `most_similar()`","As reported in a StackOverflow question/answer: https://stackoverflow.com/a/56641265/130288

An adapted version of the asker's minimal test case (which could become a unit test):

~~~Python
import numpy as np
from gensim.models.keyedvectors import WordEmbeddingsKeyedVectors

kv = WordEmbeddingsKeyedVectors(vector_size=3)
kv.add(entities=['a', 'b'],
       weights=[np.random.rand(3), np.random.rand(3)])
kv.most_similar('a')  # works

kv.add(entities=['c'], weights=[np.random.rand(3)])
kv.most_similar('c')  # fails with `IndexError`
~~~

Clearing the `vectors_norm` property (with either `del` or assignment-to-`None`) should be sufficient to trigger re-calculation upon the next `most_similar()`. "
506,https://github.com/RaRe-Technologies/gensim/issues/2534,2534,"[{'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}]",closed,2019-06-19 04:04:20+00:00,,"""Pattern library is not installed"" ... but it is (perhaps because it is called pattern3)","<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I am trying to do a gensim tutorial project. I am attempting to lemmatize and getting this error:
ImportError: Pattern library is not installed. Pattern library is needed in order to use lemmatize function

After searching the web, I installed pattern3, I still get the same error. I tried to do 'import pattern3 as pattern' but that doesn't help. Obviously I'm on python 3 (3.6)

#### Steps/code/corpus to reproduce

 import gensim
 from gensim.utils import simple_preprocess, lemmatize
 import pattern3

lemmatize(""hello"")

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```

Darwin-15.6.0-x86_64-i386-64bit
Python 3.6.8 |Anaconda, Inc.| (default, Dec 29 2018, 19:04:46) 
[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]
NumPy 1.16.4
SciPy 1.2.1
gensim 3.7.3
FAST_VERSION 1

#### Additional info

`from pattern3.web import Twitter`
this works fine

`from pattern.web import Twitter`
this does not (even after I do `import pattern3 as pattern`)"
507,https://github.com/RaRe-Technologies/gensim/issues/2535,2535,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}, {'id': 1583467927, 'node_id': 'MDU6TGFiZWwxNTgzNDY3OTI3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/help%20wanted', 'name': 'help wanted', 'color': '1d76db', 'default': True, 'description': ''}]",open,2019-06-21 21:49:35+00:00,,streamlining most_similar_cosmul,"this is a feature request to make most_similar_cosmul() more similar (pun intended) to most_similar() by the following changes:

1. add restrict_vocab argument
2. allow positive and negative to be strings instead of list-of-strings in case of single words
3. allow usage in evaluate_word_analogies

"
508,https://github.com/RaRe-Technologies/gensim/issues/2536,2536,[],closed,2019-06-24 19:36:55+00:00,,"After parsing ""wikipedia-latest-pages-articles"" dump, in the output (text file), numeric text were trimmed out..!","<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

After parsing Wikipedia dump file,  I took a look at the output (text file) and confirmed that numeric texts were all gone. I thoroughly looked over the source-codes of related gensim scripts, but still struggling with this issue. 

#### Steps/code/corpus to reproduce

In particular, I would like to capture certain terms like ""3d printer"", ""web2.0"", and ""HTML5"" inside the corpus. The code below was self-edited based on 'Pang Yang's code. I supposed the problem might be lying in the way of preprocessing in ""WikiCorpus"" class, but I am still having no idea how to fix this issue. Thanks for your help in advance!   

#### Versions

Please provide the output of:

```python
from __future__ import print_function
 
import logging
import os.path
import six
import sys
 
from gensim.corpora import WikiCorpus
 
if __name__ == '__main__':
    program = os.path.basename(sys.argv[0])
    logger = logging.getLogger(program)
 
    logging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s')
    logging.root.setLevel(level=logging.INFO)
    logger.info(""running %s"" % ' '.join(sys.argv))
 
    # check and process input arguments
    if len(sys.argv) != 3:
        print(""Using: python process_wiki.py enwiki.xxx.xml.bz2 wiki.en.text"")
        sys.exit(1)
    inp, outp = sys.argv[1:3]
    space = "" ""
    i = 0

    
    #errors = 'ignore'
    #encoding='utf-8' 
    output = open(outp, 'w')
    wiki = WikiCorpus(inp, lemmatize=False, dictionary={})
    for text in wiki.get_texts():
        text = [x.encode('utf-8') for x in text]
        if six.PY3:
            output.write(b' '.join(text).decode('utf-8') + '\n')
        #   ###another method###
        #    output.write(
        #            space.join(map(lambda x:x.decode(""utf-8""), text)) + '\n')
        else:
            output.write(space.join(text) + ""\n"")
        i = i + 1
        if (i % 10000 == 0):
            logger.info(""Saved "" + str(i) + "" articles"")
 
    output.close()
    logger.info(""Finished Saved "" + str(i) + "" articles"")
```
"
509,https://github.com/RaRe-Technologies/gensim/issues/2537,2537,[],closed,2019-06-25 18:37:18+00:00,,FastText inconsistent normalization in adjust_vectors method vs word_vec,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

There is inconsistency in normalization in ```FastTextKeyedVectors#adjust_vectors``` vs ```WordEmbeddingsKeyedVectors#word_vec```

#### Steps/code/corpus to reproduce

adjust_vectors:
```
            word_vec /= len(ngram_hashes) + 1
```

word_vec method:
```
            return word_vec / len(ngram_hashes)
```

#### Versions

```
Linux-4.18.0-24-generic-x86_64-with-Ubuntu-18.04-bionic
Python 3.7.1 (default, Oct 22 2018, 11:21:55) 
[GCC 8.2.0]
NumPy 1.16.3
SciPy 1.2.1
gensim 3.7.3
FAST_VERSION 1
```
"
510,https://github.com/RaRe-Technologies/gensim/issues/2539,2539,"[{'id': 2460503557, 'node_id': 'MDU6TGFiZWwyNDYwNTAzNTU3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/question', 'name': 'question', 'color': 'e098e2', 'default': True, 'description': 'Discussions that are generally off-topic for the github issue tracker'}]",closed,2019-06-28 03:11:40+00:00,,Is it possible to run LdaMallet through Colab or it must be run through command line?,"I have downloaded, and unzipped mallet in google drive, and I need to use it through google colab:

from google.colab import drive
drive.mount('/content/gdrive')
import os
os.environ['MALLET_HOME'] = '/content/gdrive/My Drive/mallet-2.0.8'
mallet_path = 'content/gdrive/My Drive/mallet-2.0.8/bin/mallet'
model = LdaMallet(mallet_path, corpus=common_corpus, num_topics=20, id2word=common_dictionary)

but i got this error:

CalledProcessError                        Traceback (most recent call last)
<ipython-input-110-fdec0424e86e> in <module>()
      1 mallet_path = 'content\\gdrive\\My Drive\\mallet-2.0.8\\bin\\mallet.bat'
----> 2 ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)

3 frames
/usr/local/lib/python3.6/dist-packages/gensim/utils.py in check_output(stdout, *popenargs, **kwargs)
   1877             error = subprocess.CalledProcessError(retcode, cmd)
   1878             error.output = output
-> 1879             raise error
   1880         return output
   1881     except KeyboardInterrupt:

CalledProcessError: Command 'content\gdrive\My Drive\mallet-2.0.8\bin\mallet.bat import-file --preserve-case --keep-sequence --remove-stopwords --token-regex ""\S+"" --input /tmp/f39c83_corpus.txt --output /tmp/f39c83_corpus.mallet' returned non-zero exit status 127."
511,https://github.com/RaRe-Technologies/gensim/issues/2540,2540,[],open,2019-06-28 07:08:20+00:00,,Refactor evaluate_word_analogies method,"That method is quite long, complicated and difficult to read. Tripped up over it in a recent code review."
512,https://github.com/RaRe-Technologies/gensim/issues/2541,2541,"[{'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}, {'id': 1583467927, 'node_id': 'MDU6TGFiZWwxNTgzNDY3OTI3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/help%20wanted', 'name': 'help wanted', 'color': '1d76db', 'default': True, 'description': ''}]",closed,2019-06-28 12:30:21+00:00,,min_similarity & max_distance does not work in levsim,"#### Expecting

As doc says, `max_distance` is a more efficient way, more quickly.
https://github.com/RaRe-Technologies/gensim/blob/369cc638225a2080faec25c4e2f6448d31e0492b/gensim/similarities/levenshtein.py#L32-L37

#### Problem description

However, `max_distance` does not speed up the process

https://github.com/RaRe-Technologies/gensim/blob/369cc638225a2080faec25c4e2f6448d31e0492b/gensim/similarities/levenshtein.py#L48-L51"
513,https://github.com/RaRe-Technologies/gensim/issues/2543,2543,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 175642, 'node_id': 'MDU6TGFiZWwxNzU2NDI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/wishlist', 'name': 'wishlist', 'color': 'd7e102', 'default': False, 'description': 'Feature request'}]",closed,2019-07-01 07:25:18+00:00,,Add option to choose subset for negative sampling,"I want to train a Word2Vec model where I can specify a custom negative subsampling subset for each input word.

This may be implemented by adding an argument for a pre-defined list which defines the negative sampling subset for each word in vocab. Another possible solution could be to allow passing a user function which returns the subset to sample from.

I know that this would sure make the computation much complex, but this is a much-needed feature if someone is trying to regulate the features learned by the model.

Do tell, if more explanation is needed.

Thank you! 😃"
514,https://github.com/RaRe-Technologies/gensim/issues/2548,2548,[],closed,2019-07-03 05:47:07+00:00,,Drop Py2 support,"An increasing number of our dependencies are dropping support for Py2. Numpy and pytest are the more visible examples, but there are others. Dealing with this requires identifying such packages (usually, through failed builds) and working around the problem. This hits us hard on two fronts:

1. It consumes precious maintainer time (e.g. https://github.com/RaRe-Technologies/gensim/pull/2546)
2. It blocks other work: we cannot reliably merge pull requests while our builds are failing

I recommend that we prioritize removing Py2 support. To get there:

1. Get builds working again (https://github.com/RaRe-Technologies/gensim/pull/2546 should finally work, after several days of poking around)
2. Merge any PRs that are ready to merge
3. Pause work on the remaining PRs
4. Release 3.9.0, the next minor version, and the last version to support Py2
5. Aggressively remove Py2 support
6. Release 4.0.0, explicitly mention that it's Py3 only

I think the above plan is a reasonable compromise:

- People who are stuck with Py2 for whatever reason can still continue to use 3.9.0 (or any previous version)
- Development and maintenance will continue with Py3 only

@piskvorky @menshikh-iv Thoughts?"
515,https://github.com/RaRe-Technologies/gensim/issues/2549,2549,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}, {'id': 1584013467, 'node_id': 'MDU6TGFiZWwxNTg0MDEzNDY3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/conda', 'name': 'conda', 'color': 'c9ef58', 'default': False, 'description': ''}]",closed,2019-07-03 07:32:51+00:00,,Fast version of Word2Vec gone after an update of Gensim,"Hi, I'm having trouble with the fast version of Word2Vec after an update of gensim. I am using Windows 10, Python 3.7.3 and Conda 4.7.5. 

Here are the exact steps that I did : 

1. I created a new environment with : `conda create --name envTest`

2. I successfully activated envTest (`conda activate envTest`) and installed gensim (`conda install gensim`).

The latest version available of Gensim on Anaconda seems to be 3.4.0 : 
![screen3](https://user-images.githubusercontent.com/48619415/60570834-a6b19800-9d72-11e9-8c23-fc23b2e1010d.png)

At this moment, there was the fast version of Word2Vec : 
![screen2](https://user-images.githubusercontent.com/48619415/60570880-c1840c80-9d72-11e9-881b-185374d74a42.PNG)

Then, I tried to use WordEmbeddingSimilarityIndex from gensim.models, but it gave me this error : 
![screen1](https://user-images.githubusercontent.com/48619415/60571044-13c52d80-9d73-11e9-9502-58188087843a.PNG)

According to this post [https://stackoverflow.com/questions/54650673/how-to-import-wordembeddingsimilarityindex-function-from-gensim-module](url), my version of gensim is too old to use WordEmbeddingSimiliratyIndex, so I updated it.

I tried to update it with conda, but it told me that there is nothing to update : 
![screen4](https://user-images.githubusercontent.com/48619415/60571197-6a326c00-9d73-11e9-81b0-b6834d5462e1.PNG)

So, I tried with pip, and it works (`python -m pip install --user --upgrade gensim`). Gensim's version is now 3.7.3 and WordEmbeddedSimilarityIndex works perfectly. 
![screen5](https://user-images.githubusercontent.com/48619415/60571281-95b55680-9d73-11e9-8513-a7815cf908e9.PNG)

Finally, the problem is that after the update, the fast version was gone : 
![screen6](https://user-images.githubusercontent.com/48619415/60571298-a49c0900-9d73-11e9-9c4b-8fc916264b3b.PNG)

Does someone knows where this problem comes from ? "
516,https://github.com/RaRe-Technologies/gensim/issues/2550,2550,[],closed,2019-07-03 14:00:58+00:00,,FastText with hs=1 and negative>0,"The [docs](https://radimrehurek.com/gensim/models/fasttext.html) says:
> *hs* ({1,0}, optional) – If 1, hierarchical softmax will be used for model training. If set to 0, *and negative is non-zero*, negative sampling will be used.
> *negative* (int, optional) – If > 0, negative sampling will be used, the int for negative specifies how many “noise words” should be drawn (usually between 5-20). If set to 0, no negative sampling is used.

So I would expect that if `hs=1`, the model will use hierarchical softmax and the value of `negative` is irrelevant, right?

This doesn't seem to be the case: if I run two perfectly deterministic (i.e., `worker=1`, fixed `seed` and `PYTHONHASHSEED` set) runs on the same input with:
 1. `hs=1 negative=0`, and
 2. `hs=1 negative=5`
resulting word vectors have different values.

How can `hs` and `negative` coexist? I've looked at the code but I couldn't find any place implementing the ""exclusive"" logic implied by the documentation above."
517,https://github.com/RaRe-Technologies/gensim/issues/2553,2553,"[{'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}, {'id': 1583467927, 'node_id': 'MDU6TGFiZWwxNTgzNDY3OTI3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/help%20wanted', 'name': 'help wanted', 'color': '1d76db', 'default': True, 'description': ''}]",closed,2019-07-05 21:11:42+00:00,,LdaModel trains beyond size of corpus when using an iterable,"#### Problem description

When streaming documents/bag of words to LdaModel via a custom iterable, LdaModel will train beyond the size of the corpus, with output like `19-07-05 22:53:43  PROGRESS: pass 0, at document #178000/50000` -- where the number left to the `/` is higher than the number right to it.

#### Steps/code/corpus to reproduce

```python
from gensim.models import LdaModel
import logging
logging.basicConfig(format='%(asctime)s  %(message)s', \
    datefmt='%y-%m-%d %H:%M:%S', level=logging.INFO)

class TestIterable:
    def __init__(self):
        self.bag_of_words = [(0,2), (3,1), (6,1), (100,2)]
        self.cursor = 0

    def __iter__(self):
        self.cursor = 0
        logging.info('TestIterable() __iter__ was called')
        return self

    def __next__(self):
        if self.cursor < 50000:
            self.cursor += 1
            return self.bag_of_words
        else:
            logging.info('TestIterable() returned StopIteration')
            raise StopIteration


corpus = TestIterable()
# uncommenting this part will make a list out of the corpus
# corpus = [document for document in corpus]

logging.info('performing lda training')
trained_model = LdaModel(corpus, num_topics=2)
```

Using the TestIterable() will result in LdaModel training indefinitively. Converting the TestIterable() corpus to a list will lead to the expected result of a proper training. 

I have not written too many iterables so far, and of course there could be a problem there. But as far as I could infer from the LdaModel documentation, all that is required is an interable -- and to the best of my knowledge, `corpus = TestIterable()` is a proper iterable, and iterator as well. 

Thanks a lot!

#### Versions

Linux-3.10.0-862.14.4.el7.x86_64-x86_64-with-centos-7.5.1804-Core
Python 3.6.4 (default, Apr 10 2018, 07:54:00) 
[GCC 4.8.5 20150623 (Red Hat 4.8.5-16)]
NumPy 1.14.2
SciPy 1.0.1
gensim 3.7.3
FAST_VERSION 0"
518,https://github.com/RaRe-Technologies/gensim/issues/2554,2554,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}]",closed,2019-07-10 16:50:13+00:00,,WikiCorpus.get_text logs ARTICLE_MIN_WORDS instead of article_min_tokens,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

`WikiCorpus.get_texts` logs `ARTICLE_MIN_WORDS` instead of `article_min_tokens`.
I've passed a custom value for `article_min_tokens` but instead default one gets logged.
See:
https://github.com/RaRe-Technologies/gensim/blob/3.8.0/gensim/corpora/wikicorpus.py#L703
https://github.com/RaRe-Technologies/gensim/blob/3.8.0/gensim/corpora/wikicorpus.py#L712

#### Steps/code/corpus to reproduce

1. Just provide any value for `article_min_tokens` (except 50 obviously) in `WikiCorpus.__init__`
2. Invoke `get_texts`
2. See default one in logs

#### Versions

Please provide the output of:

```python
Python 3.7.3 (default, May  8 2019, 05:28:42)
[GCC 6.3.0 20170516] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import platform; print(platform.platform())
Linux-4.9.125-linuxkit-x86_64-with-debian-9.9
>>> import sys; print(""Python"", sys.version)
Python 3.7.3 (default, May  8 2019, 05:28:42)
[GCC 6.3.0 20170516]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.16.4
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.3.0
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.7.3
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1
```
"
519,https://github.com/RaRe-Technologies/gensim/issues/2555,2555,[],closed,2019-07-10 20:02:19+00:00,,`smart_open` dependency requirement outdated?,"Gensim claims to require smart_open >= 1.7.0:
https://github.com/RaRe-Technologies/gensim/blob/f97d0e793faa57877a2bbedc15c287835463eaa9/setup.py#L384

but doesn't Gensim depend on `smart_open.open` now, which was introduced only in smart_open >= 1.8.1?

https://github.com/RaRe-Technologies/smart_open/releases/tag/1.8.1

(a suspicion based on seeing user issues on the [mailing list](https://groups.google.com/forum/#!topic/gensim/FSxNYppNpO8); are we CI testing against the *oldest* supported versions of our dependencies?)"
520,https://github.com/RaRe-Technologies/gensim/issues/2556,2556,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}, {'id': 1602279836, 'node_id': 'MDU6TGFiZWwxNjAyMjc5ODM2', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20MEDIUM', 'name': 'reach MEDIUM', 'color': 'ef7a1a', 'default': False, 'description': 'Affects a significant number of users'}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}]",closed,2019-07-14 16:23:13+00:00,,D2VTransformer raises if passed a Pandas series without index key 0,"`D2VTransformer` raises if passed a Pandas series with an index that does not contain the key 0:

```python
import pandas as pd
from gensim.sklearn_api import D2VTransformer
from gensim.test.utils import common_texts

series = pd.Series(common_texts)
series.index += 1  # Increment the index so that it does not contain the key 0

transformer = D2VTransformer(min_count=1, size=5)
transformer.fit(series)
```

Output:

```python
﻿Traceback (most recent call last):
  File ""main.py"", line 9, in <module>
    transformer.fit(series)
  File ""venv/lib/python3.7/site-packages/gensim/sklearn_api/d2vmodel.py"", line 162, in fit
    if isinstance(X[0], doc2vec.TaggedDocument):
  File ""venv/lib/python3.7/site-packages/pandas/core/series.py"", line 868, in __getitem__
    result = self.index.get_value(self, key)
  File ""venv/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 4375, in get_value
    tz=getattr(series.dtype, 'tz', None))
  File ""pandas/_libs/index.pyx"", line 81, in pandas._libs.index.IndexEngine.get_value
  File ""pandas/_libs/index.pyx"", line 89, in pandas._libs.index.IndexEngine.get_value
  File ""pandas/_libs/index.pyx"", line 132, in pandas._libs.index.IndexEngine.get_loc
  File ""pandas/_libs/hashtable_class_helper.pxi"", line 987, in pandas._libs.hashtable.Int64HashTable.get_item
  File ""pandas/_libs/hashtable_class_helper.pxi"", line 993, in pandas._libs.hashtable.Int64HashTable.get_item
KeyError: 0
```

This occurs because the [`fit`](https://github.com/RaRe-Technologies/gensim/blob/4543646d3fe3496e11bc935e72cbf9b18504442e/gensim/sklearn_api/d2vmodel.py#L162) and [`transform`](https://github.com/RaRe-Technologies/gensim/blob/4543646d3fe3496e11bc935e72cbf9b18504442e/gensim/sklearn_api/d2vmodel.py#L198) methods of `D2VTransformer` require `__getitem__` on the passed iterable not to raise an exception for key 0.

Versions:

Darwin-18.6.0-x86_64-i386-64bit
Python 3.7.3 (default, Mar 27 2019, 09:23:15) [Clang 10.0.1 (clang-1001.0.46.3)]
NumPy 1.16.4
SciPy 1.3.0
gensim 3.8.0
FAST_VERSION 1"
521,https://github.com/RaRe-Technologies/gensim/issues/2557,2557,[],closed,2019-07-15 05:04:08+00:00,,"""TypeError: '<' not supported between … 'str' and 'int'""","<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? What is the expected result? What are you seeing instead?

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
"
522,https://github.com/RaRe-Technologies/gensim/issues/2558,2558,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 1602279836, 'node_id': 'MDU6TGFiZWwxNjAyMjc5ODM2', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20MEDIUM', 'name': 'reach MEDIUM', 'color': 'ef7a1a', 'default': False, 'description': 'Affects a significant number of users'}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}]",open,2019-07-19 14:35:53+00:00,,"When creating a dictionary from a corpus with a id => word mapping, the inverse is not created","#### Problem description

CoherenceModel tries to access Dictionary.id2token when supplied with ids in the topics list. Dictionary.from_corpus initiates the token2id variable, but not the id2token variable.

A workaround is calling the dictionary as this will check and find that the id2token variable is not of equal length to token2id.

#### Steps/code/corpus to reproduce

``` python
from gensim.corpora import Dictionary as GensimDictionary
from gensim.models import CoherenceModel
from gensim.test.utils import common_corpus, common_dictionary, common_texts

common_dictionary[1]  # have it generate id2token (workaround)
id2word = common_dictionary.id2token
gensim_dict = GensimDictionary.from_corpus(common_corpus, id2word=id2word)
cm = CoherenceModel(topics=[[0, ""system""], [""human"", ""interface""]], texts=common_texts, dictionary=gensim_dict,
                    coherence='c_v')
```

Output:
```
2019-07-19 16:21:31,074 : INFO : 'pattern' package not found; tag filters are not available for English
2019-07-19 16:21:31,078 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2019-07-19 16:21:31,078 : INFO : built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)
2019-07-19 16:21:31,741 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2019-07-19 16:21:31,741 : INFO : built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)
Traceback (most recent call last):
  File ""C:\Workdir\programs\miniconda\envs\processing3.6\lib\site-packages\gensim\models\coherencemodel.py"", line 445, in _ensure_elements_are_ids
    return np.array([self.dictionary.token2id[token] for token in topic])
  File ""C:\Workdir\programs\miniconda\envs\processing3.6\lib\site-packages\gensim\models\coherencemodel.py"", line 445, in <listcomp>
    return np.array([self.dictionary.token2id[token] for token in topic])
KeyError: 0
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File ""<input>"", line 1, in <module>
  File ""C:\Program Files\JetBrains\PyCharm 2019.1.3\helpers\pydev\_pydev_bundle\pydev_umd.py"", line 197, in runfile
    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script
  File ""C:\Program Files\JetBrains\PyCharm 2019.1.3\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""gensim_failure.py"", line 22, in <module>
    coherence='c_v')
  File ""C:\Workdir\programs\miniconda\envs\processing3.6\lib\site-packages\gensim\models\coherencemodel.py"", line 212, in __init__
    self.topics = topics
  File ""C:\Workdir\programs\miniconda\envs\processing3.6\lib\site-packages\gensim\models\coherencemodel.py"", line 427, in topics
    topic_token_ids = self._ensure_elements_are_ids(topic)
  File ""C:\Workdir\programs\miniconda\envs\processing3.6\lib\site-packages\gensim\models\coherencemodel.py"", line 448, in _ensure_elements_are_ids
    return np.array([self.dictionary.token2id[token] for token in topic])
  File ""C:\Workdir\programs\miniconda\envs\processing3.6\lib\site-packages\gensim\models\coherencemodel.py"", line 448, in <listcomp>
    return np.array([self.dictionary.token2id[token] for token in topic])
  File ""C:\Workdir\programs\miniconda\envs\processing3.6\lib\site-packages\gensim\models\coherencemodel.py"", line 447, in <genexpr>
    topic = (self.dictionary.id2token[_id] for _id in topic)
KeyError: 0
```

#### Versions

Please provide the output of:

```
Windows-10-10.0.17134-SP0
Python 3.6.7 |Anaconda, Inc.| (default, Dec 10 2018, 20:35:02) [MSC v.1915 64 bit (AMD64)]
NumPy 1.15.4
SciPy 1.2.0
gensim 3.7.0
FAST_VERSION 0
```
"
523,https://github.com/RaRe-Technologies/gensim/issues/2560,2560,[],closed,2019-07-26 08:06:20+00:00,,can save model with BM25?,"Hi, thanks for sharing. :)
I want to ask something.
Can I save model , and load model when I need to compute the score?
If so, does it have any function to save and load?"
524,https://github.com/RaRe-Technologies/gensim/issues/2561,2561,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}, {'id': 1583467927, 'node_id': 'MDU6TGFiZWwxNTgzNDY3OTI3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/help%20wanted', 'name': 'help wanted', 'color': '1d76db', 'default': True, 'description': ''}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",open,2019-07-26 17:46:29+00:00,,WikiCorpus.filter_wiki/remove_markup don't remove heading-markup,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I am trying to get clean wiki texts. But still getting headings markup.

#### Steps/code/corpus to reproduce

Just create WikiCorpus and call `get_texts`. Some texts will contain `==headings==` (different number of `=` and different headings, of course).
Simple test-case:
```
>>> import gensim.corpora.wikicorpus
>>> print(gensim.corpora.wikicorpus.filter_wiki('===heading==='))
===heading===
```

#### Versions

```Linux-4.9.125-linuxkit-x86_64-with-debian-10.0
Python 3.7.4 (default, Jul 13 2019, 14:04:11) 
[GCC 8.3.0]
NumPy 1.16.4
SciPy 1.3.0
gensim 3.8.0
FAST_VERSION 1
```
"
525,https://github.com/RaRe-Technologies/gensim/issues/2562,2562,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-07-27 16:16:05+00:00,,word2vec does not find model.wv,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? What is the expected result? What are you seeing instead?

Hey,
I am trying to reproduce this [word2vec tutorial](https://radimrehurek.com/gensim/models/word2vec.html), but at a certain point I always run into the same error. When I try to run the ```vector = wv['computer']  # numpy vector of a word``` part of the tutorial, I get  the ```FileNotFoundError: [Errno 2] No such file or directory: 'model.wv'``` error. I have executed all previous tutorial steps, so the file should be created, but the model still does not find it.

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform()) Windows-10-10.0.17134-SP0

import sys; print(""Python"", sys.version) Python 3.7.3 (default, Apr 24 2019, 15:29:51) [MSC v.1915 64 bit (AMD64)]

import numpy; print(""NumPy"", numpy.__version__)  NumPy 1.16.4

import scipy; print(""SciPy"", scipy.__version__) SciPy 1.2.1

import gensim; print(""gensim"", gensim.__version__) gensim 3.4.0

from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION) FAST_VERSION 1
```
"
526,https://github.com/RaRe-Technologies/gensim/issues/2563,2563,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",open,2019-07-28 12:56:10+00:00,,HdpModel gets into infinite loop on empty input corpus,"#### Problem description

Hi ~ I find that when I give a empty array as corpus to the constructor of HdpModel, it would never ends,the program got an endless loop.

I know I really should check the corpus to make sure it cannot be an empty array,but perhaps the HdpModel constructor should raise an Exception at once instead of endless-loop without any message(which perhaps make some new learner confused )

#### Steps/code/corpus to reproduce

You can repeat the problem I found before
```python

# _*_ coding=utf-8 _*_
from gensim import corpora
from gensim.models import HdpModel

if __name__ == '__main__':
    dic = corpora.Dictionary([])
    print(1)
   m = HdpModel(corpus=[], id2word=dic, alpha=1, T=500)
    print('this will never be print')

```

in actually, when the corpus is [](an empty list),the HdpModel's constructor call the
```
 if corpus is not None:
            self.update(corpus)
```
and in the update function, when the corpus is empty array, the ""while True"" loop will never ends .It just because of that ""utils.grouper(corpus, self.chunksize)"" in ""while True"" is an empty generator too, "" for chunk in utils.grouper"" will never happen， caused the while-True loop never ends.

That's very nice of you to see the issue, I am not a native English speaker，so please forgive my pool English .If you have any question, just communicate with me .

"
527,https://github.com/RaRe-Technologies/gensim/issues/2564,2564,[],closed,2019-07-29 13:30:54+00:00,,Preprocessing Inexplicably Removes Term,"Sorry if this has already been answered, I went through quite a few closed issues and documentation but can't find an answer: why is the term `computer` removed?

```python
from gensim.parsing.preprocessing import preprocess_string

preprocess_string(""Human machine interface for lab abc computer applications"")
#> [u'human', u'machin', u'interfac', u'lab', u'abc', u'applic']
```
"
528,https://github.com/RaRe-Technologies/gensim/issues/2565,2565,[],closed,2019-07-31 07:07:12+00:00,,"KeyError: ""word 'coffee_pot' not in vocabulary""","Hello,

I am trying to get similarity between two words. I am using word vectors (numberbatch-17.06.txt) provided by ConceptNet Numberbatch. [Link](https://github.com/commonsense/conceptnet-numberbatch) to their Github, where you can downloaded their biggest multilingual file (70+ language support) or the smaller english-only version.

What have I currently achieved:
```python
model = gensim.models.KeyedVectors.load_word2vec_format('numberbatch-17.06.txt', binary=False)
print(model.vector_size)
print(model.similarity(""coffee_pot"", ""tea_kettle""))
```
Results:
```python
300
`KeyError: ""word 'coffee_pot' not in vocabulary""
```
No matter the word pairs, it never finds any similarities. 

Interesting is that when I do the exact same thing with ConceptNet smaller english-only word vector file, all works just fine:
```python
model = gensim.models.KeyedVectors.load_word2vec_format('numberbatch-en-17.06.txt', binary=False)
print(model.vector_size)
print(model.similarity(""coffee_pot"", ""tea_kettle""))
```
Results:
```python
300
0.5312845
```

For testing purposes when I iterate over every line of these files, I get the following results:
1) numberbatch-17.06.txt -> 1 917 248
2) numberbatch-en-17.06.txt -> 417 195

This shows us that the files are just fine and contain data. 

Example content of file numberbatch-en-17.06.txt:
```python
417194 300
tea_kettle 0.0387 -0.0292 0.2034 0.0983 -0.0785 -0.0051 -0.0116 -0.1310 0.1573 0.0358 -0.1409 -0.0158 -0.0262 -0.0663 -0.0684 0.1487 0.0211 0.0157 0.0348 -0.1160 -0.0701 -0.0608 -0.0211 0.0731 0.1092 -0.0442 0.0256 0.0136 0.0202 0.0671 0.0546 -0.0398 0.0347 0.1572 0.0104 0.0684 0.0615 0.0011 0.0769 -0.0849 0.1121 -0.0146 0.0206 0.0890 0.0034 0.0998 -0.1155 -0.0272 0.1015 0.0245 -0.0029 0.0695 0.0315 0.0344 -0.1253 -0.0065 0.0318 0.0381 0.0714 0.1117 0.0643 0.0176 -0.0146 0.0323 -0.0121 0.0828 0.1397 0.0657 0.0341 -0.0022 -0.0808 -0.0102 -0.0376 -0.0665 0.0470 -0.0740 0.0475 -0.0439 -0.1397 -0.0080 -0.0162 -0.0080 -0.0090 0.0758 0.0810 0.0960 0.0251 0.0324 0.0364 -0.0174 0.0730 0.0455 0.0726 -0.0408 0.1600 -0.0330 0.0497 0.0386 0.0575 0.0502 0.0282 0.0694 0.0284 0.0106 0.0604 -0.0308 0.1479 0.0419 0.0148 -0.0838 0.0076 0.0850 -0.0081 0.0001 -0.0346 0.0440 0.0194 -0.0662 -0.0037 -0.0127 0.0501 -0.0037 -0.0433 0.0840 0.0849 -0.0227 -0.0348 -0.0678 0.0064 0.0069 -0.0961 0.0382 -0.0234 -0.0157 0.0476 0.0230 0.0274 -0.0948 -0.0189 -0.0320 0.0148 0.0048 0.0111 0.0164 -0.0060 0.0528 -0.0438 -0.0374 0.0483 -0.0509 -0.0621 -0.0944 0.0287 -0.0347 0.0426 0.0072 0.0636 -0.0269 0.0194 0.0125 0.0522 -0.0145 -0.0429 -0.0658 0.0550 -0.0563 0.0634 -0.0271 0.0067 0.0529 0.0446 0.0477 -0.0389 -0.0156 -0.0803 0.0096 -0.0045 0.0738 0.0082 0.1149 0.0426 0.0435 0.1527 0.0145 0.0287 0.0157 0.0240 -0.0163 0.0111 -0.1571 -0.0086 0.0315 0.1189 -0.0286 0.0136 -0.0009 -0.0022 -0.0620 -0.0087 -0.0087 0.0451 -0.0221 0.0440 0.0300 0.0246 -0.0211 0.0015 -0.0988 0.0207 0.0209 -0.0194 0.0085 0.0048 -0.0461 -0.0463 0.0118 0.0319 0.0644 0.0314 -0.0716 0.0013 0.0189 0.0017 -0.0892 -0.0420 -0.0389 0.0255 -0.0115 -0.0180 -0.0208 -0.0679 -0.0670 -0.0114 0.0184 0.0075 -0.0079 0.0893 0.1186 -0.0519 0.0240 0.0709 -0.0012 -0.0427 0.0180 -0.0194 0.0077 0.0242 0.0327 0.0736 -0.1041 0.0360 -0.0107 0.1080 -0.0048 0.0447 -0.0109 -0.0357 0.0029 0.0464 0.0288 0.0930 0.0280 -0.0380 -0.0303 0.0239 -0.0361 0.1058 0.0381 0.0397 0.0503 0.0488 -0.0014 -0.0189 0.0218 0.0538 0.0643 -0.0117 -0.0569 -0.0072 -0.0235 -0.0106 -0.0155 0.0249 0.0790 0.0974 -0.0126 -0.0214 -0.0303 -0.0031 -0.0403 -0.1275 0.0454 -0.0159 -0.0287 -0.0092 -0.0471 -0.0019 0.0183 -0.0509 -0.0412
coffee_pot -0.0230 0.0046 0.0981 0.1118 -0.0274 -0.0430 0.0668 -0.1377 0.1417 -0.0054 -0.1251 0.0249 -0.0319 -0.0386 -0.0870 0.1135 0.0580 0.0420 -0.0394 -0.0855 -0.1048 -0.0423 -0.0198 0.0363 0.0809 -0.0504 -0.0459 0.0026 -0.1134 -0.0098 0.0396 0.0257 0.0578 0.0409 0.1037 0.0127 0.0631 0.0111 0.0341 -0.0565 0.0457 -0.0754 0.0174 0.0017 0.0379 0.0919 0.0048 -0.0303 0.1128 -0.0517 -0.0679 0.0375 0.0068 0.0612 -0.0367 -0.0346 0.0093 0.0608 0.0587 0.0321 0.0465 -0.0551 -0.0880 -0.0569 -0.0324 0.0402 0.0586 0.0173 -0.0797 -0.0163 -0.0103 -0.0142 -0.0537 -0.0697 0.1746 -0.0507 0.0150 -0.0284 -0.1064 -0.0054 -0.0395 -0.0012 0.0224 -0.0276 -0.0227 0.0777 0.0406 0.0460 0.0104 -0.0124 -0.0179 -0.0581 0.0546 0.0230 0.1200 -0.0507 0.1206 0.0995 0.1138 0.1081 0.1309 0.1133 0.0837 0.0106 0.1533 -0.0413 0.0384 0.0320 -0.0448 0.0390 -0.0273 -0.0037 0.0100 0.1070 0.1078 -0.0111 -0.0051 -0.1064 -0.0507 -0.0184 -0.0077 -0.0425 -0.0462 0.0528 0.0964 -0.0050 0.0147 -0.0723 -0.0232 0.0427 -0.1352 0.0433 -0.0277 -0.0064 0.0547 -0.0011 0.0105 0.0018 -0.0281 -0.0369 0.0138 -0.0069 0.0185 0.0368 0.0152 0.0851 -0.0760 0.0149 0.0127 -0.0212 0.0215 -0.0758 -0.0211 -0.0327 0.0059 0.0646 0.0738 -0.0097 0.0307 -0.0074 -0.0192 0.0750 0.0092 -0.0525 0.0939 0.0345 0.0386 -0.0119 -0.0113 0.0230 0.0050 0.0099 0.0856 0.0425 -0.0634 -0.0230 0.0607 -0.0060 -0.0486 0.1053 0.0487 -0.0081 0.0836 -0.0040 0.0138 -0.1171 0.0372 0.0944 0.0219 -0.0437 0.0506 0.0204 0.1172 0.0622 -0.0056 0.0303 -0.0120 -0.0067 0.0493 -0.0059 -0.0535 -0.0646 0.0731 0.0510 -0.0589 0.0143 -0.0261 -0.1250 0.0329 -0.0203 -0.0688 -0.0065 0.0075 0.0406 -0.0259 0.0218 0.0851 0.1140 0.0471 -0.0155 -0.0035 0.0228 0.0486 -0.0672 -0.0486 -0.0427 0.0194 0.1313 -0.0559 0.1879 0.0610 0.0066 -0.0540 0.0240 0.0789 0.0820 -0.0753 0.0255 -0.0801 -0.0039 0.0454 -0.0655 0.0078 -0.0493 -0.0665 -0.0217 0.0398 0.0206 0.0275 -0.1553 0.0141 -0.0150 -0.0216 -0.0092 0.0282 0.0306 0.0238 0.0245 -0.0251 -0.0183 0.0438 0.0267 -0.0379 0.0549 0.0149 -0.0172 -0.0228 0.0316 0.0067 0.0254 0.0174 -0.0269 -0.0616 0.0822 0.0304 -0.0101 0.0323 -0.0698 0.0373 0.0479 -0.0292 0.0060 0.0129 -0.0062 -0.0005 0.0549 -0.0928 0.0237 0.0139 -0.0256 -0.0110 -0.0107 0.0545 -0.0719 -0.0023 -0.0257 -0.0343 0.0371 -0.0116 -0.1188
...etc
```

I am assuming file numberbatch-17.06.txt has even more data inside (I can not open the txt file, as it is too massive).

What might be the issue here? Why I can not get similarities between words? Am I running out of memory?

#### Versions
```python
Darwin-18.6.0-x86_64-i386-64bit
Python 3.7.3 (default, Mar 27 2019, 16:54:48) 
[Clang 4.0.1 (tags/RELEASE_401/final)]
NumPy 1.15.4
SciPy 1.1.0
gensim 3.8.0
FAST_VERSION 1
```
"
529,https://github.com/RaRe-Technologies/gensim/issues/2566,2566,[],open,2019-08-01 07:08:22+00:00,,Google Cloud Jupiter Notebook: ,"Hi, 

On a Google Cloud Jupiter Notebook, I am trying to import a Glove txt file using the following commands but I keep gettting the same error. 
```
from gensim.scripts.glove2word2vec import glove2word2vec 
from gensim.test.utils import get_tmpfile
tmp_file = get_tmpfile(""test_word2vec.txt"")
glove2word2vec(""glove.6B.300d.txt"", tmp_file)
externalModel=KeyedVectors.load_word2vec_format(tmp_file)
```
The error is:
```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-8-21d446f7b71f> in <module>
----> 1 externalModel=KeyedVectors.load_word2vec_format(tmp_file)

~/.local/lib/python3.5/site-packages/gensim/models/keyedvectors.py in load_word2vec_format(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)
   1496         return _load_word2vec_format(
   1497             cls, fname, fvocab=fvocab, binary=binary, encoding=encoding, unicode_errors=unicode_errors,
-> 1498             limit=limit, datatype=datatype)
   1499 
   1500     def get_keras_embedding(self, train_embeddings=False):

~/.local/lib/python3.5/site-packages/gensim/models/utils_any2vec.py in _load_word2vec_format(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)
    392                 parts = utils.to_unicode(line.rstrip(), encoding=encoding, errors=unicode_errors).split("" "")
    393                 if len(parts) != vector_size + 1:
--> 394                     raise ValueError(""invalid vector on line %s (is this really the text format?)"" % line_no)
    395                 word, weights = parts[0], [datatype(x) for x in parts[1:]]
    396                 add_word(word, weights)

ValueError: invalid vector on line 59941 (is this really the text format?)
```
I have also tried to upgrade everything following the answers to similar issues with the following commands
```
pip3 install google-compute-engine
pip3 install --upgrade gensim smart_open
```
My current version is the following 

```
Name: gensim
Version: 3.8.0
Summary: Python framework for fast Vector Space Modelling
Home-page: http://radimrehurek.com/gensim
Author: Radim Rehurek
Author-email: me@radimrehurek.com
License: LGPLv2.1
Location: /home/jupyter/.local/lib/python3.5/site-packages
Requires: scipy, numpy, smart-open, six

```
Regards 
"
530,https://github.com/RaRe-Technologies/gensim/issues/2567,2567,"[{'id': 1583467927, 'node_id': 'MDU6TGFiZWwxNTgzNDY3OTI3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/help%20wanted', 'name': 'help wanted', 'color': '1d76db', 'default': True, 'description': ''}]",closed,2019-08-03 13:57:16+00:00,,gensim segfaults during LDA training,"Steps to reproduce:

First, create fresh virtual environment, and then

```
pip install gensim==3.8.0
pip install nltk==3.4 sklearn matplotlib==3.0.3 networkx==2.3 pandas==0.24.2 statsmodels==0.9.0
wget https://raw.githubusercontent.com/mpenkov/gensim/numfocus/docs/src/gallery/020_howtos/run_howto_compare_lda.py
python run_howto_compare_lda.py
```

The segfault occurs on the 19th training pass. I'm unable to track it down further right now, but leaving this here for the record."
531,https://github.com/RaRe-Technologies/gensim/issues/2568,2568,[],closed,2019-08-06 21:35:00+00:00,,It is possible to create word2vec that accepted in MITIE?,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description
Hi, I am a fresh rookie in NLP. 

I try MITIE (https://github.com/mit-nlp/MITIE) and it has wordrep tool that builds in cpp. But I have an issue with memory leaks when training using MITIE wordrep tool.
It is possible to create a model that accepted in MITIE word2vec?



#### Steps/code/corpus to reproduce

I need to create custom ner like (https://github.com/mit-nlp/MITIE/blob/master/examples/python/train_ner.py)

anyone know how to do gensim word2vec to train it with custom ner?


Kindly Advise"
532,https://github.com/RaRe-Technologies/gensim/issues/2569,2569,[],closed,2019-08-07 06:04:42+00:00,,loading a vocab file doesn't seem to support unicode_errors,"#### Problem description

Hi, thank you for providing gensim, which is an amzing lib, for us!

When I tried to read a vocab file generated by native word2vec command, I got an error.
```python
>>> model = gensim.models.KeyedVectors.load_word2vec_format(""test_model"",unicode_errors='replace',fvocab='test_vocab')
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/gensim-3.8.0-py3.7-linux-x86_64.egg/gensim/models/keyedvectors.py"", line 1498, in load_word2vec_format
    limit=limit, datatype=datatype)
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/gensim-3.8.0-py3.7-linux-x86_64.egg/gensim/models/utils_any2vec.py"", line 338, in _load_word2vec_format
    word, count = utils.to_unicode(line).strip().split()
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/gensim-3.8.0-py3.7-linux-x86_64.egg/gensim/utils.py"", line 359, in any2unicode
    return unicode(text, encoding, errors=errors)
UnicodeDecodeError: 'utf-8' codec can't decode bytes in position 9-10: invalid continuation byte
```

The cause seems that there is no option to work around when some decoding errors happens in the vocab file loading process.

In Python3.x, unicode is replaced with str at the top of utils_any2vec.py.

The default option of str(), built-in function, is
```python
class str(object=b'', encoding='utf-8', errors='strict')
```

So, I propose to make a room to cover some decoding errors for loading a vocab file :)


#### Steps/code/corpus to reproduce

1. Install Anaconda on Ubuntu18.04.
```bash
curl -LO https://repo.anaconda.com/archive/Anaconda3-2019.07-Linux-x86_64.sh
bash Anaconda3-2019.07-Linux-x86_64.sh
```
2 Clone 'gensim'
```bash
git clone https://github.com/RaRe-Technologies/gensim.git
```
3. Install gensim
```bash
cd gensim/
python setup.py install
```
4. Run the following script with test files.
```python
import gensim
model = gensim.models.KeyedVectors.load_word2vec_format(""test_model"",unicode_errors='replace',fvocab='test_vocab')
```
5. You will get an error like this.
```python
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/gensim-3.8.0-py3.7-linux-x86_64.egg/gensim/models/keyedvectors.py"", line 1498, in load_word2vec_format
    limit=limit, datatype=datatype)
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/gensim-3.8.0-py3.7-linux-x86_64.egg/gensim/models/utils_any2vec.py"", line 338, in _load_word2vec_format
    word, count = utils.to_unicode(line).strip().split()
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/gensim-3.8.0-py3.7-linux-x86_64.egg/gensim/utils.py"", line 359, in any2unicode
    return unicode(text, encoding, errors=errors)
UnicodeDecodeError: 'utf-8' codec can't decode bytes in position 9-10: invalid continuation byte
```

*Note: These are not generated by word2vec command. these files are for reproducing this error.*

#### Versions

Ubuntu 18.04


```python
>>> import platform; print(platform.platform())
Linux-4.15.0-1044-aws-x86_64-with-debian-buster-sid
>>> import sys; print(""Python"", sys.version)
Python 3.7.3 (default, Mar 27 2019, 22:11:17)
[GCC 7.3.0]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.17.0
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.3.0
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.8.0
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1

```


[testdata.zip](https://github.com/RaRe-Technologies/gensim/files/3475521/testdata.zip)
"
533,https://github.com/RaRe-Technologies/gensim/issues/2571,2571,[],closed,2019-08-08 06:56:57+00:00,,doc2vec.build_vocab() causes memory error when huge integer tag is given,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description
Not sure if this was intended,
but `doc2vec.build_vocab()` crashing with memory error regardless of corpus size 
when it takes huge integer tag as argument, in `TaggedDocument(sentence, tag)`
#### Steps/code/corpus to reproduce
```python
from gensim.models import Doc2Vec
from gensim.models.doc2vec import TaggedDocument

corpus = [
    ['this', 'is', 'a', 'tokenized', 'sentence']
]

tags_int = [
    1854020000
]

tags_str = [
    '1854020000'
]

docs_tagged_in_int = []
docs_tagged_in_str = []

for sentence, tag in zip(corpus, tags_int):
    tagged_document = TaggedDocument(sentence, tags=[tag])
    docs_tagged_in_int.append(tagged_document)

for sentence, tag in zip(corpus, tags_str):
    tagged_document = TaggedDocument(sentence, tags=[tag])
    docs_tagged_in_str.append(tagged_document)
    
d2v_model = Doc2Vec(vector_size=50)
d2v_model.build_vocab(docs_tagged_in_str) # This runs fine
print('this runs fine')
d2v_model = Doc2Vec(vector_size=50)
d2v_model.build_vocab(docs_tagged_in_int) # But this fails
```
Error:
```
---------------------------------------------------------------------------
MemoryError                               Traceback (most recent call last)
<ipython-input-17-ab795c660708> in <module>
      1 model_dbow = Doc2Vec(vector_size=50)
----> 2 model_dbow.build_vocab(docs_tagged)

~/anaconda3/envs/tensorflow_1.11/lib/python3.6/site-packages/gensim/models/doc2vec.py in build_vocab(self, documents, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)
    735         report_values['memory'] = self.estimate_memory(vocab_size=report_values['num_retained_words'])
    736         self.trainables.prepare_weights(
--> 737             self.hs, self.negative, self.wv, self.docvecs, update=update)
    738 
    739     def build_vocab_from_freq(self, word_freq, keep_raw_vocab=False, corpus_count=None, trim_rule=None, update=False):

~/anaconda3/envs/tensorflow_1.11/lib/python3.6/site-packages/gensim/models/doc2vec.py in prepare_weights(self, hs, negative, wv, docvecs, update)
    880         # set initial input/projection and hidden weights
    881         if not update:
--> 882             self.reset_weights(hs, negative, wv, docvecs)
    883         else:
    884             self.update_weights(hs, negative, wv)

~/anaconda3/envs/tensorflow_1.11/lib/python3.6/site-packages/gensim/models/doc2vec.py in reset_weights(self, hs, negative, wv, docvecs, vocabulary)
    886     def reset_weights(self, hs, negative, wv, docvecs, vocabulary=None):
    887         super(Doc2VecTrainables, self).reset_weights(hs, negative, wv)
--> 888         self.reset_doc_weights(docvecs)
    889 
    890     def reset_doc_weights(self, docvecs):

~/anaconda3/envs/tensorflow_1.11/lib/python3.6/site-packages/gensim/models/doc2vec.py in reset_doc_weights(self, docvecs)
    899             self.vectors_docs_lockf.fill(1.0)
    900         else:
--> 901             docvecs.vectors_docs = empty((length, docvecs.vector_size), dtype=REAL)
    902             self.vectors_docs_lockf = ones((length,), dtype=REAL)  # zeros suppress learning
    903 

MemoryError: 
```

#### Versions
```
Linux-4.20.13-1.el7.elrepo.x86_64-x86_64-with-centos-7.6.1810-Core
Python 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) 
[GCC 7.3.0]
NumPy 1.16.4
SciPy 1.2.1
gensim 3.4.0
FAST_VERSION 1
```
and I checked it crashes in version 3.8 also.

"
534,https://github.com/RaRe-Technologies/gensim/issues/2572,2572,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-08-09 09:11:27+00:00,,"C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.","How to solve this User Warning Error in Windows 10. I am running code with Command Prompt and writing it in Notepad++. 

 C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.

Kindly write such commands that can be executed in cmd."
535,https://github.com/RaRe-Technologies/gensim/issues/2574,2574,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}, {'id': 1583467927, 'node_id': 'MDU6TGFiZWwxNTgzNDY3OTI3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/help%20wanted', 'name': 'help wanted', 'color': '1d76db', 'default': True, 'description': ''}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}]",closed,2019-08-09 14:32:03+00:00,,Dictionary gensim.corpora should update the collection frequencies cfs after filtering with filter_extremes,"#### Problem description

I am using the Dictionary class gensim.corpora.dictionary.Dictionary , in particular the filter_extremes method and the cfs property (returning a collection frequencies dictionary mapping token_id to tokenfrequency). 
It appears that after using  filter_extremes, the cfs still shows unfiltered token_id's can be absent from the filtered Dictionary instance. This can lead to KeyErrors. 

#### Steps to reproduce

```python
from gensim.corpora import Dictionary
corpus = [['common','single'],['common']]
dct = Dictionary(corpus)
len(dct)  #2
dct.cfs   #{0: 2, 1: 1}
dct.filter_extremes(no_below=1, no_above=0.5, keep_n=1)
len(dct)  #1
dct.cfs   #{1: 1}
dct[1]
```

The last line fails with 'KeyError: 1', as the filtered Dictionary has only one element. I suspect the cfs dictionary should be updated once the Dictionary instance dct gets filtered by filter_extremes. The documentation has this warning for the filter_extremes method, but I do not think it is relevant for this case: ""After the pruning, resulting gaps in word ids are shrunk. Due to this gap shrinking, the same word may have a different word id before and after the call to this function!""

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)

Linux-4.15.0-50-generic-x86_64-with-LinuxMint-19-tara
Python 3.6.7 (default, Oct 22 2018, 11:32:17) 
[GCC 8.2.0]
NumPy 1.16.3
SciPy 0.19.1
gensim 3.8.0
FAST_VERSION 1
```
"
536,https://github.com/RaRe-Technologies/gensim/issues/2576,2576,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175986, 'node_id': 'MDU6TGFiZWwxNzU5ODY=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/testing', 'name': 'testing', 'color': '444444', 'default': False, 'description': 'Issue related with testing (code, documentation, etc)'}]",closed,2019-08-12 16:04:53+00:00,,Import KeyedVectors error: cannot import name 'open',"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I want to import KeyedVectors. Then I got the error: ImportError: cannot import name 'open'

#### Steps/code/corpus to reproduce
- Install the latest Gensim version (gensim-3.8.0)
- Then, try to run 'from gensim.models import KeyedVectors'
- Afterwards I got an error as printed in the below
```Traceback (most recent call last):
  File ""fastText_gensim_convert.py"", line 3, in <module>
    from gensim.models import KeyedVectors
  File ""/usr/local/lib/python3.6/dist-packages/gensim/__init__.py"", line 5, in <module>
    from gensim import parsing, corpora, matutils, interfaces, models, similarities, summarization, utils  # noqa:F401
  File ""/usr/local/lib/python3.6/dist-packages/gensim/parsing/__init__.py"", line 4, in <module>
    from .preprocessing import (remove_stopwords, strip_punctuation, strip_punctuation2,  # noqa:F401
  File ""/usr/local/lib/python3.6/dist-packages/gensim/parsing/preprocessing.py"", line 42, in <module>
    from gensim import utils
  File ""/usr/local/lib/python3.6/dist-packages/gensim/utils.py"", line 45, in <module>
    from smart_open import open
ImportError: cannot import name 'open'
```
#### Versions

```
>>> import platform; print(platform.platform())
Linux-4.15.0-55-generic-x86_64-with-Ubuntu-16.04-xenial
>>> import sys; print(""Python"", sys.version)
Python 3.6.9 (default, Jul  3 2019, 15:36:16) 
[GCC 5.4.0 20160609]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.15.4
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.1.0
>>> import gensim; print(""gensim"", gensim.__version__)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.6/dist-packages/gensim/__init__.py"", line 5, in <module>
    from gensim import parsing, corpora, matutils, interfaces, models, similarities, summarization, utils  # noqa:F401
  File ""/usr/local/lib/python3.6/dist-packages/gensim/parsing/__init__.py"", line 4, in <module>
    from .preprocessing import (remove_stopwords, strip_punctuation, strip_punctuation2,  # noqa:F401
  File ""/usr/local/lib/python3.6/dist-packages/gensim/parsing/preprocessing.py"", line 42, in <module>
    from gensim import utils
  File ""/usr/local/lib/python3.6/dist-packages/gensim/utils.py"", line 45, in <module>
    from smart_open import open
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.6/dist-packages/gensim/__init__.py"", line 5, in <module>
    from gensim import parsing, corpora, matutils, interfaces, models, similarities, summarization, utils  # noqa:F401
  File ""/usr/local/lib/python3.6/dist-packages/gensim/parsing/__init__.py"", line 4, in <module>
    from .preprocessing import (remove_stopwords, strip_punctuation, strip_punctuation2,  # noqa:F401
  File ""/usr/local/lib/python3.6/dist-packages/gensim/parsing/preprocessing.py"", line 42, in <module>
    from gensim import utils
  File ""/usr/local/lib/python3.6/dist-packages/gensim/utils.py"", line 45, in <module>
    from smart_open import open
ImportError: cannot import name 'open'
```


"
537,https://github.com/RaRe-Technologies/gensim/issues/2577,2577,[],closed,2019-08-13 08:31:03+00:00,,Bug: old versions of gensim suddenly requires Python 3.5,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

Just trying to install gensim 2.3.0 in my production environment and suddenly it has changed an requires python 3.5 so the deploy fails.

See this output from our CircleCI environment which now suddenly fails (with no changes over the summer):

```
...
Collecting gensim==2.3.0 (from -r requirements.txt (line 115))
  Downloading https://files.pythonhosted.org/packages/bc/ed/fbbb2cc3f37a39cc4ff8e5f667374478fb852b384840aa7feb9608144290/gensim-2.3.0.tar.gz (17.2MB)

     |##                              | 1.2MB 42.0MB/s eta 0:00:01           |     |##     |####         |######################        |########################        | 13.1MB 42.0MB/s et     |########     |############################    | 1     |############################### | 16.7MB 42.0MB/s eta 0:00:01
     |################################| 17.2MB 42.0MB/s 
    ERROR: Command errored out with exit status 1:
     command: /opt/circleci/python/2.7.11/bin/python2.7 -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-Kgi7w5/gensim/setup.py'""'""'; __file__='""'""'/tmp/pip-install-Kgi7w5/gensim/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' egg_info --egg-base pip-egg-info
         cwd: /tmp/pip-install-Kgi7w5/gensim/
    Complete output (55 lines):
    Traceback (most recent call last):
      File ""<string>"", line 1, in <module>
      File ""/tmp/pip-install-Kgi7w5/gensim/setup.py"", line 302, in <module>
        include_package_data=True,
      File ""/opt/circleci/python/2.7.11/lib/python2.7/distutils/core.py"", line 111, in setup
        _setup_distribution = dist = klass(attrs)
      File ""/opt/circleci/python/2.7.11/lib/python2.7/site-packages/setuptools/dist.py"", line 268, in __init__
        self.fetch_build_eggs(attrs['setup_requires'])
      File ""/opt/circleci/python/2.7.11/lib/python2.7/site-packages/setuptools/dist.py"", line 313, in fetch_build_eggs
        replace_conflicting=True,
      File ""/opt/circleci/python/2.7.11/lib/python2.7/site-packages/pkg_resources/__init__.py"", line 836, in resolve
        dist = best[req.key] = env.best_match(req, ws, installer)
      File ""/opt/circleci/python/2.7.11/lib/python2.7/site-packages/pkg_resources/__init__.py"", line 1081, in best_match
        return self.obtain(req, installer)
      File ""/opt/circleci/python/2.7.11/lib/python2.7/site-packages/pkg_resources/__init__.py"", line 1093, in obtain
        return installer(requirement)
      File ""/opt/circleci/python/2.7.11/lib/python2.7/site-packages/setuptools/dist.py"", line 380, in fetch_build_egg
        return cmd.easy_install(req)
      File ""/opt/circleci/python/2.7.11/lib/python2.7/site-packages/setuptools/command/easy_install.py"", line 629, in easy_install
        return self.install_item(spec, dist.location, tmpdir, deps)
      File ""/opt/circleci/python/2.7.11/lib/python2.7/site-packages/setuptools/command/easy_install.py"", line 659, in install_item
        dists = self.install_eggs(spec, download, tmpdir)
      File ""/opt/circleci/python/2.7.11/lib/python2.7/site-packages/setuptools/command/easy_install.py"", line 842, in install_eggs
        return self.build_and_install(setup_script, setup_base)
      File ""/opt/circleci/python/2.7.11/lib/python2.7/site-packages/setuptools/command/easy_install.py"", line 1070, in build_and_install
        self.run_setup(setup_script, setup_base, args)
      File ""/opt/circleci/python/2.7.11/lib/python2.7/site-packages/setuptools/command/easy_install.py"", line 1056, in run_setup
        run_setup(setup_script, args)
      File ""/opt/circleci/python/2.7.11/lib/python2.7/site-packages/setuptools/sandbox.py"", line 240, in run_setup
        raise
      File ""/opt/circleci/python/2.7.11/lib/python2.7/contextlib.py"", line 35, in __exit__
        self.gen.throw(type, value, traceback)
      File ""/opt/circleci/python/2.7.11/lib/python2.7/site-packages/setuptools/sandbox.py"", line 193, in setup_context
        yield
      File ""/opt/circleci/python/2.7.11/lib/python2.7/contextlib.py"", line 35, in __exit__
        self.gen.throw(type, value, traceback)
      File ""/opt/circleci/python/2.7.11/lib/python2.7/site-packages/setuptools/sandbox.py"", line 164, in save_modules
        saved_exc.resume()
      File ""/opt/circleci/python/2.7.11/lib/python2.7/site-packages/setuptools/sandbox.py"", line 139, in resume
        compat.reraise(type, exc, self._tb)
      File ""/opt/circleci/python/2.7.11/lib/python2.7/site-packages/setuptools/sandbox.py"", line 152, in save_modules
        yield saved
      File ""/opt/circleci/python/2.7.11/lib/python2.7/site-packages/setuptools/sandbox.py"", line 193, in setup_context
        yield
      File ""/opt/circleci/python/2.7.11/lib/python2.7/site-packages/setuptools/sandbox.py"", line 237, in run_setup
        DirectorySandbox(setup_dir).run(runner)
      File ""/opt/circleci/python/2.7.11/lib/python2.7/site-packages/setuptools/sandbox.py"", line 267, in run
        return func()
      File ""/opt/circleci/python/2.7.11/lib/python2.7/site-packages/setuptools/sandbox.py"", line 236, in runner
        _execfile(setup_script, ns)
      File ""/opt/circleci/python/2.7.11/lib/python2.7/site-packages/setuptools/sandbox.py"", line 46, in _execfile
        exec(code, globals, locals)
      File ""/tmp/easy_install-Cu6y0r/numpy-1.17.0/setup.py"", line 31, in <module>
        class custom_build_ext(build_ext):
    RuntimeError: Python version >= 3.5 required.
    ----------------------------------------
ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.
Exited with code 1
```
"
538,https://github.com/RaRe-Technologies/gensim/issues/2578,2578,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 1602278675, 'node_id': 'MDU6TGFiZWwxNjAyMjc4Njc1', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20HIGH', 'name': 'reach HIGH', 'color': '229e03', 'default': False, 'description': 'Affects most or all Gensim users'}, {'id': 1602334472, 'node_id': 'MDU6TGFiZWwxNjAyMzM0NDcy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20MEDIUM', 'name': 'impact MEDIUM', 'color': '7af49f', 'default': False, 'description': 'Big annoyance for affected users'}]",closed,2019-08-14 04:38:37+00:00,,"""OverflowError: value too large to convert to int"" when training word2vec on a large corpus","Hi,
i am trying to train word2vec on on a large corpus (>500GB) and the newest gensim version (3.8.0) and an error occurs on every Thread:

`Exception in thread Thread-10:
Traceback (most recent call last):
  File ""/home/michael/miniconda3/lib/python3.7/threading.py"", line 917, in _bootstrap_inner
    self.run()
  File ""/home/michael/miniconda3/lib/python3.7/threading.py"", line 865, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/michael/miniconda3/lib/python3.7/site-packages/gensim/models/base_any2vec.py"", line 175, in _worker_loop_corpusfile
    total_examples=total_examples, total_words=total_words, **kwargs)
  File ""/home/michael/miniconda3/lib/python3.7/site-packages/gensim/models/word2vec.py"", line 794, in _do_train_epoch
    total_examples, total_words, work, neu1, self.compute_loss)
  File ""gensim/models/word2vec_corpusfile.pyx"", line 379, in gensim.models.word2vec_corpusfile.train_epoch_cbow
OverflowError: value too large to convert to int`

My command for training the Model is:
`Word2Vec(corpus_file=""encc_tokenized"", size = 1024, window = 8, workers = 16)`

Thank you for help"
539,https://github.com/RaRe-Technologies/gensim/issues/2579,2579,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}]",closed,2019-08-14 08:15:46+00:00,,why skip-gram takes context word as input and predict word itself,"#### Problem description

I'm going to use the python code of skip-gram (sg) in my research but recognize difference between the implementation and the original in Mikolov's paper.
The detail of the difference will be mentioned below.
Please let me know if this difference is intentionally or just a bug.

#### Steps/code/corpus to reproduce

code in: 

> gensim/gensim/models/word2vec.py

https://github.com/RaRe-Technologies/gensim/blob/f97d0e793faa57877a2bbedc15c287835463eaa9/gensim/models/word2vec.py#L399-L414

> We can see input word is treated as output of NN, while context is embedded by matrix syn0 (vectors matrix)

...

https://github.com/RaRe-Technologies/gensim/blob/f97d0e793faa57877a2bbedc15c287835463eaa9/gensim/models/word2vec.py#L443-L456

> as a result, we're going to optimize P( input / context ) while, in the original paper, they tried to optimize P( context / input) in skip-gram architecture.


"
540,https://github.com/RaRe-Technologies/gensim/issues/2580,2580,[],closed,2019-08-17 14:15:33+00:00,,Ldamallet Error ( returned non-zero exit status 1),"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? What is the expected result? What are you seeing instead?

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
Hallo all, please help me with the followin problem. I have tried a lot without sucsses:

os.environ.update({'MALLET_HOME': ""C:\\mallet-2.0.8\\""})
mallet_path = ""C:\\mallet-2.0.8\\bin\\mallet"" # update this path
ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)

subprocess.CalledProcessError: Command 'C:\mallet-2.0.8\bin\mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex ""\S+"" --input C:\Users\LENOVO~1\AppData\Local\Temp\c53edf_corpus.txt --output C:\Users\LENOVO~1\AppData\Local\Temp\c53edf_corpus.mallet' returned non-zero exit status 1.


I have put the mallet packet in C, but it didnot work. 

Thank you!"
541,https://github.com/RaRe-Technologies/gensim/issues/2581,2581,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-08-21 00:37:17+00:00,,ldamulticore.LdaMulticore ignoring passes Parameter,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? What is the expected result? What are you seeing instead?

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
"
542,https://github.com/RaRe-Technologies/gensim/issues/2583,2583,"[{'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2019-08-24 11:27:50+00:00,,Support (> 10000)-token texts in `infer_vector()`,"As `infer_vector()` uses the same optimized Cython functions as training behind-the-scenes, it also suffers from the same fixed-token-buffer size as training, where texts with more than 10000 tokens have all overflow tokens ignored. 

But, this might be easier to fix for inference, as the it could be easy to call the training functions with a mini-batch that just reuses the same temporary candidate vector-in-training. 

(And in fact, thinking about this makes me wonder if we should just auto-chunk documents during training, too – perhaps with a warning to the user the 1st time this happens. Previously, I'd wanted to fix this limitation by using `alloca()` to replace our fixed 10000-slot on-stack arrays with variable-length on-stack arrays - which worked in my tests, and perhaps even offered a memory-compactness advantage/speedup for all the cases where texts were *smaller* than 10000 tokens – but, `alloca()` isn't guaranteed to be available everywhere, even though in practice it seems to be everywhere we support.)"
543,https://github.com/RaRe-Technologies/gensim/issues/2584,2584,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 1583467927, 'node_id': 'MDU6TGFiZWwxNTgzNDY3OTI3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/help%20wanted', 'name': 'help wanted', 'color': '1d76db', 'default': True, 'description': ''}]",closed,2019-08-28 02:10:02+00:00,,gensim.similarities.Similarity merges results from shards incorrectly (LSI model),"If ""num_best"" is used, `gensim.similarities.Similarity` runs the query against each of the shards (MatrixSimilarity objects) and then merges the results.

MatrixSimilarity uses `matutils.full2sparse_clipped()` to pick ""num_best"" results which sorts by the absolute value.

gensim.similarities.Similarity on the other hand, just uses `heapq.nlargest` (in `__getitem__`) to merge the results from each of the shards. So negative sims are either pushed down the list or cut off completely."
544,https://github.com/RaRe-Technologies/gensim/issues/2585,2585,[],closed,2019-08-28 08:23:02+00:00,,Having issue with encoding.,"#### Problem description
I am trying to process a large corpus but in preprocess_string( ) it returns an error shown below
```
Traceback (most recent call last):
  File ""D:/Projects/docs_handler/data_preprocessing.py"", line 60, in <module>
    for temp in batch(iterator,1000):
  File ""D:/Projects/docs_handler/data_preprocessing.py"", line 30, in batch
    for item in iterable:
  File ""D:/Projects/docs_handler/data_preprocessing.py"", line 23, in iter_tokenized_documents
    document = preprocess_string(open(os.path.join(root, file)).read().strip(),filters=CUSTOM_FILTERS)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\encodings\cp1252.py"", line 23, in decode
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
UnicodeDecodeError: 'charmap' codec can't decode byte 0x9d in position 16144: character maps to <undefined>
```


#### Steps/code/corpus to reproduce
```
def iter_tokenized_documents(input_directory):
    """"""Iterate over all documents, yielding a document (=list of utf8 tokens) at a time.""""""
    for root, dirs, files in os.walk(input_directory):
        for file in filter(lambda file: file.endswith('.txt'), files):
            document = preprocess_string(open(os.path.join(root, file)).read().strip(),filters=CUSTOM_FILTERS)
            if(len(document)):
                yield document
```

#### Versions
Windows-10-10.0.17763-SP0
Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)]
NumPy 1.17.0
SciPy 1.3.0
gensim 3.8.0
FAST_VERSION 0


"
545,https://github.com/RaRe-Technologies/gensim/issues/2586,2586,[],closed,2019-08-29 19:16:52+00:00,,gensim.summarization.keywords fetching different results,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

Hi, I am having a weird issue where when I pass the exact same text in the following function -  

```python
gensim.summarization.keywords(text1, ratio=0.9, pos_filter=('NP')).split(""\n"")
```

and get two different result set for exact same parameters when I run it multiple times. The output should be same for a particular text.
How is it possible that it's excluding /including few phrase extracts over a few iteration? 
Below it shows the difference - ['data'] vs ['static data'] and ['dynamic'] was not fetched in the second iter run at all.
Attached a screenshot for reference. Any guidance will be appreciated.
![gensim_summarization_diffresults](https://user-images.githubusercontent.com/20959591/63968956-cdd4cf00-ca6e-11e9-8a36-ca5e152d13c2.png)

#### Steps/code/corpus to reproduce

```python
import gensim 
text1 = 'The method according to claim3, wherein the step of collecting further comprises: receiving the static data in the management data through a notification about change of the at least one cloud server being reported by a protocol agent which is configured to collect the management data from the at least one cloud server; and requesting and receiving the dynamic data in the management data from the protocol agent.'
phrase_token=gensim.summarization.keywords(text1, ratio=0.9, pos_filter=('NP')).split(""\n"")
phrase_token
```

#### Versions

Darwin-18.7.0-x86_64-i386-64bit
Python 3.7.3 (default, Mar 27 2019, 16:54:48) 
[Clang 4.0.1 (tags/RELEASE_401/final)]
NumPy 1.16.4
SciPy 1.2.1
gensim 3.7.3
FAST_VERSION 1
"
546,https://github.com/RaRe-Technologies/gensim/issues/2587,2587,[],closed,2019-09-02 08:33:28+00:00,,Is it possible to transform a negative weight given by LSI in to positive value weight respectively,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? What is the expected result? What are you seeing instead?

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
"
547,https://github.com/RaRe-Technologies/gensim/issues/2588,2588,[],open,2019-09-02 10:20:05+00:00,,Any bugs on FastText.build_vocab ??,"
#### Problem description

I would like to retrain and update  my gensim fasttext model 

expected result:
my vocab from my text file can be loaded into the fasttext model with the command: 
    model.build_vocab(sentences, update=True)
 
Actual result:
""AttributeError: 'FastText' object has no attribute 'syn1neg'"" 

#### Versions gensim 3.8.0
    ## import libraries 
    
    import numpy as np
    import pandas as pd
    import re
    import os
    from collections import defaultdict,Counter
    from tqdm import tqdm
    import swifter

    import jieba
    import jieba.analyse
    from full_width_to_half_width import full_width_to_half_width

    import gensim.corpora as corpora
    from gensim.models.wrappers import FastText  as FastText_gensim



    ### Load the pre-trained model, not pretrained vector to make sure that i can train the model 
    print('load fasttext pretrain model ')
    pretrained_model=FastText_gensim.load(pretrained_model_file)

    ### Load the tokens of articles i wanna update and convert the tokens into list of list
    sent=token_df['token'].values.tolist()   

    ##### use the "".build_vocab"" of  pretrain model and state ""update = True""
    pretrained_model.build_vocab(sent,update=True)


    Traceback (most recent call last):
    File ""C:/Users/marcus/PycharmProjects/DIVA_CWS/FastText_pretrain.py"", line 313, in <module>
    pretrained_model.build_vocab(sent,update=True)
    File ""C:\Users\marcus\Desktop\DIVA_CWS\lib\site-packages\gensim\models\deprecated\word2vec.py"", line 712, in build_vocab
    self.finalize_vocab(update=update)  # build tables & arrays
    File ""C:\Users\marcus\Desktop\DIVA_CWS\lib\site-packages\gensim\models\deprecated\word2vec.py"", line 953, in finalize_vocab
    self.update_weights()
    File ""C:\Users\marcus\Desktop\DIVA_CWS\lib\site-packages\gensim\models\deprecated\word2vec.py"", line 1373, in update_weights
    self.syn1neg = vstack([self.syn1neg, zeros((gained_vocab, self.layer1_size), dtype=REAL)])
    AttributeError: 'FastText' object has no attribute 'syn1neg'
"
548,https://github.com/RaRe-Technologies/gensim/issues/2590,2590,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}, {'id': 1338770061, 'node_id': 'MDU6TGFiZWwxMzM4NzcwMDYx', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/stale', 'name': 'stale', 'color': 'bc4c01', 'default': False, 'description': 'Waiting for author to complete contribution, no recent effort'}]",closed,2019-09-03 04:37:56+00:00,,out of memory issue in PyLDAV visulization,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve?

Visualization of topic model having 8.5L document and 25L vocab size ang 8gb of memory

What is the expected result? 

Create a visualization file.

What are you seeing instead?

We are getting a Memory out of error while programme is preparing a data for pylda vis.

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

```
`C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\past\translation\__init__.py:35: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\past\translation\__init__.py:35: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\past\translation\__init__.py:35: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\past\translation\__init__.py:35: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\past\translation\__init__.py:35: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\past\translation\__init__.py:35: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\past\translation\__init__.py:35: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\past\translation\__init__.py:35: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
joblib.externals.loky.process_executor._RemoteTraceback: 
""""""
Traceback (most recent call last):
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\joblib\externals\loky\process_executor.py"", line 418, in _process_worker
    r = call_item()
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\joblib\externals\loky\process_executor.py"", line 272, in __call__
    return self.fn(*self.args, **self.kwargs)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\joblib\_parallel_backends.py"", line 567, in __call__
    return self.func(*args, **kwargs)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\joblib\parallel.py"", line 225, in __call__
    for func, args, kwargs in self.items]
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\joblib\parallel.py"", line 225, in <listcomp>
    for func, args, kwargs in self.items]
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pyLDAvis\_prepare.py"", line 213, in _find_relevance_chunks
    return pd.concat([_find_relevance(log_ttd, log_lift, R, l) for l in lambda_seq])
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pyLDAvis\_prepare.py"", line 213, in <listcomp>
    return pd.concat([_find_relevance(log_ttd, log_lift, R, l) for l in lambda_seq])
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pyLDAvis\_prepare.py"", line 208, in _find_relevance
    relevance = lambda_ * log_ttd + (1 - lambda_) * log_lift
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pandas\core\ops\__init__.py"", line 1506, in f
    return self._combine_const(other, op)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pandas\core\frame.py"", line 5396, in _combine_const
    return ops.dispatch_to_series(self, other, func)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pandas\core\ops\__init__.py"", line 596, in dispatch_to_series
    new_data = expressions.evaluate(column_op, str_rep, left, right)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pandas\core\computation\expressions.py"", line 220, in evaluate
    return _evaluate(op, op_str, a, b, **eval_kwargs)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pandas\core\computation\expressions.py"", line 126, in _evaluate_numexpr
    result = _evaluate_standard(op, op_str, a, b)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pandas\core\computation\expressions.py"", line 70, in _evaluate_standard
    return op(a, b)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pandas\core\ops\__init__.py"", line 570, in column_op
    return {i: func(a.iloc[:, i], b) for i in range(len(a.columns))}
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pandas\core\ops\__init__.py"", line 570, in <dictcomp>
    return {i: func(a.iloc[:, i], b) for i in range(len(a.columns))}
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pandas\core\ops\roperator.py"", line 17, in rmul
    return right * left
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pandas\core\series.py"", line 810, in __array_ufunc__
    self, ufunc, method, *inputs, **kwargs
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pandas\core\ops\__init__.py"", line 1743, in maybe_dispatch_ufunc_to_dunder_op
    return getattr(self, name, not_implemented)(inputs[0])
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pandas\core\ops\__init__.py"", line 1048, in wrapper
    result = na_op(lvalues, rvalues)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pandas\core\ops\__init__.py"", line 968, in na_op
    result = expressions.evaluate(op, str_rep, x, y, **eval_kwargs)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pandas\core\computation\expressions.py"", line 220, in evaluate
    return _evaluate(op, op_str, a, b, **eval_kwargs)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pandas\core\computation\expressions.py"", line 126, in _evaluate_numexpr
    result = _evaluate_standard(op, op_str, a, b)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pandas\core\computation\expressions.py"", line 70, in _evaluate_standard
    return op(a, b)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pandas\core\ops\roperator.py"", line 17, in rmul
    return right * left
numpy.core._exceptions.MemoryError: Unable to allocate array with shape (100,) and data type float32
""""""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""D:/Projects/docs_handler/lsi_experiment.py"", line 47, in <module>
    visulize_topic_model(model,corpus,dictionary)
  File ""D:/Projects/docs_handler/lsi_experiment.py"", line 29, in visulize_topic_model
    viz = pyLDAvis.gensim.prepare(topic_model=model,corpus=corpus,dictionary=dictionary)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pyLDAvis\gensim.py"", line 119, in prepare
    return vis_prepare(**opts)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pyLDAvis\_prepare.py"", line 398, in prepare
    topic_info         = _topic_info(topic_term_dists, topic_proportion, term_frequency, term_topic_freq, vocab, lambda_step, R, n_jobs)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pyLDAvis\_prepare.py"", line 255, in _topic_info
    for ls in _job_chunks(lambda_seq, n_jobs)))
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\joblib\parallel.py"", line 934, in __call__
    self.retrieve()
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\joblib\parallel.py"", line 833, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\joblib\_parallel_backends.py"", line 521, in wrap_future_result
    return future.result(timeout=timeout)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pattern\text\en\..\..\..\..\concurrent\futures\_base.py"", line 432, in result
    return self.__get_result()
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\pattern\text\en\..\..\..\..\concurrent\futures\_base.py"", line 384, in __get_result
    raise self._exception
numpy.core._exceptions.MemoryError: Unable to allocate array with shape (100,) and data type float32

Process finished with exit code 1
`
```

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
Windows-10-10.0.17763-SP0
Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)]
NumPy 1.17.0
SciPy 1.3.0
gensim 3.8.0
FAST_VERSION 0
"
549,https://github.com/RaRe-Technologies/gensim/issues/2592,2592,[],closed,2019-09-03 19:30:08+00:00,,"Discussion: discard ""gensim.summarization""? ","In the course of considering the list question at <https://groups.google.com/d/msg/gensim/v24RI3-oUq0/NYlPpif1AQAJ>, I took a slightly-deeper look at `gensim.summarization` than before. 

From that look, my opinion is that its presence is more likely to waste peoples' time than help them. It's fairly rudimentary functionality, but spread across many files, with its own non-configurable regex-based word- and sentence- tokenization, with a lot of hard-to-follow steps. None of the doc/tutorial examples show impressive results.  

I even find it hard to imagine anyone getting satisfactory results from this approach, so I expect most peoples' interaction with this code is: (1) ""I need summarization – and cool, gensim has a summarization feature!"" (2) View its docs/tutorial and try on some real data. (3) ""This is nowhere near what I need nor is it customizable/fixable enough to be tweaked into service."" (4) They look for something else entirely.

I'd suggest marking the whole module 'deprecated' with an eye towards eventual removal. And, if summarization is an important thing to truly support, soliciting someone to work-up a better algorithm or implementation, one that can actually demo some useful results in a tutorial/demo, and that also mixes well with other corpus-format/tokenization practices in gensim. (It might even be TextRank-based – but with configurable tokenization & sentence-similarity/graph-building steps.)"
550,https://github.com/RaRe-Technologies/gensim/issues/2593,2593,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 1602257032, 'node_id': 'MDU6TGFiZWwxNjAyMjU3MDMy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20HIGH', 'name': 'impact HIGH', 'color': 'b60205', 'default': False, 'description': 'Show-stopper for affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",closed,2019-09-04 04:20:56+00:00,,Memory error while processing with mm.serialize() method,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? 
:- To successfully store a corpus in MM formate.

What is the expected result?
:- It should store without any error.

 What are you seeing instead?
:- It is giving memory error a the end of saving a corpus.
```
2019-09-04 09:10:31,905 : INFO : PROGRESS: saving document #50014000
2019-09-04 09:10:32,156 : INFO : PROGRESS: saving document #50015000
2019-09-04 09:10:32,467 : INFO : PROGRESS: saving document #50016000
2019-09-04 09:10:32,738 : INFO : PROGRESS: saving document #50017000
2019-09-04 09:10:33,068 : INFO : PROGRESS: saving document #50018000
2019-09-04 09:10:33,336 : INFO : PROGRESS: saving document #50019000
2019-09-04 09:10:33,623 : INFO : PROGRESS: saving document #50020000
2019-09-04 09:10:33,925 : INFO : PROGRESS: saving document #50021000
2019-09-04 09:10:34,186 : INFO : PROGRESS: saving document #50022000
2019-09-04 09:10:34,478 : INFO : PROGRESS: saving document #50023000
2019-09-04 09:10:34,730 : INFO : PROGRESS: saving document #50024000
2019-09-04 09:10:34,985 : INFO : PROGRESS: saving document #50025000
Traceback (most recent call last):
  File ""email_data_experiment.py"", line 23, in <module>
    MmCorpus.serialize(fname=corpus_path, corpus=corpus, metadata=True, id2word=corpus.dictionary)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\gensim\corpora\indexedcorpus.py"", line 123, in serialize
    offsets = serializer.save_corpus(fname, corpus, id2word, **kwargs)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\gensim\corpora\mmcorpus.py"", line 125, in save_corpus
    fname, corpus, num_terms=num_terms, index=True, progress_cnt=progress_cnt, metadata=metadata
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\gensim\matutils.py"", line 1391, in write_corpus
    utils.pickle(docno2metadata, fname + '.metadata.cpickle')
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\gensim\utils.py"", line 1364, in pickle
    _pickle.dump(obj, fout, protocol=protocol)
MemoryError
```

#### Steps/code/corpus to reproduce

```
        corpus = TextDirectoryCorpus(input=data_path,metadata=True,max_depth=2,lines_are_documents=True)
        Dictionary.save_as_text(corpus.dictionary, fname_or_handle=dictionary_path)
        MmCorpus.serialize(fname=corpus_path, corpus=corpus, metadata=True, id2word=corpus.dictionary)

```
getting error on 3rd line.


#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
Windows-10-10.0.17763-SP0
Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)]
NumPy 1.17.0
SciPy 1.3.0
gensim 3.8.0
FAST_VERSION 0
"
551,https://github.com/RaRe-Technologies/gensim/issues/2594,2594,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-09-04 08:39:28+00:00,,ImportError: cannot import name 'WikiCorpus',"```
Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)] on win32
import gensim
Traceback (most recent call last):
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\IPython\core\interactiveshell.py"", line 3326, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-2-e70e92d32c6e>"", line 1, in <module>
    import gensim
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.2\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\gensim\__init__.py"", line 5, in <module>
    from gensim import parsing, corpora, matutils, interfaces, models, similarities, summarization, utils  # noqa:F401
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.2\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\gensim\corpora\__init__.py"", line 14, in <module>
    from .wikicorpus import WikiCorpus  # noqa:F401
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.2\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\gensim\corpora\wikicorpus.py"", line 29, in <module>
    from gensim.scripts import make_wiki
  File ""C:\Program Files\JetBrains\PyCharm Community Edition 2019.2\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\gensim\scripts\make_wiki.py"", line 45, in <module>
    from gensim.corpora import Dictionary, HashDictionary, MmCorpus,WikiCorpus
ImportError: cannot import name 'WikiCorpus'
```
``
how to resolve it?

_Originally posted by @gauravkoradiya in https://github.com/RaRe-Technologies/gensim/issues/2169#issuecomment-527799066_"
552,https://github.com/RaRe-Technologies/gensim/issues/2595,2595,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-09-04 09:18:55+00:00,,Having issue with load vocabulary built in HashDictionary(),"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? 
:-Build a vocab on wiki corpus online.
What is the expected result?
:- It should able to save and load a dict sucessfully.
 What are you seeing instead?
:- It is showing error while load a hash dict via load().

#### Steps/code/corpus to reproduce

```
dictionary = gensim.corpora.HashDictionary.load('dictionary/results_wordids.txt.bz2')
2019-09-04 14:46:59,356 : INFO : loading HashDictionary object from dictionary/results_wordids.txt.bz2
Traceback (most recent call last):
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\IPython\core\interactiveshell.py"", line 3326, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-11-f4a49c9d73de>"", line 1, in <module>
    dictionary = gensim.corpora.HashDictionary.load('dictionary/results_wordids.txt.bz2')
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\gensim\utils.py"", line 426, in load
    obj = unpickle(fname)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\gensim\utils.py"", line 1384, in unpickle
    return _pickle.load(f,encoding='latin1')
_pickle.UnpicklingError: invalid load key, '6'.
```

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
"
553,https://github.com/RaRe-Technologies/gensim/issues/2596,2596,[],closed,2019-09-04 22:17:49+00:00,,Pre-Trained Doc2Vec Models,"I am looking for a french pre-trained model for Doc2Vec. I found a lot of information about the non usability of Word2Vec models in Doc2Vec. I have a corpus of 10,000 little documents, but I think this number is too small to train a performing model? Does anyone have a suggestion for me? Thank you!"
554,https://github.com/RaRe-Technologies/gensim/issues/2597,2597,[],closed,2019-09-06 14:57:44+00:00,,"It is not possible to set values for BM25 model hyperparameters (K1, B, and EPSILON)","<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I'm using the BM25 implementation and there is currently no way of defining its hyperparameters.

It would be nice to tune them according to the corpus being used.

Thank you in advance"
555,https://github.com/RaRe-Technologies/gensim/issues/2598,2598,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}, {'id': 1602279836, 'node_id': 'MDU6TGFiZWwxNjAyMjc5ODM2', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20MEDIUM', 'name': 'reach MEDIUM', 'color': 'ef7a1a', 'default': False, 'description': 'Affects a significant number of users'}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}]",closed,2019-09-08 05:47:20+00:00,,keywords.py gives `IndexError: list index out of range` when `words` parameter is provided.,"Really confused why I'm getting this error. Perhaps I'm making a silly mistake I'm not familiar with gensim and nlp in general.
Im running on Windows 10 Home 64-bit, conda version : 4.7.11, conda-build version : 2.18.8, python version : 3.7.3.final.0
My code is attempting to get keywords per sentence in a loop. To simplify matters I've isolated the following code that causes this, trying to get keywords from gensim's `keywords.py`.

```python
s = ""Don’t dive right into solving without a plan (and somehow hope you can muddle your way through).""
keywords(s, words=4, scores=False, split=True, lemmatize=True)

File ""C:\Users\username\Anaconda3\envs\gensim\lib\site-packages\gensim\summarization\keywords.py"", line 521, in keywords
    extracted_lemmas = _extract_tokens(graph.nodes(), pagerank_scores, ratio, words)
  File ""C:\Users\username\Anaconda3\envs\gensim\lib\site-packages\gensim\summarization\keywords.py"", line 304, in _extract_tokens
    return [(scores[lemmas[i]], lemmas[i],) for i in range(int(length))]
  File ""C:\Users\username\Anaconda3\envs\gensim\lib\site-packages\gensim\summarization\keywords.py"", line 304, in <listcomp>
    return [(scores[lemmas[i]], lemmas[i],) for i in range(int(length))]
IndexError: list index out of range
```

I've tried setting `scores=True`, `lemmatize=False`, and `split=False` but the same error persists. I've also tried removing the parenthesis and removing the apostrophe, the error persisted. What did work is removing the `words` parameter altogether, but still it shouldn't create an error if it's provided. Thanks for the help in advance!"
556,https://github.com/RaRe-Technologies/gensim/issues/2599,2599,[],closed,2019-09-09 12:01:46+00:00,,"While Running LDA in between it throws an ""IndexError"" error.","<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? 
:- I want to run LDA completely on Wiki-dataset. I have 43lakh of wiki document and have 90 lakh feature and 50lakh(filtered dictionary).

What is the expected result?
:- Output expectation is to extract topic at the end of training model.

 What are you seeing instead?
:-  Generates an error in between because of vocab size and feature len in MM are diffrent. How to resolve it?

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

```
Traceback (most recent call last):
  File ""D:/Projects/docs_handler/email_data_experiment.py"", line 38, in <module>
    lda = LdaModel(corpus=corpus, num_topics=5, id2word=id2word,iterations=5,chunksize=100000,eval_every=0,update_every=2)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\gensim\models\ldamodel.py"", line 521, in __init__
    self.update(corpus, chunks_as_numpy=use_numpy)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\gensim\models\ldamodel.py"", line 983, in update
    gammat = self.do_estep(chunk, other)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\gensim\models\ldamodel.py"", line 744, in do_estep
    gamma, sstats = self.inference(chunk, collect_sstats=True)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\gensim\models\ldamodel.py"", line 681, in inference
    expElogbetad = self.expElogbeta[:, ids]
IndexError: index 5000000 is out of bounds for axis 1 with size 5000000
```
Log:
```
2019-09-09 17:20:56,008 : INFO : PROGRESS: pass 0, at document #1700000/4257515
2019-09-09 17:20:56,008 : INFO : Performing E-step
2019-09-09 17:21:13,868 : INFO : 0/100000 documents converged within 5 iterations
2019-09-09 17:21:13,936 : INFO : Finished E-step
2019-09-09 17:21:13,936 : INFO : performing M-step
2019-09-09 17:21:13,936 : INFO : finished M-step
2019-09-09 17:21:26,342 : INFO : PROGRESS: pass 0, at document #1800000/4257515
2019-09-09 17:21:26,348 : INFO : Performing E-step
2019-09-09 17:21:46,477 : INFO : 0/100000 documents converged within 5 iterations
2019-09-09 17:21:46,565 : INFO : Finished E-step
2019-09-09 17:21:46,565 : INFO : performing M-step
2019-09-09 17:21:46,566 : INFO : updating topics
2019-09-09 17:21:47,982 : INFO : merging changes from 200000 documents into a model of 4257515 documents
2019-09-09 17:21:49,516 : INFO : topic #0 (0.200): 0.005*""new"" + 0.004*""school"" + 0.004*""references"" + 0.004*""league"" + 0.003*""season"" + 0.003*""university"" + 0.003*""national"" + 0.003*""american"" + 0.003*""club"" + 0.003*""born""
2019-09-09 17:21:49,602 : INFO : topic #1 (0.200): 0.005*""new"" + 0.003*""time"" + 0.003*""team"" + 0.003*""year"" + 0.002*""war"" + 0.002*""references"" + 0.002*""world"" + 0.002*""links"" + 0.002*""national"" + 0.002*""later""
2019-09-09 17:21:49,677 : INFO : topic #2 (0.200): 0.002*""state"" + 0.002*""new"" + 0.002*""university"" + 0.002*""references"" + 0.002*""year"" + 0.002*""used"" + 0.002*""time"" + 0.002*""city"" + 0.002*""years"" + 0.002*""known""
2019-09-09 17:21:49,758 : INFO : topic #3 (0.200): 0.003*""new"" + 0.003*""school"" + 0.003*""references"" + 0.002*""years"" + 0.002*""city"" + 0.002*""station"" + 0.002*""time"" + 0.002*""united"" + 0.002*""area"" + 0.002*""north""
2019-09-09 17:21:49,846 : INFO : topic #4 (0.200): 0.004*""new"" + 0.004*""album"" + 0.004*""music"" + 0.003*""released"" + 0.003*""film"" + 0.002*""song"" + 0.002*""references"" + 0.002*""time"" + 0.002*""series"" + 0.002*""links""
2019-09-09 17:21:49,958 : INFO : topic diff=0.062798, rho=0.242536
2019-09-09 17:21:49,986 : INFO : finished M-step
2019-09-09 17:22:02,037 : INFO : PROGRESS: pass 0, at document #1900000/4257515
2019-09-09 17:22:02,037 : INFO : Performing E-step
Traceback (most recent call last):
  File ""D:/Projects/docs_handler/email_data_experiment.py"", line 38, in <module>
    lda = LdaModel(corpus=corpus, num_topics=5, id2word=id2word,iterations=5,chunksize=100000,eval_every=0,update_every=2)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\gensim\models\ldamodel.py"", line 521, in __init__
    self.update(corpus, chunks_as_numpy=use_numpy)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\gensim\models\ldamodel.py"", line 983, in update
    gammat = self.do_estep(chunk, other)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\gensim\models\ldamodel.py"", line 744, in do_estep
    gamma, sstats = self.inference(chunk, collect_sstats=True)
  File ""C:\Users\koradg\AppData\Local\Programs\Python\Python36\lib\site-packages\gensim\models\ldamodel.py"", line 681, in inference
    expElogbetad = self.expElogbeta[:, ids]
IndexError: index 5000000 is out of bounds for axis 1 with size 5000000
```

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)

Windows-10-10.0.17763-SP0
Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)]
NumPy 1.17.0
SciPy 1.3.0
gensim 3.8.0
FAST_VERSION 0

```

I got this issue because of in MM i have (4300000*9000000) matrix and i have vocab size of 5000000. Can anyone give solution for this?
"
557,https://github.com/RaRe-Technologies/gensim/issues/2600,2600,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}]",closed,2019-09-09 12:38:27+00:00,,Missing wheels for Windows,"Lately, there's been a stream of issues from Windows users, e.g. [here](https://groups.google.com/forum/#!topic/gensim/PbiMySYNPjs).

Looking at PyPI, it seems binary wheels are completely missing from the last few distributions (incl. the latest 3.8.0):
https://pypi.org/project/gensim/#files

This means Windows users don't get to install the optimized Gensim easily, and unless they have a compiler properly set up, they'll install the slow (uncompiled) version of word2vec, fastttext etc.

We definitely want those binary wheels on PyPI, **especially** for Windows. Windows users are the least tech-savvy, least likely to have a C compiler, and most likely to raise confused support tickets."
558,https://github.com/RaRe-Technologies/gensim/issues/2602,2602,[],closed,2019-09-14 12:13:06+00:00,,Import error when loading model,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I'm trying to load a model I created from an other script with SaveLoad class. Everything worked fined when I last checked it, but since a few days I got an import error. I don't remember having changed anything specific to the model loading, so I'm not sure what's happening. Here is the error:
```python
WARNING:this function is deprecated, use smart_open.open instead
Traceback (most recent call last):
  File ""bin/advisor.py"", line 32, in <module>
    adv.start()
  File ""./semantic/advisor.py"", line 256, in start
    sentences, relevances = self.compare_sentences()
  File ""./semantic/advisor.py"", line 198, in compare_sentences
    model = sv.load('models/{id}.mdl'.format(id=self.corpus_id))
  File ""/usr/local/lib/python3.5/dist-packages/gensim/utils.py"", line 426, in load
    obj = unpickle(fname)
  File ""/usr/local/lib/python3.5/dist-packages/gensim/utils.py"", line 1384, in unpickle
    return _pickle.load(f, encoding='latin1')
ImportError: No module named 'numpy.random._pickle'
```

#### Steps/code/corpus to reproduce

Here is the code used to loading the model:
```python
sv = SaveLoad()
model = sv.load('models/{id}.mdl'.format(id=id)).
```
It's a Word2Vec model, nothing really 'exotic'. I tried loading the model in the python console with
```python
with open('./my_model.mdl', 'rb') as f:
     res = pickle.load(f)
```
And I get me the same error:
```python
Traceback (most recent call last):
  File ""<stdin>"", line 2, in <module>
ImportError: No module named 'numpy.random._pickle'
```
So I think that the problem happens at the model creation more than at the model loading ?
However here is the code for model creation
```python
model = Word2Vec(window=CONTEXT_WINDOW_SIZE, workers=4, sg=0, seed=21, min_count=1, size=300,
                             batch_words=1000, hs=1, negative=0)
[training]
 model.save(my_path + '/../models/{id}.mdl'.format(id=corpus_id))
```
I could provide the pickle file but I'm not sure it's a good idea to provide it on the issue for security reasons, I guess it could seem fishy
#### Versions


```python
>>> import platform; print(platform.platform())
Linux-4.4.0-142-generic-x86_64-with-Ubuntu-16.04-xenial
>>> import sys; print(""Python"", sys.version)
Python 3.5.2 (default, Nov 12 2018, 13:43:14) 
[GCC 5.4.0 20160609]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.16.3
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 0.19.1
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.7.1
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1
```
Don't hesitate to point at anything I could provide to help
Thanks a lot ;-)"
559,https://github.com/RaRe-Technologies/gensim/issues/2603,2603,[],closed,2019-09-15 14:48:14+00:00,,Couldn't print topics,"When I was using author-topic model and tried to call `print_topics` method, it gives me an error showing that this method is not in the `atmodel`. This is a method in the superclass `ldamodel`, so I'm not sure what's going on here.


https://github.com/RaRe-Technologies/gensim/blob/a47eed80cf225181717cba09761922d4a54027d8/gensim/models/atmodel.py#L215"
560,https://github.com/RaRe-Technologies/gensim/issues/2604,2604,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}, {'id': 1338770061, 'node_id': 'MDU6TGFiZWwxMzM4NzcwMDYx', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/stale', 'name': 'stale', 'color': 'bc4c01', 'default': False, 'description': 'Waiting for author to complete contribution, no recent effort'}]",closed,2019-09-18 09:51:44+00:00,,FastText：size setting 200~300 computer will crash...,"I don't know why when szie is too big（size = 200 or 300）, it will get stuck."
561,https://github.com/RaRe-Technologies/gensim/issues/2608,2608,[],closed,2019-09-25 11:03:29+00:00,,AttributeError in Doc2vec when compute_loss=True,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Description

Gensim's Doc2Vec include an initialization parameter compute_loss which, if True, cause the model to keep a running total of loss during training which can then be requested via get_training_loss(). But i get 'Doc2Vec' object has no attribute 'get_training_loss'. A quick look at doc2vec.py verifies that that method isn't implemented there.

What are you trying to achieve? What is the expected result? What are you seeing instead?
I am trying to get the loss so that i can figure out how many epochs to run my model on

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

#############################################################################

```
AttributeError                            Traceback (most recent call last)
<ipython-input-9-8c794e318315> in <module>
      4 else:
      5     print('Model does not exists, creating new one. This will take some time...')
----> 6     create_doc2vec_model(data['content'])
      7     model_doc = Doc2Vec.load(""/home/ubuntu/Jupyter_Notebook/Akash_testing/d2v_testing.model"")
      8 print(""Model Loaded"")

<ipython-input-5-f3af8a0c71ca> in create_doc2vec_model(X)
     20         model_doc.train(tagged_data,
     21                     total_examples=model_doc.corpus_count,
---> 22                     epochs=model_doc.iter)
     23         model_doc.alpha -= 0.0002
     24         model_doc.min_alpha = model_doc.alpha

~/anaconda3/lib/python3.7/site-packages/gensim/models/doc2vec.py in train(self, documents, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks)
    811             sentences=documents, corpus_file=corpus_file, total_examples=total_examples, total_words=total_words,
    812             epochs=epochs, start_alpha=start_alpha, end_alpha=end_alpha, word_count=word_count,
--> 813             queue_factor=queue_factor, report_delay=report_delay, callbacks=callbacks, **kwargs)
    814 
    815     @classmethod

~/anaconda3/lib/python3.7/site-packages/gensim/models/base_any2vec.py in train(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)
   1079             total_words=total_words, epochs=epochs, start_alpha=start_alpha, end_alpha=end_alpha, word_count=word_count,
   1080             queue_factor=queue_factor, report_delay=report_delay, compute_loss=compute_loss, callbacks=callbacks,
-> 1081             **kwargs)
   1082 
   1083     def _get_job_params(self, cur_epoch):

~/anaconda3/lib/python3.7/site-packages/gensim/models/base_any2vec.py in train(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)
    537 
    538         for callback in self.callbacks:
--> 539             callback.on_train_begin(self)
    540 
    541         trained_word_count = 0

~/anaconda3/lib/python3.7/site-packages/keras/callbacks.py in on_train_begin(self, logs)
    293 
    294     def on_train_begin(self, logs=None):
--> 295         self.verbose = self.params['verbose']
    296         self.epochs = self.params['epochs']
    297 

AttributeError: 'ProgbarLogger' object has no attribute 'params'
```

#############################################################################

#### Versions

Please provide the output of:
```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)

Linux-4.4.0-1094-aws-x86_64-with-debian-stretch-sid
Python 3.7.3 (default, Mar 27 2019, 22:11:17) 
[GCC 7.3.0]
NumPy 1.16.4
SciPy 1.3.0
gensim 3.8.0
FAST_VERSION 1
```
"
562,https://github.com/RaRe-Technologies/gensim/issues/2609,2609,[],closed,2019-09-25 12:51:16+00:00,,bm25 score is not symmetrical,"I think bm25 score is not symmetrical, but the code now fill the graph weights assume it is.

https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/summarization/graph.py#L310

Hope the authors can fix it. And will it influence the summary performance?
Or if I'm wrong, please let me know.

Thanks!





The code:
```python
from gensim.summarization.bm25 import get_bm25_weights
corpus = [
      [""black"", ""cat"", ""white"", ""cat""],
      [""cat"", ""outer"", ""space""],
    [""wag"", ""dog""]
 ]
get_bm25_weights(corpus)
# outputs:
[[1.1237959024144617, 0.1824377227735681, 0],
 [0.11770175662810844, 1.1128701089187656, 0],
 [0, 0, 1.201942644155272]]
```
"
563,https://github.com/RaRe-Technologies/gensim/issues/2611,2611,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}, {'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",closed,2019-09-28 22:19:30+00:00,,Implement saving to Facebook format,"We currently support reading FastText models from Facebook's format. The [gensim.models._fasttext_bin](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/_fasttext_bin.py) does this.

This enables people to use gensim with a model that was trained using Facebook's binaries.

Sometimes, people want things to work the other way: they start with gensim, train a model, and then want to save it to Facebook's format.

For this ticket, you will implement a `save(model, fout)` function that accepts a FastText object and saves it to a file stream in a Facebook-compatible format. It will essentially reverse the effects of the [load](https://github.com/RaRe-Technologies/gensim/blob/f89808d52d0250e4e4bbab2293980f8f4d3989b9/gensim/models/_fasttext_bin.py#L291) function. "
564,https://github.com/RaRe-Technologies/gensim/issues/2612,2612,[],open,2019-09-29 06:46:34+00:00,,Triage github tickets,"We have a ton of issues on github (over 220) and for me personally, it feels a bit overwhelming.  What do you think?

Realistically, that's more than we can ever hope to resolve given our current velocity. I think it's worth performing a bug triage: going through the issues and identifying:

- Priority
- Severity
- Approximate time scope (now / weeks / months / years / never)

Here are some places to start (issue labels may overlap):

- [bug](https://github.com/RaRe-Technologies/gensim/labels/bug): 75 open
- [feature](https://github.com/RaRe-Technologies/gensim/labels/feature): 83 issues
- [wishlist](https://github.com/RaRe-Technologies/gensim/labels/wishlist): 42 issues

You can see the full list of our labels [here](https://github.com/RaRe-Technologies/gensim/labels).

@piskvorky @gojomo What's the best medium to do this? Perhaps a phone call? It does not have to happen now or even in the immediate future, but it should happen sometime."
565,https://github.com/RaRe-Technologies/gensim/issues/2613,2613,"[{'id': 175642, 'node_id': 'MDU6TGFiZWwxNzU2NDI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/wishlist', 'name': 'wishlist', 'color': 'd7e102', 'default': False, 'description': 'Feature request'}, {'id': 175986, 'node_id': 'MDU6TGFiZWwxNzU5ODY=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/testing', 'name': 'testing', 'color': '444444', 'default': False, 'description': 'Issue related with testing (code, documentation, etc)'}]",open,2019-09-30 11:44:56+00:00,,Add Windows to Travis testing,"Apparently Travis CI has (beta) support for Windows now:
https://blog.travis-ci.com/2018-10-11-windows-early-release

Look into how we could improve our release cycle, make our life easier. Perhaps even build Win wheels there?

(I only noticed this feature recently, in this comment https://github.com/spotify/annoy/pull/429#issuecomment-536520293, although apparently it's been out for almost a year)"
566,https://github.com/RaRe-Technologies/gensim/issues/2614,2614,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-09-30 15:49:18+00:00,,Get the ,"Hello! I think there is a problem with the params spec of the show_topics method in the docs https://radimrehurek.com/gensim/models/hdpmodel.html 

When you pass -1 you don't get any topic. And if you omit such a param, you always get the default number of events (20).

I choose the HdpModel since it is a model that does not require to know, a priori, the number of topics to detect. That's really cool and this is supposed to be the main contribution of Hdp. But this implementation doesn't allow me to profit from such benefit.

Best,

# SEE TEMPLATE BELOW

<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? What is the expected result? What are you seeing instead?

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```"
567,https://github.com/RaRe-Technologies/gensim/issues/2617,2617,[],open,2019-10-01 16:40:52+00:00,,"Fix, improve, complete 'training loss' computation for *2Vec models","Word2Vec training-loss isn't quite yet the epoch-based loss most would expect – as pending PR #2135 might address – but also `Doc2Vec` and `FastText` should offer functional, analogous reporting, and the docs should make clear what this loss is good for (monitoring training progress) and what it's not good for (assessing overall model fitness for downstream tasks). 

(Loss for `Doc2Vec` looks like it might be there due to inherited interfaces, and was requested along with `Word2Vec` as in #1272, but that request was closed as a duplicate of #999, which wound up only implementing it for `Word2Vec`.)"
568,https://github.com/RaRe-Technologies/gensim/issues/2623,2623,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",open,2019-10-07 14:50:58+00:00,,Wrong power base in LDA Model log_perplexity documentation,"#### Problem description

Gensim LDAModel documentation incorrect

#### Steps/code/corpus to reproduce

Based on the code in log_perplexity, it looks like it should be e^(-bound) since all of the functions used in computing it seem to be using the natural logarithm/e

"
569,https://github.com/RaRe-Technologies/gensim/issues/2624,2624,[],open,2019-10-07 19:58:35+00:00,,Results of docvec.most_similar() are all 0.0 when using a previously trained model,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->
#### System information
- Windows-10-10.0.14393-SP0
- Python 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]
- NumPy 1.16.2
- SciPy 1.2.1
- gensim 3.8.0
- FAST_VERSION 1

#### Problem description

I trained a Doc2Vec model a year ago, with a then-current version of gensim (I believe Version 3.7.3). The model worked very well at the time. I then updated gensim to version 3.8.0 not too long ago. Now if I use the model to find similar documents, all the outputted results have a cosine similarity score of 0.0 (see below).

```
import gensim

model = gensim.models.doc2vec.Doc2Vec.load(r""D:\Projects\doc2vec_model_20180831.bin"")
vec= model.infer_vector(docs[0].split())
model.docvecs.most_similar([vec])
#[(104968, 0.0), (104970, 0.0), (104962, 0.0), (104963, 0.0), (104964, 0.0), (104965, 0.0), (104966, 0.0), (104967, 0.0), (104960, 0.0), (104969, 0.0)]
```

This happens even when I use a vector that is from the training set document, like below:

```
model.docvecs.most_similar([model.docvecs[0]])
#[(104968, 0.0), (104970, 0.0), (104962, 0.0), (104963, 0.0), (104964, 0.0), (104965, 0.0), (104966, 0.0), (104967, 0.0), (104960, 0.0), (104969, 0.0)]
model.docvecs.most_similar([model.docvecs[1]])
#[(104968, 0.0), (104970, 0.0), (104962, 0.0), (104963, 0.0), (104964, 0.0), (104965, 0.0), (104966, 0.0), (104967, 0.0), (104960, 0.0), (104969, 0.0)]
model.docvecs.most_similar([model.docvecs[2]])
#[(104968, 0.0), (104970, 0.0), (104962, 0.0), (104963, 0.0), (104964, 0.0), (104965, 0.0), (104966, 0.0), (104967, 0.0), (104960, 0.0), (104969, 0.0)]
model.docvecs.most_similar([model.docvecs[3]])
#[(104968, 0.0), (104970, 0.0), (104962, 0.0), (104963, 0.0), (104964, 0.0), (104965, 0.0), (104966, 0.0), (104967, 0.0), (104960, 0.0), (104969, 0.0)]
```

I wonder if anyone has any insight on why this is happening. Thanks! 


"
570,https://github.com/RaRe-Technologies/gensim/issues/2631,2631,[],closed,2019-10-12 12:13:54+00:00,,KeyedVectors will not import,"#### Problem description

KeyedVectors will not import

#### Steps/code/corpus to reproduce

``` python
>>> from gensim.models import KeyedVectors
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ImportError: cannot import name 'KeyedVectors' from 'gensim.models' (/usr/lib/python3.7/site-packages/gensim/models/__init__.py)
```


#### Versions

``` python
>>> import platform; print(platform.platform())
Linux-5.3.4-300.fc31.x86_64-x86_64-with-fedora-31-Thirty_One
>>> import sys; print(""Python"", sys.version)
Python 3.7.4 (default, Aug 12 2019, 14:45:07) 
[GCC 9.1.1 20190605 (Red Hat 9.1.1-2)]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.17.2
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.2.1
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 0.10.0
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION -1
```
"
571,https://github.com/RaRe-Technologies/gensim/issues/2634,2634,[],open,2019-10-15 19:19:39+00:00,,numpy requirement is too strict/outdated,"#### Problem description

Since `gensim 3.8.0`,  `numpy` is restricted to be `numpy >= 1.11.3, <= 1.16.1`.
That was first introduced in #2546 for py2 since `numpy 1.16.1` **was** the last version supporting py2. However, as of now, the latest version supporting py2 is [`numpy 1.16.5`](https://github.com/numpy/numpy/releases/tag/v1.16.5).

Should restrict numpy to `numpy >= 1.11.3, < 1.17.0`, since `1.17.0` is the first version removing python2 support.

#### Versions

```
$ python
Python 2.7.12 (default, Jan  9 2017, 12:16:27)
[GCC 4.8.4] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import platform; print(platform.platform())
Linux-4.9.184-linuxkit-x86_64-with-Ubuntu-14.04-trusty
>>> import sys; print(""Python"", sys.version)
('Python', '2.7.12 (default, Jan  9 2017, 12:16:27) \n[GCC 4.8.4]')
>>> import numpy; print(""NumPy"", numpy.__version__)
('NumPy', '1.16.1')
>>> import scipy; print(""SciPy"", scipy.__version__)
('SciPy', '0.18.1')
>>> import gensim; print(""gensim"", gensim.__version__)
('gensim', '3.8.1')
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
('FAST_VERSION', 1)
```
"
572,https://github.com/RaRe-Technologies/gensim/issues/2635,2635,[],closed,2019-10-17 03:27:58+00:00,,Wikicorpus interlinks storage should be list of tuples instead of dict. ,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I am trying to get the list of interlinks occurring on a wikipedia page. The current parser uses a dict to store the links. However, the same link might be referred to using different text on the same page. 

E.g. for the `Anarchism` page in the test script the `Anarchism in Italy` link is referred using 2 different texts. 

```
Anarchism in Italy -> Italian anarchists
Anarchism in Italy -> Italy
Anarchism in Italy -> Italy
```

This motivates the reasoning that interlinks should be stored as a list of tuples instead of a dictionary. 

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

The issue is at the following line: 
https://github.com/RaRe-Technologies/gensim/blob/3e027c252eac3cf7e613f425ad8b070e8fe88065/gensim/corpora/wikicorpus.py#L174

And the subsequence assignment in later lines. 
The above code only keeps track of the last interlink mapping instead of all interlink mappings in the text. 

I will send a PR resolving this issue. 



#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```

Output of above: 

```
Darwin-18.7.0-x86_64-i386-64bit
Python 3.7.4 (default, Aug 13 2019, 15:17:50) 
[Clang 4.0.1 (tags/RELEASE_401/final)]
NumPy 1.17.2
SciPy 1.3.1
gensim 3.8.1
FAST_VERSION -1
```
"
573,https://github.com/RaRe-Technologies/gensim/issues/2637,2637,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",closed,2019-10-17 08:37:34+00:00,,Incomplete DTM docs,"In https://radimrehurek.com/gensim/models/wrappers/dtmmodel.html#gensim.models.wrappers.dtmmodel.DtmModel : 

```
top_chain_var (int, optional) – Hyperparameter that affects.
```

"
574,https://github.com/RaRe-Technologies/gensim/issues/2638,2638,[],closed,2019-10-17 18:32:10+00:00,,Can't reload similarity index shards,"#### Problem description

I can't reload a similarity index if the location of that index has changed. For example, let's say I create an index following the instructions described [here](https://radimrehurek.com/gensim/similarities/docsim.html#gensim.similarities.docsim.Similarity.save). If I move the shards to a different directory and then load them, they will not be callable as intended.

When we call `similarities.Similarity.load(<path here>)`, there are a few issues.

- `gensim.similarities.docsim.Similarity.output_prefix` is still the old location to where it was originally saved (not from where it was loaded).
- Each shard inside `gensim.similarities.docsim.Similarity.shards` has the attribute `dirname` as the old location where it was saved (not from the new directory where the shards reside).

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

I think you can do this with any similarity index. When I get more time, I'll try to create a small example from one of the included sample datasets.

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```

Output

```
Linux-4.15.0-65-generic-x86_64-with-debian-buster-sid
Python 3.7.4 (default, Aug 13 2019, 20:35:49) 
[GCC 7.3.0]
NumPy 1.17.2
SciPy 1.3.1
gensim 3.8.0
FAST_VERSION 1
```
"
575,https://github.com/RaRe-Technologies/gensim/issues/2641,2641,[],closed,2019-10-18 13:59:15+00:00,,'>=' not supported between instances of 'str' and 'int' error,"Hi! 
I have a the following error in my code that says:

'>=' not supported between instances of 'str' and 'int'

I have a dictionary with dataframes like the following:
`sells={'df1':'Dataframe','df2':'Dataframe','df3':'Dataframe','df4':'Dataframe'}`

While applying the following code the error appears for both codes, does anyone know what am I doing wrong?

`peak={k: df[df[""Hour""].between(9, 20)] for k, df in sells.items()}`
`offpeak={k: df[(df[""Hour""]< 9)| (df[""Hour""] > 20)] for k, df in sells.items()}`







"
576,https://github.com/RaRe-Technologies/gensim/issues/2642,2642,"[{'id': 175986, 'node_id': 'MDU6TGFiZWwxNzU5ODY=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/testing', 'name': 'testing', 'color': '444444', 'default': False, 'description': 'Issue related with testing (code, documentation, etc)'}, {'id': 708430967, 'node_id': 'MDU6TGFiZWw3MDg0MzA5Njc=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/performance', 'name': 'performance', 'color': 'd93f0b', 'default': False, 'description': 'Issue related to performance (in HW meaning)'}, {'id': 1072221028, 'node_id': 'MDU6TGFiZWwxMDcyMjIxMDI4', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/Hacktoberfest', 'name': 'Hacktoberfest', 'color': 'b396e0', 'default': False, 'description': 'Issues marked for hacktoberfest'}, {'id': 1583467927, 'node_id': 'MDU6TGFiZWwxNTgzNDY3OTI3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/help%20wanted', 'name': 'help wanted', 'color': '1d76db', 'default': True, 'description': ''}, {'id': 1602257032, 'node_id': 'MDU6TGFiZWwxNjAyMjU3MDMy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20HIGH', 'name': 'impact HIGH', 'color': 'b60205', 'default': False, 'description': 'Show-stopper for affected users'}, {'id': 1602279836, 'node_id': 'MDU6TGFiZWwxNjAyMjc5ODM2', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20MEDIUM', 'name': 'reach MEDIUM', 'color': 'ef7a1a', 'default': False, 'description': 'Affects a significant number of users'}]",closed,2019-10-21 20:51:55+00:00,,Speed up word2vec / fasttext model loading,"Loading a large word2vec model with `load_word_format(binary=True)` is slow. Users complain that loading the ""standard"" models published by Facebook is too slow, plus it also affects the speed of our own tests and tutorial autogeneration.

Some numbers:

```python
time gensim.models.keyedvectors.KeyedVectors.load_word2vec_format('./word2vec-google-news-300.gz', binary=True)
2019-10-21 22:24:08,326 : INFO : loading projection weights from ./word2vec-google-news-300.gz
2019-10-21 22:26:54,620 : INFO : loaded (3000000, 300) matrix from ./word2vec-google-news-300.gz
CPU times: user 2min 42s, sys: 3.64 s, total: 2min 46s
Wall time: 2min 46s
```

The I/O part itself = only loading the bytes from the file without any interpretation, takes about 30 seconds:

```python
time full = io.BytesIO(smart_open.open('./word2vec-google-news-300.gz', 'rb').read())
CPU times: user 20.9 s, sys: 8.13 s, total: 29.1 s
Wall time: 31.9 s
```

…which means our parsing code is taking up the majority of the `load_word2vec_format` time. Ideally, we shouldn't need much more than the 30 seconds (= the raw I/O speed) for the full `load_word_format(binary=True)`. Nearly 3 minutes is too much.

**Task**: Optimize `load_word2vec_format`, especially the `binary=True` branch. The code seems to live here:
https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/utils_any2vec.py#L369"
577,https://github.com/RaRe-Technologies/gensim/issues/2644,2644,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",open,2019-10-23 12:22:55+00:00,,Error “too many values to unpack” when trying to get similiraties in Gensim using LDA model,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I'm trying to use a trained LDA model to compare similarity between the models documents, stored in corpus, and new documents unseen by the model. 

#### Steps/code/corpus to reproduce

'm using anaconda enviroment python 3.7, gensim 3.8.0, basically. I have my data as a dataframe that I separated in a test and training set, they both have this structure:

X_test and Xtrain dataframe format :

```
 id                                            alltext  
1710  3264537  [exmodelo, karen, mcdougal, asegura, mantuvo, ...   
8211  3272079  [grupo, socialista, pionero, supone, apoyar, n...   
1885  3263933  [parte, entrenador, zaragoza, javier, aguirre,...   
2481  3263744  [fans, hielo, fuego, saga, literaria, dio, pie...   
2975  3265302  [actividad, busca, repetir, tres, ediciones, a... 
```
already preprocessed.

This is the code I use for creating my model

```python
id2word = corpora.Dictionary(X_train[""alltext""])   
texts = X_train[""alltext""]
corpus = [id2word.doc2bow(text) for text in texts]

lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,
    id2word=id2word,
    num_topics=20,
    random_state=100, 
    update_every=1, 
    chunksize=400, 
    passes=10, 
    alpha='auto',
    per_word_topics=True)
```


Until here, everything works fine. I can effectively use

```python
pprint(lda_model.print_topics())
doc_lda = lda_model[corpus]](url)
```
to get my topics.

The problem comes, when I try to compare similarity between a new document and the corpus. Here is the code I'm using

```python
newddoc = X_test[""alltext""][2730] #I get a particular instance of the test_set
new_doc_freq_vector = id2word.doc2bow(newddoc)  #vectorize its list of words
model_vec= lda_model[new_doc_freq_vector] #run the trained model on it
index = similarities.MatrixSimilarity(lda_model[corpus]) # error
sims = index[model_vec] #error
```
In the last two lines, I get this error:

```
-------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-110-352248c464f8> in <module>
      4 
      5 #index = Similarity('model/indexes/similarity_index_01', lda_model[corpus], num_features=len(id2word)) #the first argument, the place where the
----> 6 index = similarities.MatrixSimilarity(lda_model[corpus]) # funciona si en vez de lda_model[corpus] usamos solo corpus
      7 index = similarities.MatrixSimilarity(model_vec)
      8 #sims = index[model_vec] #funciona si usamos index[new_doc_freq_vector] en vez de model_vec

~\AppData\Local\Continuum\anaconda3\envs\lda_henneo_01\lib\site-packages\gensim\similarities\docsim.py in __init__(self, corpus, num_best, dtype, num_features, chunksize, corpus_len)
    776                 ""scanning corpus to determine the number of features (consider setting `num_features` explicitly)""
    777             )
--> 778             num_features = 1 + utils.get_max_id(corpus)
    779 
    780         self.num_features = num_features

~\AppData\Local\Continuum\anaconda3\envs\lda_henneo_01\lib\site-packages\gensim\utils.py in get_max_id(corpus)
    734     for document in corpus:
    735         if document:
--> 736             maxid = max(maxid, max(fieldid for fieldid, _ in document))
    737     return maxid
    738 

~\AppData\Local\Continuum\anaconda3\envs\lda_henneo_01\lib\site-packages\gensim\utils.py in <genexpr>(.0)
    734     for document in corpus:
    735         if document:
--> 736             maxid = max(maxid, max(fieldid for fieldid, _ in document))
    737     return maxid
    738 

ValueError: too many values to unpack (expected 2
```

#### Versions
anaconda enviroment python 3.7, gensim 3.8.0,
Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```"
578,https://github.com/RaRe-Technologies/gensim/issues/2649,2649,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",open,2019-10-24 14:17:41+00:00,,Rename auto_examples directory to something more helpful,e.g. documentation
579,https://github.com/RaRe-Technologies/gensim/issues/2657,2657,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",open,2019-10-29 08:43:15+00:00,,Tweak placeholders,"Continued from https://github.com/RaRe-Technologies/gensim/pull/2654

Point each placeholder to its corresponding tutorial."
580,https://github.com/RaRe-Technologies/gensim/issues/2658,2658,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}]",closed,2019-10-30 09:07:58+00:00,,Can you add compute Loss feature (as seen in Word2Vec model) in the fasttext Implementation too. It will help us in sending a callback to monitor the loss at each epoch.,"I was trying to monitor the loss vs epoch for word2vec and fasttext. But wasn't able to do so for fasttext because of no implementation of compute loss function.

"
581,https://github.com/RaRe-Technologies/gensim/issues/2659,2659,[],open,2019-10-30 09:23:42+00:00,,Strange embedding from FastText,"I am struggled understanding word embeddings of FastText. According to the white paper [Enriching Word Vectors with Subword Information](https://arxiv.org/pdf/1607.04606.pdf), embeddings of a word is the mean (or sum) of embeddings of its subwords.

I failed to verify this. On `common_text` imported from `gensim.test.utils`, embedding of `user` is `[-0.03062156 -0.02879291 -0.01737508 -0.02839565]`. The mean of embeddings of ['<us', 'use', 'ser', 'er>'] (setting `min_n=max_n=3`) is `[-0.047664   -0.01677518  0.02312234  0.03452689]`. The sum of embeddings also result in a different vector.

Is it a mismatch between Gensim implementation and original FastText, or am I missing something?

Below is my code:

```python
import numpy as np
from gensim.models import FastText
from gensim.models._utils_any2vec import compute_ngrams
from gensim.models.keyedvectors import FastTextKeyedVectors
from gensim.test.utils import common_texts

model = FastText(size=4, window=3, min_count=1)
model.build_vocab(sentences=common_texts)
model.train(sentences=common_texts, total_examples=len(common_texts), epochs=10, min_n=3, max_n=3)

print('survey' in model.wv.vocab)
print('ser' in model.wv.vocab)
print('ree' in model.wv.vocab)
ngrams = compute_ngrams('user', 3, 3)
print('num vector of ""user"": ', model.wv['user'])
print('ngrams of ""user"": ', ngrams)
print('mean of num vectors of {}: \n{}'.format(ngrams, np.mean([model.wv[c] for c in ngrams], axis=0)))
```
"
582,https://github.com/RaRe-Technologies/gensim/issues/2660,2660,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",closed,2019-10-31 09:05:07+00:00,,Document accessing the vocabulary of a *2vec model,"@andreamoro like this:

```python
from gensim.test.utils import common_texts
from gensim.models import Word2Vec

model = Word2Vec(common_texts, size=100, window=5, min_count=1, workers=4)
word_vectors = model.wv
print(list(word_vectors.vocab.keys()))

['minors', 'graph', 'system', 'trees', 'eps', 'computer', 'survey', 'user', 'human', 'time', 'interface', 'response']
```

[Documentation of `KeyedVectors`](https://radimrehurek.com/gensim/models/keyedvectors.html) = the class holding the trained word vectors.

@mpenkov listing the model vocab is a reasonable task, but I couldn't find it in our documentation either. I had to look at the source code. Maybe we can add it somewhere? API ref? Tutorial? @andreamoro where would you expect / look for this information?

_Originally posted by @piskvorky in https://github.com/RaRe-Technologies/gensim/issues/2422#issuecomment-547780433_"
583,https://github.com/RaRe-Technologies/gensim/issues/2662,2662,[],closed,2019-10-31 14:02:50+00:00,,BM25 Average IDF returns negative even with Epsilon correction,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Description

Currently the BM25 algorithm uses the correction formula described by [Barrios et al.](https://arxiv.org/pdf/1602.03606.pdf#page=4) when a calculated IDF is negative. However, this solution returns a negative value when the average IDF is also negative, creating an issue. Perhaps the IDF should be 0 when both the word's IDF and the average IDF is negative.  

#### Code to reproduce

```
>>> from gensim.summarization.bm25 import BM25
>>> corpus = [
    ['people', 'drink', 'bar'],
    ['bear', 'consume', 'drink']
]
>>> BM25(corpus).idf
{'people': 0.0, 'drink': -0.08047189562170502, 'bar': 0.0, 'bear': 0.0, 'consume': 0.0}

```

"
584,https://github.com/RaRe-Technologies/gensim/issues/2663,2663,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",open,2019-10-31 17:01:29+00:00,,DOCSIM Problem adding new articles to a loaded model,"#### Problem description
Using gensim I want to save a model and load it afterwards and still be able to use the model as it always was on memory

#### Steps/code/corpus to reproduce
As far as I can gather if I add a document to the model I need to save otherwise It will not be loaded properly

In the example I create the model and save them when the program is run for the first time and everything runs fine. If I let the program do the index.add_articles on the first run even if I don't save the model afterwards the program will not run a second time.

The program will run if I save after the add_article.

```python
import os
from gensim.similarities import Similarity
from gensim import corpora

def main():
    stoplist = {'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're""}

    articles_1_10 =  [""This is the first sentence"", ""And here is another one"", ""how many sentences can I write before this starts to get boring"",
                      ""This sentences are the sentences to construct the dictionary"",""I think I want ten of them"",""how many of them are in here already?"",
                      ""Only six so far with this one is the seven"",""I think we are almost there"",""Why didn't I get the first paragraphs of a book"",""I think this is the last one""]

    articles_11_15 =  [""This second set are the articles that will be added when the object is created"", ""So they will be saved when the object is saved"",
                       ""And they will be compared agains each other in the first print"", ""So there is not much to them this ones are not causing the issue"", ""This is the last sentence""]

    articles_16_20 = [""This third set are the articles that will be added after the loading"", ""So they will be saved when the object is saved"",
                       ""And they will be compared agains each other only in the second print"", ""This ones are the ones causing the issue"", ""This is the last sentence of them all""]

    articles_21_22 = [""this is getting stupid"", ""i dont know what is going on""]

    dictionary_path = ""temp_d1.dict""
    model_path = ""temp_test1""

    if os.path.isfile(dictionary_path):
        dictionary = corpora.Dictionary.load(dictionary_path)
    else:
        texts = [[word for word in document.lower().split() if word not in stoplist] for document in articles_1_10]
        dictionary = corpora.Dictionary(texts)
        dictionary.save(dictionary_path)

    if os.path.isfile(model_path):
        index = Similarity.load(model_path)
    else:
        texts = [dictionary.doc2bow(document.lower().split()) for document in articles_11_15]
        index = Similarity(model_path, texts, num_features=len(dictionary))  # create index
        index.save(model_path)

    print([x for x in index])
    texts2 = [dictionary.doc2bow(document.lower().split()) for document in articles_16_20]
    index.add_documents(texts2)
    print([x for x in index])
    #index.save(model_path)
    #texts3 = [dictionary.doc2bow(document.lower().split()) for document in articles_16_20]
    #index.add_documents(texts3)

if __name__ == '__main__':
    main()

```

#### Versions

Linux-5.3.4-arch1-1-ARCH-x86_64-with-arch
Python 3.6.6 (default, Oct 29 2018, 15:19:57) 
[GCC 8.2.1 20180831]
NumPy 1.17.3
SciPy 1.3.1
gensim 3.8.1
FAST_VERSION 1
"
585,https://github.com/RaRe-Technologies/gensim/issues/2665,2665,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",open,2019-10-31 22:03:52+00:00,,`train()` doc-comments don't explain `corpus_file` requires both `total_words` and `total_examples` ,"As using the `corpus_file` option requires **both** `total_words` and `total_examples` to be specified (unlike how the iteratable-corpus needed just one or the other), the doc-comments for `train()` in `Word2Vec`, `Doc2Vec`, & `FastText` are out-of-date about the 'optional' status of these parameters & description of when they're needed. "
586,https://github.com/RaRe-Technologies/gensim/issues/2666,2666,[],open,2019-11-01 15:21:03+00:00,,Memory Error While Loading a FastText Model Previously Trained via Gensim 3.4.0.,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I'm trying to load a fast text model previously trained by myself, via gensim 3.4.0.
 
The Error: 

`MemoryError: Unable to allocate array with shape (1757544, 300) and data type float32`
#### Steps/code/corpus to reproduce
By upgrading my gensim version to the newest version I can no longer load the pretrained model. No other steps are needed.

With Gensim 3.4.0 the following code needs a maximum memory of `1068.94921875 MiB` while with Gensim 3.8.0 it gets out of memory error. I have a total of 8GB RAM.

```
from gensim.models import FastText

from memory_profiler import memory_usage

def myfunc():
    fasttext_loc = 'wordvectors/FastText/ft.txt'
    model = FastText.load(fasttext_loc)

mem = max(memory_usage(myfunc))

print(""Maximum memory used: {0} MiB"".format(str(mem)))
```

This is the output of `ls -l` in my model's directory(my ft.txt file is around 16MB, the folder is around 800MB in total): 

> -rw-rw-r-- 1 farhood farhood  16584918 Apr  5  2019 ft.txt
> -rw-rw-r-- 1 farhood farhood  63660128 Apr  5  2019 ft.txt.trainables.syn1neg.npy
> -rw-rw-r-- 1 farhood farhood  63660128 Apr  5  2019 ft.txt.trainables.syn1.npy
> -rw-rw-r-- 1 farhood farhood 290947328 Apr  5  2019 ft.txt.trainables.vectors_ngrams_lockf.npy
> -rw-rw-r-- 1 farhood farhood  63660128 Apr  5  2019 ft.txt.trainables.vectors_vocab_lockf.npy
> -rw-rw-r-- 1 farhood farhood 290947328 Apr  5  2019 ft.txt.wv.vectors_ngrams.npy
> -rw-rw-r-- 1 farhood farhood  63660128 Apr  5  2019 ft.txt.wv.vectors.npy
> -rw-rw-r-- 1 farhood farhood  63660128 Apr  5  2019 ft.txt.wv.vectors_vocab.npy

#### Versions
Works on 3.4.0, doesn't work in the newest version 3.8.0.


Please provide the output of:

```python
Python 3.7.4 (default, Aug 13 2019, 20:35:49) 
[GCC 7.3.0] :: Anaconda, Inc. on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import platform; print(platform.platform())
Linux-5.0.0-32-generic-x86_64-with-debian-buster-sid
>>> import sys; print(""Python"", sys.version)
Python 3.7.4 (default, Aug 13 2019, 20:35:49) 
[GCC 7.3.0]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.17.3
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.3.1
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.4.0
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1
```
"
587,https://github.com/RaRe-Technologies/gensim/issues/2667,2667,[],closed,2019-11-03 01:22:48+00:00,,"FastTextKeyedVectors.word_vec(...,use_norm=True) nonsensically summing ngrams norms","The logic in <https://github.com/RaRe-Technologies/gensim/blob/ee6169100d13d7f684b96ac137065e302aeb7b1e/gensim/models/keyedvectors.py#L2090> regarding the summing of *normed* ngram-vectors, looks like nonsense to me. 

A caller supplying `use_norm` expects (per doc-comment) a unit-normed vector back. But summing a bunch of individually unit-normed ngram vectors won't achieve that: you'd need to unit-norm the final result. And it's unlikely you'd want to use unit-normed summands: the original raw ngram vectors are what the algorithm has trained to model words-from-fragments.

Of course, matching the FB reference implementation's behavior should be a top goal, but I doubt it offers any such summing-of-normed-ngram-vectors. 

If this current behavior is replaced with the more sensible ""add raw vecs, unit-normalize final result"", then there's no need to ever calculate/store the `vectors_ngrams_norm` array. 


"
588,https://github.com/RaRe-Technologies/gensim/issues/2668,2668,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-11-04 10:34:22+00:00,,No module named 'gensim.models.fasttext_bin',"[(https://radimrehurek.com/gensim/models/_fasttext_bin.html)](url)
I tried this to load bin file of facebook pretrained fasttext wordembedding, but it warns No module named 'gensim.models.fasttext_bin'.
I have installed gensim 3.8,1"
589,https://github.com/RaRe-Technologies/gensim/issues/2669,2669,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",open,2019-11-05 17:17:55+00:00,,word2vec doc-comment example of KeyedVectors usage broken,"The usage example in the word2vec.py doc-comment regarding `KeyedVectors` uses inconsistent paths and thus doesn't work. 

https://github.com/RaRe-Technologies/gensim/blob/e859c11f6f57bf3c883a718a9ab7067ac0c2d4cf/gensim/models/word2vec.py#L73

https://github.com/RaRe-Technologies/gensim/blob/e859c11f6f57bf3c883a718a9ab7067ac0c2d4cf/gensim/models/word2vec.py#L76

If vectors were saved to a tmpfile-path based on the filename `'wordvectors.kv'`, they need to loaded from that same path, not some other local-directory file named 'model.wv'.

(Also, in my opinion the use of `get_tmpfile()` adds unnecessary extra complexity to this example. People usually **don't** want their models in a ""temp"" directory, which some systems will occasionally delete, so the examples might as well do the simplest possible thing: store in the current working directory with simple string filenames. The example code above this is also confused, because it creates a temp-file path, but then doesn't actually use it, choosing to do the simple & right thing with a local file instead.)"
590,https://github.com/RaRe-Technologies/gensim/issues/2670,2670,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 1602257032, 'node_id': 'MDU6TGFiZWwxNjAyMjU3MDMy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20HIGH', 'name': 'impact HIGH', 'color': 'b60205', 'default': False, 'description': 'Show-stopper for affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",closed,2019-11-07 06:16:17+00:00,,"Python 3.7.3, gensim 3.8.1: UnboundLocalError: local variable 'doc_no2' referenced before assignment","Client code:
`    model = LogEntropyModel(corpus=data_corpus, normalize=True)
`
Referenced code:
https://github.com/RaRe-Technologies/gensim/blob/44ea7931c916349821aa1c717fbf7e90fb138297/gensim/models/logentropy_model.py#L115

Exception thrown:

```
  File ""/anaconda3/lib/python3.7/site-packages/gensim/models/logentropy_model.py"", line 76, in __init__
    self.initialize(corpus)
  File ""/anaconda3/lib/python3.7/site-packages/gensim/models/logentropy_model.py"", line 115, in initialize
    if doc_no2 != doc_no:
UnboundLocalError: local variable 'doc_no2' referenced before assignment

```"
591,https://github.com/RaRe-Technologies/gensim/issues/2673,2673,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",open,2019-11-09 13:02:13+00:00,,Author documentation for Ensemble LDA,"We've recently renewed our documentation section: https://radimrehurek.com/gensim/auto_examples/index.html. I think the recently added Ensemble LDA feature is great, but are difficult to discover for new users without a top-level document.

@aloosley @sezanzeb Would you be interested in authoring a new tutorial or howto to cover LDA? If yes, please let me know!

---

Thanks @piskvorky for reviewing our idea and @sezanzeb contribution to gensim.  

In case a audio-visual introduction of eLDA could help with any part of thinking about the code, I wanted to also share this link to a 22 minute eLDA overview presented this year at ML Prague:

https://slideslive.com/38913528/solving-the-text-labeling-challenge-with-ensemblelda-and-active-learning

_Originally posted by @aloosley in https://github.com/RaRe-Technologies/gensim/pull/2282#issuecomment-487158493_"
592,https://github.com/RaRe-Technologies/gensim/issues/2674,2674,[],open,2019-11-10 03:43:58+00:00,,RuntimeWarning: overflow encountered in exp expElogthetad,"I also meet the problem when I ran an LDA from Gensim library. Here is the error:

```
/anaconda3/lib/python3.6/site-packages/gensim/models/ldamodel.py:678: RuntimeWarning: overflow encountered in exp expElogthetad = np.exp(Elogthetad).
```

After going through the answers mentioned above, I tried to update my Numpy version and Gensim version to the updated one. However, the problem is still here. My dataset includes about 10,000 tweets. Btw, I tried to use 5 tweets, it seems no problem in generating the topics. 

Hope to get a response soon. Thank you!

_Originally posted by @Yukisu03 in https://github.com/RaRe-Technologies/gensim/issues/2115#issuecomment-515297412_"
593,https://github.com/RaRe-Technologies/gensim/issues/2675,2675,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",open,2019-11-10 05:26:15+00:00,,Documentation for built-in overrides missing,Classes like `gensim.corpora.dictionary.Dictionary` implement methods `__getitem__` and others. This is documented with docstrings [in the code](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/corpora/dictionary.py#L89-L107) but does not show up in our [public documentation](https://radimrehurek.com/gensim/corpora/dictionary.html) for that class. This is a problem because it hides valuable information from the general user.
594,https://github.com/RaRe-Technologies/gensim/issues/2679,2679,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 1602257032, 'node_id': 'MDU6TGFiZWwxNjAyMjU3MDMy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20HIGH', 'name': 'impact HIGH', 'color': 'b60205', 'default': False, 'description': 'Show-stopper for affected users'}, {'id': 1602279836, 'node_id': 'MDU6TGFiZWwxNjAyMjc5ODM2', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20MEDIUM', 'name': 'reach MEDIUM', 'color': 'ef7a1a', 'default': False, 'description': 'Affects a significant number of users'}]",open,2019-11-14 02:35:01+00:00,,"Some Doc2Vec vectors remain untrained, with either giant #s of docvecs or small contrived corpuses","Investigating the user report at <https://groups.google.com/d/msg/gensim/XbH5Sr6RBcI/w5-AIwpSAwAJ>, I ran with a (much-smaller) version of the synthetic-corpus there, & reproduced similarly inexplicable results, with doc-vectors that *should* have received at least *some* training-adjustment showing no change after an epoch of training. 

To demonstrate:

```python
import logging
logging.root.setLevel(level=logging.INFO)
from gensim.models.doc2vec import TaggedDocument
from gensim.models import Doc2Vec
import numpy as np
import inspect

class DummyTaggedDocuments(object):

    def __init__(self, count=1001, shared_word=True, doc_word=True, digit_words=False):
        self.count = count
        self.shared_word = shared_word
        self.doc_word = doc_word
        self.digit_words = digit_words
        
    def __iter__(self):
        for i in range(self.count):
            words = []
            if self.shared_word:
                words += ['shared']
            if self.doc_word: 
                words += ['doc_'+str(i)]
            if self.digit_words:
                words += str(i)  
            tags = [i]
            if i == self.count - 1:
                logging.info(""yielding last DummyTaggedDocument %i"", i)
            yield TaggedDocument(words=words, tags=tags)

def test_d2v_docvecs_trained(doc_args={}, d2v_args={}):
    """"""Demo bug in Doc2Vec (& more?) as of gensim 3.8.1 with sample>0""""""
    docs = DummyTaggedDocuments(**doc_args)
    d2v_model = Doc2Vec(**d2v_args)
    
    d2v_model.build_vocab(docs, progress_per=100000)
    starting_vecs = d2v_model.docvecs.vectors_docs.copy()  
    
    d2v_model.train(docs, total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs, report_delay=5)
    
    unchanged = np.all(starting_vecs==d2v_model.docvecs.vectors_docs, axis=1)
    unchanged_indexes = np.argwhere(unchanged)
    
    return (len(unchanged_indexes), list(unchanged_indexes))

test_d2v_docvecs_trained(d2v_args=dict(min_count=0, sample=0.01, vector_size=4, epochs=1, workers=1))
```

The return value of this test method should, for the given parameters, be a count of 0 unchanged vectors, and and empty-list of unchanged vector indexes. But in a typical run I'm getting instead:

```
(12,
 [array([0]),
  array([1]),
  array([4]),
  array([6]),
  array([9]),
  array([11]),
  array([13]),
  array([14]),
  array([15]),
  array([30]),
  array([33]),
  array([80])])
```

Though this is an artificial dataset, with peculiar 2-word documents, which will often only be 1-word documents (after frequent-word-downsampling of the term shared by all documents) – every document should be at least 1 word long, and thus get at least some training in any single epoch. The logging output regarding sampling accurately reports what the effects *should* be (at this sampling level):

```
INFO:gensim.models.doc2vec:collected 1002 word types and 1001 unique tags from a corpus of 1001 examples and 2002 words
INFO:gensim.models.word2vec:Loading a fresh vocabulary
INFO:gensim.models.word2vec:effective_min_count=0 retains 1002 unique words (100% of original 1002, drops 0)
INFO:gensim.models.word2vec:effective_min_count=0 leaves 2002 word corpus (100% of original 2002, drops 0)
INFO:gensim.models.word2vec:deleting the raw counts dictionary of 1002 items
INFO:gensim.models.word2vec:sample=0.01 downsamples 1 most-common words
INFO:gensim.models.word2vec:downsampling leaves estimated 1162 word corpus (58.1% of prior 2002)
``` 

I get similar evidence of unchanged vectors in `dm=0` (PV-DBOW) mode. However, running more epochs usually drives the number of unchanged vectors to 0. 

Turning off downsampling with `sample=0` ensures all vectors show some update, implying some error in the downsampling is involved. Essentially, that strongly implies something going wrong in  the code at or around:

https://github.com/RaRe-Technologies/gensim/blob/3d6596112f8f1fc0e839a32c5a00ef3d7365c264/gensim/models/doc2vec_inner.pyx#L344

But, a manual check of the precalculated `sample_int` values for all-but-the-most-frequent word suggests they're where they should be: a value that the random-int is never higher-than, and thus a value that should result in the corresponding words never being down-sampled. 

I may not have time to dig deeper anytime soon, so placing this recipe-to-reproduce & key observations so far here. 

Notably, `Word2Vec` & `FastText` may be using similar sampling logic – so even though there's not yet a sighting there, similar issues may exist. 

(Separately, I somewhat doubt this sample-related anomaly, whatever its cause, is necessarily related to actual original problem of the user in the thread referenced – which seemed only present in extremely large corpuses, likely with real many-word texts, over a normal number of repeated epochs, and perhaps only in the ""very tail-end"" doc-vectors.)


"
595,https://github.com/RaRe-Technologies/gensim/issues/2680,2680,[],closed,2019-11-14 22:25:49+00:00,,Can't import gensim.models.KeyedVectors with -OO,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I'm trying to use `gensim.models.KeyedVectors` in a Python3 program. 

My non-gensim code has `assert` calls in it that I'd like to have removed as they're taking up too much time. 

Disabling the assert calls via `-OO` seems to cause problems.

#### Steps/code/corpus to reproduce

I'm using `Python 3.7.3`.

I'm using gensim version `3.8.1`.

```
puser@pusermachine:~/$ python3
Python 3.7.3 (default, Oct  7 2019, 12:56:13) 
[GCC 8.3.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import gensim
>>> gensim.__version__
'3.8.1'
>>> 
```
It seems to work with `-O` but not `-OO`.
```
puser@pusermachine:~/$ python3 -c ""from gensim.models import KeyedVectors""
puser@pusermachine:~/$ python3 -Oc ""from gensim.models import KeyedVectors""
puser@pusermachine:~/$ python3 -OOc ""from gensim.models import KeyedVectors""
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/home/puser/.local/lib/python3.7/site-packages/gensim/__init__.py"", line 5, in <module>
    from gensim import parsing, corpora, matutils, interfaces, models, similarities, summarization, utils  # noqa:F401
  File ""/home/puser/.local/lib/python3.7/site-packages/gensim/parsing/__init__.py"", line 4, in <module>
    from .preprocessing import (remove_stopwords, strip_punctuation, strip_punctuation2,  # noqa:F401
  File ""/home/puser/.local/lib/python3.7/site-packages/gensim/parsing/preprocessing.py"", line 42, in <module>
    from gensim import utils
  File ""/home/puser/.local/lib/python3.7/site-packages/gensim/utils.py"", line 45, in <module>
    from smart_open import open
  File ""/home/puser/.local/lib/python3.7/site-packages/smart_open/__init__.py"", line 28, in <module>
    from .smart_open_lib import open, smart_open, register_compressor
  File ""/home/puser/.local/lib/python3.7/site-packages/smart_open/smart_open_lib.py"", line 364, in <module>
    doctools.extract_kwargs(smart_open_s3.open.__doc__),
  File ""/home/puser/.local/lib/python3.7/site-packages/smart_open/doctools.py"", line 66, in extract_kwargs
    lines = inspect.cleandoc(docstring).split('\n')
  File ""/usr/lib/python3.7/inspect.py"", line 619, in cleandoc
    lines = doc.expandtabs().split('\n')
AttributeError: 'NoneType' object has no attribute 'expandtabs'
puser@pusermachine:~/$ 
```

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
Here's my output of the above:
```

puser@pusermachine:~/$ python3
Python 3.7.3 (default, Oct  7 2019, 12:56:13) 
[GCC 8.3.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import platform; print(platform.platform())
Linux-5.0.0-32-generic-x86_64-with-Ubuntu-19.04-disco
>>> import sys; print(""Python"", sys.version)
Python 3.7.3 (default, Oct  7 2019, 12:56:13) 
[GCC 8.3.0]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.17.0
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.3.1
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.8.1
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1
>>> 
```

I pre-emptively apologize if I've missed something obvious in the documentation. "
596,https://github.com/RaRe-Technologies/gensim/issues/2681,2681,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-11-15 11:46:51+00:00,,ModuleNotFoundError: No module named 'gensim.models.keyedvectors',"I am running the code of DeepWalk Implementation. While running the code i got the following error.

from gensim.models.keyedvectors import KeyedVectors
ModuleNotFoundError: No module named 'gensim.models.keyedvectors'

"
597,https://github.com/RaRe-Technologies/gensim/issues/2683,2683,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}]",open,2019-11-21 16:53:13+00:00,,Doc2VecKeyedVectors doesn't effectively support __setitem__()/add(),"Per [user report on SO,](https://stackoverflow.com/questions/58964243/doc2vec-how-can-i-manually-modify-a-trained-vector-in-a-doc2vec-gensim-model/58966486?noredirect=1#comment104203509_58966486) neither assignment to a bracketed-access (as would be implemented by `__setitem__()`) nor use of the `add()` method will successfully mutate a `Doc2VecKeyedVectors` object. 

Looking closer, it seems the superclass `__setItem__()` passes through to superclass `add()`, which was only ever implemented for word-centric sets of vectors – consulting/updating properties like `.vocab` that only exist as empty values in `Doc2VecKeyedVectors` because of the currently confused inheritance created by #1777."
598,https://github.com/RaRe-Technologies/gensim/issues/2684,2684,[],closed,2019-11-23 21:14:11+00:00,,Unreasonable Query Result,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

      **The query result seems not correct. The code is self-explained. Thank you!**

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

```
from gensim.summarization.bm25 import BM25, get_bm25_weights


text1 = ""A constellation is a group of stars that are considered to form imaginary outlines or meaningful patterns on the celestial sphere.""
text2 = ""The 88 modern constellations are formally defined regions of the sky together covering the entire celestial sphere.""
text = [text1, text2]

corpus = [text1.split("" ""), text2.split("" "")]
print(f'corpus: {corpus}')

query = text2.split("" "")

bm25 = BM25(corpus)
scores = bm25.get_scores(query)
scores = [(s, i) for i, s in enumerate(scores)]
scores.sort(key=lambda t: t[0], reverse=True)
print(f'scores:         {scores}')

for s, idx in scores:
  print(f'{s}\t{idx}: {text[idx]}')
```

Output:

```
-0.3601521710456333         0: A constellation is a group of stars that are considered to form imaginary outlines or meaningful patterns on the celestial sphere.
-0.44989406787023367     1: The 88 modern constellations are formally defined regions of the sky together covering the entire celestial sphere.
```

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```

Output:
```
macOS-10.14.6-x86_64-i386-64bit
Python 3.8.0 (default, Nov  6 2019, 15:49:01)
[Clang 4.0.1 (tags/RELEASE_401/final)]
NumPy 1.17.4
SciPy 1.3.3
gensim 3.8.1
FAST_VERSION 0
```
"
599,https://github.com/RaRe-Technologies/gensim/issues/2685,2685,[],closed,2019-11-25 11:27:29+00:00,,Can I  get synonyms from Gensim word2vec model?,"Hi

with word2vec model, we are getting most similar words. can I get synonyms?
below are two queries: please clarify.
1) Is there a differentiation of related words vs synonyms from model?
2) can I change the word dimension, when I am trying to get the most similar words from model?

Thanks
"
600,https://github.com/RaRe-Technologies/gensim/issues/2686,2686,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}]",closed,2019-11-25 16:01:06+00:00,,lda mallet random seed not working,"#### Problem description

I tried to use random_seed on ldamallet but its not working

#### Code
```
mallet_path = 'mallet-2.0.8/mallet-2.0.8/bin/mallet' 
ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=25, id2word=id2word, random_seed = 0)
```

#### Output:

The model shows different output everytime i print out the topics

#### Versions:

Linux-4.15.0-70-generic-x86_64-with-debian-buster-sid
Python 3.7.2 (default, Dec 29 2018, 06:19:36) 
[GCC 7.3.0]
NumPy 1.15.1
SciPy 1.1.0
gensim 3.8.1
FAST_VERSION 1

"
601,https://github.com/RaRe-Technologies/gensim/issues/2688,2688,[],closed,2019-11-27 15:31:25+00:00,,LeveshteinSimilarityIndex fails when called from SparseTermSimilarityMatrix,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

When trying to build a SparseTermSimilarityMatrix using Levenshtein it fails.

#### Steps/code/corpus to reproduce

```python
index = LevenshteinSimilarityIndex(dictionary)
SparseTermSimilarityMatrix(index, dictionary) # <- fails here
```
```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-59-c16b89564835> in <module>
----> 1 similarity_matrix1 = SparseTermSimilarityMatrix(similarity_index1, dictionary)

~/.local/share/virtualenvs/pdftagger-LHy_2RHk/lib/python3.6/site-packages/gensim/similarities/termsim.py in __init__(self, source, dictionary, tfidf, symmetric, positive_definite, nonzero_limit, dtype)
    234                 for term, similarity in index.most_similar(t1, topn=num_rows)
    235                 if term in dictionary.token2id
--> 236             ] if num_rows > 0 else []
    237 
    238             if tfidf is None:

~/.local/share/virtualenvs/pdftagger-LHy_2RHk/lib/python3.6/site-packages/gensim/similarities/levenshtein.py in most_similar(self, t1, topn)
    151             if similarity > 0
    152         )
--> 153         return islice(most_similar, topn)

ValueError: Stop argument for islice() must be None or an integer: 0 <= x <= sys.maxsize.
```

#### Versions

Linux-4.18.0-25-generic-x86_64-with-debian-buster-sid
Python 3.6.9 (default, Nov 18 2019, 15:20:23) 
[GCC 8.3.0]
NumPy 1.17.4
SciPy 1.3.3
gensim 3.8.1
FAST_VERSION 1

"
602,https://github.com/RaRe-Technologies/gensim/issues/2690,2690,[],open,2019-11-28 10:00:30+00:00,,Errors when continuing training Doc2Vec model with previously-saved wv,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? What is the expected result? What are you seeing instead?

I tried to continue training from previously saved Doc2Vec model, and I only want to update docvec weights but not wordvec weights (i.e. freeze wv weights during subsequent training). After some search, I did it in the following way (using .load_word2vec_format because the latest Gensim disabled ""intersect_word2vec_format"" in Doc2Vec). However there is an error during train() - just wondering if this is a bug or I did something wrong (which is as simple as 3 lines, easily reproduced by any corpus/TaggedDocument)? Much appreciated for your help

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

code:
```python
d2v = Doc2Vec.load('previously_saved_d2v_model_file')
d2v.wv = Word2VecKeyedVectors.load_word2vec_format('previously_saved_w2v_binfile', binary=True) # the file was previously saved using Doc2Vec.save_word2vec_format, according to Gensim Docs this freezes wv by not updating 
d2v.train(documents, total_examples=d2v.corpus_count,  epochs=d2v.epochs, start_alpha=0.01, end_alpha=0.001)
```
code for previously saving the doc2vec/word2vec files:
```python
prev_d2v = Doc2Vec(vector_size=512,
              epochs=9,
              min_count=1,
              max_vocab_size=None,
              window=1024,
              hs=0,
              negative=90,
              workers=2,
              dm=0, # DBOW
              dbow_words=1 # if require Skip-gram word-vector
             )
prev_d2v.build_vocab(docs)
prev_d2v.train(docs,
          total_examples=prev_d2v.corpus_count,
          epochs=prev_d2v.epochs,
          start_alpha=0.01,
          end_alpha=0.001
         )
prev_d2v.save_word2vec_format('previously_saved_w2v_binfile', binary=True)
prev_d2v.save('previously_saved_d2v_model_file')
```


The full error tracebacks are:
```
-------------------------------------
Exception in thread Thread-8:
Traceback (most recent call last):
  File ""c:\users\documents\miniconda_python\lib\threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""c:\users\documents\miniconda_python\lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""c:\users\documents\miniconda_python\lib\site-packages\gensim\models\base_any2vec.py"", line 211, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""c:\users\documents\miniconda_python\lib\site-packages\gensim\models\doc2vec.py"", line 721, in _do_train_job
    doctag_vectors=doctag_vectors, doctag_locks=doctag_locks
  File ""gensim/models/doc2vec_inner.pyx"", line 344, in gensim.models.doc2vec_inner.train_document_dbow
AttributeError: 'Vocab' object has no attribute 'sample_int'
Exception in thread Thread-7:
Traceback (most recent call last):
  File ""c:\users\documents\miniconda_python\lib\threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""c:\users\documents\miniconda_python\lib\threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""c:\users\documents\miniconda_python\lib\site-packages\gensim\models\base_any2vec.py"", line 211, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""c:\users\documents\miniconda_python\lib\site-packages\gensim\models\doc2vec.py"", line 721, in _do_train_job
    doctag_vectors=doctag_vectors, doctag_locks=doctag_locks
  File ""gensim/models/doc2vec_inner.pyx"", line 344, in gensim.models.doc2vec_inner.train_document_dbow
AttributeError: 'Vocab' object has no attribute 'sample_int'
```
#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```

Windows-10-10.0.14393-SP0
Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]
NumPy 1.17.2
SciPy 1.3.1
gensim 3.8.1
FAST_VERSION 0


"
603,https://github.com/RaRe-Technologies/gensim/issues/2692,2692,[],open,2019-12-01 03:17:30+00:00,,"A error in word2vec.py, function train_sg_pair, model.neg_labels has not been defined before.",https://github.com/RaRe-Technologies/gensim/blob/e391f0c25599c751e127dde925e062c7132e4737/gensim/models/word2vec.py#L271   I guess there is also such a bug in function train_cbow_pair but I have not tried
604,https://github.com/RaRe-Technologies/gensim/issues/2693,2693,[],open,2019-12-02 10:11:29+00:00,,Number of Sentences in corpusfile don't match trained sentences.,"#### Problem description

I'm training a fasttext model (CBOW) over a corpus, for instance `enwik8`. 
The number of sentences trained (or example_count as referred in log methods) on doesn't equal the number of sentences in the file (`wc -l` or `len(f.readlines())`, referred as `expected_count` or `total_examples` ). 
Why is this happening? Also, in the method [here](https://github.com/RaRe-Technologies/gensim/blob/e391f0c25599c751e127dde925e062c7132e4737/gensim/models/base_any2vec.py#L1301), this warning has been suppressed for corpus mode.


### Versions

```python
Linux-4.4.0-1096-aws-x86_64-with-debian-stretch-sid
Python 3.7.5 (default, Oct 25 2019, 15:51:11)
[GCC 7.3.0]
NumPy 1.17.2
SciPy 1.3.1
gensim 3.8.1
FAST_VERSION 1
```
"
605,https://github.com/RaRe-Technologies/gensim/issues/2694,2694,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-12-03 09:23:13+00:00,,Use linesentence to stream corpus from file,"I have used gensim to train word embedding about 6 months ago. At that time, the code used to stream data works just fine, but now I used it again, I meet so many error, one of them from fasttext model using too much ram. I think the document have not been updated 

```
corpus_file = datapath('sample.txt')
model = FT_gensim(size=100)

# build the vocabulary
model.build_vocab(corpus_file=corpus_file)

# train the model
model.train(
    corpus_file=corpus_file, epochs=model.epochs,
    total_examples=model.corpus_count, total_words=model.corpus_total_words
)

print(model)
```"
606,https://github.com/RaRe-Technologies/gensim/issues/2696,2696,"[{'id': 175642, 'node_id': 'MDU6TGFiZWwxNzU2NDI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/wishlist', 'name': 'wishlist', 'color': 'd7e102', 'default': False, 'description': 'Feature request'}, {'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",open,2019-12-04 13:34:30+00:00,,"Look into ""Github Actions""","Internal dev ticket.

Github introduced ""actions"", for automating triaging / deployment tasks:
https://github.com/RaRe-Technologies/gensim/actions/new

Looks quite interesting; anything we could use there to our advantage? CC @mpenkov @gojomo "
607,https://github.com/RaRe-Technologies/gensim/issues/2697,2697,[],closed,2019-12-04 18:47:26+00:00,,Cannot use gensim 3.8.x when `nltk` package is installed,"#### Problem description

> What are you trying to achieve? What is the expected result? What are you seeing instead?

In my script i'm trying to `import gensim.models.keyedvectors` and also import another package, that requires `nltk` package internally. Whenever i have NLTK installed in the same virtualenv (i'm not using virtualenv, but a docker image actually) - the gensim model fails to import.

#### Steps/code/corpus to reproduce

```
# pip list | grep -E 'gensim|nltk'
gensim                        3.8.1

# pip install nltk
Processing /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483/nltk-3.4.5-cp36-none-any.whl
Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from nltk) (1.13.0)
Installing collected packages: nltk
Successfully installed nltk-3.4.5

# pip list | grep -E 'gensim|nltk'
gensim                        3.8.1
nltk                          3.4.5

# python
Python 3.6.8 (default, Jun 11 2019, 01:16:11)
[GCC 6.3.0 20170516] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.6/site-packages/gensim/__init__.py"", line 5, in <module>
    from gensim import parsing, corpora, matutils, interfaces, models, similarities, summarization, utils  # noqa:F401
  File ""/usr/local/lib/python3.6/site-packages/gensim/corpora/__init__.py"", line 14, in <module>
    from .wikicorpus import WikiCorpus  # noqa:F401
  File ""/usr/local/lib/python3.6/site-packages/gensim/corpora/wikicorpus.py"", line 539, in <module>
    class WikiCorpus(TextCorpus):
  File ""/usr/local/lib/python3.6/site-packages/gensim/corpora/wikicorpus.py"", line 577, in WikiCorpus
    def __init__(self, fname, processes=None, lemmatize=utils.has_pattern(), dictionary=None,
  File ""/usr/local/lib/python3.6/site-packages/gensim/utils.py"", line 1614, in has_pattern
    from pattern.en import parse  # noqa:F401
  File ""/usr/local/lib/python3.6/site-packages/pattern/text/en/__init__.py"", line 61, in <module>
    from pattern.text.en.inflect import (
  File ""/usr/local/lib/python3.6/site-packages/pattern/text/en/__init__.py"", line 80, in <module>
    from pattern.text.en import wordnet
  File ""/usr/local/lib/python3.6/site-packages/pattern/text/en/wordnet/__init__.py"", line 57, in <module>
    nltk.data.find(""corpora/"" + token)
  File ""/usr/local/lib/python3.6/site-packages/nltk/data.py"", line 673, in find
    return find(modified_name, paths)
  File ""/usr/local/lib/python3.6/site-packages/nltk/data.py"", line 660, in find
    return ZipFilePathPointer(p, zipentry)
  File ""/usr/local/lib/python3.6/site-packages/nltk/compat.py"", line 228, in _decorator
    return init_func(*args, **kwargs)
  File ""/usr/local/lib/python3.6/site-packages/nltk/data.py"", line 506, in __init__
    zipfile = OpenOnDemandZipFile(os.path.abspath(zipfile))
  File ""/usr/local/lib/python3.6/site-packages/nltk/compat.py"", line 228, in _decorator
    return init_func(*args, **kwargs)
  File ""/usr/local/lib/python3.6/site-packages/nltk/data.py"", line 1055, in __init__
    zipfile.ZipFile.__init__(self, filename)
  File ""/usr/local/lib/python3.6/zipfile.py"", line 1131, in __init__
    self._RealGetContents()
  File ""/usr/local/lib/python3.6/zipfile.py"", line 1198, in _RealGetContents
    raise BadZipFile(""File is not a zip file"")
zipfile.BadZipFile: File is not a zip file
```

#### Versions

```python
 python
Python 3.6.8 (default, Jun 11 2019, 01:16:11)
[GCC 6.3.0 20170516] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import platform; print(platform.platform())
Linux-5.0.0-050000rc8-generic-x86_64-with-debian-9.11
>>> import sys; print(""Python"", sys.version)
Python 3.6.8 (default, Jun 11 2019, 01:16:11)
[GCC 6.3.0 20170516]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.17.4
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.3.3
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.8.1
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1
```
"
608,https://github.com/RaRe-Technologies/gensim/issues/2699,2699,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2019-12-06 07:18:27+00:00,,Documentation may have code error!,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

[Similarity Queries](https://radimrehurek.com/gensim/auto_examples/core/run_similarity_queries.html#sphx-glr-auto-examples-core-run-similarity-queries-py)--Part--`Performing queries`
I think there is a code error. Document id error. Please see the code below.


### code

```python
sims = sorted(enumerate(sims), key=lambda item: -item[1])
for i, s in enumerate(sims):
    print(s, documents[i])  # s[0] is the document id, the 'i' is not.
```
corrected code should be
```python
sims = sorted(enumerate(sims), key=lambda item: -item[1])
for i, s in enumerate(sims):
    print(s, documents[s[0]])
```
"
609,https://github.com/RaRe-Technologies/gensim/issues/2701,2701,[],open,2019-12-10 19:16:43+00:00,,Sample weights.,"#### Problem description

I need to weight my data in training.  The Gensim API does not currently provide this functionality.

#### Proposed solution

I'm pretty sure adding a `sample_weight` arg to `train_cbow_pair`, `train_sg_pair`, `Word2Vec.__init__`, and `Word2Vec.train` will get the argument everywhere it needs to be.  Also, adding `neu1e *= sample_weight` to `train_cbow_pair` (line 375) and `train_sg_pair` (line 280) will accomplish a naive weighting scheme by simply weighting the individual loss terms.  I'm happy to implement this and write some tests if anyone seconds this motion.
"
610,https://github.com/RaRe-Technologies/gensim/issues/2702,2702,[],open,2019-12-16 08:48:08+00:00,,Word2VecKeyedVectors.vocab.keys() broken with chinese characters,"#### Problem description

A gensim model was trained under Python 2.7 with a **chinese** dataset.

However, now we are using Python3.6, and we got some broken strings in .vocab.keys() as title.

Any helpful steps to convert a model trained under Python2.7 to compatible with Python3.6?

Thanks in advance.

#### Steps/code/corpus to reproduce

```
gmodel = gensim.models.Word2Vec.load('word2vec.emb')
words = gmodel.wv.vocab.keys()
print(words[:10])
```

```
['',
 'æ··ç\x9d\x80',
 'è\x82\x9aå\xad\x90å¤§',
 'é\x82\x84ä¹\x8b',
 'DISSFMIINATIOII',
 'é\x83\x91ä¹\x9dç§\x91',
 'æ\x9c\x89è\x85¹é\x83¨æ\x89\x8bæ\x9c¯å\x8f²',
 'è¾\x83ä»\x85ç\x94¨',
 'ä»¥ç¬\x94',
 'ä»¥ç¬\x91']
```

#### Versions

```
Linux-3.10.0_3-0-0-10-x86_64-with-centos-6.3-Final
Python 3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) 
[GCC 7.2.0]
NumPy 1.14.3
SciPy 1.1.0
gensim 3.7.3
FAST_VERSION 1
```
"
611,https://github.com/RaRe-Technologies/gensim/issues/2704,2704,[],closed,2019-12-18 15:22:04+00:00,,Using gensim Doc2Vec for vectorizing documents of varying sizes,"I have tried implementing Doc2Vec on datasets consisting of similar document sizes (of about 300 words), and Doc2Vec performs really well as long as the data I provide during evaluation is similar in size compared to the docs on which the model was trained on (300 words).

But I also wanted to train the model on datasets where the doc size has a lot of variance (20 - 1000 words), and I feel that training the model on such a dataset would not produce good results as the documents that have lesser number of words like 20 or so would have provide lesser features and have lesser influence on the model, when compared to the docs with 1000 words in the same dataset.

I'm not sure if this understanding of mine is right.

Hence, one workaround which I thought of is, to train multiple models for fixed doc lengths (with some buffer).
i.e.

| model | doc-size range |
| -------- | -------------------- |
| model_1 | 20 - 150 |
| model_2 | 150-500 |
| model_3 | 500-1000 |

And after the model is deployed, vectorize new docs based on their lenghts.

I'm not sure if this is a good approach, or if there is a better way of achieving the goal."
612,https://github.com/RaRe-Technologies/gensim/issues/2705,2705,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",open,2019-12-19 22:49:50+00:00,,Poincare_Tutorial notebook: missing model bug,"I am unable to find 'gensim_model_batch_size_10_burn_in_0_epochs_50_neg_20_dim_50' in the gensim project.

I cloned the Gensim repo, and then ran the [Poincare Tutorial notebook](https://github.com/RaRe-Technologies/gensim/blob/bcee414663bdcbdf6a58684531ee69c6949550bf/docs/notebooks/Poincare%20Tutorial.ipynb).

This is the error message:

FileNotFoundError: [Errno 2] No such file or directory: '/home/gensim/docs/notebooks/poincare/models/gensim_model_batch_size_10_burn_in_0_epochs_50_neg_20_dim_50'

Possible solution: The model was moved elsewhere and the path needs to be updated.

Where can I find this model in the meantime?"
613,https://github.com/RaRe-Technologies/gensim/issues/2707,2707,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",open,2019-12-22 09:10:46+00:00,,Code issues with unpickle(),"While investigating one [mailing list issue](https://groups.google.com/forum/#!topic/gensim/sDWRgRzIThU), I saw this code we use in `.load()`:

https://github.com/RaRe-Technologies/gensim/blob/36ae46feaa1091f69eba952f678ef21820b4149e/gensim/utils.py#L1376-L1395

The code is confusing for two reasons:
1. In `# Because of loading from S3 load can't be used (missing readline in smart_open)`, what happens ""because of""? What is it referring to? And the line right under actually *does* use `load`. 
   What is this comment trying to say, or warn against? And is `smart_open` really missing some standard feature parity for S3?
2. Why does `load` decode its binary data as `latin1` in Python > 3.0?? At the very least, there should be a big fat comment for this strange construct."
614,https://github.com/RaRe-Technologies/gensim/issues/2708,2708,[],open,2019-12-23 18:32:32+00:00,,Error When Running LDA with 2000 Topics,"Hi All,
I'm running LDA using Gensim on the full English Wikipedia corpus.  I've been trying out different numbers of topics to figure out what gives the best performance and I've tried out 100, 500 and 1000 with no problems.  However, when I set the number of topics to 2000 I get the following errors:
```
INFO : accepted corpus with 4245368 documents, 100000 features, 702829711 non-zero entries
INFO : using symmetric alpha at 0.0005
INFO : using symmetric eta at 0.0005
INFO : using serial LDA version on this node
INFO : running online LDA training, 2000 topics, 1 passes over the supplied corpus of 4245368 documents, updating every 158000 documents, evaluating every ~1580000 documents, iterating 50x with a convergence threshold of 0.001000
INFO : training LDA model using 79 processes
INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #2000/4245368, outstanding queue size 1
Traceback (most recent call last):
  File ""/opt/conda/lib/python3.7/multiprocessing/queues.py"", line 242, in _feed
    send_bytes(obj)
  File ""/opt/conda/lib/python3.7/multiprocessing/connection.py"", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File ""/opt/conda/lib/python3.7/multiprocessing/connection.py"", line 393, in _send_bytes
    header = struct.pack(""!i"", n)
struct.error: 'i' format requires -2147483648 <= number <= 2147483647
INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #4000/4245368, outstanding queue size 2
```

Which I consistently get for each chunk.  Is there some kind of limit that I'm hitting with LDA?  Also, as an aside, if anyone has run LDA on the full Wikipedia corpus, what was the most topics that you could get out of it?
Thanks
"
615,https://github.com/RaRe-Technologies/gensim/issues/2709,2709,[],closed,2019-12-25 14:18:23+00:00,,Strange loss behaviour,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I monitor the loss during training word2vec. I have a callback that shows me how the loss was changed after each epoch. Look at the picture below:
![loss](https://user-images.githubusercontent.com/5142577/71446682-16f41180-2737-11ea-870c-68e1b0873a5f.png)

The difference between ""loss"" and ""train_loss"" is that ""loss"" is calculated at each epoch in the callback and ""train_loss"" is calculated as a loss on a copy of the model in ""train"" method with alpha near to zero (as well as ""valid_loss"") on the same dataset, it is like a loss, after saving and loading model. 

I expect that ""loss"" and ""train_loss"" will be equal, but they are very different: while the ""loss"" decreases rapidly, the ""train_loss"" remains at the same level. Is it expected behaviour?

This behaviour remains the same for any values provided to `sg` and `hs` arguments.

#### Steps/code/corpus to reproduce

See this notebook. I tried to keep it as small as possible.
https://colab.research.google.com/drive/1FF9J-DVplEUCrC47Cl1WU4jJHXPStBSc

#### Versions

Linux-4.14.137+-x86_64-with-Ubuntu-18.04-bionic
Python 3.6.9 (default, Nov  7 2019, 10:44:02) 
[GCC 8.3.0]
NumPy 1.17.4
SciPy 1.3.3
gensim 3.6.0
FAST_VERSION 1
"
616,https://github.com/RaRe-Technologies/gensim/issues/2710,2710,[],open,2019-12-26 07:55:35+00:00,,Distributed LDA Connection refused - Dispatcher host is always 127.0.0.1,"## Problem description

I am trying to run the distributed LDA on multiple machines. Following this tutorial: https://radimrehurek.com/gensim/models/lda_worker.html

Setup is working but once I run the distributed lda I get the following error:
![error](https://user-images.githubusercontent.com/963798/71465376-c0c9b180-27bc-11ea-9bab-ce061f33a424.PNG)

Dispatcher worker recognizes that there are lda-workers available but they cannot connect to the dispatcher.

![gensim](https://user-images.githubusercontent.com/963798/71465420-e8207e80-27bc-11ea-83df-17a063fcbe89.PNG)

The dispatcher host is always 127.0.0.1

I have also tried setting the host ip on the dispatcher but no luck
```
python -m gensim.models.lda_dispatcher --host HOST_IP &
```

Nameserver is recognized on other machines and shows the correct ip."
617,https://github.com/RaRe-Technologies/gensim/issues/2711,2711,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2019-12-27 14:50:00+00:00,,Coherence score on new data Key Error,"I want to compare different models (LDA, Mallet, etc.) with a Cross Validation. I train the model with training data and want to calculate the coherence score (c_v) with the test data. I do something like this:

```python
    dictionary = gensim.corpora.Dictionary(test)
    corpus = [dictionary.doc2bow(text) for text in test]

    cm = CoherenceModel(topics=topics, 
                        corpus=corpus, 
                        texts=test,
                        dictionary=dictionary, 
                        coherence=""c_v"")
    
    cm.get_coherence()
```

When a word in a topic found on the training data is not present in the test data this raises an key error in the dictionary at some point. Does someone know something about this? is this a bug or how do i solve this issue?

![grafik](https://user-images.githubusercontent.com/21197958/71521525-7d0ca000-28c1-11ea-858c-673f33d6965d.png)

"
618,https://github.com/RaRe-Technologies/gensim/issues/2713,2713,[],closed,2019-12-27 22:05:30+00:00,,Proposal: drop support for Python 3.5; add Python 3.8 to builds,"I recommend the next major gensim release (4.x) also drop official Python 3.5 testing/support. Rationale:

* it's close to full end-of-life (under 10 months to 2020-09-13) – currently receiving only security fixes
* major Python-using cloud services (including Heroku, AWS Lambda, Google Cloud/Colab, etc) already only support Python 3.6+
* some useful features (like the variable annotations needed for dataclasses) only arrive in 3.6
* for most users, moving forward to 3.6.x+ isn't hard; those absolutely stuck on 3.5 can use an earlier gensim version, or try their luck in an unsupported configuration (some modules might still work in Python 3.5)

Meanwhile, Python 3.8 has been out a few months (with support at Heroku & AWS Lambda) and deserves added build/test support. So we could replace the 3.5 builds/test in our CI setup with a new 3.8 target. 
"
619,https://github.com/RaRe-Technologies/gensim/issues/2716,2716,[],open,2019-12-29 11:10:15+00:00,,lemmatize: generator raised StopIteration,"#### Problem description

I'm trying to use lemmatize function to my text but getting StopIteration exception.

#### Steps/code/corpus to reproduce

```
from gensim.utils import lemmatize


s = lemmatize('eight')
print(s)
```

Result:
```
python3 lem.py 
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/pattern/text/__init__.py"", line 609, in _read
    raise StopIteration
StopIteration

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""lem.py"", line 4, in <module>
    s = lemmatize('eight')
  File ""/usr/local/lib/python3.7/site-packages/gensim/utils.py"", line 1692, in lemmatize
    parsed = parse(content, lemmata=True, collapse=False)
  File ""/usr/local/lib/python3.7/site-packages/pattern/text/en/__init__.py"", line 169, in parse
    return parser.parse(s, *args, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/pattern/text/__init__.py"", line 1172, in parse
    s[i] = self.find_tags(s[i], **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/pattern/text/en/__init__.py"", line 114, in find_tags
    return _Parser.find_tags(self, tokens, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/pattern/text/__init__.py"", line 1113, in find_tags
    lexicon = kwargs.get(""lexicon"", self.lexicon or {}),
  File ""/usr/local/lib/python3.7/site-packages/pattern/text/__init__.py"", line 376, in __len__
    return self._lazy(""__len__"")
  File ""/usr/local/lib/python3.7/site-packages/pattern/text/__init__.py"", line 368, in _lazy
    self.load()
  File ""/usr/local/lib/python3.7/site-packages/pattern/text/__init__.py"", line 625, in load
    dict.update(self, (x.split("" "")[:2] for x in _read(self._path) if len(x.split("" "")) > 1))
  File ""/usr/local/lib/python3.7/site-packages/pattern/text/__init__.py"", line 625, in <genexpr>
    dict.update(self, (x.split("" "")[:2] for x in _read(self._path) if len(x.split("" "")) > 1))
RuntimeError: generator raised StopIteration

```

#### Versions

I'm using MacOS, Python3:

```>>> import platform; print(platform.platform())
Darwin-18.7.0-x86_64-i386-64bit
>>> import sys; print(""Python"", sys.version)
Python 3.7.4 (default, Sep  7 2019, 18:27:02) 
[Clang 10.0.1 (clang-1001.0.46.4)]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.18.0
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.4.1
>>> import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
gensim 3.8.1
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 0
```

```
pip3 freeze | grep pattern
pattern3==3.0.0
pip3 freeze | grep gensim
gensim==3.8.1
```
"
620,https://github.com/RaRe-Technologies/gensim/issues/2717,2717,[],closed,2019-12-30 07:58:07+00:00,,Mallet Gensim error. (Non-zero exit status 1),"<!--

- **IMPORTANT**:


-->
Hi all,
please help me to solve the following error, i tried a lot to fix it but with no help. 

#### code

import os 
os.environ.update({'MALLET_HOME':r'C:new_mallet/'})
### 1.bulding LDA mallet model
mallet_path = 'C:\\new_mallet\\bin\\mallet' # update this path
ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)

#### error
CalledProcessError: Command 'C:\new_mallet\bin\mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex ""\S+"" --input C:\Users\zhaoyi\AppData\Local\Temp\7a71ac_corpus.txt --output C:\Users\zhaoyi\AppData\Local\Temp\7a71ac_corpus.mallet' returned non-zero exit status 1.
#### log
ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)
Traceback (most recent call last):

  File ""<ipython-input-45-6e0dbb876ee6>"", line 1, in <module>
    ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)

  File ""D:\anaconda\lib\site-packages\gensim\models\wrappers\ldamallet.py"", line 131, in __init__
    self.train(corpus)

  File ""D:\anaconda\lib\site-packages\gensim\models\wrappers\ldamallet.py"", line 272, in train
    self.convert_input(corpus, infer=False)

  File ""D:\anaconda\lib\site-packages\gensim\models\wrappers\ldamallet.py"", line 261, in convert_input
    check_output(args=cmd, shell=True)

  File ""D:\anaconda\lib\site-packages\gensim\utils.py"", line 1918, in check_output
    raise error
#### Versions

Please provide the output of:

```python
platform:Windows-10-10.0.17134-SP0
sys:Python 3.7.3 (default, Apr 24 2019, 15:29:51) [MSC v.1915 64 bit (AMD64)]
numpy:NumPy 1.16.4
scipy:SciPy 1.2.1
gensim:gensim 3.8.1
FAST_VERSION:FAST_VERSION 1
```
Thanks a  lot
"
621,https://github.com/RaRe-Technologies/gensim/issues/2718,2718,[],closed,2019-12-31 11:37:03+00:00,,Fix simple typo: voacab -> vocab,"# Issue Type

[x] Bug (Typo)

# Steps to Replicate

1. Examine gensim/test/test_keyedvectors.py.
2. Search for `voacab`.

# Expected Behaviour

1. Should read `vocab`.

"
622,https://github.com/RaRe-Technologies/gensim/issues/2721,2721,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",open,2020-01-04 14:02:54+00:00,,model.ldamulticore.LdaMulticore() seems does not work in ubuntu16.04 mechine?,"My pc is 64 cpu with cuda GPU,but when i use 
```
lda_corpus = models.ldamulticore.LdaMulticore(corpus=train_corpus, num_topics=num_topics, id2word=dictionary,
                              alpha=0.01, eta=0.01, minimum_probability=0.0001, 
                              iterations=100,workers=10)
```

using the code output nothing and mechine seems get dead cycle, but there are nothing output.

when i use the below code:
```
lda_corpus = models.LdaModel(train_corpus, num_topics=num_topics, id2word=dictionary,
                        alpha=0.01, eta=0.01, minimum_probability=0.001,
                        update_every = 1, iterations=iterations) 
```

got work.

why not use multicore when in linux(ubuntu)?
any help is thanks very much."
623,https://github.com/RaRe-Technologies/gensim/issues/2723,2723,[],closed,2020-01-07 13:24:08+00:00,,how to implemente get_document_topics(),"Hi all,
I use the method of AuthorTopicModel() build a model, then i want to get the topic of each document or the document belongs to which topic(assume that i have 10 topics) and the tutorial tell me that the method of get_document_topics() are not be implemented, so how to implemente it.

thanks in advance
yi zhao
"
624,https://github.com/RaRe-Technologies/gensim/issues/2724,2724,[],closed,2020-01-08 14:36:09+00:00,,load_facebook_model memory footprint,"#### Problem description
Hey everyone,
I encountered an issue when loading a pre-trained facebook FastText models. Loading a 7,24 GB pretrained model blows up to more than 20 GB in RAM on my machine when loading with Gensim. So my computer keeps swapping memory like crazy and never loads the model. It would be awesome if we could lower the memory footprint in Gensim's FastText loading mechanism. Is this a known problem and is anyone aware how to fix it? 

#### Steps/code/corpus to reproduce
1. Download a pre-trained FastText model  (e.g., cc.en.300.bin) from: https://fasttext.cc/docs/en/crawl-vectors.html
2. Try to load the model using `load_facebook_model('cc.en.300.bin')`

#### Versions

Please provide the output of:

```python
Darwin-19.0.0-x86_64-i386-64bit
Python 3.7.6 | packaged by conda-forge | (default, Dec 26 2019, 23:46:52) 
[Clang 9.0.0 (tags/RELEASE_900/final)]
NumPy 1.17.2
SciPy 1.4.1
gensim 3.8.1
```
"
625,https://github.com/RaRe-Technologies/gensim/issues/2725,2725,"[{'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",open,2020-01-08 23:57:23+00:00,,"Sigmoid-table behavior in FastText, etc code is fishy","Our implementation of FastText training error-backpropagation does some fishy things that deviate from the FB reference implementation. 

For example, at..

https://github.com/RaRe-Technologies/gensim/blob/fbc7d0952f1461fb5de3f6423318ae33d87524e3/gensim/models/fasttext_inner.pyx#L338

...we simply short-circuit skip to the next loop when an exponent is out of the desired range. (The same approach appears in Word2Vec and Doc2Vec cython code, as well.)

However, the seemingly-analogous code in Facebook's FastText instead clips the values to 0.0/1.0 in these cases, allowing backprop to proceed. See:

https://github.com/facebookresearch/fastText/blob/26bcbfc6b288396bd189691768b8c29086c0dab7/src/loss.cc#L52

Our deviation from Facebook's code's practice is suspicious on both correctness & consistency grounds. This simple `continue` does however match the behavior we copied long-ago from `word2vec.c`. 

Other perhaps-more superficial changes are that FB's code makes its lookup-tables 512 slots long instead of 1000, but allows exponents to 8 instead of 6:

https://github.com/facebookresearch/fastText/blob/51e6738d734286251b6ad02e4fdbbcfe5b679382/src/loss.cc#L16

Again, our FT implementation seems to have copied our copy-of-word2vec.c choices, instead of the reference FB implementation choices. If anything, it could make more sense to update the word2vec-derived code with these newer choices – as they at least plausibly represent practices improved by experience. "
626,https://github.com/RaRe-Technologies/gensim/issues/2726,2726,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2020-01-15 01:41:06+00:00,,"C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.","Im trying to run naive-bayes.py from the following file(https://github.com/rockash/Fake-news-Detection) but i get the error mentioned in the title, i have tried uninstalling gensim and reinstalling it again using both pip and conda but nothing seems to work.i also have mingw installed and have added /bin to path as the warning suggests but it doesnt work either.I'm using windows 10 64 bit
![Screenshot (2)](https://user-images.githubusercontent.com/36754286/72397510-21b62b00-3766-11ea-913b-6a283d85fff3.png)

"
627,https://github.com/RaRe-Technologies/gensim/issues/2727,2727,[],open,2020-01-16 02:11:33+00:00,,Parallel problem in MALLET LDA (gensim wrapper),"Hi,

I use the `gensim` wrapper, `LdaMallet()` [[link]](https://radimrehurek.com/gensim/models/wrappers/ldamallet.html), to run `MALLET`.

Gensim library provide a parameter `workers` to assign the `--num-threads` argument in `MALLET`.  
(Ref: [Gensim Code - line274](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/wrappers/ldamallet.py))

But I found the `workers` seems not working, here is the different setting and running time:
```
 `workers=1` -> run time: 7.32 sec   # <--
 `workers=2` -> run time: 2min 25s
 `workers=4` -> run time: 2min 38s
 `workers=16` -> run time: 3min 13s  # <--
```
   
   
No matter I run this on my computer:
```
openjdk version ""1.8.0_162""
OpenJDK Runtime Environment (build 1.8.0_162-8u162-b12-0ubuntu0.16.04.2-b12)
OpenJDK 64-Bit Server VM (build 25.162-b12, mixed mode)
```
or on the Colab:
```
openjdk version ""11.0.4"" 2019-07-16
OpenJDK Runtime Environment (build 11.0.4+11-post-Ubuntu-1ubuntu218.04.3)
OpenJDK 64-Bit Server VM (build 11.0.4+11-post-Ubuntu-1ubuntu218.04.3, mixed mode, sharing)
```
the results are similar, more workers spent more time.
(and I have also tried `mallet-2.0.8` & `mallet-2.0.7`)  
  
  
Dose it means I am not using a proper way to run MALLET LDA in parallel?  
  
Thanks!   

   
---
reference code:

```
# code in gensim (python)
# (i tried with different `workers`)

workers = 16
gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word, 
                                 optimize_interval=1, iterations=6000, workers=workers)
```
```
# the equivalent commands in mallet (key in shell, ignore the I/O setting):

$ bin/mallet train-topics --num-threads 16
```"
628,https://github.com/RaRe-Technologies/gensim/issues/2728,2728,[],closed,2020-01-16 13:23:23+00:00,,[QUESTION] Update LDA model,"## Problem description
Update an existing LDA model with an incremental approach. We create a LDA model for a collection of documents on demand basis. We save the resulting model file on the cloud. When a new LDA request arrives with fresh data, I need a way to incrementally update the model (live training) wit the these data. Typically I would use `lda.update()`. But what happens when the `lda.update()` takes as input a corpus that includes the same documents of the previous model?

Assumed to have `model1` trained on `corpus1` and a new `corpus2`, which is the best approach to do the incremental training of the new `model2` against `corpus2`?

I have seen a `lda.diff` function. So one could train `model2` and then run `mdiff, annotation = model1.diff(model2)`, then check `diff` and `annotation` and decide to promote `model2`. Does it make sense? Which is the best criterion to promote the new model then?

Thank you in advance!

#### Steps/code/corpus to reproduce

```python
from smart_open import open

# load the existing LDA model
current_model = LdaModel.load(open(s3_model_path))

# load the corpus
data = TextCorpus( open(s3_corpus_path) )
corpus_sentences = data.get_texts()
dictionary = Dictionary(corpus_sentences)
corpus = [dictionary.doc2bow(text) for text in corpus_sentences]

# update current model on the corpus
current_model.update(corpus)
```

#### Versions
```
Linux-5.0.0-36-generic-x86_64-with-Ubuntu-18.04-bionic
Python 3.6.9 (default, Nov  7 2019, 10:44:02) 
[GCC 8.3.0]
NumPy 1.17.4
SciPy 1.0.0
gensim 3.8.1
FAST_VERSION 1
```
"
629,https://github.com/RaRe-Technologies/gensim/issues/2733,2733,[],open,2020-01-25 03:10:42+00:00,,RuntimeWarning: overflow encountered in exp2   perwordbound.. when training LDA model,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

When training lda model
```
    model = LdaModel(
        corpus=corpus,
        id2word=id2word,
        chunksize=2000, # default
        alpha='auto', # asymmetric alpha prior computed from corpus not supported for multicore
        eta='auto',
        iterations=50, # default
        num_topics=2000,
        passes=2, # default
    )
```

with 
Number of unique tokens: 71959
Number of documents: 418422

I get this runtime warning 
```
/usr/local/lib/python2.7/dist-packages/gensim-3.7.2-py2.7-linux-x86_64.egg/gensim/models/ldamodel.py:824: RuntimeWarning: overflow encountered in exp2
  perwordbound, np.exp2(-perwordbound), len(chunk), corpus_words
```
#### Versions

```
Python 2.7.6 (default, Nov 13 2018, 12:45:42) 
[GCC 4.8.4] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import platform; print(platform.platform())
Linux-5.3.0-26-generic-x86_64-with-Ubuntu-14.04-trusty
>>> import sys; print(""Python"", sys.version)
('Python', '2.7.6 (default, Nov 13 2018, 12:45:42) \n[GCC 4.8.4]')
>>> import numpy; print(""NumPy"", numpy.__version__)
('NumPy', '1.11.3')
>>> import scipy; print(""SciPy"", scipy.__version__)
('SciPy', '0.18.1')
>>> import gensim; print(""gensim"", gensim.__version__)
('gensim', '3.8.1')
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
('FAST_VERSION', 1)
```"
630,https://github.com/RaRe-Technologies/gensim/issues/2735,2735,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2020-01-26 13:28:16+00:00,,Word2vec: loss tally maxes at 134217728.0 due to float32 limited-precision,"
<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Cumulative loss of word2vec maxes out at 134217728.0

I'm training a word2vec model with 2,793,404 sentences / 33,499,912 words, vocabulary size 162,253 (words with at least 5 occurrences).

Expected behaviour: with `compute_loss=True`, gensim's word2vec should compute the loss in the expected way.

Actual behaviour: the cumulative loss seems to be maxing out at `134217728.0`:

    Building vocab...
    Vocab done. Training model for 120 epochs, with 16 workers...
    Loss after epoch 1: 16162246.0 / cumulative loss: 16162246.0
    Loss after epoch 2: 11594642.0 / cumulative loss: 27756888.0

    [ - snip - ]

    Loss after epoch 110: 570688.0 / cumulative loss: 133002056.0
    Loss after epoch 111: 564448.0 / cumulative loss: 133566504.0
    Loss after epoch 112: 557848.0 / cumulative loss: 134124352.0
    Loss after epoch 113: 93376.0 / cumulative loss: 134217728.0
    Loss after epoch 114: 0.0 / cumulative loss: 134217728.0
    Loss after epoch 115: 0.0 / cumulative loss: 134217728.0

And it stays at `134217728.0` thereafter. The value `134217728.0` is of course exactly `128*1024*1024`, which does not seem like a coincidence.

#### Steps to reproduce

My code is as follows:

    class MyLossCalculator(CallbackAny2Vec):
        def __init__(self):
            self.epoch = 1
            self.losses = []
            self.cumu_losses = []

        def on_epoch_end(self, model):
            cumu_loss = model.get_latest_training_loss()
            loss = cumu_loss if self.epoch <= 1 else cumu_loss - self.cumu_losses[-1]
            print(f""Loss after epoch {self.epoch}: {loss} / cumulative loss: {cumu_loss}"")
            self.epoch += 1
            self.losses.append(loss)
            self.cumu_losses.append(cumu_loss)

    def train_and_check(my_sentences, my_epochs, my_workers=8):
        print(f""Building vocab..."")
        my_model: Word2Vec = Word2Vec(sg=1, compute_loss=True, workers=my_workers)
        my_model.build_vocab(my_sentences)
        print(f""Vocab done. Training model for {my_epochs} epochs, with {my_workers} workers..."")
        loss_calc = MyLossCalculator()
        trained_word_count, raw_word_count = my_model.train(my_sentences, total_examples=my_model.corpus_count, compute_loss=True,
                                                            epochs=my_epochs, callbacks=[loss_calc])
        loss = loss_calc.losses[-1]
        print(trained_word_count, raw_word_count, loss)
        loss_df = pd.DataFrame({""training loss"": loss_calc.losses})
        loss_df.plot(color=""blue"")
    #    print(f""Calculating accuracy..."")
    #    acc, details = my_model.wv.evaluate_word_analogies(questions_file, case_insensitive=True)
    #    print(acc)
        return loss_calc, my_model

The data is a news article corpus in Finnish; I'm not at liberty to share all of it (and anyway it's a bit big), but it looks like one would expect:

    [7]: df.head(2)
    [7]: [Row(file_and_id='data_in_json/2018/04/0001.json.gz%%3-10169118', index_in_file='853', headline='Parainen pyristelee pois lastensuojelun kriisistä: irtisanoutuneiden tilalle houkutellaan uusia sosiaalityöntekijöitä paremmilla työeduilla', publication_date='2018-04-20 11:59:35+03:00', publication_year='2018', publication_month='04', sentence='hän tiesi minkälaiseen tilanteeseen tulee', lemmatised_sentence='hän tietää minkälainen tilanne tulla', source='yle', rnd=8.436637410902392e-08),
         Row(file_and_id='data_in_xml/arkistosiirto2018.zip%%arkistosiirto2018/102054668.xml', index_in_file=None, headline='*** Tiedote/SDP: Medialle tiedoksi: SDP:n puheenjohtaja Antti Rinteen puhe puoluevaltuuston kokouksessa ***', publication_date='2018-04-21T12:51:44', publication_year='2018', publication_month='04', sentence='me haluamme jättää hallitukselle välikysymyksen siitä miksi nuorten ihmisten tulevaisuuden uskoa halutaan horjuttaa miksi epävarmuutta ja näköalattomuutta sekä pelkoa tulevaisuuden suhteen halutaan lisätä', lemmatised_sentence='me haluta jättää hallitus välikysymys se miksi nuori ihminen tulevaisuus usko haluta horjuttaa miksi epävarmuus ja näköalattomuus sekä pelko tulevaisuus suhteen haluta lisätä', source='stt', rnd=8.547760445010155e-07)]

    sentences = list(map(lambda r: r[""lemmatised_sentence""].split("" ""), df.select(""lemmatised_sentence"").collect()))

    [18]: sentences[0]
    [18]: ['hän', 'tietää', 'minkälainen', 'tilanne', 'tulla']

#### Versions

The output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```

is:

    Windows-10-10.0.18362-SP0
    Python 3.7.3 | packaged by conda-forge | (default, Jul  1 2019, 22:01:29) [MSC v.1900 64 bit (AMD64)]
    NumPy 1.17.3
    SciPy 1.3.1
    gensim 3.8.1
    FAST_VERSION 1

Finally, I'm not the only one who has encountered this issue. I found the following related links:

https://groups.google.com/forum/#!topic/gensim/IH5-nWoR_ZI

https://stackoverflow.com/questions/59823688/gensim-word2vec-model-loss-becomes-0-after-few-epochs

I'm not sure if this is only a display issue and the training continues normally even after the cumulative loss reaches its ""maximum"", or if the training in fact stops at that point. The trained word vectors seem reasonably ok, judging by `my_model.wv.evaluate_word_analogies()`, though they do need more training than this.
"
631,https://github.com/RaRe-Technologies/gensim/issues/2736,2736,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2020-01-26 18:10:56+00:00,,Mistake in tutorial code,"Tutorial: Similarity Queries
https://radimrehurek.com/gensim/auto_examples/core/run_similarity_queries.html#sphx-glr-auto-examples-core-run-similarity-queries-py

Notice the document order in the tutorial:
```
documents = [
    ""Human machine interface for lab abc computer applications"",
    ""A survey of user opinion of computer system response time"",
    ""The EPS user interface management system"",
    ""System and human system engineering testing of EPS"",
```

Current snippet in the tutorial prints text in the original documents order, not the actual associated text. 
```
sims = sorted(enumerate(sims), key=lambda item: -item[1])
for i, s in enumerate(sims):
    print(s, documents[i])

Out:
(2, 0.9984453) Human machine interface for lab abc computer applications
(0, 0.998093) A survey of user opinion of computer system response time
(3, 0.9865886) The EPS user interface management system
(1, 0.93748635) System and human system engineering testing of EPS
```

The code should be
```
sims = sorted(enumerate(sims), key=lambda item: -item[1])
for s in sims:
    print(s, documents[s[0]])

Out:
(2, 0.9984453) The EPS user interface management system
(0, 0.998093) Human machine interface for lab abc computer applications
(3, 0.9865886) System and human system engineering testing of EPS
(1, 0.93748635) A survey of user opinion of computer system response time
```"
632,https://github.com/RaRe-Technologies/gensim/issues/2737,2737,[],closed,2020-01-28 18:22:59+00:00,,Word2Vec Wikipedia Corpus 2017 no vocabulary,"#### Problem description

When following the example code [here](https://radimrehurek.com/gensim/auto_examples/howtos/run_downloader_api.html#sphx-glr-auto-examples-howtos-run-downloader-api-py) I receive a ""Word not in vocabulary"" error. Opening at the request of Radim: https://groups.google.com/forum/#!topic/gensim/ULW_OKrPtqE

#### Steps/code/corpus to reproduce
```python
from gensim.models.word2vec import Word2Vec
import gensim.downloader as gensim_download_api

wikipedia_corpus = gensim_download_api('wiki-english-2017001')
model_with_wikipedia = Word2Vec(wikipedia_corpus)
model_with_wikipedia.wv.most_similar('cat')
KeyError: ""word 'cat' not in vocabulary""
```

Logging output (truncated to non-repeat / progress):

```
INFO:gensim.models.word2vec:PROGRESS: at sentence #4920000, processed 14760000 words, keeping 3 word types
INFO:gensim.models.word2vec:collected 3 word types from a corpus of 14774682 raw words and 4924894 sentences
INFO:gensim.models.word2vec:Loading a fresh vocabulary
INFO:gensim.models.word2vec:effective_min_count=5 retains 3 unique words (100% of original 3, drops 0)
INFO:gensim.models.word2vec:effective_min_count=5 leaves 14774682 word corpus (100% of original 14774682, drops 0)
INFO:gensim.models.word2vec:deleting the raw counts dictionary of 3 items
INFO:gensim.models.word2vec:sample=0.001 downsamples 3 most-common words
INFO:gensim.models.word2vec:downsampling leaves estimated 853566 word corpus (5.8% of prior 14774682)
INFO:gensim.models.base_any2vec:estimated required memory for 3 words and 100 dimensions: 3900 bytes
INFO:gensim.models.word2vec:resetting layer weights
INFO:gensim.models.base_any2vec:training model with 3 workers on 3 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5
```

#### Versions

Linux-4.15.0-74-generic-x86_64-with-debian-buster-sid
Python 3.7.4 (default, Sep  5 2019, 19:15:53) 
[GCC 7.4.0]
NumPy 1.18.1
SciPy 1.4.1
gensim 3.8.1
FAST_VERSION 1"
633,https://github.com/RaRe-Technologies/gensim/issues/2740,2740,[],closed,2020-01-30 16:06:28+00:00,,remove_stopwords doesn't remove capitalized stopwords,"### Problem description

I'm trying to remove stopwords from sentences and I've noticed that capitalized stopwords do not get removed from the sentence using `gensim.parsing.preprocessing.remove_stopwords`.

#### Steps/code/corpus to reproduce

```
from gensim.parsing.preprocessing import remove_stopwords
remove_stopwords(""My dog ate my homework."")
actual output:
>>> 'My dog ate homework.'
expected output:
>>> 'dog ate homework.'
```


#### Versions

Linux-4.14.137+-x86_64-with-Ubuntu-18.04-bionic
Python 3.6.9 (default, Nov  7 2019, 10:44:02) 
[GCC 8.3.0]
NumPy 1.17.5
SciPy 1.4.1
gensim 3.6.0
FAST_VERSION 1

"
634,https://github.com/RaRe-Technologies/gensim/issues/2742,2742,[],closed,2020-02-01 15:23:21+00:00,,Can't get attribute 'Word2VecKeyedVectors' during model.load() when using `hashfxn`,"#### Problem description

Created a model using very straightforward code with a hash function to improve reproducibility (used in an academic setting):

```
MODEL_DIR = '.../somepath'
hash =
model = Word2Vec(
        corpus,
        size=SIZE,
        window=WINDOW,
        min_count=1,
        workers=WORKERS,
        iter=ITER,
        seed=100,
        hashfxn=hash
    )

model.save(MODEL_DIR)
```

The code above runs without problem. However, when trying to load using `Word2Vec.load(MODEL_PATH)` it would throw a large trace stack. To narrow it down and save everyone some reading, I isolated it down to this line:

> AttributeError: Can't get attribute 'hash' on <module '__main__' from 'plot/demo/embedding.py'>

I've saved multiple models in my project, none of which require the use of a hashing function. The same code can load those other models without a problem. This is the only one model so it's quite clearly something to do with the hashing.

#### Steps/code/corpus to reproduce

When trying to load the same model:

```
model = Word2Vec.load(MODEL_PATH)
```

Returns the following Traceback:
```
Traceback (most recent call last):
  File ""/Users/samuel/anaconda3/envs/deeplearning/lib/python3.6/site-packages/gensim/models/word2vec.py"", line 1330, in load
    model = super(Word2Vec, cls).load(*args, **kwargs)
  File ""/Users/samuel/anaconda3/envs/deeplearning/lib/python3.6/site-packages/gensim/models/base_any2vec.py"", line 1244, in load
    model = super(BaseWordEmbeddingsModel, cls).load(*args, **kwargs)
  File ""/Users/samuel/anaconda3/envs/deeplearning/lib/python3.6/site-packages/gensim/models/base_any2vec.py"", line 603, in load
    return super(BaseAny2VecModel, cls).load(fname_or_handle, **kwargs)
  File ""/Users/samuel/anaconda3/envs/deeplearning/lib/python3.6/site-packages/gensim/utils.py"", line 426, in load
    obj = unpickle(fname)
  File ""/Users/samuel/anaconda3/envs/deeplearning/lib/python3.6/site-packages/gensim/utils.py"", line 1384, in unpickle
    return _pickle.load(f, encoding='latin1')
AttributeError: Can't get attribute 'hash' on <module '__main__' from 'plot/demo/embedding.py'>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""plot/demo/embedding.py"", line 11, in <module>
    model = Word2Vec.load(MODEL_PATH)
  File ""/Users/samuel/anaconda3/envs/deeplearning/lib/python3.6/site-packages/gensim/models/word2vec.py"", line 1341, in load
    return load_old_word2vec(*args, **kwargs)
  File ""/Users/samuel/anaconda3/envs/deeplearning/lib/python3.6/site-packages/gensim/models/deprecated/word2vec.py"", line 172, in load_old_word2vec
    old_model = Word2Vec.load(*args, **kwargs)
  File ""/Users/samuel/anaconda3/envs/deeplearning/lib/python3.6/site-packages/gensim/models/deprecated/word2vec.py"", line 1641, in load
    model = super(Word2Vec, cls).load(*args, **kwargs)
  File ""/Users/samuel/anaconda3/envs/deeplearning/lib/python3.6/site-packages/gensim/models/deprecated/old_saveload.py"", line 87, in load
    obj = unpickle(fname)
  File ""/Users/samuel/anaconda3/envs/deeplearning/lib/python3.6/site-packages/gensim/models/deprecated/old_saveload.py"", line 379, in unpickle
    return _pickle.loads(file_bytes, encoding='latin1')
AttributeError: Can't get attribute 'Word2VecKeyedVectors' on <module 'gensim.models.deprecated.keyedvectors' from '/Users/samuel/anaconda3/envs/deeplearning/lib/python3.6/site-packages/gensim/models/deprecated/keyedvectors.py'>
```

Removing the hashing function will see the `Word2Vec.load()` function works again. I'm not using any keyed vectors helper function, just a straight up Word2Vec save and load. I hope it's easy to reproduce given how it only affects model created with a hash function. 

#### Versions

```
# Platform
Darwin-19.2.0-x86_64-i386-64bit
# Python
Python 3.6.7 | packaged by conda-forge | (default, Nov 20 2018, 18:20:05) 
[GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.37)]
# numpy version
NumPy 1.15.4
# SciPy version
SciPy 1.1.0
# gensim version
gensim 3.8.1
# word2vec
FAST_VERSION 1
```"
635,https://github.com/RaRe-Technologies/gensim/issues/2743,2743,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}]",open,2020-02-02 20:27:38+00:00,,"Word2vec: total loss suspiciously drops with worker count, probably thread-unsafe tallying","<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

The word2vec implementation requires a workaround, as detailed in #2735, to correctly report the total loss per epoch. After doing that though, the next issue is that the total loss reported seems to vary depending on the number of workers.

#### Steps/code/corpus to reproduce

This is my code:

    class MyLossCalculatorII(CallbackAny2Vec):
        def __init__(self):
            self.epoch = 1
            self.losses = []
            self.cumu_loss = 0.0
            self.previous_epoch_time = time.time()

        def on_epoch_end(self, model):
            loss = model.get_latest_training_loss()
            norms = [linalg.norm(v) for v in model.wv.vectors]
            now = time.time()
            epoch_seconds = now - self.previous_epoch_time
            self.previous_epoch_time = now
            self.cumu_loss += float(loss)
            print(f""Loss after epoch {self.epoch}: {loss} (cumulative loss so far: {self.cumu_loss}) ""+\
                  f""-> epoch took {round(epoch_seconds, 2)} s - vector norms min/avg/max: ""+\
                  f""{round(float(min(norms)), 2)}, {round(float(sum(norms)/len(norms)), 2)}, {round(float(max(norms)), 2)}"")
            self.epoch += 1
            self.losses.append(float(loss))
            model.running_training_loss = 0.0

    def train_and_check(my_sentences, my_epochs, my_workers=8, my_loss_calc_class=MyLossCalculatorII):
        print(f""Building vocab..."")
        my_model: Word2Vec = Word2Vec(sg=1, compute_loss=True, workers=my_workers)
        my_model.build_vocab(my_sentences)
        print(f""Vocab done. Training model for {my_epochs} epochs, with {my_workers} workers..."")
        loss_calc = my_loss_calc_class()
        trained_word_count, raw_word_count = my_model.train(my_sentences, total_examples=my_model.corpus_count, compute_loss=True,
                                                            epochs=my_epochs, callbacks=[loss_calc])
        loss = loss_calc.losses[-1]
        print(trained_word_count, raw_word_count, loss)
        loss_df = pd.DataFrame({""training loss"": loss_calc.losses})
        loss_df.plot(color=""blue"")
    #    print(f""Calculating accuracy..."")
    #    acc, details = my_model.wv.evaluate_word_analogies(questions_file, case_insensitive=True)
    #    print(acc)
        return loss_calc, my_model

My data is an in-memory list of sentences of Finnish text, each sentence being a list of strings:

    [18]: sentences[0]
    [18]: ['hän', 'tietää', 'minkälainen', 'tilanne', 'tulla']

I'm running the following code:

    lc4, model4 = train_and_check(sentences, my_epochs=20, my_workers=4)
    lc8, model8 = train_and_check(sentences, my_epochs=20, my_workers=8)
    lc16, model16 = train_and_check(sentences, my_epochs=20, my_workers=16)
    lc32, model32 = train_and_check(sentences, my_epochs=20, my_workers=32)

And the outputs are (last few lines + plot only):

    # lc4
    Loss after epoch 20: 40341580.0 (cumulative loss so far: 830458060.0) -> epoch took 58.15 s - vector norms min/avg/max: 0.02, 3.79, 12.27
    589841037 669998240 40341580.0
    Wall time: 20min 14s

![lc4](https://user-images.githubusercontent.com/1218171/73614674-35ccaa00-45f9-11ea-9c43-7eee099dcad2.png)

    # lc8
    Loss after epoch 20: 25501282.0 (cumulative loss so far: 521681620.0) -> epoch took 36.6 s - vector norms min/avg/max: 0.02, 3.79, 12.24
    589845960 669998240 25501282.0
    Wall time: 12min 46s

![lc8](https://user-images.githubusercontent.com/1218171/73614677-3cf3b800-45f9-11ea-8fe2-fbb06b43706d.png)

    # lc16
    Loss after epoch 20: 14466763.0 (cumulative loss so far: 295212011.0) -> epoch took 26.25 s - vector norms min/avg/max: 0.02, 3.79, 12.55
    589839763 669998240 14466763.0
    Wall time: 9min 35s

![lc16](https://user-images.githubusercontent.com/1218171/73614681-43822f80-45f9-11ea-959a-a8af660a89ac.png)

    # lc32
    Loss after epoch 20: 7991086.5 (cumulative loss so far: 161415654.5) -> epoch took 27.5 s - vector norms min/avg/max: 0.02, 3.79, 12.33
    589843184 669998240 7991086.5
    Wall time: 9min 37s

![lc32](https://user-images.githubusercontent.com/1218171/73614687-49781080-45f9-11ea-8339-7770f72f0fe7.png)

What is going on here? The loss (whether total loss, final-epoch loss or average loss per epoch) varies, although the data is the same and the number of epochs is the same. I would imagine that ""1 epoch"" means ""each data point is considered precisely once"", in which case the number of workers should only affect how quickly the training is done and not the loss (the loss would still vary randomly a bit depending on which order the data points are considered etc, but that should be minor). Here though the loss seems to be roughly proportional to 1/n where n = number of workers.

I'm guessing based on the similar shape of the loss progressions and the very similar vector magnitudes that the training is actually fine in all four cases, so hopefully this is just another display bug similar to #2735.

#### Versions

The output of

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```

is

    Windows-10-10.0.18362-SP0
    Python 3.7.3 | packaged by conda-forge | (default, Jul  1 2019, 22:01:29) [MSC v.1900 64 bit (AMD64)]
    NumPy 1.17.3
    SciPy 1.3.1
    gensim 3.8.1
    FAST_VERSION 1
"
636,https://github.com/RaRe-Technologies/gensim/issues/2744,2744,[],open,2020-02-04 13:00:16+00:00,,AttributeError: 'WikiCorpus' object has no attribute 'input',"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I am using WikiCorpus to read and process the wikipedia dump. However when I try to iterate  over  getstream() output, I get the error that there is no attribute input. Indeed, there is no input attribute but there is a fname attribute.
#### Steps/code/corpus to reproduce

```python
path = ""data/dewiki-latest-pages-articles.xml.bz2""
wiki = WikiCorpus(path)
for stream in wiki.getstream():
    print(stream)
    break
```

On the other hand, this fixes the problem, but I guess would be better if it gets fixed in the source code if the attribute missing is the problem.

```python
setattr(wiki, ""input"", wiki.fname)
```

#### Versions

```python
Linux-x86_64-with-debian-9.11
Python 3.7.0 (default, Oct  9 2018, 10:31:47) 
[GCC 7.3.0]
NumPy 1.17.3
SciPy 1.3.2
gensim 3.8.0
FAST_VERSION 1
```
"
637,https://github.com/RaRe-Technologies/gensim/issues/2745,2745,[],closed,2020-02-05 13:33:03+00:00,,Meaning of negative LSI weight for words in topics,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

Hello!

I am barely understand what does the words with negative weight means. Is it their weight in another topic clusters? Can i use them to increase topics modeling accuracy or i can easily ignore them and it will not affect results.

Thanks in advance!
"
638,https://github.com/RaRe-Technologies/gensim/issues/2746,2746,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}]",closed,2020-02-06 15:17:19+00:00,,Word2Vec ns_exponent cannot be changed from default,"#### Problem description

I am trying to train Word2Vec and tune the `ns_exponent` hyperparameter. When I initialize the model, I set `ns_exponent = 0.5`, but find that it has reset to the default of `ns_exponent = 0.75` immediately after initializing.

I looked through the Word2Vec source code for any mentions of `ns_exponent`, but found no reason for the class to ignore my argument. I suspected the Vocabulary initialization may have something to do with it, but that seems to take its argument straight from the `__init__`. Neither do I believe that I am overriding the `ns_exponent` setting with one of the other parameters, because this occurs even when `ns_exponent` is the only one explicitly set.

#### Steps/code/corpus to reproduce

```
model = Word2Vec(ns_exponent = 0.5)
print(model.ns_exponent)
```

The printed output is: 

```
0.75
```

and the resulting model's `ns_exponent` attribute is set to 0.75 as well.


#### Versions

```
Windows-10-10.0.18362-SP0
Python 3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]
NumPy 1.16.0
SciPy 1.1.0
gensim 3.6.0
FAST_VERSION 0
```
"
639,https://github.com/RaRe-Technologies/gensim/issues/2747,2747,[],closed,2020-02-08 19:31:40+00:00,,Rackspace account discontinued ,"https://github.com/MacPython/gensim-wheels is using the rackspace account for the release process and on top of that some gensim maintainers have dedicated gensim containers on our shared rackspace cloud storage infrastructure.

However the free hosting offer for open source projects has ended:

More details: https://mail.python.org/pipermail/scipy-dev/2020-February/023990.html

So we need to move on to something else. Please delete the files you own and no longer need in the rackspace admin interface and let's join on https://github.com/matthew-brett/multibuild/issues/304 to discuss how to setup a new release infrastructure."
640,https://github.com/RaRe-Technologies/gensim/issues/2748,2748,[],closed,2020-02-08 19:45:28+00:00,, CalledProcessError: returned non-zero exit status 127,"####

I saw similar issues reported before and tried different suggestions but still get the CalledProcessError. 

#### Steps/code/corpus to reproduce
My code:

```
mallet_path = 'Users/av/DS/mallet-2.0.8/bin/mallet'
ldamallet_model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=40, id2word=dictionary)

```
---------------------------------------------------------------------------
CalledProcessError                        Traceback (most recent call last)
<ipython-input-77-9a6d0211c7fd> in <module>
      1 mallet_path = 'Users/av/DS/mallet-2.0.8/bin/mallet'
----> 2 ldamallet_model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=40, id2word=dictionary)

/Applications/anaconda3/lib/python3.7/site-packages/gensim/models/wrappers/ldamallet.py in __init__(self, mallet_path, corpus, num_topics, alpha, id2word, workers, prefix, optimize_interval, iterations, topic_threshold, random_seed)
    129         self.random_seed = random_seed
    130         if corpus is not None:
--> 131             self.train(corpus)
    132 
    133     def finferencer(self):

/Applications/anaconda3/lib/python3.7/site-packages/gensim/models/wrappers/ldamallet.py in train(self, corpus)
    270 
    271         """"""
--> 272         self.convert_input(corpus, infer=False)
    273         cmd = self.mallet_path + ' train-topics --input %s --num-topics %s  --alpha %s --optimize-interval %s '\
    274             '--num-threads %s --output-state %s --output-doc-topics %s --output-topic-keys %s '\

/Applications/anaconda3/lib/python3.7/site-packages/gensim/models/wrappers/ldamallet.py in convert_input(self, corpus, infer, serialize_corpus)
    259             cmd = cmd % (self.fcorpustxt(), self.fcorpusmallet())
    260         logger.info(""converting temporary corpus to MALLET format with %s"", cmd)
--> 261         check_output(args=cmd, shell=True)
    262 
    263     def train(self, corpus):

/Applications/anaconda3/lib/python3.7/site-packages/gensim/utils.py in check_output(stdout, *popenargs, **kwargs)
   1916             error = subprocess.CalledProcessError(retcode, cmd)
   1917             error.output = output
-> 1918             raise error
   1919         return output
   1920     except KeyboardInterrupt:

CalledProcessError: Command 'Users/avs/DS/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex ""\S+"" --input /var/folders/pp/mw9ffc953kq3wx770qqwrm2httlj5s/T/3c2a5c_corpus.txt --output /var/folders/pp/mw9ffc953kq3wx770qqwrm2httlj5s/T/3c2a5c_corpus.mallet' returned non-zero exit status 127.

#### Versions

Please provide the output of:

```
Darwin-18.7.0-x86_64-i386-64bit
Python 3.7.4 (default, Aug 13 2019, 15:17:50) 
[Clang 4.0.1 (tags/RELEASE_401/final)]
NumPy 1.17.2
SciPy 1.3.1
gensim 3.8.1
FAST_VERSION 1
```
"
641,https://github.com/RaRe-Technologies/gensim/issues/2749,2749,[],closed,2020-02-08 21:49:24+00:00,,"collections.Mapping deprecated, to be removed in py3.9","#### Problem description

`python -Wdefault -c 'from gensim.corpora import dictionary'`

reports

```
gensim/corpora/dictionary.py:11: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
  from collections import Mapping, defaultdict
```

expected no warning.


#### Versions

Linux-5.4.10-200.fc31.x86_64-x86_64-with-fedora-31-Thirty_One
Python 3.7.6 (default, Dec 19 2019, 22:52:49) 
[GCC 9.2.1 20190827 (Red Hat 9.2.1-1)]
NumPy 1.18.1
SciPy 1.4.1
gensim 3.8.1
FAST_VERSION 1"
642,https://github.com/RaRe-Technologies/gensim/issues/2752,2752,[],closed,2020-02-13 08:09:49+00:00,,n,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? What is the expected result? What are you seeing instead?

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
"
643,https://github.com/RaRe-Technologies/gensim/issues/2753,2753,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}]",open,2020-02-15 21:09:56+00:00,,Incorrect documentation for `fit_transform` in `sklearn_api` API ,"#### Problem description

`fit_transform`  in the `sklearn_api` is documented to return:
`X_new : numpy array of shape [n_samples, n_features_new]`

This is not the case. What is returned is:
` iterable of list (int, float) 2-tuples.`

It appears `fit_transform` is inherited from `sklearn.base.TransformerMixin` and therefore needs to be documented appropriately (or the method overridden).

#### Steps/code/corpus to reproduce

```python
model2 = TfIdfTransformer(dictionary=dct)
vecs = model2.fit_transform(corpus)
type(vecs)
> list
```

#### Versions
```
Linux-4.14.146-119.123.amzn2.x86_64-x86_64-with-debian-buster-sid
Python 3.7.6 (default, Jan  8 2020, 19:59:22) 
[GCC 7.3.0]
NumPy 1.18.1
SciPy 1.3.2
gensim 3.8.0
FAST_VERSION 1
```
"
644,https://github.com/RaRe-Technologies/gensim/issues/2754,2754,[],closed,2020-02-16 17:07:42+00:00,,LdaModel throws exception when the corpus is a sparse term by doc CSC matrix,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I'm trying to fit an LDA modeling using a term by doc CSC matrix.

#### Steps/code/corpus to reproduce

![image](https://user-images.githubusercontent.com/1140359/74609111-c654c100-50b4-11ea-93d8-8ae785ab5e46.png)

```pytb
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-29-da24849da160> in <module>
----> 1 model = LdaModel(X)

/usr/local/lib/python3.7/site-packages/gensim/models/ldamodel.py in __init__(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)
    431         if self.id2word is None:
    432             logger.warning(""no word id mapping provided; initializing from corpus, assuming identity"")
--> 433             self.id2word = utils.dict_from_corpus(corpus)
    434             self.num_terms = len(self.id2word)
    435         elif len(self.id2word) > 0:

/usr/local/lib/python3.7/site-packages/gensim/utils.py in dict_from_corpus(corpus)
    824 
    825     """"""
--> 826     num_terms = 1 + get_max_id(corpus)
    827     id2word = FakeDict(num_terms)
    828     return id2word

/usr/local/lib/python3.7/site-packages/gensim/utils.py in get_max_id(corpus)
    733     maxid = -1
    734     for document in corpus:
--> 735         if document:
    736             maxid = max(maxid, max(fieldid for fieldid, _ in document))
    737     return maxid

/usr/local/lib/python3.7/site-packages/scipy/sparse/base.py in __bool__(self)
    285             return self.nnz != 0
    286         else:
--> 287             raise ValueError(""The truth value of an array with more than one ""
    288                              ""element is ambiguous. Use a.any() or a.all()."")
    289     __nonzero__ = __bool__

ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all().
```

#### Versions

Darwin-19.3.0-x86_64-i386-64bit
Python 3.7.5 (default, Nov  1 2019, 02:16:23) 
[Clang 11.0.0 (clang-1100.0.33.8)]
NumPy 1.17.4
SciPy 1.3.3
gensim 3.8.1
FAST_VERSION 0
"
645,https://github.com/RaRe-Technologies/gensim/issues/2755,2755,[],open,2020-02-17 08:23:04+00:00,,Doc2Vec.clear_sims bug,"I was reading Doc2Vec source code and noticed a probable bug in clear_sims method. 
https://github.com/RaRe-Technologies/gensim/blob/8d79794118a3adeda8cf9c873eb205cecf47cfef/gensim/models/doc2vec.py#L387

It sets vectors_docs_norm attribute of Word2VecKeyedVectors to None. However, Word2VecKeyedVectors does not have this attribute. So I think this line should be
`self.docvecs.vectors_docs_norm = None`
"
646,https://github.com/RaRe-Technologies/gensim/issues/2756,2756,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2020-02-19 21:57:21+00:00,,"""Pattern library is not installed"" -- this still is a problem","<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description
I am having the same problem that was reported in issue #2534, which has subsequently been closed. I am attempting to literally do the same exact thing that the author of  that was doing:

> I am trying to do a gensim tutorial project. I am attempting to lemmatize and getting this error:
ImportError: Pattern library is not installed. Pattern library is needed in order to use lemmatize function.

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

The following is from the [Topic Modeling for Fun and Profit](https://github.com/piskvorky/topic_modeling_tutorial) tutorial:

```python
import numpy
import scipy
import gensim
    
gensim.utils.lemmatize(""The quick brown fox jumps over the lazy dog!"")
--------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
ipython-input-5-23224c08425f> in <module>
1 import gensim
----> 2 gensim.utils.lemmatize(""The quick brown fox jumps over the lazy dog!"")
    
anaconda3/lib/python3.7/site-packages/gensim/utils.py in lemmatize(content, allowed_tags, light, stopwords, min_length, max_length)
1676     if not has_pattern():
1677         raise ImportError(
-> 1678             ""Pattern library is not installed. Pattern library is needed in order to use lemmatize function""
1679         )
1680     from pattern.en import parse
    
ImportError: Pattern library is not installed. Pattern library is needed in order to use lemmatize function
```


#### Versions

Please provide the output of:

```python
>>>import platform; print(platform.platform())
Darwin-17.7.0-x86_64-i386-64bit

>>> import sys; print(""Python"", sys.version)
Python 3.7.4 (default, Aug 13 2019, 15:17:50)
[Clang 4.0.1 (tags/RELEASE_401/final)]

>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.17.2

>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.3.1

>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.8.0

>>> pattern3.__version__
'2.6'

>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1
```
"
647,https://github.com/RaRe-Technologies/gensim/issues/2757,2757,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 1602334472, 'node_id': 'MDU6TGFiZWwxNjAyMzM0NDcy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20MEDIUM', 'name': 'impact MEDIUM', 'color': '7af49f', 'default': False, 'description': 'Big annoyance for affected users'}]",open,2020-02-20 13:57:10+00:00,,Doc2vec corpusfile mode skips some documents during training,"### Problem description
During training of Doc2Vec on corpusfile, some documents are skipped. I think it is because of the way how corpusfile is partitioned. Some lines are processed by two or more workers while some are not processed at all. This behavior could be acceptable for Word2Vec and FasText as the same word occurs several times in different lines. But that is not the case with Doc2Vec where each document corresponds to exactly one line and if that line is skipped, corresponding document vector will not be trained.

### Steps to reproduce

documents.txt
```
a very long document with huge number of words in it
several
short
documents
```
script.py
```
from gensim.models import Doc2Vec
import copy
offsets, start_lines = Doc2Vec._get_offsets_and_start_doctags_for_corpusfile('documents.txt', 2)
print(""Offsets for workers: "", offsets)
model = Doc2Vec(sample=0, workers=2, min_count=1, vector_size=5, seed=1)
model.build_vocab(corpus_file='documents.txt')
old_vectors = copy.copy(model.docvecs.vectors_docs)
model.train(corpus_file='documents.txt', total_examples=model.corpus_count, 
            total_words=model.corpus_total_words, epochs=10)
new_vectors = copy.copy(model.docvecs.vectors_docs)
for i in range(len(old_vectors)):
    if all(old_vectors[i] == new_vectors[i]):
        print(""vector {} did not change"".format(i))
    else:
        print(""vector {} changed"".format(i))
```
output
```
Offsets for workers:  [0, 0]
vector 0 changed
vector 1 did not change
vector 2 did not change
vector 3 did not change
```
"
648,https://github.com/RaRe-Technologies/gensim/issues/2758,2758,[],open,2020-02-22 13:54:00+00:00,,How to use LdaModel with Callback,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I wonder if I can implement early stopping while training LdaModel using Callbacks and throwing exception.
 But when I try to use Callback class gensim throws an error about `logger` attribute. If I add `logger` it then requires `get_value` method, i.e. it treats Callback like it's a Metric class. So how do you use it correctly?

#### Steps/code/corpus to reproduce
```
from gensim import corpora, models
from gensim.models.callbacks import Callback    


texts = [['Lorem ipsum dolor sit amet, consectetur adipiscing elit'],['sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ']]
bigram = models.Phrases(texts, min_count=5, threshold=100)
trigram = models.Phrases(bigram[texts], threshold=100)
bigram_mod = models.phrases.Phraser(bigram)
trigram_mod = models.phrases.Phraser(trigram)
dictionary = corpora.Dictionary(trigram_mod[bigram_mod[texts]])

corpus = [dictionary.doc2bow(text) for text in texts]
callback = Callback(metrics=['DiffMetric'])
lda_model = models.LdaModel(
    corpus, num_topics=3, id2word=dictionary,  callbacks=[callback] )
```

> ---------------------------------------------------------------------------
> AttributeError                            Traceback (most recent call last)
> <ipython-input-2-67d9133f842a> in <module>
>      13 
>      14 lda_model = models.LdaModel(
> ---> 15     corpus, num_topics=3, id2word=dictionary,  callbacks=[callback] )
> 
> ~\Anaconda3\lib\site-packages\gensim\models\ldamodel.py in __init__(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)
>     517         if corpus is not None:
>     518             use_numpy = self.dispatcher is not None
> --> 519             self.update(corpus, chunks_as_numpy=use_numpy)
>     520 
>     521     def init_dir_prior(self, prior, name):
> 
> ~\Anaconda3\lib\site-packages\gensim\models\ldamodel.py in update(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)
>     945             # pass the list of input callbacks to Callback class
>     946             callback = Callback(self.callbacks)
> --> 947             callback.set_model(self)
>     948             # initialize metrics list to store metric values after every epoch
>     949             self.metrics = defaultdict(list)
> 
> ~\Anaconda3\lib\site-packages\gensim\models\callbacks.py in set_model(self, model)
>     482             # store diff diagonals of previous epochs
>     483             self.diff_mat = Queue()
> --> 484         if any(metric.logger == ""visdom"" for metric in self.metrics):
>     485             if not VISDOM_INSTALLED:
>     486                 raise ImportError(""Please install Visdom for visualization"")
> 
> ~\Anaconda3\lib\site-packages\gensim\models\callbacks.py in <genexpr>(.0)
>     482             # store diff diagonals of previous epochs
>     483             self.diff_mat = Queue()
> --> 484         if any(metric.logger == ""visdom"" for metric in self.metrics):
>     485             if not VISDOM_INSTALLED:
>     486                 raise ImportError(""Please install Visdom for visualization"")
> 
> AttributeError: 'Callback' object has no attribute 'logger'
> 

#### Versions

Windows-10-10.0.18362-SP0
Python 3.5.6 |Anaconda custom (64-bit)| (default, Aug 26 2018, 16:05:27) [MSC v.1900 64 bit (AMD64)]
NumPy 1.15.2
SciPy 1.1.0
gensim 3.8.1
FAST_VERSION 1"
649,https://github.com/RaRe-Technologies/gensim/issues/2759,2759,[],closed,2020-02-23 13:46:37+00:00,,DeprecationWarning: Calling np.sum(generator) is deprecated - LDA. (2020-Feb),"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I am trying to extrac topics from from a dataset using LDA.

#### Steps/code/corpus to reproduce

```
LDA = gensim.models.ldamodel.LdaModel

# Build LDA model
#lda_model = LDA(corpus=doc_term_matrix, id2word=dictionary, num_topics=10, random_state=100,chunksize=1000, passes=50)

lda_model =  LDA(corpus=doc_term_matrix, id2word=dictionary, num_topics=10, chunksize=1000, passes=50)
```
#### Versions

version output :

```python
Linux-4.14.137+-x86_64-with-Ubuntu-18.04-bionic
Python 3.6.9 (default, Nov  7 2019, 10:44:02) 
[GCC 8.3.0]
NumPy 1.17.5
SciPy 1.4.1
gensim 3.6.0
FAST_VERSION 1
```

#### Error Message

`DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead. score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc`
"
650,https://github.com/RaRe-Technologies/gensim/issues/2760,2760,[],closed,2020-02-24 09:29:42+00:00,,Proper tokenizers for pretrained word embeddings models?,"#### Problem description

I wan't to tokenize the text the same way it was tokenized when the model was trained. For example, google-news word2vec has separate vectors for common phrases, like San Francisco. It is also not clear which tokenizer to use for other models, like, how to handle apostrophes in words like ""shouldn't"".

Is there any general way to do so?"
651,https://github.com/RaRe-Technologies/gensim/issues/2762,2762,[],closed,2020-03-02 18:45:30+00:00,,Mallet Gensim error. (Non-zero exit status 1),"I'm having trouble creating my environment path and getting my LDAMallet model to run. The code I am using is copied below.

This same code executes with no problems on my coworker's PC. Not sure why that would be. I've seen this issue in other posts and have tried every possible combination of slashes (/ vs \ vs \ \ vs // ) and have redownloaded the mallet zip file to various locations on my PC. Nothing has worked. When I run the command string in the code in the command prompt it seems to execute just fine. 

Any insight would be greatly appreciated. 

### Code ###
`import os
os.environ.update({'MALLET_HOME':r'C:\\new_mallet\\mallet-2.0.8/'})
mallet_path = 'C:\\new_mallet\\mallet-2.0.8\\bin\\mallet' 
ldamallet = gensim.models.wrappers.LdaMallet(mallet_path,corpus=corpus,num_topics=10,id2word=id2word)`


### Error ###
````
---------------------------------------------------------------------------
CalledProcessError                        Traceback (most recent call last)
<ipython-input-85-e62e55379006> in <module>
----> 1 ldamallet = gensim.models.wrappers.LdaMallet(mallet_path,corpus=corpus,num_topics=10,id2word=id2word)

C:\ProgramData\Anaconda3\lib\site-packages\gensim\models\wrappers\ldamallet.py in __init__(self, mallet_path, corpus, num_topics, alpha, id2word, workers, prefix, optimize_interval, iterations, topic_threshold, random_seed)
    129         self.random_seed = random_seed
    130         if corpus is not None:
--> 131             self.train(corpus)
    132 
    133     def finferencer(self):

C:\ProgramData\Anaconda3\lib\site-packages\gensim\models\wrappers\ldamallet.py in train(self, corpus)
    270 
    271         """"""
--> 272         self.convert_input(corpus, infer=False)
    273         cmd = self.mallet_path + ' train-topics --input %s --num-topics %s  --alpha %s --optimize-interval %s '\
    274             '--num-threads %s --output-state %s --output-doc-topics %s --output-topic-keys %s '\

C:\ProgramData\Anaconda3\lib\site-packages\gensim\models\wrappers\ldamallet.py in convert_input(self, corpus, infer, serialize_corpus)
    259             cmd = cmd % (self.fcorpustxt(), self.fcorpusmallet())
    260         logger.info(""converting temporary corpus to MALLET format with %s"", cmd)
--> 261         check_output(args=cmd, shell=True)
    262 
    263     def train(self, corpus):

C:\ProgramData\Anaconda3\lib\site-packages\gensim\utils.py in check_output(stdout, *popenargs, **kwargs)
   1916             error = subprocess.CalledProcessError(retcode, cmd)
   1917             error.output = output
-> 1918             raise error
   1919         return output
   1920     except KeyboardInterrupt:

CalledProcessError: Command 'C:\new_mallet\mallet-2.0.8\bin\mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex ""\S+"" --input C:\Users\CST~1.JEO\AppData\Local\Temp\c24558_corpus.txt --output C:\Users\CST~1.JEO\AppData\Local\Temp\c24558_corpus.mallet' returned non-zero exit status 1.
````
"
652,https://github.com/RaRe-Technologies/gensim/issues/2763,2763,[],closed,2020-03-03 18:33:54+00:00,,FastText OOV word embedding are calculated incorrectly when passing `use_norm=True` ,"#### Problem description

FastText OOV word embedding are calculated incorrectly when passing `use_norm=True` (particularly, when looking for most similar words).  The library first normalizes n-gram vectors, then averages them. But it should average them first; otherwise, results are inconsistent.

What happens: cosine similarities used for neighbor retrieval are different from similarities calculated directly from word vectors. 

Why it happens:
* usually when calculating vectors for OOV words fasttext calculates average of n-gram vectors
* but if we pass `use_norm=True`, then fasttext calculates average of *L2-normalized* n-gram vectors ([code](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/keyedvectors.py#L2090)). And it is wrong!
* when we lookup for most similar words, we use just this option, `use_norm=True` ([code](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/keyedvectors.py#L831)), how unfortunate!
* why averaging normalized vectors is wrong: because it was never done when model was trained, and is normally never done when the model is applied, so such vectors are most probably meaningless.
* how to do it right: *first* average n-gram vectors, and *then* normalize them. 

#### Call to action: 
Rewrite `word_vec` method for FastTextKeyedVectors to apply normalization and averaging in the rigth order. 

#### Steps/code/corpus to reproduce
```
word = 'some_oov_word'
pairs = model.most_similar(word)
top_neighbor, top_simil = pairs[0]
print(top_simil)
print(model.cosine_similarities(model[word], model[top_neighbor].reshape(1, -1))[0])
```
these two prints are expected to produce identical numbers (similarity between the oov words and its closest neighbor), but in fact the numbers are different.

This [notebook](https://gist.github.com/avidale/c6b1d13b32a36f19750cd01148560561) reproduces the problem with a particular model for Russian language, but it is relevant for any language. 

#### Versions

The output of 
```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
is
```
Linux-4.14.137+-x86_64-with-Ubuntu-18.04-bionic
Python 3.6.9 (default, Nov  7 2019, 10:44:02) 
[GCC 8.3.0]
NumPy 1.17.5
SciPy 1.4.1
gensim 3.8.1
FAST_VERSION 1
```

"
653,https://github.com/RaRe-Technologies/gensim/issues/2766,2766,[],closed,2020-03-06 17:13:12+00:00,,Do gensim have this function,"Suppose input a sequence of char as 'text',  can we use gensim to calculate the probability that the input text as a real/resonable sentence base on the corpus we trained"
654,https://github.com/RaRe-Technologies/gensim/issues/2767,2767,[],open,2020-03-07 04:42:31+00:00,,Soft Cosine Measure tutorial notebook example has inconsistent wording,"#### Problem description

I was reading Soft Cosine Measure tutorial notebook (https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/soft_cosine_tutorial.ipynb), and it seems the wording on the example is inconsistent. It says (bolded by myself)

> SCM is illustrated below for two very similar sentences. The sentences have **no words in common**, but by modeling ...

However, the two sentences are ""Hi, world!"" and ""Hello, world!"" which obviously share the word ""world"".

Please let me know if I'm mistaken. Thank you!


"
655,https://github.com/RaRe-Technologies/gensim/issues/2768,2768,[],closed,2020-03-13 12:16:17+00:00,,AttributeError: 'MmCorpus' object has no attribute 'get_texts',"
#### When loading wiki corpus cannot use get_texts method.
I have serialized a wiki corpus after processed with the following method:

`MmCorpus.serialize('deWikiProcessed.gensim', wiki)
`
However when I load it and try to use get_texts attribute I get an error. 

```python
wiki = MmCorpus('deWikiProcessed.gensim')
wiki.metadata = True
for content, (page_id, title) in wiki.get_texts():
         pass
```

I need to load the wiki in order to train a new doc2vec model. I use the .get_text() method to get the articles again.
Is there any way I can retrieve the method get_texts, or I just need to reprocess the wiki corpus again and not use MmCorpus format? I was hoping there was a way to convert MmCorpus to WikiCorpus object in order to get the .get_texts() method

#### Versions

```python
Linux-5.0.7-kd-cluster-x86_64-with-debian-9.12
Python 3.7.0 (default, Oct  9 2018, 10:31:47) 
[GCC 7.3.0]
NumPy 1.17.3
SciPy 1.4.1
gensim 3.8.0
FAST_VERSION 0
```
"
656,https://github.com/RaRe-Technologies/gensim/issues/2769,2769,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",open,2020-03-14 16:24:10+00:00,,ldamodel does not accept csc matrix,"Docs say a scipy sparse csc matrix can be used but it can't. It works with sparse3corpus. Here is example:

```python
import gensim
from sklearn.feature_extraction.text import CountVectorizer
from gensim.matutils import Sparse2Corpus
from random_word import RandomWords
#r = RandomWords()
# texts = []
# for x in range(10):
#     texts.append("" "".join(r.get_random_words(limit=""200"")))
vec = CountVectorizer()
docterm = vec.fit_transform(texts)
termdoc = docterm.T.tocsc()
#termdoc = Sparse2Corpus(termdoc)
id2word = {v:k for k,v in vec.vocabulary_.items()}
ldamodel = gensim.models.ldamodel.LdaModel(termdoc, 2, id2word=id2word, passes=10)
```

There are two different error messages depending on length of texts I think. Here are both:

ypeError                                 Traceback (most recent call last)
<ipython-input-184-c30fffea0a1c> in <module>
     12 #termdoc = Sparse2Corpus(termdoc)
     13 id2word = {v:k for k,v in vec.vocabulary_.items()}
---> 14 ldamodel = gensim.models.ldamodel.LdaModel(termdoc, 2, id2word=id2word, passes=10)

~\Anaconda3\lib\site-packages\gensim\models\ldamodel.py in __init__(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)
    517         if corpus is not None:
    518             use_numpy = self.dispatcher is not None
--> 519             self.update(corpus, chunks_as_numpy=use_numpy)
    520 
    521     def init_dir_prior(self, prior, name):

~\Anaconda3\lib\site-packages\gensim\models\ldamodel.py in update(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)
    978                         pass_, chunk_no * chunksize + len(chunk), lencorpus
    979                     )
--> 980                     gammat = self.do_estep(chunk, other)
    981 
    982                     if self.optimize_alpha:

~\Anaconda3\lib\site-packages\gensim\models\ldamodel.py in do_estep(self, chunk, state)
    740         if state is None:
    741             state = self.state
--> 742         gamma, sstats = self.inference(chunk, collect_sstats=True)
    743         state.sstats += sstats
    744         state.numdocs += gamma.shape[0]  # avoids calling len(chunk) on a generator

~\Anaconda3\lib\site-packages\gensim\models\ldamodel.py in inference(self, chunk, collect_sstats)
    669         epsilon = np.finfo(self.dtype).eps
    670         for d, doc in enumerate(chunk):
--> 671             if len(doc) > 0 and not isinstance(doc[0][0], integer_types):
    672                 # make sure the term IDs are ints, otherwise np will get upset
    673                 ids = [int(idx) for idx, _ in doc]

~\Anaconda3\lib\site-packages\scipy\sparse\base.py in __len__(self)
    293     # non-zeros is more important.  For now, raise an exception!
    294     def __len__(self):
--> 295         raise TypeError(""sparse matrix length is ambiguous; use getnnz()""
    296                         "" or shape[0]"")
    297 

TypeError: sparse matrix length is ambiguous; use getnnz() or shape[0]
###############################################################
ValueError                                Traceback (most recent call last)
<ipython-input-185-f34a495bb264> in <module>
     12 #termdoc = Sparse2Corpus(termdoc)
     13 id2word = {v:k for k,v in vec.vocabulary_.items()}
---> 14 ldamodel = gensim.models.ldamodel.LdaModel(termdoc[:3], 2, id2word=id2word, passes=10)

~\Anaconda3\lib\site-packages\gensim\models\ldamodel.py in __init__(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)
    517         if corpus is not None:
    518             use_numpy = self.dispatcher is not None
--> 519             self.update(corpus, chunks_as_numpy=use_numpy)
    520 
    521     def init_dir_prior(self, prior, name):

~\Anaconda3\lib\site-packages\gensim\models\ldamodel.py in update(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)
    963 
    964                 if eval_every and ((reallen == lencorpus) or ((chunk_no + 1) % (eval_every * self.numworkers) == 0)):
--> 965                     self.log_perplexity(chunk, total_docs=lencorpus)
    966 
    967                 if self.dispatcher:

~\Anaconda3\lib\site-packages\gensim\models\ldamodel.py in log_perplexity(self, chunk, total_docs)
    817         if total_docs is None:
    818             total_docs = len(chunk)
--> 819         corpus_words = sum(cnt for document in chunk for _, cnt in document)
    820         subsample_ratio = 1.0 * total_docs / len(chunk)
    821         perwordbound = self.bound(chunk, subsample_ratio=subsample_ratio) / (subsample_ratio * corpus_words)

~\Anaconda3\lib\site-packages\gensim\models\ldamodel.py in <genexpr>(.0)
    817         if total_docs is None:
    818             total_docs = len(chunk)
--> 819         corpus_words = sum(cnt for document in chunk for _, cnt in document)
    820         subsample_ratio = 1.0 * total_docs / len(chunk)
    821         perwordbound = self.bound(chunk, subsample_ratio=subsample_ratio) / (subsample_ratio * corpus_words)

ValueError: not enough values to unpack (expected 2, got 1)
"
657,https://github.com/RaRe-Technologies/gensim/issues/2771,2771,[],closed,2020-03-21 04:25:54+00:00,,Get rid of tox progress bars in CI,"Stuff like this:

     |███████████████████████████▏    | 36.6 MB 103.0 MB/s eta 0:00:01

[pollutes the logs](https://circleci.com/gh/RaRe-Technologies/gensim/3209) and makes it impossible to extract anything useful from them."
658,https://github.com/RaRe-Technologies/gensim/issues/2775,2775,[],closed,2020-03-29 14:43:18+00:00,,xml.etree.cElementTree was deprecated and removed in Python 3.9 in favor of ElementTree,"#### Problem description

xml.etree.cElementTree was deprecated and removed in Python 3.9 in favor of ElementTree

Ref : https://github.com/python/cpython/pull/19108

#### Versions

Python 3.9

I will raise a PR for this issue."
659,https://github.com/RaRe-Technologies/gensim/issues/2776,2776,[],open,2020-03-29 15:24:51+00:00,,id2word param ambiguity,"#### Problem description

The `id2word` param is used in che constructor of these classes:
1. https://radimrehurek.com/gensim/models/ldamodel.html
2. https://radimrehurek.com/gensim/sklearn_api/ldamodel.html
3. https://radimrehurek.com/gensim/models/hdpmodel.html
4. https://radimrehurek.com/gensim/sklearn_api/hdp.html

1 and 2 refers to the same model. The same for 3 and 4.

`id2word` in 1 is optional but it is not specified in the docstring, while in 2 it is.
In 3 it is not optional, while in 4 it is marked as optional but a default value is never assigned.

It makes sense to uniformly set that parameter as optional in the docstrings and set it as None by default.

#### Versions
```
Linux-5.3.0-7642-generic-x86_64-with-debian-buster-sid
Python 3.7.6 (default, Jan  8 2020, 19:59:22) 
[GCC 7.3.0]
NumPy 1.18.2
SciPy 1.4.1
gensim 3.8.1
FAST_VERSION 1
```
"
660,https://github.com/RaRe-Technologies/gensim/issues/2778,2778,[],closed,2020-03-30 18:36:58+00:00,,Accuracy is 0 when negative sampling is disabled,"#### Problem description

When Word2Vec is trained on the text8 dataset with negative=0 (negative sampling disabled), the accuracy drops to 0 when evaluated on questions-words.txt.

#### Steps/code/corpus to reproduce

Minimal reproducible example:
```
import gensim.downloader
from gensim.models import Word2Vec

def evaluate(model):
    globalStats = model.wv.accuracy(""questions-words.txt"") 
    numberCorrect = len(globalStats[-1]['correct'])
    return numberCorrect

dataset = gensim.downloader.load(""text8"")
model1 = Word2Vec(dataset, size=300, workers=1, negative=5)
model2 = Word2Vec(dataset, size=300, workers=1, negative=0)

print(""Number correct with negative sampling:"", evaluate(model1))
print(""Number correct without negative sampling:"", evaluate(model2))
```

Output:
```
Number correct with negative sampling: 4031
Number correct without negative sampling: 0
```

questions-words.txt was downloaded from [https://github.com/nicholas-leonard/word2vec/blob/master/questions-words.txt](https://github.com/nicholas-leonard/word2vec/blob/master/questions-words.txt)

#### Versions

Linux-3.10.0-862.2.3.el7.x86_64-x86_64-with-centos-7.5.1804-Core
Python 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) 
[GCC 7.3.0]
NumPy 1.16.4
SciPy 1.3.0
gensim 3.8.1
FAST_VERSION 1"
661,https://github.com/RaRe-Technologies/gensim/issues/2779,2779,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}]",closed,2020-03-30 21:33:25+00:00,,AttributeError: module 'smart_open' has no attribute 's3',"python 3.6
trying to import gensim and got:

```python
AttributeError                            Traceback (most recent call last)
<ipython-input-8-492cbaec3fd5> in <module>()
     12 import configparser
     13 
---> 14 from dataset.conversation import Conversation
     15 # from train import train
     16 logging.basicConfig(stream=sys.stdout, format=""%(asctime)s %(levelname)s %(message)s"", level=logging.INFO)

~/SageMaker/conversation-platform/src/dataset/conversation.py in <module>()
      5 import torch
      6 import json
----> 7 from preprocess.builder import PipeBuilder
      8 from utils import VECTORIZED_COL, PATICIPANT_COL, BEGIN_TIME_COL, END_TIME_COL, AGENT_COL, CUSTOMER_COL
      9 

~/SageMaker/conversation-platform/src/preprocess/builder.py in <module>()
----> 1 from preprocess.filtering import IntervalsFilter, ParticipateFilter
      2 import preprocess.transformer as transformer
      3 from sklearn.pipeline import Pipeline
      4 from utils import build_embedding_matrix
      5 

~/SageMaker/conversation-platform/src/preprocess/filtering.py in <module>()
      1 from sklearn.base import BaseEstimator, TransformerMixin
      2 import pandas as pd
----> 3 from utils import UTTERANCE_ITEM
      4 
      5 

~/SageMaker/conversation-platform/src/utils.py in <module>()
      6 from sklearn import metrics
      7 import numpy as np
----> 8 from gensim.models import KeyedVectors
      9 
     10 

~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/gensim/__init__.py in <module>()
      3 """"""
      4 
----> 5 from gensim import parsing, corpora, matutils, interfaces, models, similarities, summarization, utils  # noqa:F401
      6 import logging
      7 

~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/gensim/parsing/__init__.py in <module>()
      2 
      3 from .porter import PorterStemmer  # noqa:F401
----> 4 from .preprocessing import (remove_stopwords, strip_punctuation, strip_punctuation2,  # noqa:F401
      5                             strip_tags, strip_short, strip_numeric,
      6                             strip_non_alphanum, strip_multiple_whitespaces,

~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/gensim/parsing/preprocessing.py in <module>()
     40 import glob
     41 
---> 42 from gensim import utils
     43 from gensim.parsing.porter import PorterStemmer
     44 

~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/gensim/utils.py in <module>()
     43 from six.moves import range
     44 
---> 45 from smart_open import open
     46 
     47 from multiprocessing import cpu_count

~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/smart_open/__init__.py in <module>()
     25 from smart_open import version
     26 
---> 27 from .smart_open_lib import open, smart_open, register_compressor
     28 from .s3 import iter_bucket as s3_iter_bucket
     29 __all__ = ['open', 'smart_open', 's3_iter_bucket', 'register_compressor']

~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/smart_open/smart_open_lib.py in <module>()
     36 # smart_open.submodule to reference to the submodules.
     37 #
---> 38 import smart_open.s3 as smart_open_s3
     39 import smart_open.hdfs as smart_open_hdfs
     40 import smart_open.webhdfs as smart_open_webhdfs

AttributeError: module 'smart_open' has no attribute 's3'
```
"
662,https://github.com/RaRe-Technologies/gensim/issues/2780,2780,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 1602257032, 'node_id': 'MDU6TGFiZWwxNjAyMjU3MDMy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20HIGH', 'name': 'impact HIGH', 'color': 'b60205', 'default': False, 'description': 'Show-stopper for affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",open,2020-04-02 17:38:32+00:00,,OverflowError: Python int too large to convert to C long,"#### Problem description

`fakeDataset = downloader.load('fake-news')` 

fails with the above error on Windows machines running Python 3.7 64 bit with gensim 3.8.1

#### Steps/code/corpus to reproduce

`fakeDataset = downloader.load('fake-news')`

on machine with above configuration.

#### Versions

Windows-10-10.0.18362
Python 3.7.6
NumPy 1.18.1
SciPy 1.4.1
gensim 3.8.1
FAST_VERSION 0

#### Attempted workaround

I zipped the data directory from a Linux machine and gave it to a student to unzip on their Windows machine. Re-executing the code above failed with the same error, suggesting the problem is not in downloading but in loading the downloaded data. Perhaps there is a bug in unzipping the archive with Python?"
663,https://github.com/RaRe-Technologies/gensim/issues/2781,2781,[],closed,2020-04-03 11:58:54+00:00,,failed to load projection (LSA model),"Hi,
I have a problem with gensim (0.13.3) on python 2.7: when I want to load a LSA model, I receive an error message saying that we cannot find a file named projection. The message is as follows: WARNING:root:failed to load projection from .../LSA/lsaModel.npy.projection: [Errno 2] No such file or directory: '.../LSA/lsaModel.npy.projection' Anyone have a solution?
For informations:
-python 2.7
- gensim 0.13.3
- scipy (0.18.1)
- scikit-learn (0.17.1)
- numpy (1.16.6)
"
664,https://github.com/RaRe-Technologies/gensim/issues/2782,2782,"[{'id': 708430967, 'node_id': 'MDU6TGFiZWw3MDg0MzA5Njc=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/performance', 'name': 'performance', 'color': 'd93f0b', 'default': False, 'description': 'Issue related to performance (in HW meaning)'}, {'id': 1583467927, 'node_id': 'MDU6TGFiZWwxNTgzNDY3OTI3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/help%20wanted', 'name': 'help wanted', 'color': '1d76db', 'default': True, 'description': ''}, {'id': 1602278675, 'node_id': 'MDU6TGFiZWwxNjAyMjc4Njc1', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20HIGH', 'name': 'reach HIGH', 'color': '229e03', 'default': False, 'description': 'Affects most or all Gensim users'}, {'id': 1602334472, 'node_id': 'MDU6TGFiZWwxNjAyMzM0NDcy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20MEDIUM', 'name': 'impact MEDIUM', 'color': '7af49f', 'default': False, 'description': 'Big annoyance for affected users'}]",open,2020-04-03 17:16:49+00:00,,random.RandomState with different versions of numpy has vastly different performance,"the performance of random.RandomState in word2vec.py (version 3.8.0)

```
def seeded_vector(self, seed_string, vector_size):
         once = random.RandomState(self.hashfxn(seed_string) & 0xffffffff)
         return (once.rand(vector_size) - 0.5) / vector_size
```

seemingly depends greatly on the version of numpy installed. With numpy = 1.14.3, the following code 

```
from  numpy.random import RandomState as Ran
from time import time
t1 = time()
for i in range(100000):
    temp = Ran(hash((i)) & 0xffffffff)
t2 = time()
t2-t1 
```


produced 
`0.28105926513671875`
exactly the same code with numpy= 1.18.1 produced 

`18.590345859527588`

I noticed this because I was training a model with millions of words as vocabulary, and after updating numpy unwittingly (via a anaconda update), I noticed that the time for build_vocab was significantly longer, and after some debugging, I nailed it down to random.RandomState in the `seeded_vector` function. 
I know this is indeed a numpy issue, but even they mentioned it that RandomState is legacy (https://docs.scipy.org/doc/numpy/reference/random/performance.html). Therefore I wonder if you have some plans to upgrade randomstate? Thanks! "
665,https://github.com/RaRe-Technologies/gensim/issues/2784,2784,[],closed,2020-04-05 15:30:55+00:00,,gensim/utils.py is referencing the old boto package,"#2250 ## Problem description

I'm installing gensim on a new computer. I noticed the installation log to have imported boto3 and boto

```
Collecting boto3
  Downloading boto3-1.12.36-py2.py3-none-any.whl (128 kB)
Collecting boto>=2.32
  Using cached boto-2.49.0-py2.py3-none-any.whl (1.4 MB)
```
but on the first run I got the ModuleNotFoundError error

#### Steps/code/corpus to reproduce

```
import sys
!{sys.executable} -m pip install gensim

from gensim import corpora
```

#### Versions

Please provide the output of:

Darwin-19.4.0-x86_64-i386-64bit
Python 3.7.7 (default, Mar 10 2020, 15:43:33) 
[Clang 11.0.0 (clang-1100.0.33.17)]
NumPy 1.18.1
SciPy 1.4.1
gensim 3.8.1
FAST_VERSION 0
"
666,https://github.com/RaRe-Technologies/gensim/issues/2785,2785,[],closed,2020-04-05 16:12:20+00:00,,metrics.precision_score and the not supported zero_division ,"#### Problem description

If I try to use the zero_division argument to ignore the errors I get the `unexpected keyword argument 'zero_division' ` error message

#### Steps/code/corpus to reproduce

metrics.precision_score(y, y_pred, average=""weighted"", zero_division='warn')
```

print(len(y))
>>> 608

print(len(y_pred))
>>> 608
```

#### Versions

Please provide the output of:
Darwin-19.4.0-x86_64-i386-64bit
Python 3.7.7 (default, Mar 10 2020, 15:43:33) 
[Clang 11.0.0 (clang-1100.0.33.17)]
NumPy 1.18.1
SciPy 1.4.1
gensim 3.8.1
FAST_VERSION 0
"
667,https://github.com/RaRe-Technologies/gensim/issues/2786,2786,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 1602257032, 'node_id': 'MDU6TGFiZWwxNjAyMjU3MDMy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20HIGH', 'name': 'impact HIGH', 'color': 'b60205', 'default': False, 'description': 'Show-stopper for affected users'}, {'id': 1602278675, 'node_id': 'MDU6TGFiZWwxNjAyMjc4Njc1', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20HIGH', 'name': 'reach HIGH', 'color': '229e03', 'default': False, 'description': 'Affects most or all Gensim users'}]",closed,2020-04-09 09:42:49+00:00,,Recent versions of smart-open (1.11.0 and 1.11.1)  break gensim in Python 2.7,"### Problem description

What are you trying to achieve? What is the expected result? What are you seeing instead?

Using gensim with Python2.7

#### Steps/code/corpus to reproduce
```
pip install gensim
...
python
>>> import gensim
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/brukau/tmp/gensim/local/lib/python2.7/site-packages/gensim/__init__.py"", line 5, in <module>
    from gensim import parsing, corpora, matutils, interfaces, models, similarities, summarization, utils  # noqa:F401
  File ""/home/brukau/tmp/gensim/local/lib/python2.7/site-packages/gensim/parsing/__init__.py"", line 4, in <module>
    from .preprocessing import (remove_stopwords, strip_punctuation, strip_punctuation2,  # noqa:F401
  File ""/home/brukau/tmp/gensim/local/lib/python2.7/site-packages/gensim/parsing/preprocessing.py"", line 42, in <module>
    from gensim import utils
  File ""/home/brukau/tmp/gensim/local/lib/python2.7/site-packages/gensim/utils.py"", line 45, in <module>
    from smart_open import open
  File ""/home/brukau/tmp/gensim/local/lib/python2.7/site-packages/smart_open/__init__.py"", line 28, in <module>
    from .smart_open_lib import open, parse_uri, smart_open, register_compressor
  File ""/home/brukau/tmp/gensim/local/lib/python2.7/site-packages/smart_open/smart_open_lib.py"", line 23, in <module>
    import pathlib
ImportError: No module named pathlib
>>> 
```

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```

Linux-5.3.0-45-generic-x86_64-with-Ubuntu-19.10-eoan
('Python', '2.7.17 (default, Nov  7 2019, 10:07:09) \n[GCC 9.2.1 20191008]')
('NumPy', '1.16.1')
('SciPy', '1.2.3')
gensim import fails

"
668,https://github.com/RaRe-Technologies/gensim/issues/2788,2788,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 175986, 'node_id': 'MDU6TGFiZWwxNzU5ODY=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/testing', 'name': 'testing', 'color': '444444', 'default': False, 'description': 'Issue related with testing (code, documentation, etc)'}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",closed,2020-04-09 17:32:23+00:00,,Do test instructions still work?,"In our [README](https://github.com/RaRe-Technologies/gensim#installation), we tell users to run `python setup.py test`.

One user [reported on our mailing list](https://groups.google.com/forum/#!topic/gensim/JfeV2phNTjk) that this doesn't actually work.

We should fix the docs or the tests – whichever is at fault here."
669,https://github.com/RaRe-Technologies/gensim/issues/2790,2790,[],closed,2020-04-12 08:57:49+00:00,,FastText RAM usage,"#### Problem description

The `FastText` model takes too much RAM. We saw this issue many times in our CI systems, this typically looks like

```
____________________ TestFastTextModel.test_cbow_hs_online _____________________
self = <gensim.test.test_fasttext.TestFastTextModel testMethod=test_cbow_hs_online>
    @unittest.skipIf(IS_WIN32, ""avoid memory error with Appveyor x32"")
    def test_cbow_hs_online(self):
        model = FT_gensim(
>           sg=0, cbow_mean=1, alpha=0.05, window=2, hs=1, negative=0, min_count=3, iter=1, seed=42, workers=1
        )
self       = <gensim.test.test_fasttext.TestFastTextModel testMethod=test_cbow_hs_online>
/venv/lib/python3.7/site-packages/gensim/test/test_fasttext.py:733: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/venv/lib/python3.7/site-packages/gensim/models/fasttext.py:595: in __init__
    self.trainables.prepare_weights(hs, negative, self.wv, update=False, vocabulary=self.vocabulary)
...
/venv/lib/python3.7/site-packages/gensim/models/fasttext.py:1130: in prepare_weights
    self.init_ngrams_weights(wv, update=update, vocabulary=vocabulary)
 ...
mtrand.pyx:1307: in mtrand.RandomState.uniform
    ???
        ...
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
>   ???
E   MemoryError

```
#### Steps/code/corpus to reproduce

```python
from gensim.models import FastText

m = FastText()  # and measure RAM after that
```
It will ""eat"" around 1.6GB after `__init__`. I guess than issue in ""bucket"" matrix (too large). 
Itself, this isn't a problem, but this is an issue in our tests (because we almost never pin this parameter).

#### Versions

Please provide the output of:

```python
>>> import platform; print(platform.platform())
Linux-5.3.0-46-generic-x86_64-with-Ubuntu-19.10-eoan
>>> import sys; print(""Python"", sys.version)
('Python', '2.7.17 (default, Nov  7 2019, 10:07:09) \n[GCC 9.2.1 20191008]')
>>> import numpy; print(""NumPy"", numpy.__version__)
('NumPy', '1.16.1')
>>> import scipy; print(""SciPy"", scipy.__version__)
('SciPy', '1.2.3')
>>> import gensim; print(""gensim"", gensim.__version__)
('gensim', '3.8.1')
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
('FAST_VERSION', 1)
```
I'm sure than other `py` versions and more early gensim versions affected in the same way
"
670,https://github.com/RaRe-Technologies/gensim/issues/2792,2792,[],open,2020-04-12 21:51:43+00:00,,HdpModel not using all CPU cores,"#### Problem description

I am running HdpModel on a machine with 2 CPUs with 16 cores each.
Instead of running it on 32 cores, htop reports an usage of only 16+1 cores.

Moreover, I don't have any parameter to tweak in order to increase or decrease the number of workers in that particular model in order to test it.

#### Versions

```
Linux-5.3.0-7642-generic-x86_64-with-debian-buster-sid
Python 3.7.6 (default, Jan  8 2020, 19:59:22) 
[GCC 7.3.0]
NumPy 1.18.2
SciPy 1.4.1
gensim 3.8.1
FAST_VERSION 1

```
"
671,https://github.com/RaRe-Technologies/gensim/issues/2793,2793,[],open,2020-04-13 00:49:39+00:00,,Sphinx 3.0 and above appears to break doc build,"No idea, just don't build with latest sphinx (raise wired errors, I don't want to dig into)

_Originally posted by @menshikh-iv in https://github.com/RaRe-Technologies/gensim/pull/2791/files_"
672,https://github.com/RaRe-Technologies/gensim/issues/2794,2794,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 708430967, 'node_id': 'MDU6TGFiZWw3MDg0MzA5Njc=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/performance', 'name': 'performance', 'color': 'd93f0b', 'default': False, 'description': 'Issue related to performance (in HW meaning)'}, {'id': 1602257032, 'node_id': 'MDU6TGFiZWwxNjAyMjU3MDMy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20HIGH', 'name': 'impact HIGH', 'color': 'b60205', 'default': False, 'description': 'Show-stopper for affected users'}, {'id': 1602278675, 'node_id': 'MDU6TGFiZWwxNjAyMjc4Njc1', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20HIGH', 'name': 'reach HIGH', 'color': '229e03', 'default': False, 'description': 'Affects most or all Gensim users'}]",closed,2020-04-14 15:20:35+00:00,,FAST_VERSION is -1 when using latest gensim (3.8.1) ,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

`assert gensim.models.doc2vec.FAST_VERSION > -1` fails with gensim 3.8.1, even though it works with 3.7.0.

#### Steps/code/corpus to reproduce
When I install the latest version of gensim using `pip install --upgrade gensim`, I observe the following:
```>>> import multiprocessing
>>> import gensim.models.doc2vec
>>> assert gensim.models.doc2vec.FAST_VERSION > -1, ""This will be painfully slow otherwise""
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
AssertionError: This will be painfully slow otherwise
```  
When I roll back to version 3.7, the assertion passes:
```
>>> import multiprocessing
>>> import gensim.models.doc2vec
>>> assert gensim.models.doc2vec.FAST_VERSION > -1, ""This will be painfully slow otherwise""
>>> 
```


#### Versions
```
>>> import platform; print(platform.platform())
Darwin-18.7.0-x86_64-i386-64bit
>>> import sys; print(""Python"", sys.version)
Python 3.7.6 (default, Dec 30 2019, 19:38:28) 
[Clang 11.0.0 (clang-1100.0.33.16)]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.18.1
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.4.1
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.8.1
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION -1
```
"
673,https://github.com/RaRe-Technologies/gensim/issues/2795,2795,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}]",open,2020-04-15 05:43:25+00:00,,Incorrect behavior of KeyedVectors.save_word2vec_format,"### Problem description

I'm getting the ""impossible"" situation when I can't `load_word2vec_format` after succesfull  `save_word2vec_format`.

The reason was in ""token with space"".

#### Steps/code/corpus to reproduce

```python
from gensim.models import KeyedVectors                                  


kv = KeyedVectors(1)
kv.add([""hello"", ""my name"", ""is Ivan""], [[1.], [2.], [3.]])  # ""my name"" are ""bad token""

kv.save_word2vec_format(""kek.vec.gz"")  # no errors here
KeyedVectors.load_word2vec_format(""kek.vec.gz"")  # raised an exeption
```
```python
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-5-e851184c3643> in <module>
----> 1 KeyedVectors.load_word2vec_format(""kek.vec.gz"")

~/.virtualenvs/pre-makedonsky/lib/python3.7/site-packages/gensim/models/keyedvectors.py in load_word2vec_format(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)
   1496         return _load_word2vec_format(
   1497             cls, fname, fvocab=fvocab, binary=binary, encoding=encoding, unicode_errors=unicode_errors,
-> 1498             limit=limit, datatype=datatype)
   1499 
   1500     def get_keras_embedding(self, train_embeddings=False):

~/.virtualenvs/pre-makedonsky/lib/python3.7/site-packages/gensim/models/utils_any2vec.py in _load_word2vec_format(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)
    392                 parts = utils.to_unicode(line.rstrip(), encoding=encoding, errors=unicode_errors).split("" "")
    393                 if len(parts) != vector_size + 1:
--> 394                     raise ValueError(""invalid vector on line %s (is this really the text format?)"" % line_no)
    395                 word, weights = parts[0], [datatype(x) for x in parts[1:]]
    396                 add_word(word, weights)

ValueError: invalid vector on line 1 (is this really the text format?)
```
#### Possible solutions

Detect this situation on `save_word2vec_format` stage and:
- Raise warning for each ""word with space"" and skip these lines
- Raise `ValueError` (with ""bad token"" in message)
- (preferred) Starts from checking ""token sanity"" for
  - `save_word2vec_format`
  - `add`
  and fallback to previous variants "
674,https://github.com/RaRe-Technologies/gensim/issues/2796,2796,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}]",closed,2020-04-15 10:05:36+00:00,,Inconsistency between pip version (3.8.2) and installed version (3.8.1),"#### Problem description
The gensim package version is 3.8.2 on [pip](https://pypi.org/project/gensim/), but after installing it and checking the version on python console I see 3.8.1:
```python
import gensim
gensim.__version__
# '3.8.1'
```

#### Versions
```bash
Linux-5.3.0-46-generic-x86_64-with-glibc2.10
Python 3.8.2 (default, Mar 26 2020, 15:53:00) 
[GCC 7.3.0]
NumPy 1.18.1
SciPy 1.4.1
gensim 3.8.1
FAST_VERSION 1
```
"
675,https://github.com/RaRe-Technologies/gensim/issues/2798,2798,[],open,2020-04-16 01:39:40+00:00,,fix duplicate version handling,"We specify the verison manually in multiple places:

- `gensim/__init__.py`
- `setup.py`
- `docs/src/conf.py`

Makes us prone to problems like #2796

It would be helpful to consolidate them into a single location."
676,https://github.com/RaRe-Technologies/gensim/issues/2801,2801,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",open,2020-04-21 16:58:19+00:00,,Warning when batch_words > MAX_WORDS_IN_BATCH in word2vec,"The doc says

         batch_words : int, optional
            Target size (in words) for batches of examples passed to worker threads (and
            thus cython routines).(Larger batches will be passed if individual
            texts are longer than 10000 words, but the standard cython code truncates to that maximum.)

I think a larger value should not be accepted."
677,https://github.com/RaRe-Technologies/gensim/issues/2802,2802,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175986, 'node_id': 'MDU6TGFiZWwxNzU5ODY=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/testing', 'name': 'testing', 'color': '444444', 'default': False, 'description': 'Issue related with testing (code, documentation, etc)'}, {'id': 1602257032, 'node_id': 'MDU6TGFiZWwxNjAyMjU3MDMy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20HIGH', 'name': 'impact HIGH', 'color': 'b60205', 'default': False, 'description': 'Show-stopper for affected users'}, {'id': 1602279836, 'node_id': 'MDU6TGFiZWwxNjAyMjc5ODM2', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20MEDIUM', 'name': 'reach MEDIUM', 'color': 'ef7a1a', 'default': False, 'description': 'Affects a significant number of users'}]",closed,2020-04-21 23:55:21+00:00,,gensim installed with pip on Mac with python 3.7 not finding C extension ,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description
 I am trying to train a w2v model on my local machine (Mac OS 10.14.5), but I am getting message about needing to install C compiler: 

> /Users/hsimpson/envs/py3/lib/python3.7/site-packages/gensim/models/base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.

#### Steps/code/corpus to reproduce

any call to gensim.models.Word2Vec 

I am working in a python3 virtual env (name = `py3`)

I tried the following to fix: 
- `pip install --upgrade gensim`
response is : 
> `Requirement already up-to-date: gensim in /Users/hsimpson/envs/py3/lib/python3.7/site-packages (3.8.2)` 
and get `Requirement already satisfied` messages for all dependencies

- `pip uninstall gensim; pip install gensim`
this installed that same version `3.8.2` 

neither solved the problem . 

I know installing conda might fix as it did for user **guo18306671737**  in  https://github.com/RaRe-Technologies/gensim/issues/2572 but I don't use conda anymore as it has caused issues for me with paths etc.  so would really like pip install to work for me  -- for that user looks like the problem was attributed to being Windows specific but I am on a Mac so thought it's worth letting you know at least --- that user was also on Python 3.7

#### Versions

on CLI & in PyCharm (both with virtual env py3):
```
Darwin-18.6.0-x86_64-i386-64bit
Python 3.7.5 (default, Nov  1 2019, 02:16:32) 
[Clang 11.0.0 (clang-1100.0.33.8)]
NumPy 1.16.5
SciPy 1.3.1
gensim 3.8.1
FAST_VERSION -1
```
in jupyter notebook, with either Python3 or py3 kernel selected: 
```
Darwin-18.6.0-x86_64-i386-64bit
Python 3.7.5 (default, Nov  1 2019, 02:16:32) 
[Clang 11.0.0 (clang-1100.0.33.8)]
NumPy 1.16.4
SciPy 1.4.1
gensim 3.2.0
FAST_VERSION -1
```
so, strangely, the gensim version pip says it installed (`3.8.2`), the version in CLI/PyCharm (`3.8.1`) and version in jupyter notebook kernel (`3.2.0`) all do not match ..  not sure why .. in my notebook I had to prepend the path to `/Users/hsimpson/envs/py3/lib/python3.7/site-packages` (where pip says it's installing gensim 3.8.2) in order to get spacy to be imported, but it still says it's running `gensim 3.2.0`

however since both `3.8.1` and `3.2.0` versions say FAST_VERSION -1 not sure if that matters"
678,https://github.com/RaRe-Technologies/gensim/issues/2803,2803,[],open,2020-04-23 00:31:01+00:00,,Word2Vec Retraining Fails after Adding New Word Vectors from another Model,"#### Problem description

Using the add() function to add new word vectors to a model from a different model and having the first model retrain on its own dataset causes an exception. Given two separate Word2Vec models trained on different data, we are trying to retrain one model after adding word vectors that are present in the other model but not originally present in the first model.

Expected result:
Retraining succeeds.

Actual result:
Retraining fails with:
AttributeError: 'Vocab' object has no attribute 'code'

#### Steps/code/corpus to reproduce

Minimal reproducible example:
```
import gensim.downloader
from gensim.models import Word2Vec

print(""Loading text8 as list. This should succeed."")
dataset = list(gensim.downloader.load(""text8""))

print(""Splitting text8. This should succeed."")
dataset1 = dataset[:int(len(dataset)/2)]
dataset2 = dataset[int(len(dataset)/2):]

print(""Training model1. This should succeed."")
model1 = Word2Vec(dataset1, size=300, workers=1, negative=0, hs=1, sample=0)

print(""Training model2. This should succeed."")
model2 = Word2Vec(dataset2, size=300, workers=1, negative=0, hs=1, sample=0)

print(""Initiating first retraining. This should succeed."")
model1.train(dataset1, total_examples=len(dataset1), epochs=model1.epochs)

# Based on the documentation, this is the idiom for adding the word vectors that are present in model2 but not in model1                     
print(""Adding vocab from model2. This should succeed."")
model1.wv.add(list(model2.wv.vocab.keys()), model2.wv.syn0, replace=False)

print(""Initiating second retraining. This fails."")
model1.train(dataset1, total_examples=len(dataset1), epochs=model1.epochs)
```

Output:
```
Loading text8 as list. This should succeed.
Splitting text8. This should succeed.
Training model1. This should succeed.
Training model2. This should succeed.
Initiating first retraining. This should succeed.
Adding vocab from model2. This should succeed.
Initiating second retraining. This should fail.
Exception in thread Thread-31:
Traceback (most recent call last):
  File ""/lib/python3.6/threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""/lib/python3.6/threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""~/.local/lib/python3.6/site-packages/gensim/models/base_any2vec.py"", line 211, in _worker_loop
    tally, raw_tally = self._do_train_job(data_iterable, job_parameters, thread_private_mem)
  File ""~/.local/lib/python3.6/site-packages/gensim/models/word2vec.py"", line 821, in _do_train_job
    tally += train_batch_cbow(self, sentences, alpha, work, neu1, self.compute_loss)
  File ""gensim/models/word2vec_inner.pyx"", line 638, in gensim.models.word2vec_inner.train_batch_cbow
AttributeError: 'Vocab' object has no attribute 'code'
```


#### Versions

Linux-3.10.0-862.2.3.el7.x86_64-x86_64-with-centos-7.5.1804-Core
Python 3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34)
[GCC 7.3.0]
NumPy 1.16.4
SciPy 1.3.0
gensim 3.8.1
FAST_VERSION 1
"
679,https://github.com/RaRe-Technologies/gensim/issues/2804,2804,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 1602257032, 'node_id': 'MDU6TGFiZWwxNjAyMjU3MDMy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20HIGH', 'name': 'impact HIGH', 'color': 'b60205', 'default': False, 'description': 'Show-stopper for affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",open,2020-04-23 03:53:21+00:00,,ModuleNotFoundError: No module named 'testfixtures',"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

* running the following code in `/docs/notebooks/howtos/run_doc2vec_imdb.ipynb`:
`from gensim.test.test_doc2vec import ConcatenatedDoc2Vec`


![Selection_013](https://user-images.githubusercontent.com/79341/80056798-aabdca80-84ea-11ea-8cf9-c2d60b6ecd0d.png)

* A quick review of `/gensim/test/test_doc2vec.py` shows the offending import on line#21. I've tried replacing the line with `from fixtures import log_capture`, but with no improvement.

#### Steps/code/corpus to reproduce

run `run_doc2vec_imdb.ipynb`

#### Versions

Linux-4.15.0-91-generic-x86_64-with-Ubuntu-18.04-bionic
Python 3.6.9 (default, Jul  3 2019, 15:36:16) 
[GCC 5.4.0 20160609]
NumPy 1.18.3
SciPy 1.4.1
gensim 3.8.1
FAST_VERSION 1

"
680,https://github.com/RaRe-Technologies/gensim/issues/2805,2805,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",closed,2020-04-23 13:50:42+00:00,,README badges fail to render,"I see this often in many Github repos (not just Gensim):

<img width=""1114"" alt=""Screen Shot 2020-04-23 at 15 35 54"" src=""https://user-images.githubusercontent.com/610412/80105011-43e6f280-8578-11ea-8a11-8448e26f429f.png"">

According to https://github.com/badges/shields/issues/1568, this is an issue with Github's non-caching proxy (`https://camo.githubusercontent.com`) timing out when querying the original image (hosted at `https://img.shields.io`).

The proxy timeout limit seems to be 4 seconds. So if `img.shields.io` takes longer than 4 seconds to return the image, Github will show a broken image instead.

Github injects its proxy automatically to all `<img>` links and I found no way to disable it.

A solution suggested [here](https://github.com/badges/shields/issues/1568#issuecomment-407860059) is to use *another* proxy, one that caches the img.shields.io response so that github's proxy doesn't time out. For example Google's caching proxy at `https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy`.

Example of a cached ""shields => google's cache => github's proxy => browser"" badge:
`https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?container=focus&refresh=3600&url=https%3A%2F%2Fimg.shields.io%2Fpypi%2Fdm%2Fgensim%3Fcolor%3Dblue` ![example](https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?container=focus&refresh=3600&url=https%3A%2F%2Fimg.shields.io%2Fpypi%2Fdm%2Fgensim%3Fcolor%3Dblue)"
681,https://github.com/RaRe-Technologies/gensim/issues/2807,2807,[],closed,2020-04-24 07:33:23+00:00,,how to do Incremental training on an existing doc2vec model?,"hi,

I am an newer in deep learning. I tried to train a doc2vec model for about 1000docs, but when I get another new 1000 docs, I don't know how to do the incremental training in which I can get the exact vector of the new docs, not by using ""infer_vector"".

Please help me ,thanks very much!
"
682,https://github.com/RaRe-Technologies/gensim/issues/2811,2811,"[{'id': 1602257032, 'node_id': 'MDU6TGFiZWwxNjAyMjU3MDMy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20HIGH', 'name': 'impact HIGH', 'color': 'b60205', 'default': False, 'description': 'Show-stopper for affected users'}]",closed,2020-04-27 08:15:39+00:00,,Investigate Py2.7 support,"[This PR](https://github.com/RaRe-Technologies/gensim/pull/2630) silently removed Py2.7 support as a side-effect. There is no mention of it in the PR description, commit messages or discussion with the reviewers.

I'm the one who made the change, but it was several months ago, and I myself don't remember what the original intention was.

We need Python 2.7 support for the 3.8.3 release, because a significant number of users (not sure how many) still use that version of Python.

- [x] Get gensim building on Py2.7 again. Try working of the current develop branch, if not, consider alternatives.
- [x] Start a new branch to bring back Py2.7 builds in the gensim-wheels repo (see https://github.com/MacPython/gensim-wheels/pull/24). "
683,https://github.com/RaRe-Technologies/gensim/issues/2813,2813,"[{'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",closed,2020-04-28 05:04:33+00:00,,Use python_requires in setup.py,"https://packaging.python.org/guides/distributing-packages-using-setuptools/#python-requires, please :)

_Originally posted by @menshikh-iv in https://github.com/RaRe-Technologies/gensim/pull/2812_"
684,https://github.com/RaRe-Technologies/gensim/issues/2816,2816,"[{'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",open,2020-05-01 02:08:05+00:00,,Deal with different dependencies between gensim CI and wheel building,"you have 3 ways:

1. Revert this change (`nmslib` & `pyemd`)
2. Stay them and raise an issue in `gensim` repo about ""syncing"" test dependencies with `gensim-wheel`, but you shouldn't count on me about this issue (I’m constantly repairing your wheels, to be honest, I'm sick of it)
3. Fix that yourself, it's your project, it's good to know how parts work.

*Originally posted by @menshikh-iv in https://github.com/RaRe-Technologies/gensim/pull/2814#discussion_r418056757*"
685,https://github.com/RaRe-Technologies/gensim/issues/2817,2817,[],open,2020-05-01 02:11:07+00:00,,Investigate segfault with tensorflow with Py3.6 on Travis CI,"@gojomo yes, the crashes are reliable. I narrowed it down to having tensorflow installed:

* tensorflow installed => Travis py3.6 crashes during `test_doc2vec`
* tensorflow not installed => Travis all tests pass, including 3.6

So my ""fix"" was https://github.com/RaRe-Technologies/gensim/pull/2814/commits/8cd68b2a5ea537f2953bdd592b1a1973b148431d but it's really a crude hack. Still a mystery to me what's happening. There may be a deeper issue lurking there, which affects other Pythons too but doesn't cause a Travis crash.

_Originally posted by @piskvorky in https://github.com/RaRe-Technologies/gensim/pull/2814#issuecomment-622036840_"
686,https://github.com/RaRe-Technologies/gensim/issues/2818,2818,[],open,2020-05-01 02:16:16+00:00,,Investigate numpy dependency versions,"Speaking of dependency versions & looking at these output examples: 

The version constraint `numpy<=1.16.1,>=1.11.3` looks fishy to me - staying on a 15-month-old version (`numpy-1.16.1`) of such an intensely-maintained and often-improved library as `numpy`seems unwise. 

But, I don't see where in our source this is declared. (Maybe it's a side-effect of another dependency?) 

If the aim is to pick the latest `numpy` supporting Python-2.7, that appears to be `numpy-1.16.6` dated 2019-12-29.

_Originally posted by @gojomo in https://github.com/RaRe-Technologies/gensim/issues/2786#issuecomment-612721289_"
687,https://github.com/RaRe-Technologies/gensim/issues/2819,2819,"[{'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",closed,2020-05-01 12:03:18+00:00,,Set up Azure pipelines for gensim,"@piskvorky basic config is ready https://github.com/menshikh-iv/gensim/pull/2, waiting when you activate `azure` for gensim (please make sure than pipeline runs in separate PR, after that I'll continue)

_Originally posted by @menshikh-iv in https://github.com/RaRe-Technologies/gensim/pull/2814#issuecomment-621950805_"
688,https://github.com/RaRe-Technologies/gensim/issues/2820,2820,"[{'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",closed,2020-05-02 23:59:19+00:00,,Prepare gensim 3.8.3,"OK guys, looks like we're getting close to releasing this thing. I've just updated the CHANGELOG - @piskvorky please have a look and make any changes as necessary. Each update will require a re-run of the CI and a rebuild of the wheels, so please keep that in mind.

Some other relevant things to check:

- [Release checklist](https://github.com/RaRe-Technologies/gensim/wiki/Developer-page#making-a-new-release)
- [Release milestone](https://github.com/RaRe-Technologies/gensim/milestone/2?closed=1)
- [Diff with current develop HEAD](https://github.com/RaRe-Technologies/gensim/compare/develop...release-3.8.3?expand=1)

I've gone through the above myself and think like we're ready to release. @piskvorky @menshikh-iv Please let me know if you feel the same and we'll get this thing out the door."
689,https://github.com/RaRe-Technologies/gensim/issues/2822,2822,[],open,2020-05-03 21:12:52+00:00,,HDP model parameters K and T mismatch.,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

In documentation parameters K and T mismatch from original paper. Original paper states:
` We set the top-level truncation K = 150 and the second
level truncation T = 15. Here T<<K, since documents usually don’t have many topics.`

Documentation states: 
- K (int, optional) – Second level truncation
- T (int, optional) – Top level truncation   

#### Steps/code/corpus to reproduce

#### Versions

```python
Darwin-18.7.0-x86_64-i386-64bit
Python 3.7.3 (default, Mar 27 2019, 16:54:48)
NumPy 1.16.1
SciPy 1.3.0
gensim 3.8.0
FAST_VERSION 1
```
"
690,https://github.com/RaRe-Technologies/gensim/issues/2825,2825,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",open,2020-05-04 16:50:16+00:00,,sklearn_api `transform()` methods not compatible with generators,"Example (from [TfidfTransformer](https://github.com/RaRe-Technologies/gensim/blob/b3b844e32cf03c28e58586cbd8b66d288d41758d/gensim/sklearn_api/tfidf.py#L157))

```python
if isinstance(docs[0], tuple):
    docs = [docs]
return [self.gensim_model[doc] for doc in docs]
```

This method expects a list of tuples, instead of an iterable. This means that the entire corpus has to be stored as a list in memory, instead of just the TFIDF matrix produced at the end. This is unfeasible for large datasets.

Why do we need to create a list from `docs`, instead of just doing:
```python
return (self.gensim_model[doc] for doc in docs)
```"
691,https://github.com/RaRe-Technologies/gensim/issues/2826,2826,[],closed,2020-05-05 13:19:49+00:00,,can't install gensim to conda because of python version 3.8,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I wanted to install gesim in my condo environment. I have used both the command suggested in the [conda page](https://anaconda.org/anaconda/gensim) `conda install -c anaconda gensim` and which suggested in the [gensim page](https://radimrehurek.com/gensim/index.html) `conda install -c conda-forge gensim`. I think the issue is the gensim version on conda is not updated to support python version 3.8. My OS is Ubuntu 20.04.

#### Steps/code/corpus to reproduce
Traceback for `install -c anaconda gensim`:
<pre>(regenv) <font color=""#4E9A06""><b>➜  </b></font><font color=""#06989A""><b>reg</b></font> <font color=""#3465A4""><b>git:(</b></font><font color=""#CC0000""><b>master</b></font><font color=""#3465A4""><b>) </b></font><font color=""#C4A000""><b>✗</b></font> <font color=""#4E9A06"">conda</font> install -c anaconda gensim
Collecting package metadata (current_repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.
Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.
Solving environment: - 
Found conflicts! Looking for incompatible packages.
This can take several minutes.  Press CTRL-C to abort.
failed                                                                                                        

UnsatisfiableError: The following specifications were found
to be incompatible with the existing python installation in your environment:

Specifications:

  - gensim -&gt; python[version=&apos;&gt;=2.7,&lt;2.8.0a0|&gt;=3.6,&lt;3.7.0a0|&gt;=3.7,&lt;3.8.0a0|&gt;=3.5,&lt;3.6.0a0&apos;]

Your python: python=3.8

If python is on the left-most side of the chain, that&apos;s the version you&apos;ve asked for.
When python appears to the right, that indicates that the thing on the left is somehow
not available for the python version you are constrained to. Note that conda will not
change your python version to a different minor version unless you explicitly specify
that.

The following specifications were found to be incompatible with your CUDA driver:

  - feature:/linux-64::__cuda==10.2=0

Your installed CUDA driver is: 10.2


</pre>
TraceBack for `conda install -c conda-forge gensim`:
<pre>(regenv) <font color=""#CC0000""><b>➜  </b></font><font color=""#06989A""><b>reg</b></font> <font color=""#3465A4""><b>git:(</b></font><font color=""#CC0000""><b>master</b></font><font color=""#3465A4""><b>) </b></font><font color=""#C4A000""><b>✗</b></font> <font color=""#4E9A06"">conda</font> install -c conda-forge gensim
Collecting package metadata (current_repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.
Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.
Solving environment: - 
Found conflicts! Looking for incompatible packages.
This can take several minutes.  Press CTRL-C to abort.
failed                                                                                                        

UnsatisfiableError: The following specifications were found
to be incompatible with the existing python installation in your environment:

Specifications:

  - gensim -&gt; python[version=&apos;2.7.*|3.5.*|3.6.*|&gt;=2.7,&lt;2.8.0a0|&gt;=3.6,&lt;3.7.0a0|&gt;=3.7,&lt;3.8.0a0|&gt;=3.5,&lt;3.6.0a0&apos;]

Your python: python=3.8

If python is on the left-most side of the chain, that&apos;s the version you&apos;ve asked for.
When python appears to the right, that indicates that the thing on the left is somehow
not available for the python version you are constrained to. Note that conda will not
change your python version to a different minor version unless you explicitly specify
that.

The following specifications were found to be incompatible with your CUDA driver:

  - feature:/linux-64::__cuda==10.2=0
  - feature:|@/linux-64::__cuda==10.2=0

Your installed CUDA driver is: 10.2


</pre>
#### Versions
```python
Linux-5.4.0-28-generic-x86_64-with-glibc2.10
Python 3.8.2 (default, Mar 26 2020, 15:53:00) 
[GCC 7.3.0]
NumPy 1.18.1
SciPy 1.4.1
```
Thanks."
692,https://github.com/RaRe-Technologies/gensim/issues/2827,2827,[],closed,2020-05-05 17:59:09+00:00,,module 'gensim.models.doc2vec' has no attribute 'FAST_VERSION',"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? What is the expected result? What are you seeing instead?

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
Linux-5.3.0-46-generic-x86_64-with-debian-buster-sid
Python 3.7.7 (default, Mar 26 2020, 15:48:22) 
[GCC 7.3.0]
NumPy 1.18.4
SciPy 1.4.1
gensim 3.8.3
AttributeError: module 'gensim.models.doc2vec' has no attribute 'FAST_VERSION'

The issue is that the FAST_VERSION attribute is not there anymore in this new version. All works well in Gensim 3.8.1
"
693,https://github.com/RaRe-Technologies/gensim/issues/2828,2828,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 1602334472, 'node_id': 'MDU6TGFiZWwxNjAyMzM0NDcy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20MEDIUM', 'name': 'impact MEDIUM', 'color': '7af49f', 'default': False, 'description': 'Big annoyance for affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",closed,2020-05-05 23:02:47+00:00,,CHANGELOG.md vs PyPI?,"PyPI shows gensim releases ""3.8.2"" and ""3.8.3"". But these aren't mentioned in the `CHANGELOG.md`, nor were they announced on the project discussion list. (There was a tweet announcing 3.8.3.) Should those steps – especially, updating `CHANGELOG.md` – be part of a release checklist, or maybe even some sort of automated-pre-release check?"
694,https://github.com/RaRe-Technologies/gensim/issues/2834,2834,[],closed,2020-05-10 15:58:31+00:00,,api.load of fasttext vectors returns Word2VecKeyedVectors ,"![image](https://user-images.githubusercontent.com/14852840/81504015-09d65a00-92b5-11ea-8b6c-21082e4479ff.png)

Firstly, thanks for the great library. 
When loading FastText using the API, the model returned is actually one with Word2VecKeyedVectors , not FastTextKeyedVectors, hence this causes issues for OOV loading
```
Linux-4.19.104+-x86_64-with-Ubuntu-18.04-bionic
Python 3.6.9 (default, Apr 18 2020, 01:56:04) 
[GCC 8.4.0]
NumPy 1.18.4
SciPy 1.4.1
gensim 3.6.0
FAST_VERSION 1
```
"
695,https://github.com/RaRe-Technologies/gensim/issues/2835,2835,"[{'id': 2460507316, 'node_id': 'MDU6TGFiZWwyNDYwNTA3MzE2', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/duplicate', 'name': 'duplicate', 'color': 'd7ea07', 'default': True, 'description': 'This issue duplicates another issue'}]",closed,2020-05-10 19:10:43+00:00,,Can't get attribute 'callback' on <module '__main__' (built-in)> when calling load(),"#### Problem description
I have trained a word2vec model using the following code
https://gist.github.com/AkibSadmanee/d946f14c397c317f938eeea66dca79dc

But when I  am trying to laod the model using the load() function, I get an AttributeError: *Can't get attribute 'callback' on <module '__main__' (built-in)>*
```python
from gensim.models import Word2Vec
w2v = Word2Vec.load(""word2vec_dim300_skipgram_iter35.model"")
```
**However, for your infirmation,  the model was trained on Bangla language corpora which contain unicode characters.** 
I tried reinstalling the package but the issue persists. I guess I am missing something important. 

#### The detailed error I am getting:
```python
Traceback (most recent call last):
  File ""C:\Users\akibs\Anaconda3\lib\site-packages\gensim\models\word2vec.py"", line 1141, in load
    model = super(Word2Vec, cls).load(*args, **kwargs)
  File ""C:\Users\akibs\Anaconda3\lib\site-packages\gensim\models\base_any2vec.py"", line 1230, in load
    model = super(BaseWordEmbeddingsModel, cls).load(*args, **kwargs)
  File ""C:\Users\akibs\Anaconda3\lib\site-packages\gensim\models\base_any2vec.py"", line 602, in load
    return super(BaseAny2VecModel, cls).load(fname_or_handle, **kwargs)
  File ""C:\Users\akibs\Anaconda3\lib\site-packages\gensim\utils.py"", line 435, in load
    obj = unpickle(fname)
  File ""C:\Users\akibs\Anaconda3\lib\site-packages\gensim\utils.py"", line 1398, in unpickle
    return _pickle.load(f, encoding='latin1')
AttributeError: Can't get attribute 'callback' on <module '__main__' (built-in)>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\akibs\Anaconda3\lib\site-packages\gensim\models\word2vec.py"", line 1152, in load
    return load_old_word2vec(*args, **kwargs)
  File ""C:\Users\akibs\Anaconda3\lib\site-packages\gensim\models\deprecated\word2vec.py"", line 169, in load_old_word2vec      
    old_model = Word2Vec.load(*args, **kwargs)
  File ""C:\Users\akibs\Anaconda3\lib\site-packages\gensim\models\deprecated\word2vec.py"", line 1617, in load
    model = super(Word2Vec, cls).load(*args, **kwargs)
  File ""C:\Users\akibs\Anaconda3\lib\site-packages\gensim\models\deprecated\old_saveload.py"", line 87, in load
    obj = unpickle(fname)
  File ""C:\Users\akibs\Anaconda3\lib\site-packages\gensim\models\deprecated\old_saveload.py"", line 379, in unpickle
    return _pickle.loads(file_bytes, encoding='latin1')
AttributeError: Can't get attribute 'callback' on <module '__main__' (built-in)>
```

#### This is the package information of my installed version,
Name: gensim
Version: 3.8.3
Summary: Python framework for fast Vector Space Modelling
Home-page: http://radimrehurek.com/gensim
Author: Radim Rehurek
Author-email: me@radimrehurek.com
License: LGPLv2.1
Location: c:\users\akibs\anaconda3\lib\site-packages
Requires: smart-open, scipy, numpy, Cython, six
Required-by:
Please provide the output of:
"
696,https://github.com/RaRe-Technologies/gensim/issues/2838,2838,[],open,2020-05-13 00:59:47+00:00,,HdpModel converging to only one topic,"Hi -
I love this library but have been running into troubles with the hdp function. I've been trying to fit an hdp model to the standard scikit-learn 20newsgroup dataset with the following parameters T=20, K=8, alpha =0.1 given I expect there to be 20 topics and want topics to be highly concentrated at the doc level (small alpha).

I've done some general preprocessing (tokenized, removed stop-words, created bigrams, and lemmatized nouns/verbs/adj), and created a compact vocab of about 4000 words based on word frequencies across docs. 
All of this using gensim methods except the lemmatization for which I used spaCy.

I've been trying different approaches, and adjusting parameters to try to get topics not to converge to a single topic as shown in the diagram below. At this point I can't think of any else to test whether it is an issue on gensim or my end.

<img width=""588"" alt=""Screen Shot 2020-05-12 at 8 57 06 PM"" src=""https://user-images.githubusercontent.com/42551278/81759629-35af3680-9493-11ea-88e8-1f37b638ae4b.png"">

I'm happy to share my code if it would be helpful.

Here's some on versions:
```python
Darwin-18.5.0-x86_64-i386-64bit
Python 3.7.6 (default, Dec 30 2019, 19:38:28) 
[Clang 11.0.0 (clang-1100.0.33.16)]
NumPy 1.18.1
SciPy 1.4.1
gensim 3.8.1
FAST_VERSION -1
```
"
697,https://github.com/RaRe-Technologies/gensim/issues/2839,2839,"[{'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",open,2020-05-14 06:18:48+00:00,,Fix newline weirdness on Azure,"Some of our tests were failing on Azure because of LF/CRLF weirdness once the .gitattributes file was deleted. In the interest of moving things along, I've disabled those tests (look for AZURE in gensim/test/test_*.py).

Ideally, we should make these tests run and pass.

---

I have 2 ideas
- apply `.gitattribute` only for the concrete subset of files that fail azure (replace `*` with paths). This will definitely fix azure, but I'm not sure does this avoid effect with ""modified files"" that Gordon described
- ""re-checkout"" repo in azure with generated `.gitattribute` in runtime, this definitely avoid Gordon issue, but not sure will azure work with it (`.gitattributes` works in a pretty strange way for me, looks like this applied on `clone`, not on local `checkout`, worth to investigate)

Gordon right: hacks for CI shouldn't affect contributors

_Originally posted by @menshikh-iv in https://github.com/RaRe-Technologies/gensim/pull/2836#issuecomment-627106300_"
698,https://github.com/RaRe-Technologies/gensim/issues/2840,2840,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}]",open,2020-05-14 14:12:41+00:00,,Implement position-dependent weighting to fastText,"In Section 2.2 of the [2017 “Advances” paper by Mikolov et al.][advances], a position-dependent weighting is introduced to the context vector computation in the fastText CBOW model. On [Common Crawl][], this extension has led to **5 point improvement in total accuracy** on the English word analogy task.

Despite the usefulness of the position-dependent weighting extension, it has [not been implemented to facebook's code base yet](https://github.com/facebookresearch/fastText/issues/445). I propose to add this extension to Gensim's fastText and be the first publicly available implementation of the extension.

Table 4, row CBOW of the [2018 “Learning” paper by Grave et al.][learning] shows the word analogy task results of CBOW fastText models for 10 languages trained on Wikipedia:

| Cs | De | Es | Fi | Fr | Hi | It | Pl | Pt | Zh |
|--|--|--|--|--|--|--|--|--|--|
| 63.9 | 71.7 | 64.4 | 42.8 | 71.6 | 14.1 | 66.2 | 56.0 | 60.6 | 51.5 |

The CBOW fastText models use the position-dependent weighting extension and the default parameters described in Section 4.3 of the [2017 “Enriching” paper by Bojanowski et al.][enriching]: hash table bucket size 2*10^6, 5 epochs, 300 vector dimensions, negative sampling loss with 5 negative samples, initial learning rate 0.05, sampling threshold 10^-4, and window size 5. The correctness of our implementation can be checked by comparing with [Grave][learning]'s results (above).

 [advances]: https://arxiv.org/pdf/1712.09405.pdf#page=2
 [learning]: https://arxiv.org/pdf/1802.06893.pdf#page=4
 [common crawl]: https://commoncrawl.org/
 [enriching]: https://arxiv.org/pdf/1607.04606.pdf#page=4"
699,https://github.com/RaRe-Technologies/gensim/issues/2841,2841,[],open,2020-05-15 14:53:34+00:00,,"Weighted jaccard defined over the range (0, 0.5)?","I noticed that jaccard for BOW representations (weighted jaccard) is computed as the sum of min feature weights over the sum of the feature weights (which gives a jaccard between 0 and 0.5) instead of the sum of min feature weights over the sum of max feature weights (which gives a jaccard between 0 and 1). Is there a reason for this rather non standard choice?

https://github.com/RaRe-Technologies/gensim/blob/e859c11f6f57bf3c883a718a9ab7067ac0c2d4cf/gensim/matutils.py#L1056-L1064"
700,https://github.com/RaRe-Technologies/gensim/issues/2842,2842,[],closed,2020-05-16 21:13:49+00:00,,KeyedVectors importing keras instead of tensorflow.keras?,"Hello there,

I got a super quick question regarding the function `get_keras_embeddings` of KeyedVectors.py. Is there a reason behind requiring keras package to be installed (specifically referring to [these lines](https://github.com/RaRe-Technologies/gensim/blob/2360459e0014f5db8fc587005933a6399efab435/gensim/models/keyedvectors.py#L1415-L1419)) instead of going through tensorflow 2.0 API (i.e., `import tensorflow.keras`)? 
"
701,https://github.com/RaRe-Technologies/gensim/issues/2843,2843,"[{'id': 2460503557, 'node_id': 'MDU6TGFiZWwyNDYwNTAzNTU3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/question', 'name': 'question', 'color': 'e098e2', 'default': True, 'description': 'Discussions that are generally off-topic for the github issue tracker'}, {'id': 2460507316, 'node_id': 'MDU6TGFiZWwyNDYwNTA3MzE2', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/duplicate', 'name': 'duplicate', 'color': 'd7ea07', 'default': True, 'description': 'This issue duplicates another issue'}]",closed,2020-05-18 15:21:27+00:00,,Conflicts between hyperparameters for negative sampling?,"Hi,

I wonder if there are possible interactions/conflicts when you use negative sampling with `negative>0 `and have hierarchical softmax accidentally activated` hs=1`? The docs says that only if hs=0 negative sampling will be used (negative>0). So I can hope that still if hs=1 and `negative>0 `  hopefully _**no**_ negative sampling is used?

Python 3.6
Win 10
NumPy 1.18.1
SciPy 1.1.0
gensim 3.8.1
"
702,https://github.com/RaRe-Technologies/gensim/issues/2844,2844,"[{'id': 2460503557, 'node_id': 'MDU6TGFiZWwyNDYwNTAzNTU3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/question', 'name': 'question', 'color': 'e098e2', 'default': True, 'description': 'Discussions that are generally off-topic for the github issue tracker'}]",closed,2020-05-18 16:30:41+00:00,,Conflicts between hyperparameters for negative sampling? ,"Hi,

I wonder if there are possible interactions/conflicts when you use negative sampling with `negative>0 `and have hierarchical softmax accidentally activated` hs=1`? The docs says that only if hs=0 negative sampling will be used (negative>0). So I can hope that still if hs=1 and `negative>0 `  hopefully _**no**_ negative sampling is used?

Python 3.6
Win 10
NumPy 1.18.1
SciPy 1.1.0
gensim 3.8.1
"
703,https://github.com/RaRe-Technologies/gensim/issues/2845,2845,[],closed,2020-05-21 19:56:38+00:00,,id2word returns weird numbers instead of words with get_topic_terms,"# Problem description

While getting the top topic terms for my lda model, I get numbers instead of words. The corpus doesn't contain any numbers. Other models return the top words correctly, but for my corpus the results are always numbers.

Code for training:
```python
    dictionary = Dictionary(texts)  # texts list has documents split by  words
    dictionary.filter_extremes(no_above=0.8, no_below=3)
    dictionary.compactify()

    corpus = [dictionary.doc2bow(text) for text in texts]
    model = LdaMulticore(corpus=corpus, num_topics=num_topics, passes=5)
```

#### Versions
version 3.8.1

Please provide the output of:
I used this code to get the top words, which works for other models.
```python 
def get_topic_top_words(lda_model, topic_id, nr_top_words=5):
    """""" Returns the top words for topic_id from lda_model.
    """"""
    id_tuples = lda_model.get_topic_terms(topic_id, topn=nr_top_words)
    word_ids = np.array(id_tuples)[:,0]
    words = map(lambda id_: lda_model.id2word[id_], word_ids)
    return words
```
Output:
```python

For topic 0, the top words are: 9143.0, 3313.0, 14517.0, 17358.0, 306.0, 8569.0, 2560.0, 20018.0, 320.0, 2807.0, 2838.0, 14388.0.
For topic 1, the top words are: 14.0, 405.0, 496.0, 90.0, 440.0, 270.0, 417.0, 143.0, 274.0, 145.0, 193.0, 817.0.
For topic 2, the top words are: 496.0, 405.0, 14.0, 90.0, 1713.0, 40.0, 199.0, 71.0, 193.0, 931.0, 248.0, 145.0.
For topic 3, the top words are: 47065.0, 143.0, 1080.0, 14.0, 1598.0, 90.0, 147.0, 272.0, 900.0, 248.0, 595.0, 2580.0.
For topic 4, the top words are: 14.0, 1335.0, 1061.0, 339.0, 959.0, 2366.0, 809.0, 352.0, 147.0, 1312.0, 268.0, 989.0.
For topic 5, the top words are: 9143.0, 19553.0, 14.0, 759.0, 437.0, 22.0, 456.0, 405.0, 1971.0, 1704.0, 1821.0, 27175.0.
For topic 6, the top words are: 2560.0, 1229.0, 14.0, 93649.0, 817.0, 496.0, 71.0, 143.0, 270.0, 231.0, 914.0, 455.0.
For topic 7, the top words are: 417.0, 817.0, 150.0, 2644.0, 14.0, 147.0, 405.0, 622.0, 183.0, 2535.0, 517.0, 496.0.
For topic 8, the top words are: 183.0, 469.0, 14.0, 1331.0, 143.0, 389.0, 696.0, 332.0, 39.0, 104.0, 405.0, 886.0.
For topic 9, the top words are: 14.0, 921.0, 22.0, 405.0, 545.0, 417.0, 183.0, 24.0, 484.0, 71.0, 231.0, 143.0.
```
"
704,https://github.com/RaRe-Technologies/gensim/issues/2847,2847,"[{'id': 2460503557, 'node_id': 'MDU6TGFiZWwyNDYwNTAzNTU3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/question', 'name': 'question', 'color': 'e098e2', 'default': True, 'description': 'Discussions that are generally off-topic for the github issue tracker'}]",closed,2020-05-23 13:56:32+00:00,,doc2vec - infer_vector gives different values on every run,"Hi,

I used doc2vec to train the documents following the post [here](https://www.thinkinfi.com/2019/10/doc2vec-implementation-in-python-gensim.html
)

I get different values for infer_vector - most similar documents on every run. I tried to set a seed value to avoid the initial randomization but that didn't seem to fix this issue. Any better suggestions would be helpful!

Thanks!"
705,https://github.com/RaRe-Technologies/gensim/issues/2848,2848,"[{'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}, {'id': 575779925, 'node_id': 'MDU6TGFiZWw1NzU3Nzk5MjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/breaks%20backward-compatibility', 'name': 'breaks backward-compatibility', 'color': 'e96f1b', 'default': False, 'description': 'Change breaks backward compatibility'}, {'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",open,2020-05-26 16:28:49+00:00,,Consider: dropping custom SaveLoad in favor of Pickle v.5 or joblib.dump? ,"[PEP 574](https://www.python.org/dev/peps/pep-0574/) defines pickle-version-5, which supports alternate serialization of things like large numpy arrays. It's natively available in Python 3.8, with a PyPI backport [pickle5](https://pypi.org/project/pickle5/)  that works in 3.5, 3.6, and 3.7. 

I'm not yet certain it allows the same mmap-on-load possible with `gensim.utils.SaveLoad`, but I suspect it might. 

Similarly, `joblib`'s [dump()](https://joblib.readthedocs.io/en/latest/generated/joblib.dump.html) supports serializing large objects with large `numpy` arrays, and it is already what `sklearn` & others use for large models. Its matching [load()](https://joblib.readthedocs.io/en/latest/generated/joblib.load.html#joblib.load) has an `mmap_mode` option. 

Gensim should consider whether either of these could be a superior alternative to `gensim.utils.SaveLoad` – in terms of being in sync with Python & related projects, & minimizing gensim idiosyncratic code. If so, a transition goal cold be set in some future release, with perhaps just one version supporting both modes (if continued forward-migration of old models is to be supported). "
706,https://github.com/RaRe-Technologies/gensim/issues/2849,2849,[],open,2020-05-31 14:53:36+00:00,,HdpModel inference doesn't sum to 1 for each document,"# Problem description
Inference should gives you a probability distribution from a dirichlet, it instead gives you a series of numbers that doesn't add to 1

# Steps/code/corpus to reproduce
```python
hdp = HdpModel(corpus, vocab)
doctopic = corpus2dense(hdp[corpus], num_terms=hdp.m_T,
                            num_docs=bow_data.shape[0],
                            dtype=np.float32)
print(np.sum(doctopic[:,0]))
```
#### Versions
```python
>>> import sys; print(""Python"", sys.version)
Python 3.7.6 (default, Jan  8 2020, 19:59:22) 
[GCC 7.3.0]
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.18.1
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.4.1
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.8.0
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1
```
"
707,https://github.com/RaRe-Technologies/gensim/issues/2850,2850,[],closed,2020-06-04 11:27:03+00:00,,AttributeError: 'Doc2VecTrainables' object has no attribute 'vectors_lockf',"Python version 3.7.5
gensim version 3.6.0
apache-beam[gcp] 2.20.0 
tensorflow==1.14

#### Problem description
Trying to create tf records using gensim Doc2Vec. 
Expected result is to create tf records with the given parameters. 

In Directrunner

tf record creation is happening when used with gensim 3.6.0 
but AttributeError is raised when ran with 3.8.0 version of gensim (AttributeError: 'Doc2VecTrainables' object has no attribute 'vectors_lockf')

While running a dataflow job even with gensim 3.6.0 
Attribute error is raised

#### Steps/code/corpus to reproduce

pretrained_emb = 'glove.6B.100d.txt'
        vector_size = 300
        window_size = 15
        min_count = 1
        sampling_threshold = 1e-5
        negative_size = 5
        train_epoch = 100
        dm = 0 #0 = dbow; 1 = dmpv
        worker_count = 1 #number of parallel processes
        print('max_seq_len which is being passed above Doc2Vec', self.max_seq_len)
        self.model = g.Doc2Vec(documents=None,size=vector_size,
                               window=window_size, min_count=min_count,
                               sample=sampling_threshold,
                               workers=worker_count, hs=0,
                               dm=dm, negative=negative_size,
                               dbow_words=1, dm_concat=1,
                               pretrained_emb=pretrained_emb,
                               iter=100)
        print(""Loaded Model"")
  plot class type is 'string'
    embedding_vector = self.model.infer_vector([plot])

 It is raising an attribute error when ran in dataflow runner. In Directrunner issue is raised when gensim version is 3.8.0

Error log:
I have pasted the entire error log.
textPayload: ""Error message from worker: Traceback (most recent call last):
  File ""apache_beam/runners/common.py"", line 950, in apache_beam.runners.common.DoFnRunner.process
  File ""apache_beam/runners/common.py"", line 547, in apache_beam.runners.common.SimpleInvoker.invoke_process
  File ""apache_beam/runners/common.py"", line 1078, in apache_beam.runners.common._OutputProcessor.process_outputs
  File ""tfrecord_util/csv2tfrecord_train_valid.py"", line 310, in process
    x = self.preprocess(x)
  File ""tfrecord_util/csv2tfrecord_train_valid.py"", line 233, in preprocess
    embedding_vector = self._embedding(plot)
  File ""tfrecord_util/csv2tfrecord_train_valid.py"", line 300, in _embedding
    embedding_vector = self.model.infer_vector([plot])
  File ""/usr/local/lib/python3.7/site-packages/gensim/models/doc2vec.py"", line 915, in infer_vector
    learn_words=False, learn_hidden=False, doctag_vectors=doctag_vectors, doctag_locks=doctag_locks
  File ""gensim/models/doc2vec_inner.pyx"", line 332, in gensim.models.doc2vec_inner.train_document_dbow
  File ""gensim/models/doc2vec_inner.pyx"", line 254, in gensim.models.doc2vec_inner.init_d2v_config
AttributeError: 'Doc2VecTrainables' object has no attribute 'vectors_lockf'


I hope you understand the issue from the above details. Please let me know if you still need any additional information.
During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/dataflow_worker/batchworker.py"", line 647, in do_work
    work_executor.execute()
  File ""/usr/local/lib/python3.7/site-packages/dataflow_worker/executor.py"", line 176, in execute
    op.start()
  File ""dataflow_worker/native_operations.py"", line 38, in dataflow_worker.native_operations.NativeReadOperation.start
  File ""dataflow_worker/native_operations.py"", line 39, in dataflow_worker.native_operations.NativeReadOperation.start
  File ""dataflow_worker/native_operations.py"", line 44, in dataflow_worker.native_operations.NativeReadOperation.start
  File ""dataflow_worker/native_operations.py"", line 54, in dataflow_worker.native_operations.NativeReadOperation.start
  File ""apache_beam/runners/worker/operations.py"", line 329, in apache_beam.runners.worker.operations.Operation.output
  File ""apache_beam/runners/worker/operations.py"", line 192, in apache_beam.runners.worker.operations.SingletonConsumerSet.receive
  File ""apache_beam/runners/worker/operations.py"", line 682, in apache_beam.runners.worker.operations.DoOperation.process
  File ""apache_beam/runners/worker/operations.py"", line 683, in apache_beam.runners.worker.operations.DoOperation.process
  File ""apache_beam/runners/common.py"", line 952, in apache_beam.runners.common.DoFnRunner.process
  File ""apache_beam/runners/common.py"", line 1013, in apache_beam.runners.common.DoFnRunner._reraise_augmented
  File ""apache_beam/runners/common.py"", line 950, in apache_beam.runners.common.DoFnRunner.process
  File ""apache_beam/runners/common.py"", line 547, in apache_beam.runners.common.SimpleInvoker.invoke_process
  File ""apache_beam/runners/common.py"", line 1105, in apache_beam.runners.common._OutputProcessor.process_outputs
  File ""apache_beam/runners/worker/operations.py"", line 192, in apache_beam.runners.worker.operations.SingletonConsumerSet.receive
  File ""apache_beam/runners/worker/operations.py"", line 682, in apache_beam.runners.worker.operations.DoOperation.process
  File ""apache_beam/runners/worker/operations.py"", line 683, in apache_beam.runners.worker.operations.DoOperation.process
  File ""apache_beam/runners/common.py"", line 952, in apache_beam.runners.common.DoFnRunner.process
  File ""apache_beam/runners/common.py"", line 1028, in apache_beam.runners.common.DoFnRunner._reraise_augmented
  File ""/usr/local/lib/python3.7/site-packages/future/utils/__init__.py"", line 421, in raise_with_traceback
    raise exc.with_traceback(traceback)
  File ""apache_beam/runners/common.py"", line 950, in apache_beam.runners.common.DoFnRunner.process
  File ""apache_beam/runners/common.py"", line 547, in apache_beam.runners.common.SimpleInvoker.invoke_process
  File ""apache_beam/runners/common.py"", line 1078, in apache_beam.runners.common._OutputProcessor.process_outputs
  File ""tfrecord_util/csv2tfrecord_train_valid.py"", line 310, in process
    x = self.preprocess(x)
  File ""tfrecord_util/csv2tfrecord_train_valid.py"", line 233, in preprocess
    embedding_vector = self._embedding(plot)
  File ""tfrecord_util/csv2tfrecord_train_valid.py"", line 300, in _embedding
    embedding_vector = self.model.infer_vector([plot])
  File ""/usr/local/lib/python3.7/site-packages/gensim/models/doc2vec.py"", line 915, in infer_vector
    learn_words=False, learn_hidden=False, doctag_vectors=doctag_vectors, doctag_locks=doctag_locks
  File ""gensim/models/doc2vec_inner.pyx"", line 332, in gensim.models.doc2vec_inner.train_document_dbow
  File ""gensim/models/doc2vec_inner.pyx"", line 254, in gensim.models.doc2vec_inner.init_d2v_config
AttributeError: 'Doc2VecTrainables' object has no attribute 'vectors_lockf' [while running 'PreprocessData']
```
"
708,https://github.com/RaRe-Technologies/gensim/issues/2851,2851,[],closed,2020-06-05 18:43:16+00:00,,CalledProcessError: non-zero returned non-zero exit status 1. Gensim Mallet,"I was trying to run ldaMallet for modeling, but ran into the CalledProcessError. 

![image](https://user-images.githubusercontent.com/4327768/83911368-fd60e800-a720-11ea-9a3d-ee86ea0eb9c9.png)

Then, we I run the following code:

`model_list, coherence_values = compute_coherence_values(dictionary=words_id2word, corpus=words_corpus, texts=data_words_nonstop_trigrams, start=2, limit=40, step=6)`

I encountered the calledprocesserror:

'CalledProcessError: Command 'C:/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex ""\S+"" --input C:\Users\jia\AppData\Local\Temp\aa34be_corpus.txt --output C:\Users\jia\AppData\Local\Temp\aa34be_corpus.mallet' returned non-zero exit status 1.
'
I tried the solutions in https://github.com/RaRe-Technologies/gensim/issues/2163, as well as stackoverlow solutions, but none of them worked. Please help. Thank you in advance. 

#### Versions

```python
Windows-10-10.0.18362-SP0
Python 3.7.3 (default, Apr 24 2019, 15:29:51) [MSC v.1915 64 bit (AMD64)]
NumPy 1.16.4
SciPy 1.4.1
gensim 3.8.0
FAST_VERSION  1
```
"
709,https://github.com/RaRe-Technologies/gensim/issues/2852,2852,"[{'id': 575779925, 'node_id': 'MDU6TGFiZWw1NzU3Nzk5MjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/breaks%20backward-compatibility', 'name': 'breaks backward-compatibility', 'color': 'e96f1b', 'default': False, 'description': 'Change breaks backward compatibility'}, {'id': 1602257032, 'node_id': 'MDU6TGFiZWwxNjAyMjU3MDMy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20HIGH', 'name': 'impact HIGH', 'color': 'b60205', 'default': False, 'description': 'Show-stopper for affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}, {'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",closed,2020-06-10 07:34:42+00:00,,Reduce gensim surface area,"Are there subpackages/submodules that we're not maintaining anymore, and could remove?

- [x] summarization
- [x] HDP
- [x] wordrank
- [x] dependency on pattern
- [x] various wrappers (incl. sklearn) and others.
- [x] simserver documentation
- [x] viz

The goal is to reduce the maintenance burden of the project.
"
710,https://github.com/RaRe-Technologies/gensim/issues/2853,2853,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}]",closed,2020-06-10 20:21:07+00:00,,save_facebook_model() - AssertionError,"#### Problem description
I am trying to save the trained model of fasttext using the new save_facebook_model function.
I was unable to do it so because an assertionError arises in the code line:
`assert vocab_n == len(model.wv.vocab)`
 The vocabulary of my model is of 2000264:
```
len(model.wv.vocab)
2000264
```
I tried with a model with a vocabulary of 4500 and it worked. So I guess there is a limitation in that. But the error message did not tell any of that.

#### Steps/code/corpus to reproduce

```
from gensim.models.fasttext import save_facebook_model

save_facebook_model(model,'own_fasttext_model_pretrained.bin')

---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
<ipython-input-201-0a3c1c458b74> in <module>
      2 from gensim.models.fasttext import load_facebook_model, load_facebook_vectors,save_facebook_model
      3 
----> 4 save_facebook_model(model,'own_fasttext_model_pretrained.bin')

/opt/conda/lib/python3.7/site-packages/gensim/models/fasttext.py in save_facebook_model(model, path, encoding, lr_update_rate, word_ngrams)
   1334     """"""
   1335     fb_fasttext_parameters = {""lr_update_rate"": lr_update_rate, ""word_ngrams"": word_ngrams}
-> 1336     gensim.models._fasttext_bin.save(model, path, fb_fasttext_parameters, encoding)

/opt/conda/lib/python3.7/site-packages/gensim/models/_fasttext_bin.py in save(model, fout, fb_fasttext_parameters, encoding)
    666     if isinstance(fout, str):
    667         with open(fout, ""wb"") as fout_stream:
--> 668             _save_to_stream(model, fout_stream, fb_fasttext_parameters, encoding)
    669     else:
    670         _save_to_stream(model, fout, fb_fasttext_parameters, encoding)

/opt/conda/lib/python3.7/site-packages/gensim/models/_fasttext_bin.py in _save_to_stream(model, fout, fb_fasttext_parameters, encoding)
    629 
    630     # Save words and ngrams vectors
--> 631     _input_save(fout, model)
    632     fout.write(struct.pack('@?', False))  # Save 'quot_', which is False for unsupervised models
    633 

/opt/conda/lib/python3.7/site-packages/gensim/models/_fasttext_bin.py in _input_save(fout, model)
    573 
    574     assert vocab_dim == ngrams_dim
--> 575     assert vocab_n == len(model.wv.vocab)
    576     assert ngrams_n == model.wv.bucket
    577 

AssertionError: 
```





#### Versions

```
Python 3.7.6 | packaged by conda-forge | (default, Jan  7 2020, 22:33:48) 
[GCC 7.3.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
Linux-4.9.0-12-amd64-x86_64-with-debian-9.12
Python 3.7.6 | packaged by conda-forge | (default, Jan  7 2020, 22:33:48) 
[GCC 7.3.0]
NumPy 1.18.1
SciPy 1.4.1
gensim 3.8.3
FAST_VERSION 0
```"
711,https://github.com/RaRe-Technologies/gensim/issues/2855,2855,[],closed,2020-06-12 17:08:31+00:00,,mallet wrapper return non-zero exit status 126,"#### Problem description

I am using the cloudera data science workbench for my Latent Dirichlet Allocation project, I am training a model using the command

```python
mallet_path = '../mallet-2.0.8/bin/mallet' # update this path
ldamallet_nv7 = gensim.models.wrappers.LdaMallet(mallet_path, corpus=nv_corpus, num_topics=7, id2word=nv_id2word, iterations = 5000, random_seed = 1997)
ldamallet_nv7.print_topics()
```
here mallet_path is the relative path I put in my project folder.

When I run the code, I have the error like this:
```python
'''Command '../mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex ""\S+"" --input /tmp/f58d7e_corpus.txt --output /tmp/f58d7e_corpus.mallet' returned non-zero exit status 126.'''
```

There is no commonly asked questions about this issue so I am thinking posting a new issue


#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)

##output:
##Linux-3.10.0-862.14.4.el7.x86_64-x86_64-with-debian-buster-sid
##Python 3.6.9 (default, Dec  4 2019, 05:05:08) 
##[GCC 7.4.0]
##NumPy 1.17.2
##SciPy 1.3.3
##gensim 3.8.3
##FAST_VERSION 1
```
"
712,https://github.com/RaRe-Technologies/gensim/issues/2856,2856,"[{'id': 2460503557, 'node_id': 'MDU6TGFiZWwyNDYwNTAzNTU3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/question', 'name': 'question', 'color': 'e098e2', 'default': True, 'description': 'Discussions that are generally off-topic for the github issue tracker'}]",closed,2020-06-12 20:39:33+00:00,,"KeyError: ""word '...' not in vocabulary"" 20-newsgroups","I want to use pre-trained 20-newsgroups model. My code is this:
`from gensim.models import Word2Vec`
`import gensim.downloader as api`
`corpus = api.load('20-newsgroups')`
`print (model.similarity(""jesus"", ""game""))`

But it gives the error
KeyError: ""word 'jesus' not in vocabulary"""
713,https://github.com/RaRe-Technologies/gensim/issues/2857,2857,[],closed,2020-06-13 11:56:10+00:00,,Type mismatch in utils.py: use an iterator as an iterable,"I noticed that in both line 1177 and line 1179 _it_ was passed as the first argument to itertools.islice().

Note that itertools.islice() expects its first argument to be an _iterable_ (see [this](https://docs.python.org/3/library/itertools.html#itertools.islice)), but  _it_ is not necessarily an iterable. It is simply an iterator (see line 1172). So there is a type mismatch.
https://github.com/RaRe-Technologies/gensim/blob/8149035e22c3df932a22fc654ae35942d5e2f866/gensim/utils.py#L1145-L1183


I guess an easy fix to this bug would be to directly pass the provided argument, _iterable_. I didn't see any need to create an iterator for it.


I met this bug when I was using LdaModel. In the initializer of that class it tries to break the corpus, which is an iterable, into chunks using chunkize_serial. I attempted to implement my own corpus to stream documents from the disk. Then I met with a TypeError claiming that the corresponding iterator I implemented was not iterable.

Thanks for taking a look at this!"
714,https://github.com/RaRe-Technologies/gensim/issues/2858,2858,"[{'id': 2460503557, 'node_id': 'MDU6TGFiZWwyNDYwNTAzNTU3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/question', 'name': 'question', 'color': 'e098e2', 'default': True, 'description': 'Discussions that are generally off-topic for the github issue tracker'}]",closed,2020-06-16 14:28:19+00:00,,How To Save/Plot Poincare Embedding Model After Every Epoch?,"I would like to be able to make a plot of the embeddings after every epoch as per [this blogpost](https://rare-technologies.com/implementing-poincare-embeddings).

I assume that this requires saving the model every epoch and then loading it into the plotting function later on? I cannot see how to save and load the models though.

According to [this link](https://radimrehurek.com/gensim/models/base_any2vec.html), Poincare embeddings should be compatible with callbacks and I could use a callback to save the model after each epoch. This link suggests that we can pass the callback in when we create an object of the PoincareModel class:

class gensim.models.base_any2vec.BaseAny2VecModel(workers=3, vector_size=100, epochs=5, **callbacks=()**, batch_words=10000)

However, according to [this link](https://radimrehurek.com/gensim/models/poincare.html) it is not possible to pass callbacks into PoincareModel and when I try to do so, I get an error."
715,https://github.com/RaRe-Technologies/gensim/issues/2859,2859,[],open,2020-06-17 06:19:11+00:00,,Inconsistent hash,"Hi,
I noticed that the default hash() is used for training. I think you should change the default or greatly emphasize the importance of properly setting and testing the seed. It's not well hinted in the docs that PYTHONHASHSEED is not only required to control consistency between runs, but also proper control of hashing is needed for inference after loading a new model, right? Please correct me if I've missed something, but consider this scenario. I train the model with the default hash() and it gives a seed of 10. I save the model to be used in production. 2 servers load the model to encode strings, but inference could be using a seed of 20 and 30. What happens is that a word `car` gets hashed to a different bucket and therefore encoded differently in each instance. The best fix is probably to always set PYTHONHASHSEED for code that uses the default hash(). From what I wrote below, I obviously solved my immediate issue, but the engineer that puts my code into prod will probably miss setting the variable, which is why I would like to have a warning message on this. Thanks.

A simple test for hash consistency would be running this code at initialization and stop/warn on failure (variable not defined). Note that python 2 is deprecated/dead, so I will not even consider the old behavior of hash() in this suggestion.
```
import os
os.environ['PYTHONHASHSEED']
%env PYTHONHASHSEED #notebook
hash('abcdefg')#should be the same every run
```

As for suggested alternate hash functions, these would not be compatible with a prebuilt model, but would work well enough for a new model. Using a secure hash in the 2nd function is overkill, but it's the fastest stable library implementation I could find. The downside is having to encode every string. A native hash function would be preferred if anyone knows of a better alternative.
```
from numba import jit,njit
@njit
def hash(s):#Java formula for string hash code
    #measured 5.5x slower than built in, so fixing the hash seed of default hash is preferred. Overall runtime is only a little slower however, not 5x.
    h = 0
    for b in s:
        h = 31*h + b
    return h

def hash(s):#10x slower than builtin, but much better hash. 
    return int(hashlib.blake2s(s).hexdigest(),32)

hash(ss.encode('utf-8'))
```
Lastly, advice for anyone finding this with a similar problem and using Jupyter. Define `env` `PYTHONHASHSEED` and  in your kernel definition `kernel.json`. https://jupyter-client.readthedocs.io/en/stable/kernels.html#kernel-specs"
716,https://github.com/RaRe-Technologies/gensim/issues/2860,2860,[],open,2020-06-17 14:51:08+00:00,,AttributeError: 'FastText' object has no attribute 'intersect_word2vec_format',"#### Problem description

I would like to fine-tune a fasttext embeddings model trained on wiki data on new in domain data, 
I was using this code;
#### Steps/code/corpus to reproduce
model = KeyedVectors.load_word2vec_format(args.pretrained_model,binary=False)
model_Fasttext_cbow = FastText(size=args.vector_size, window=args.window, min_count=args.min_count, workers=8,sg=0)
model_Fasttext_cbow.build_vocab(sentences)
total_examples = model_Fasttext_cbow.corpus_count
model_Fasttext_cbow.build_vocab([list(model.wv.vocab.keys())], update=True)
model_Fasttext_cbow.intersect_word2vec_format(args.pretrained_model, binary=False,lockf=1.0)
model_Fasttext_cbow.train(sentences, total_examples=total_examples, epochs=5)

But I got this error : 
AttributeError: 'FastText' object has no attribute 'intersect_word2vec_format'


How can I fix this problem ? 
#### Versions

Please provide the output of:

```python
import platform; print(platform.platform()): Linux-4.4.0-164-generic-x86_64-with-debian-stretch-sid
import sys; print(""Python"", sys.version): Python 3.7.7 [GCC 7.3.0]
import numpy; print(""NumPy"", numpy.__version__): NumPy 1.18.1
import scipy; print(""SciPy"", scipy.__version__): SciPy 1.4.1
import gensim; print(""gensim"", gensim.__version__): gensim 3.8.0
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION): FAST_VERSION 1
```
"
717,https://github.com/RaRe-Technologies/gensim/issues/2862,2862,[],open,2020-06-20 02:16:10+00:00,,load_facebook_model() perturbs model with lower quality,"How can I get this to load the original model without reducing the quality as shown in the log? I plan to continue training and it automatically downsamples. When I call `model.build_vocab_from_freq()`, it also reduces from the intended vocab.
```
    from  gensim.models.fasttext import *
    model_path = datapath(model_file)
    model = load_facebook_model(model_path)

INFO:gensim.models._fasttext_bin:loading 2000000 words for fastText model from /home/me/data/external_models/cc.en.300.bin
INFO:gensim.models.word2vec:resetting layer weights
INFO:gensim.models.word2vec:Updating model with new vocabulary
INFO:gensim.models.word2vec:New added 2000000 unique words (50% of original 4000000) and increased the count of 2000000 pre-existing words (50% of original 4000000)
INFO:gensim.models.word2vec:deleting the raw counts dictionary of 2000000 items
INFO:gensim.models.word2vec:sample=1e-05 downsamples 6996 most-common words
INFO:gensim.models.word2vec:downsampling leaves estimated 390315457935 word corpus (70.7% of prior 552001338161)
INFO:gensim.models.fasttext:loaded (4000000, 300) weight matrix for fastText model from /home/me/data/external_models/cc.en.300.bin
```
The data I'm using is
`crawl-300d-2M-subword.zip: 2 million word vectors trained with subword information on Common Crawl (600B tokens).`

"
718,https://github.com/RaRe-Technologies/gensim/issues/2863,2863,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",closed,2020-06-20 18:39:04+00:00,,"Keep ""lifecycle log"" in models","## Why

When Gensim users report issues with models, we have trouble deciding what they actually did, what version they used, etc. They're often confused themselves.

This leads to protracted communication => increased support effort => slower issue resolution and more annoyance all around. Not good.

## What

Keep an internal ""lifecycle log"" inside each model. This could be as simple as an internal list-of-strings attribute, e.g. `word2vec.lifecycle = [""init() created on 2020-06-20 15:49:03 UTC with Gensim 3.8.3 on Python 3.6"", ""train() called on 2020-06-20 15:49:04 UTC"", ""load() called on 2020-06-29 8:7:58 UTC"", …]`. We would serialize this log on `save()`, and ask users to provide its value when investigating an issue.

We probably want to keep this simple and human-readable, both in the API and log content. Not to over-engineer to start with – not attempting a full model recreation from the log or anything, I can see how this could turn into a rabbit hole.

*Originally conceived by @gojomo in https://github.com/RaRe-Technologies/gensim/pull/2698#issuecomment-646929210.*"
719,https://github.com/RaRe-Technologies/gensim/issues/2865,2865,[],closed,2020-06-26 01:43:57+00:00,,Investigate and fix Keras problem under Python 3.8,"One of our unit tests fails on Travis under Py3.8.

```
=================================== FAILURES ===================================

_____________ TestKerasWord2VecWrapper.testEmbeddingLayerCosineSim _____________

self = <gensim.test.test_keras_integration.TestKerasWord2VecWrapper testMethod=testEmbeddingLayerCosineSim>

    def testEmbeddingLayerCosineSim(self):

        """"""

        Test Keras 'Embedding' layer returned by 'get_embedding_layer' function for a simple word similarity task.

        """"""

        keras_w2v_model = self.model_cos_sim

        keras_w2v_model_wv = keras_w2v_model.wv

    

        embedding_layer = keras_w2v_model_wv.get_keras_embedding()

    

        input_a = Input(shape=(1,), dtype='int32', name='input_a')

        input_b = Input(shape=(1,), dtype='int32', name='input_b')

        embedding_a = embedding_layer(input_a)

        embedding_b = embedding_layer(input_b)

        similarity = dot([embedding_a, embedding_b], axes=2, normalize=True)

    

>       model = Model(input=[input_a, input_b], output=similarity)

embedding_a = <tf.Tensor 'embedding_4/Identity:0' shape=(None, 1, 100) dtype=float32>

embedding_b = <tf.Tensor 'embedding_4_1/Identity:0' shape=(None, 1, 100) dtype=float32>

embedding_layer = <tensorflow.python.keras.layers.embeddings.Embedding object at 0x7f603df0d130>

input_a    = <tf.Tensor 'input_a_3:0' shape=(None, 1) dtype=int32>

input_b    = <tf.Tensor 'input_b_3:0' shape=(None, 1) dtype=int32>

keras_w2v_model = <gensim.models.word2vec.Word2Vec object at 0x7f603df0d760>

keras_w2v_model_wv = <gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x7f603df0d250>

self       = <gensim.test.test_keras_integration.TestKerasWord2VecWrapper testMethod=testEmbeddingLayerCosineSim>

similarity = <tf.Tensor 'dot_3/Identity:0' shape=(None, 1, 1) dtype=float32>

gensim/test/test_keras_integration.py:62: 

_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.tox/py38-linux/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:167: in __init__

    super(Model, self).__init__(*args, **kwargs)

        __class__  = <class 'tensorflow.python.keras.engine.training.Model'>

        args       = ()

        kwargs     = {'input': [<tf.Tensor 'input_a_3:0' shape=(None, 1) dtype=int32>, <tf.Tensor 'input_b_3:0' shape=(None, 1) dtype=int32>], 'output': <tf.Tensor 'dot_3/Identity:0' shape=(None, 1, 1) dtype=float32>}

        self       = <tensorflow.python.keras.engine.training.Model object at 0x7f603df18ac0>

.tox/py38-linux/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py:176: in __init__

    self._init_subclassed_network(**kwargs)

        args       = ()

        kwargs     = {'input': [<tf.Tensor 'input_a_3:0' shape=(None, 1) dtype=int32>, <tf.Tensor 'input_b_3:0' shape=(None, 1) dtype=int32>], 'output': <tf.Tensor 'dot_3/Identity:0' shape=(None, 1, 1) dtype=float32>}

        self       = <tensorflow.python.keras.engine.training.Model object at 0x7f603df18ac0>

.tox/py38-linux/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py:456: in _method_wrapper

    result = method(self, *args, **kwargs)

        args       = ()

        kwargs     = {'input': [<tf.Tensor 'input_a_3:0' shape=(None, 1) dtype=int32>, <tf.Tensor 'input_b_3:0' shape=(None, 1) dtype=int32>], 'output': <tf.Tensor 'dot_3/Identity:0' shape=(None, 1, 1) dtype=float32>}

        method     = <function Network._init_subclassed_network at 0x7f60465f6d30>

        previous_value = True

        self       = <tensorflow.python.keras.engine.training.Model object at 0x7f603df18ac0>

.tox/py38-linux/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py:367: in _init_subclassed_network

    self._base_init(name=name, **kwargs)

        kwargs     = {'input': [<tf.Tensor 'input_a_3:0' shape=(None, 1) dtype=int32>, <tf.Tensor 'input_b_3:0' shape=(None, 1) dtype=int32>], 'output': <tf.Tensor 'dot_3/Identity:0' shape=(None, 1, 1) dtype=float32>}

        name       = None

        self       = <tensorflow.python.keras.engine.training.Model object at 0x7f603df18ac0>

.tox/py38-linux/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py:456: in _method_wrapper

    result = method(self, *args, **kwargs)

        args       = ()

        kwargs     = {'input': [<tf.Tensor 'input_a_3:0' shape=(None, 1) dtype=int32>, <tf.Tensor 'input_b_3:0' shape=(None, 1) dtype=int32>], 'name': None, 'output': <tf.Tensor 'dot_3/Identity:0' shape=(None, 1, 1) dtype=float32>}

        method     = <function Network._base_init at 0x7f60465f6a60>

        previous_value = False

        self       = <tensorflow.python.keras.engine.training.Model object at 0x7f603df18ac0>

.tox/py38-linux/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py:202: in _base_init

    generic_utils.validate_kwargs(kwargs, {'trainable', 'dtype', 'dynamic',

        __class__  = <class 'tensorflow.python.keras.engine.network.Network'>

        kwargs     = {'input': [<tf.Tensor 'input_a_3:0' shape=(None, 1) dtype=int32>, <tf.Tensor 'input_b_3:0' shape=(None, 1) dtype=int32>], 'output': <tf.Tensor 'dot_3/Identity:0' shape=(None, 1, 1) dtype=float32>}

        name       = None

        self       = <tensorflow.python.keras.engine.training.Model object at 0x7f603df18ac0>

_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

kwargs = {'input': [<tf.Tensor 'input_a_3:0' shape=(None, 1) dtype=int32>, <tf.Tensor 'input_b_3:0' shape=(None, 1) dtype=int32>], 'output': <tf.Tensor 'dot_3/Identity:0' shape=(None, 1, 1) dtype=float32>}

allowed_kwargs = {'autocast', 'dtype', 'dynamic', 'trainable'}

error_message = 'Keyword argument not understood:'

    def validate_kwargs(kwargs,

                        allowed_kwargs,

                        error_message='Keyword argument not understood:'):

      """"""Checks that all keyword arguments are in the set of allowed keys.""""""

      for kwarg in kwargs:

        if kwarg not in allowed_kwargs:

>         raise TypeError(error_message, kwarg)

E         TypeError: ('Keyword argument not understood:', 'input')

allowed_kwargs = {'autocast', 'dtype', 'dynamic', 'trainable'}

error_message = 'Keyword argument not understood:'

kwarg      = 'input'

kwargs     = {'input': [<tf.Tensor 'input_a_3:0' shape=(None, 1) dtype=int32>, <tf.Tensor 'input_b_3:0' shape=(None, 1) dtype=int32>], 'output': <tf.Tensor 'dot_3/Identity:0' shape=(None, 1, 1) dtype=float32>}
```"
720,https://github.com/RaRe-Technologies/gensim/issues/2870,2870,[],closed,2020-07-01 03:52:12+00:00,,Error ,"Hi,
I used python code uisng gensim , and I  got error and the output not printed.
![image](https://user-images.githubusercontent.com/20572241/86201124-f7381d00-bba1-11ea-972c-50866402f156.png)

/_**usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:56: DeprecationWarning:

Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).**_

"
721,https://github.com/RaRe-Technologies/gensim/issues/2872,2872,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}]",closed,2020-07-05 07:24:23+00:00,,Broken file link in `run_corpora_and_vector_spaces` tutorial,"#### Problem description

The `run_corpora_and_vector_spaces.ipynb` tutorial depends on a file on the web, and that file is missing.

#### Steps/code/corpus to reproduce

See https://groups.google.com/g/gensim/c/nX4lc8j0ZO0

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```

Unknown (probably any)."
722,https://github.com/RaRe-Technologies/gensim/issues/2873,2873,[],open,2020-07-06 20:00:39+00:00,,Further focus/slim keyedvectors.py module,"Pre-#2698, `keyedvectors.py` was 2500+ lines, including functionality over-specific to other models, & redundant classes. Post-#2698, with some added generic functionality, it's still over 1800 lines. 

It should shed some other grab-bag utility functions that have accumulated, & don't logically fit inside the `KeyedVectors` class. 

In particular, the evaluation (analogies, word_ranks) helpers could move to their own module that takes a KV instance as an argument. (If other more-sophisticated evaluations can be contributed, as would be welcome, they should also live alongside those, rather than bloating `KeyedVectors`.)

The `get_keras_embedding` method, as its utilit is narrow to very specific uses, and is conditional on a not-necessarily install package, could go elsewhere too – either a kera-focused utilities module, or even just documentation/example code about how to convert to/from keras from `KeyedVectors. 

Some of the more advanced word-vector-**using** calculations, like 'Word Mover's Distance' or 'Soft Cosine SImilarity', could move to method-specific modules that are then better documented/self-contained/optimized, without bloating the generic 'set of vectors' module. (They might be more discoverable, there, as well.)

And finally, some of the existing calculations could be unified/streamlined (especially the two variants of `most_similar()`, and some of the steps shared by multiple operations). My hope would be the module is eventually <1000 lines. "
723,https://github.com/RaRe-Technologies/gensim/issues/2876,2876,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2020-07-07 21:38:18+00:00,,corpus.mallet returned non-zero exit status 1.,"#### Problem description

So many people have had this issue, and I have tried all the fixes suggested, to no avail. The path is correct, and I have changed it multiple times to remove spaces etc. I get the same error. Bearing in mind I have no idea how to provide all the information necessary, please respond with precise instructions as to how to debug this issue.

**Error is**
CalledProcessError: Command 'mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex ""\S+"" --input C:\Users\DraGoN\AppData\Local\Temp\b76d8f_corpus.txt --output C:\Users\DraGoN\AppData\Local\Temp\b76d8f_corpus.mallet' returned non-zero exit status 1.

I have looked and the temp files do exist in the temp directory. I have even tried editing the .bat file to hard code the mallet_home directory, and the java installation directory. Nothing works. I get the same error.

#### Steps/code/corpus to reproduce
```python
import os
from gensim.models.wrappers import LdaMallet

os.environ.update({'MALLET_HOME':r'C:/Users/DraGoN/Documents/python/mallet-2.0.8'})
mallet_path = 'mallet-2.0.8/bin/mallet' # update this path

#Alternative LDA model, download here and put in directory - https://www.machinelearningplus.com/wp-content/uploads/2018/03/mallet-2.0.8.zip
ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)`
```
#### Versions

Please provide the output of:

```python
Windows-10-10.0.18362-SP0
Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]
NumPy 1.19.0
SciPy 1.4.1
gensim 3.8.3
FAST_VERSION 1
```
"
724,https://github.com/RaRe-Technologies/gensim/issues/2877,2877,[],closed,2020-07-08 17:12:38+00:00,,Finetuning gensim doc2vec,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

My question is about fine-tune a pretrained doc2vec model on Gensim. Suppose that we have a doc2vec model pretrained on Wikipedia corpus, and we have another specified small corpus. My aim is to fine-tune the pretrained model on my own corpus. Is it make sense in this context? Because, fine-tuning in this context means we want to increase the vocab of the pretrained model and consequently change the structure of the network! I have read several tutorial on the website but nothing  mentioned fine-tuning.

"
725,https://github.com/RaRe-Technologies/gensim/issues/2879,2879,"[{'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",open,2020-07-12 02:14:23+00:00,,Proposal: Replace word2vec-specific implementation w/ constrained subclass of FastText,"I believe that everything `Word2Vec` does can also already be done equivalently via `FastText`, with constrained options (like turning off char-ngrams). So we could potentially eliminate a lot of duplicated algorithm code & future maintenance overhead by recharacterizing `FastText` as the root of our 2Vec hierarchy, instead of the original `Word2Vec` code. 

We'd want to ensure `FastText` gracefully handles char-ngram-disablement (by not making allocations/class-choices only required when ngrams are enabled), and make `Word2Vec` a subclass of `FastText` which hides some options, rather than the other way around with `FastText` as a subclass that adds new options. 

User-visible APIs might not change at all. Some new ngram-enabled `Doc2Vec` options might become possible if `Doc2Vec` derives from `FastText` (like an inference that works at least a little, in some modes, even with all OOV words). 

(Relates to: #2852)
"
726,https://github.com/RaRe-Technologies/gensim/issues/2880,2880,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}, {'id': 1602334472, 'node_id': 'MDU6TGFiZWwxNjAyMzM0NDcy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20MEDIUM', 'name': 'impact MEDIUM', 'color': '7af49f', 'default': False, 'description': 'Big annoyance for affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",open,2020-07-12 04:39:25+00:00,,"Really remove the 10000-token limit in [Word2Vec, FastText, Doc2Vec]","The *2Vec models have an underdocumented implementation limit in their Cython paths: any single text passed to training that's more than 10000 tokens is silently truncated to 10000 tokens, discarding the rest. This may surprise users with larger texts - as much of the text, including words discovered during the vocabulary-survey (which doesn't truncate texts), can thus be skipped. 

Fixing this would make a warning like that I objected to in PR #2861 irrelevant. 

Fixing this would also fix #2583, the limit with respect to Doc2Vec inference. 

As mentioned in #2583, one possible fix would be to auto-break user texts into smaller chunks. Possible fixes thus include:

* auto-breaking user texts into <10k token internal texts
* using malloc, rather than a stack-allocated array of constant length, inside the Cython routines (might add allocate/free overhead & achieve less cache-locality than the current approach)
* use alloca - not an official part of the relevant C standard but likely available everywhere relevant (MacOS, Windows, Linux, BSDs, other Unixes) - instead of the constant stack-allocated array (some risk of overflowing if users provide gigantic texts)
* doing some one-time allocation per thread in Python-land that's usually reused for in Cython land small-sized texts, but when oversized texts are encountered replacing that with a larger allocation.

Each of these may need to be done slightly differently in the `corpus_file` high-thread-parallelism codepaths. "
727,https://github.com/RaRe-Technologies/gensim/issues/2881,2881,[],closed,2020-07-13 10:35:24+00:00,,"KeyedVectors.load_word2vec_format('w2v.bin',binary=False) raise Value Error","<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

A value exception was thrown while loading the word vector file.

#### Steps/code/corpus to reproduce
```
from gensim.models import Word2Vec
from gensim.models import KeyedVectors


common_texts = [['human', 'interface', 'computer',' '],
 ['survey', 'user', 'computer', 'system', 'response', 'time'],
 ['eps', 'user', 'interface', 'system'],
 ['system', 'human', 'system', 'eps'],
 ['user', 'response', 'time'],
 ['trees'],
 ['graph', 'trees'],
 ['graph', 'minors', 'trees'],
 ['graph', 'minors', 'survey']]
model = Word2Vec(common_texts, size=10, window=5, min_count=1, workers=4)
model.wv.save_word2vec_format('w2v.bin',binary=False)
# load word embedding
KeyedVectors.load_word2vec_format('w2v.bin',binary=False)
```

问题：加载训练语料的词向量文件过程中抛出值异常：
When there is a space in the corpus, the loading word vector file will throw a ValueError.
抛出异常的文件位置
**gensim/models/utils_any2vec.py**
```
parts = utils.to_unicode(line.rstrip(), encoding=encoding, errors=unicode_errors).split("" "")
if len(parts) != vector_size + 1:
    raise ValueError(""invalid vector on line %s (is this really the text format?)"" % line_no)
word, weights = parts[0], [datatype(x) for x in parts[1:]]
```

解决方案：去除预料中的空格或者使用加载模型的方式
Solution: remove the space in the corpus and load model

#### Versions

Please provide the output of:

Linux-4.4.0-142-generic-x86_64-with-debian-stretch-sid
Python 3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) 
[GCC 7.2.0]
NumPy 1.18.1
Sc```iPy 1.4.1
gensim 3.8.3
FAST_VERSION 1
"
728,https://github.com/RaRe-Technologies/gensim/issues/2882,2882,[],closed,2020-07-13 23:31:36+00:00,,"Working from trunk branch 'develop', gensim.__version__ reports as 3.8.1","If working in a checkout/branch from `develop`, `gensim.__version__` reports as `'3.8.1`, per https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/__init__.py#L8

Ideally, as part of the release process, this would be updated to reflect a precise release number in release tags/packaging, but then immediately thereafter changed to indicate something non-released - perhaps based on some implied next-release number, like `3.8.4-dev` or `4.0.0-dev`."
729,https://github.com/RaRe-Technologies/gensim/issues/2883,2883,[],closed,2020-07-14 23:38:01+00:00,,"Mmap model shared between process , memory use is not stable","#### Problem description

I'm exposing a word2vec model with Gunicorn sync workers.

_(and I run this gunicorn process inside one docker container )_

With 1 worker there is no problem. But with multiples workers ( forks from the main gunicorn process and with preload activated ) :

- mmap work well at statup , the memory use is almost the same than if I'm using only one process.

- But when I start to query the API ( each call execute a  `indexer.model.wv.most_similar` ) with a loadtest program, the memory usage grow until it stabilize.

This is with 8 sync workers (memory is growing):
![Screenshot from 2020-07-15 01-25-44](https://user-images.githubusercontent.com/10202690/87486375-7c5c1100-c63b-11ea-9f1f-ce835237dbc2.png)


 with only one worker the lines stay perfectly flat : 
![Screenshot from 2020-07-15 01-43-00](https://user-images.githubusercontent.com/10202690/87486905-a19d4f00-c63c-11ea-87f7-de820c8d49bd.png)


#### Steps/code/corpus to reproduce

Load a word2vec Gensim model with mmap activated and fork N times , then query the model in each subprocesses.

The problem is  already in stackoverflow , but no solution proposed : 

https://stackoverflow.com/questions/51616074/sharing-memory-for-gensims-keyedvectors-objects-between-docker-containers/51722607#51722607

What I tried :

This is the loading code of the model
```Python
from gensim.similarities.index import AnnoyIndexer
from gensim.models import KeyedVectors
from gensim.similarities import index as gensim_index
from my_project.patch_annoy import annoy_load

gensim_index.AnnoyIndexer.load = annoy_load # monkeypatch to put self.index.load(fname, prefault=True)

indexer = AnnoyIndexer()
indexer.load(LOCAL_MODEL_PATH)
wv = KeyedVectors.load(LOCAL_VECTORS_NORMED, mmap='r')
indexer.model = wv
```

Also i get this message when I load the previously normalized ( `init_sims(replace=True)` ) model is  :

`setting ignored attribute vectors_norm to None`

#### Versions


```
Linux-5.0.0-38-generic-x86_64-with-Ubuntu-19.04-disco
Python 3.7.3 (default, Oct  7 2019, 12:56:13) 
[GCC 8.3.0]
NumPy 1.17.1
SciPy 1.4.1
gensim 3.8.3
FAST_VERSION 1
```
"
730,https://github.com/RaRe-Technologies/gensim/issues/2884,2884,[],open,2020-07-15 12:56:17+00:00,,Not possible to continue training with hs=1...,"Hi,
i came now multiple times across this error... Now I want to post it.

It seems not possible to continue training if hs=1.
```

  File ""C:\Users\\Anaconda3\envs\tf2\lib\site-packages\gensim\models\fasttext.py"", line 617, in build_vocab
    keep_raw_vocab=keep_raw_vocab, trim_rule=trim_rule, **kwargs)
  File ""C:\Users\\Anaconda3\envs\tf2\lib\site-packages\gensim\models\base_any2vec.py"", line 929, in build_vocab
    self.trainables.prepare_weights(self.hs, self.negative, self.wv, update=update, vocabulary=self.vocabulary)
  File ""C:\Users\\Anaconda3\envs\tf2\lib\site-packages\gensim\models\fasttext.py"", line 1021, in prepare_weights
    super(FastTextTrainables, self).prepare_weights(hs, negative, wv, update=update, vocabulary=vocabulary)
  File ""C:\Users\\Anaconda3\envs\tf2\lib\site-packages\gensim\models\word2vec.py"", line 1689, in prepare_weights
    self.update_weights(hs, negative, wv)
  File ""C:\Users\\Anaconda3\envs\tf2\lib\site-packages\gensim\models\word2vec.py"", line 1734, in update_weights
    self.syn1 = vstack([self.syn1, zeros((gained_vocab, self.layer1_size), dtype=REAL)])
AttributeError: 'FastTextTrainables' object has no attribute 'syn1'


example

model=FastText(sg=1,hs=1,min_n=5,max_n=5,workers=4,ns_exponent=0.75,iter=5,alpha=0.025,window=5,size=300,negative=10,min_count=1)
model.build_vocab(sentences=sentences)
total_examples = model.corpus_count
model.train(sentences=sentences, total_examples=total_examples, epochs=model.epochs)

model.build_vocab(sentnews, update=True)
total_examples = model.corpus_count
model.train(sentences=sentnews, total_examples=total_examples, epochs=5)

```"
731,https://github.com/RaRe-Technologies/gensim/issues/2885,2885,[],closed,2020-07-16 07:31:38+00:00,,Broken link in the tutorial code,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

Reading the tutorial there is a sample url corpus at :

https://radimrehurek.com/gensim/auto_examples/core/mycorpus.txt

That link appears to be broken 
#### Steps/code/corpus to reproduce

click the link on the second page of the tutorial 

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
"
732,https://github.com/RaRe-Technologies/gensim/issues/2886,2886,[],open,2020-07-18 23:40:48+00:00,,Clean up keras code,"> But looking more closely at both the tested method & test code:
> 
> This utility function doesn't really belong cluttering up the `KeyedVectors` class: it's a fairly trivial bit of data-translation, very specific to some narrow uses, with an extra package requirement. It could & should be a in a keras-specific submodule that's only imported by people using keras, and could take the `KeyedVectors` instance as an argument (rather than `self`). 
> 
> Or, in the spirit of #2852 (""reduce gensim surface area""), it could be moved to a separate package (`gensim-extras`) - so it doesn't encumber testing/development of core gensim, or removed in favor of a tiny bit of example code, ""here's how you convert gensim KeyedVectors into a keras Embedding"", in docs, an example notebook, a 'recipes' webpage, or a blog post. It's 2-6 lines of trifling code, but its test failure due to a 'cosmic ray' from another project has soaked up a bunch of attention/time from 4 people who could be making other more important gensim improvements. 
> 
> Looking at the `test_keras_integration.py` code, it also failed because it was insufficiently focused on the gensim functionality.  It's not checking if the return value is just a translation of gensim values into a legal/sensible `Embedding` - it's doing some full-cycle `Word2Vec` training and some full-cycle `keras` training. It's one of the 20 slowest tests in our whole test suite – sure, only ~9 seconds, but of negligible value usually over the many hundreds/thousands of times it's triggered as a result of other changes, and of negative value in this case. 
> 
> (Gensim has a bunch of tests that take a lot of time but don't test much real, just completion-without-error, and often which deeply test inner structural details rather than meaningful results, and thus serve as a drag on sensible refactorings when they trigger test failures that require maintenance without tangible benefits to developer or gensim end-users.)
> 
> To advance #2852, I'd copy the existing method code to a new wiki page on ""using gensim with keras"", leave a stub pointing users there, and remove the functionality/tests from gensim so there will be no further maintenance cost.

_Originally posted by @gojomo in https://github.com/RaRe-Technologies/gensim/pull/2869#issuecomment-651354811_"
733,https://github.com/RaRe-Technologies/gensim/issues/2887,2887,[],closed,2020-07-19 04:08:30+00:00,,Measure performance of gensim 4.0.0 vs previous versions,"Not every 1-line decision; just ones that are in inner loops of hot-spot code.

Definitely a big TODO: compare performance before/after.

_Originally posted by @piskvorky in https://github.com/_render_node/MDExOlB1bGxSZXF1ZXN0MzQ5Mjk1NTk1/timeline/more_items_"
734,https://github.com/RaRe-Technologies/gensim/issues/2888,2888,"[{'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",closed,2020-07-19 04:10:56+00:00,,Clean up variable names,"I think go with (a) now and open up a ticket to clean up names globally later. This PR is already large enough.

_Originally posted by @mpenkov in https://github.com/_render_node/MDExOlB1bGxSZXF1ZXN0MzQ5Mjk1NTk1/timeline/more_items_"
735,https://github.com/RaRe-Technologies/gensim/issues/2889,2889,[],closed,2020-07-19 13:14:09+00:00,,Document the X2Vec refactoring in the change log.,"Document the X2Vec refactoring in the change log.

What changed from the user's perspective?

_Originally posted by @mpenkov in https://github.com/RaRe-Technologies/gensim/pull/2698/review_comment/create_"
736,https://github.com/RaRe-Technologies/gensim/issues/2890,2890,"[{'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}, {'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",closed,2020-07-20 06:10:14+00:00,,Apply new convention of delimiting instance params in `str` function,"```suggestion
        return ""%s<%s>"" % (self.__class__.__name__, ', '.join(vals))
```

By convention, we now use `<>` to delimit instance parameters in `str()`.
I know this PR carried this code over without change, just cleaning up.

_Originally posted by @piskvorky in https://github.com/RaRe-Technologies/gensim/pull/2698_"
737,https://github.com/RaRe-Technologies/gensim/issues/2893,2893,[],closed,2020-07-23 20:41:33+00:00,," _pickle.UnpicklingError: invalid load key, '\xd0'.","<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? What is the expected result? What are you seeing instead?

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
"
738,https://github.com/RaRe-Technologies/gensim/issues/2894,2894,[],closed,2020-07-24 04:22:34+00:00,,Gensim Doc2Vec model Segmentation Faulting for Large Corpus,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? 
I was trying to train a doc2vec model on a corpus of 10M (10 millions) documents for my dataset roughly having a length of ~5000 words on average. The idea was to generate a semantic search index on these documents using the doc2vec model.

What is the expected result? 
I was expecting it to be completed successfully as I tested for the smaller dataset. On a smaller dataset of size 100K documents, it worked fine and I was able to do basic benchmarking for the search index, which successfully passed the criteria.

What are you seeing instead?
When I started training on the 10M dataset. After building the vocabulary the training of the doc2vec model stoped and resulted in **Segmentation Fault**.

#### Steps/code/corpus to reproduce


Include full tracebacks, logs, and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").
Here is the [link](https://github.com/mohsin-ashraf/reproduce-gensim-bug) to the example to reproduce it. It uses the following libraries (unfortunately I could not make a virtual env. due to some issues.) other than mentioned below.
[RandomWords](https://pypi.org/project/RandomWords/)

Attached is the logging file.
[logging_progress.log](https://github.com/RaRe-Technologies/gensim/files/4970118/logging_progress.log)

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```

```
Linux-4.15.0-45-generic-x86_64-with-Ubuntu-18.04-bionic
Python 3.6.9 (default, Nov  7 2019, 10:44:02) 
[GCC 8.3.0]
NumPy 1.19.0
SciPy 1.5.1
gensim 3.8.3
FAST_VERSION 1
```

[Here](https://groups.google.com/forum/?utm_medium=email&utm_source=footer#!msg/gensim/AK4ydLclz5g/bQsKVEUKCQAJ) is the google group thread for a detailed discussion
"
739,https://github.com/RaRe-Technologies/gensim/issues/2895,2895,[],closed,2020-07-24 13:12:25+00:00,,LdaMallet eta parameter ,"Hi!

Thanks for this great package! I have noticed that when using LdaMallet there is no option to adjust the eta parameter, which by default is 0.01 (in mallet train-topics).  Is there any plan to add this option?

Thanks!

C"
740,https://github.com/RaRe-Technologies/gensim/issues/2898,2898,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175986, 'node_id': 'MDU6TGFiZWwxNzU5ODY=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/testing', 'name': 'testing', 'color': '444444', 'default': False, 'description': 'Issue related with testing (code, documentation, etc)'}, {'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",open,2020-07-26 11:58:03+00:00,,Refused Visdom connection in Travis tests,"Sometimes the Gensim Travis tests fail because `Visdom.check_connection()` returns `False`:

https://travis-ci.org/github/RaRe-Technologies/gensim/jobs/711898928#L752

<img width=""1440"" alt=""Screen Shot 2020-07-26 at 13 55 33"" src=""https://user-images.githubusercontent.com/610412/88478320-bb496b00-cf47-11ea-9c51-2121828c4db6.png"">

I'm not sure what Visdom is or does, but the test code indicates a localhost connection. Not sure why that should fail.

**Task**: see whether we need that Visdom code, and if so, make the code/test more robust."
741,https://github.com/RaRe-Technologies/gensim/issues/2900,2900,[],closed,2020-07-27 04:37:16+00:00,,TypeError: summary() got an unexpected keyword argument 'sentenses',"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? What is the expected result? What are you seeing instead?

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
"
742,https://github.com/RaRe-Technologies/gensim/issues/2903,2903,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2020-07-28 13:01:41+00:00,,"""Wrong"" default parameter for [sum]alpha for LdaMallet","The [original Mallet](https://github.com/mimno/Mallet/blob/3bda6c73b2ff90d2e91a35dc6e9d604fbea8248e/src/cc/mallet/topics/tui/TopicTrainer.java#L152) default parameters are 
--alpha DECIMAL
  SumAlpha parameter: sum over topics of smoothing over doc-topic distributions. [alpha_k = [this value] / [num topics]](https://github.com/mimno/Mallet/blob/12487de1aa6433bdcf5af0ee0a17b368e64c7acf/src/cc/mallet/topics/ParallelTopicModel.java#L181)
  Default is 5.0
--beta DECIMAL
  Beta parameter: smoothing parameter for each topic-word. beta_w = [this value]
  Default is 0.01



The default value provided by gensim is confusing, as could be seen here:
https://stackoverflow.com/questions/52989568/lda-gensim-mallet-documentation-on-alpha

https://github.com/RaRe-Technologies/gensim/blob/27bbb7015dc6bbe02e00bb1853e7952ac13e7fe0/gensim/models/wrappers/ldamallet.py#L78"
743,https://github.com/RaRe-Technologies/gensim/issues/2906,2906,"[{'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",closed,2020-07-29 18:37:04+00:00,,Add 32/64-bit reporting to issue template,"It's be useful if the issue template also requested whether the local Python is a 32-bit or 64-bit executable. Adding this line to the ""Please provide the output of"" code should be enough:

```python
import struct; print(8 * struct.calcsize(""P""))
```"
744,https://github.com/RaRe-Technologies/gensim/issues/2908,2908,"[{'id': 175986, 'node_id': 'MDU6TGFiZWwxNzU5ODY=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/testing', 'name': 'testing', 'color': '444444', 'default': False, 'description': 'Issue related with testing (code, documentation, etc)'}, {'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",closed,2020-07-30 21:08:37+00:00,,Re-enable tests for Keras integration,"The Keras tests started failing on py3.7 + 3.8 in #2899:

https://travis-ci.org/github/RaRe-Technologies/gensim/jobs/713448950#L862

None of the changes in that PR seem related to these errors, so probably some TF / Keras weirdness again.

**Task**: Look into it and either fix, or rip out that entire Keras submodule. One of the contributed / never properly vetted features. Or Keras is that unstable… same difference."
745,https://github.com/RaRe-Technologies/gensim/issues/2912,2912,[],open,2020-08-06 20:02:31+00:00,,"D2VTransformer: if fit() accepts TaggedDocuments, transform() should as well","#### Problem description

I am trying to train and transform some documents using the D2VTransformer. The issue I am seeing is the following message when calling `transform`:

```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-51-ec0273aa2084> in <module>
----> 1 docvecs = model.transform(docs)

~/.pyenv/versions/3.7.8/lib/python3.7/site-packages/gensim/sklearn_api/d2vmodel.py in transform(self, docs)
    198         if isinstance(docs[0], string_types):
    199             docs = [docs]
--> 200         vectors = [self.gensim_model.infer_vector(doc) for doc in docs]
    201         return np.reshape(np.array(vectors), (len(docs), self.gensim_model.vector_size))

~/.pyenv/versions/3.7.8/lib/python3.7/site-packages/gensim/sklearn_api/d2vmodel.py in <listcomp>(.0)
    198         if isinstance(docs[0], string_types):
    199             docs = [docs]
--> 200         vectors = [self.gensim_model.infer_vector(doc) for doc in docs]
    201         return np.reshape(np.array(vectors), (len(docs), self.gensim_model.vector_size))

~/.pyenv/versions/3.7.8/lib/python3.7/site-packages/gensim/models/doc2vec.py in infer_vector(self, doc_words, alpha, min_alpha, epochs, steps)
    666         epochs = epochs or steps or self.epochs
    667 
--> 668         doctag_vectors, doctag_locks = self.trainables.get_doctag_trainables(doc_words, self.docvecs.vector_size)
    669         doctag_indexes = [0]
    670         work = zeros(self.trainables.layer1_size, dtype=REAL)

~/.pyenv/versions/3.7.8/lib/python3.7/site-packages/gensim/models/doc2vec.py in get_doctag_trainables(self, doc_words, vector_size)
   1217     def get_doctag_trainables(self, doc_words, vector_size):
   1218         doctag_vectors = zeros((1, vector_size), dtype=REAL)
-> 1219         doctag_vectors[0] = self.seeded_vector(' '.join(doc_words), vector_size)
   1220         doctag_locks = ones(1, dtype=REAL)
   1221         return doctag_vectors, doctag_locks

TypeError: sequence item 0: expected str instance, list found
```

#### Steps/code/corpus to reproduce
```
from gensim.utils import simple_preprocess
from gensim.sklearn_api import D2VTransformer
from gensim.models.doc2vec import Doc2Vec, TaggedDocument
docs = [TaggedDocument(simple_preprocess(doc), [i]) for i, doc in enumerate(df['docs'].values.tolist())]
model = D2VTransformer(size=128, window=10, min_count=5, workers=2)
model.fit(docs)
# error, from the next line
docvecs = model.transform(docs)
```

My tagged docs:

```
TaggedDocument(words=['mum', 'wows', 'after', 'doing', 'better', 'diy', 'job', 'cleaning', 'her', 'staircase', 'than', 'professionals', 'australian', 'woman', 'remove', 'mud', 'food', 'stains', 'rust', 'blood', 'wine', 'carpets', 'saying', 'worked', 'better', 'professional', 'cleaners', 'brought'], tags=[0])
```

#### Versions

```python
Darwin-19.5.0-x86_64-i386-64bit
Python 3.7.8 (default, Jul 23 2020, 13:28:14) 
[Clang 11.0.3 (clang-1103.0.32.62)]
Bits 64
NumPy 1.18.5
SciPy 1.4.1
gensim 3.8.3
FAST_VERSION 0
```
"
746,https://github.com/RaRe-Technologies/gensim/issues/2913,2913,"[{'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",open,2020-08-07 14:06:25+00:00,,Add tests that exercise the version pins in setup.py,"> I personally feel it's OK (and even beneficial) for fresh gensim releases to require fairly-recent releases of those libraries

Yes, upgrading numpy is not a problem. I'd expect our tests to fail though. I'm pretty sure we were testing against the oldest lib, explicitly, but with all the recent changes to the testing framework (azure etc) it's possible that fell through the cracks. We should put it back if possible, @mpenkov WDYT?

_Originally posted by @piskvorky in https://github.com/RaRe-Technologies/gensim/pull/2899#issuecomment-664175841_"
747,https://github.com/RaRe-Technologies/gensim/issues/2914,2914,[],closed,2020-08-09 15:56:05+00:00,,logs are printed without values,"
#### Problem description
the logs of `build_vocab` and `train` are printed without the values inside

examples:
`model.build_vocab(sentences=docs, progress_per=10000)`
```
08/09/2020 08:25:52 AM [INFO] collecting all words and their counts
08/09/2020 08:25:52 AM [INFO] PROGRESS: at sentence #%i, processed %i words, keeping %i word types
08/09/2020 08:25:52 AM [INFO] PROGRESS: at sentence #%i, processed %i words, keeping %i word types
08/09/2020 08:25:52 AM [INFO] PROGRESS: at sentence #%i, processed %i words, keeping %i word types
08/09/2020 08:25:52 AM [INFO] PROGRESS: at sentence #%i, processed %i words, keeping %i word types
08/09/2020 08:25:52 AM [INFO] PROGRESS: at sentence #%i, processed %i words, keeping %i word types
08/09/2020 08:25:53 AM [INFO] PROGRESS: at sentence #%i, processed %i words, keeping %i word types
08/09/2020 08:25:53 AM [INFO] PROGRESS: at sentence #%i, processed %i words, keeping %i word types
```

`model.train(sentences=docs, total_examples=len(docs), epochs=3)`
```
08/09/2020 08:26:05 AM [INFO] training model with %i workers on %i vocabulary and %i features, using sg=%s hs=%s sample=%s negative=%s window=%s
08/09/2020 08:26:06 AM [INFO] EPOCH %i - PROGRESS: at %.2f%% examples, %.0f words/s, in_qsize %i, out_qsize %i
08/09/2020 08:26:07 AM [INFO] EPOCH %i - PROGRESS: at %.2f%% examples, %.0f words/s, in_qsize %i, out_qsize %i
08/09/2020 08:26:08 AM [INFO] EPOCH %i - PROGRESS: at %.2f%% examples, %.0f words/s, in_qsize %i, out_qsize %i
08/09/2020 08:26:09 AM [INFO] EPOCH %i - PROGRESS: at %.2f%% examples, %.0f words/s, in_qsize %i, out_qsize %i
08/09/2020 08:26:10 AM [INFO] EPOCH %i - PROGRESS: at %.2f%% examples, %.0f words/s, in_qsize %i, out_qsize %i
08/09/2020 08:26:11 AM [INFO] EPOCH %i - PROGRESS: at %.2f%% examples, %.0f words/s, in_qsize %i, out_qsize %i
08/09/2020 08:26:12 AM [INFO] EPOCH %i - PROGRESS: at %.2f%% examples, %.0f words/s, in_qsize %i, out_qsize %i
08/09/2020 08:26:13 AM [INFO] EPOCH %i - PROGRESS: at %.2f%% examples, %.0f words/s, in_qsize %i, out_qsize %i
```
it happened both for FastText and Word2Vec models 

#### Versions

Linux-4.9.217-0.1.ac.205.84.332.metal1.x86_64-x86_64-with-redhat-5.3-Tikanga
Python 3.6.10 (default, Jul 27 2020, 00:14:34) 
[GCC 4.9.4]
Bits 64
NumPy 1.19.1
SciPy 1.2.1
gensim 3.8.3
FAST_VERSION 1"
748,https://github.com/RaRe-Technologies/gensim/issues/2915,2915,[],closed,2020-08-14 10:03:22+00:00,,docvecs.most_similar() does not return cosine similarity = 1 for same document vector,"If you call the most_similar() method with an inferred vector a top-n list of most similar documents including consine similarities is returned.

If the document was also present in the training set the returned most_similar document should be the same document. 

Suprisingly the cosine_similarity of the same document is  +-0.86 but never 1 

Is this a bug? Or is there any explanation for this behaviour?
"
749,https://github.com/RaRe-Technologies/gensim/issues/2916,2916,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",open,2020-08-16 11:01:16+00:00,,Add script to verify that autogenerated docs are up to date,"I see no real alternative either. Doesn't moving parts of our docs + testing elsewhere simply shift the problem around? That new place will still need testing, whenever things change. No difference.

Except code + docs in one place (=now) makes more sense conceptually IMO.

Yes, scripts / hooks that verify docs are in-sync, preferably at PR merge-time, would be nice.

_Originally posted by @piskvorky in https://github.com/RaRe-Technologies/gensim/pull/2907#issuecomment-671317949_"
750,https://github.com/RaRe-Technologies/gensim/issues/2918,2918,[],closed,2020-08-17 15:06:59+00:00,,intersect_word2vec_format lock-factor is not triggered when the data is not in the binary format,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

The method intersect_word2vec_format lacks updating the lock-factor (lockf) if the data is not in binary format.

#### Steps/code/corpus to reproduce

I base my issue on reading the source code of intersect_word2vec_format: https://tedboy.github.io/nlps/_modules/gensim/models/word2vec.html#Word2Vec.intersect_word2vec_format

In the [if binary: ... else: ... ] statement the lock is triggered only in the ""if"" clause: 
```
if word in self.vocab:
    overlap_count += 1
    self.syn0[self.vocab[word].index] = weights
    self.syn0_lockf[self.vocab[word].index] = lockf  # lock-factor: 0.0 stops further changes
``` 

However, when the data is not stored in the binary format, that is when the default binary=False value is passed, the lock is not triggered:

```
if word in self.vocab:
    overlap_count += 1
    self.syn0[self.vocab[word].index] = weights
```
#### Versions

I base my issue solely on the source code provided in the documentation.
"
751,https://github.com/RaRe-Technologies/gensim/issues/2919,2919,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}]",open,2020-08-18 15:47:59+00:00,,Uninitialized dictionary.id2token used in CoherenceModel,"#### Problem description

I have created multiple LdaModels and a CoherenceModel.
Calling ```coherence_model.compare_models([lda_model_1, lda_model_2])``` throws a KeyError.
This is caused by the following line:
https://github.com/RaRe-Technologies/gensim/blob/817cac99422a255001034203dc0720f7d0df0ce6/gensim/models/coherencemodel.py#L447

Initializing the dictionary (dictionary.id2token) beforehand fixes the problem (e.g. call ```dictionary[0]```).

The problem could be fixed by simply replacing the line with ``` topic = (self.dictionary[_id] for _id in topic)```."
752,https://github.com/RaRe-Technologies/gensim/issues/2920,2920,[],closed,2020-08-20 17:07:34+00:00,,Gensim's word2vec has a loss of 0 from epoch 1?,"I am using the Word2vec module of Gensim library to train a word embedding, the dataset is 400k sentences with 100k unique words (its not english)

I'm using this code to monitor and calculate the loss : 


```

class MonitorCallback(CallbackAny2Vec):
    def __init__(self, test_words):
        self._test_words = test_words




def on_epoch_end(self, model):
    print(""Model loss:"", model.get_latest_training_loss())  # print loss
    for word in self._test_words:  # show wv logic changes
        print(model.wv.most_similar(word))



monitor = MonitorCallback([""MyWord""])  # monitor with demo words


w2v_model = gensim.models.word2vec.Word2Vec(size=W2V_SIZE, window=W2V_WINDOW, min_count=W2V_MIN_COUNT  , callbacks=[monitor])

w2v_model.build_vocab(tokenized_corpus)


words = w2v_model.wv.vocab.keys()
vocab_size = len(words)
print(""Vocab size"", vocab_size)


print(""[*] Training..."")

w2v_model.train(tokenized_corpus, total_examples=len(tokenized_corpus), epochs=W2V_EPOCH)



```


The problem is from epoch 1 the loss is 0 and the vector of the monitored words dont change at all! 




    [*] Training...
    Model loss: 0.0
    Model loss: 0.0
    Model loss: 0.0
    Model loss: 0.0



so what is the problem here? is this normal?  the tokenized corpus is a list of lists that are something like tokenized_corpus[0] = [ ""word1"" , ""word2"" , ...]




I googled and seems like some of the old versions of gensim had problem with calculating loss function, but they are from almost a year ago and it seems like it should be fixed right now?




I tried the code provided in the answer of this question as well but still the loss is 0 : 

https://stackoverflow.com/questions/52038651/loss-does-not-decrease-during-training-word2vec-gensim"
753,https://github.com/RaRe-Technologies/gensim/issues/2924,2924,[],open,2020-08-27 22:24:01+00:00,,Add compute for value perplexity as an evaluation metrics for LDA and LDAseqmodel,"I have been trying to compute for value perplexity, topic diversity and topic quality in lda and ldaseq but I can't seem to find any method that has it"
754,https://github.com/RaRe-Technologies/gensim/issues/2925,2925,[],closed,2020-08-28 10:30:11+00:00,,Change parameter used in dtm_coherence() (in DTM wrapper) to avoid persistent warning,"Within the DTM wrapper, using `dtm_coherence()` always produces a warning:

> ""The parameter `num_words` is deprecated, will be removed in 4.0.0, use `topn` instead.""

Although the function works, obviously the intention is to deprecate the parameter at some point. 

This can be tracked back to `show_topic()`, which is where `num_words` has switched to `topn`. It is a very simple fix to just change the parameter used in the `dtm_coherence()` function accordingly. 

PR incoming with fix. "
755,https://github.com/RaRe-Technologies/gensim/issues/2927,2927,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",closed,2020-08-29 12:22:31+00:00,,RFC: New website design,"I've hired a designer to redesign the Gensim website, give it a more modern & unified look for our 4.0 release.

I asked them to keep the same content + structure = static ""plain HTML"" pages for the ""outside"" website, plus auto-generated docs for the ""inside"" API ref. Just looking better than the current https://radimrehurek.com/gensim/.

The designer came up with the following options. They are generic templates, to be customized and filled with content, so it's only about the general look&feel at this point.

### ""Outside"" pages

* http://be.beantownthemes.com/html/index-erp2.html
* http://be.beantownthemes.com/html/content/electronics/contact.html
* http://be.beantownthemes.com/html/index-landing2.html
* http://be.beantownthemes.com/html/index-app4.html
* http://be.beantownthemes.com/html/index-mechanic4.html
* http://be.beantownthemes.com/html/index-pay2.html
* http://preview.themeforest.net/item/saasbox-multipurpose-html-template-for-saas/full_screen_preview/25607146
* https://preview.themeforest.net/item/jumpstart-app-and-software-template/full_screen_preview/24207799
* http://preview.themeforest.net/item/landrick-responsive-saas-and-software-template/full_screen_preview/24438577

### ""Inner"" API reference pages

* https://sphinx-rtd-theme.readthedocs.io/en/stable/
* http://docs.guzzlephp.org/en/stable/
* https://bashtage.github.io/sphinx-material/

@gojomo @mpenkov any preference? Your input and comments are welcome. Otherwise I'll go ahead and pick something, not critical. Cheers."
756,https://github.com/RaRe-Technologies/gensim/issues/2928,2928,[],closed,2020-08-31 10:24:05+00:00,,The type information about job_queue in word2vec is wrong,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

`_worker_loop` and `_job_producer` say that the `job_queue` element is a `(list of object, dict of (str, int))` type, when in fact it appears to be a `(list of object, float)` type.
Is this a statement for a future change, or is it a mistake?

#### Steps/code/corpus to reproduce

```python
def _worker_loop(self, job_queue, progress_queue):
        """"""Train the model, lifting batches of data from the queue.

        This function will be called in parallel by multiple workers (threads or processes) to make
        optimal use of multicore machines.

        Parameters
        ----------
        job_queue : Queue of (list of objects, (str, int))
            A queue of jobs still to be processed. The worker will take up jobs from this queue.
            Each job is represented by a tuple where the first element is the corpus chunk to be processed and
            the second is the dictionary of parameters.
```

but

```python
def _job_producer(self, data_iterator, job_queue, cur_epoch=0, total_examples=None, total_words=None):
        ...
        next_job_params = self._get_job_params(cur_epoch)
        job_no = 0

        for data_idx, data in enumerate(data_iterator):
            data_length = self._raw_word_count([data])

            # can we fit this sentence into the existing job batch?
            if batch_size + data_length <= self.batch_words:
                # yes => add it to the current job
                job_batch.append(data)
                batch_size += data_length
            else:
                job_no += 1
                job_queue.put((job_batch, next_job_params))
```

In `_get_job_params`

```python
def _get_job_params(self, cur_epoch):
        """"""Get the learning rate used in the current epoch.

        Parameters
        ----------
        cur_epoch : int
            Current iteration through the corpus

        Returns
        -------
        float
            The learning rate for this epoch (it is linearly reduced with epochs from `self.alpha` to `self.min_alpha`).

        """"""
        alpha = self.alpha - ((self.alpha - self.min_alpha) * float(cur_epoch) / self.epochs)
        return alpha
```

#### Versions

```python
Darwin-19.6.0-x86_64-i386-64bit
Python 3.7.4 (default, Jan 24 2020, 20:34:38)
[Clang 11.0.0 (clang-1100.0.33.16)]
Bits 64
NumPy 1.19.1
SciPy 1.5.2
gensim 4.0.0.dev0
```
"
757,https://github.com/RaRe-Technologies/gensim/issues/2929,2929,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2020-09-01 01:37:18+00:00,,ImportError: cannot import name 'logsumexp' on KeyedVectors,"####Problem description

I'm unable to import KeyedVectors.

I guess replacing 
`from scipy.misc import logsumexp`
 to
`from scipy.special import logsumexp`
on the source code should fix it, but I'm not quite sure.

#### Steps/code/corpus to reproduce

from gensim.models import KeyedVectors

#### Versions

Linux-5.3.0-61-generic-x86_64-with-Ubuntu-18.04-bionic
Python 3.6.5 (default, Apr  1 2018, 05:46:30) 
[GCC 7.3.0]
Bits 64
NumPy 1.19.1
SciPy 1.5.2
"
758,https://github.com/RaRe-Technologies/gensim/issues/2932,2932,"[{'id': 175986, 'node_id': 'MDU6TGFiZWwxNzU5ODY=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/testing', 'name': 'testing', 'color': '444444', 'default': False, 'description': 'Issue related with testing (code, documentation, etc)'}, {'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",open,2020-09-03 07:05:28+00:00,,Change text corpus for unit tests,"Many of our tests currently use the Lee corpus, which is quite small.

The idea is to make the tests fast. But with such a small corpus, tests are flaky, which we ""solve"" by training in more epochs, which beats the purpose of using a small corpus.

**Task**: See how a larger corpus fares in test speed/stability. How about a corpus of the opening sections of the top-10k Wikipedia articles?

*Originally by @gojomo in https://github.com/RaRe-Technologies/gensim/pull/2930#issuecomment-685891470*:

> But, there's many other more basic & potentially higher-priority improvements to gensim testing that could also be considered...

> * harmonizing test-methods style to snake_case rather than leaked-in-from-JUnit's-origins camelCase
> * eliminating excess warnings/output, unless a test is specifically trying to exercise a warning - the clutter in output makes test results harder to review
> * using better data - doing a default Word2Vec epochs=5 train over a dataset thats 12x as large would be no slower, and much more substantive/valuable, than epochs=60 over a toy dataset
> * inventorying, better-naming/documenting, & committing-code-to-create any static test files that are necessary for other test methods - no more missing-version-numbers, generically-named, unclear-provenance ""old_model.bin"" or ""test_data.txt"" files
> * discarding outdated test methods (esp. loading ancient models)
> * removing fully-redundant tests that only do a subset of what other multiple other fuller-cycle tests are doing
> * ensure long-running tests are earning their runtime with substantive checks-of-functionality - no reason to run a 1-minute-long intense-training if the only check at the end is ""is the return value the right shape?""
check test coverage, to find any major methods/modes not being tested at all & add tests
> * moving to more-than-one suite, so that long/sensitive/subtle-performance-regression tests (that might take hours or even days to run, and be most interesting in lead-up to official releases) can be separate from the immediate/automatic tests (ideally completing in 5-10m) that are run every commit


"
759,https://github.com/RaRe-Technologies/gensim/issues/2933,2933,[],open,2020-09-07 08:24:24+00:00,,Giving -1 to show_topics in LDAMulticore and HDPModel will result in an empty array,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I'm trying to get a list of all topics in the model. So far I'm using `m_T` as a input as a workaround in HDPModel.
#### Versions
```
Linux-4.19.112+-x86_64-with-debian-buster-sid
Python 3.7.6 | packaged by conda-forge | (default, Mar 23 2020, 23:03:20) 
[GCC 7.3.0]
Bits 64
NumPy 1.18.5
SciPy 1.4.1
gensim 3.8.3
FAST_VERSION 1
```
"
760,https://github.com/RaRe-Technologies/gensim/issues/2934,2934,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}, {'id': 1602279836, 'node_id': 'MDU6TGFiZWwxNjAyMjc5ODM2', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20MEDIUM', 'name': 'reach MEDIUM', 'color': 'ef7a1a', 'default': False, 'description': 'Affects a significant number of users'}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}]",closed,2020-09-08 06:55:12+00:00,,"Word2Vec docs indicate sents can be a generator, but it can't","<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

Tried to pass a generator as the `sentences` argument when training Word2Vec, as suggested [in the docs](https://radimrehurek.com/gensim/models/word2vec.html#usage-examples:~:text=sentences%20can%20be%20a%20generator). But then I get this error:

    TypeError: You can't pass a generator as the sentences argument. Try a sequence.

#### Steps/code/corpus to reproduce

```

from gensim.models import Word2Vec

def get_sents():
    for ii in range(100):
        yield ['hi']

sents = get_sents()
model = Word2Vec(sents, size=100, window=5, min_count=1, workers=4)
```

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import struct; print(""Bits"", 8 * struct.calcsize(""P""))
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
```
Linux-5.8.5-arch1-1-x86_64-with-glibc2.2.5
Python 3.8.5 (default, Jul 27 2020, 08:42:51) 
[GCC 10.1.0]
Bits 64
NumPy 1.19.1
SciPy 1.4.1
gensim 3.8.3
FAST_VERSION 1
```
"
761,https://github.com/RaRe-Technologies/gensim/issues/2936,2936,[],open,2020-09-08 09:15:57+00:00,,PerplexityMetric example from docs doesn't print to terminal in my conda environment,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

> What are you trying to achieve? 

I am trying to print the perplexity of an LDA model to stdout/stderr in a shell.

> What is the expected result? 

Some floating point number printed to stdout/stderr
> What are you seeing instead?

I see no output in either stderr or stdout

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").
```sh 
$ cat test.py
from gensim.models.callbacks import PerplexityMetric
from gensim.models.ldamodel import LdaModel
from gensim.test.utils import common_corpus, common_dictionary

# Log the perplexity score at the end of each epoch.
perplexity_logger = PerplexityMetric(corpus=common_corpus, logger='shell')
lda = LdaModel(common_corpus, id2word=common_dictionary, num_topics=5, callbacks=[perplexity_logger])
$ python test.py
$
```
#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import struct; print(""Bits"", 8 * struct.calcsize(""P""))
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```

```
Python 3.6.11 | packaged by conda-forge | (default, Aug  5 2020, 20:09:42)
[GCC 7.5.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import platform; print(platform.platform())
Linux-5.4.0-7642-generic-x86_64-with-debian-bullseye-sid
>>> import sys; print(""Python"", sys.version)
Python 3.6.11 | packaged by conda-forge | (default, Aug  5 2020, 20:09:42)
[GCC 7.5.0]
>>> import struct; print(""Bits"", 8 * struct.calcsize(""P""))
Bits 64
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.19.1
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.5.2
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.8.3
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 0
```

I have also dumped my conda env to a pastebin, [here is the link](https://pastebin.com/Du3kJ5QC).

----

I feel like I'm missing something obvious here, but as far as I can tell this example *should* be printing perplexity in my terminal, but it isn't. Many thanks in advance to the people who take the time to reply to this issue."
762,https://github.com/RaRe-Technologies/gensim/issues/2938,2938,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 1602278675, 'node_id': 'MDU6TGFiZWwxNjAyMjc4Njc1', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20HIGH', 'name': 'reach HIGH', 'color': '229e03', 'default': False, 'description': 'Affects most or all Gensim users'}, {'id': 1602334472, 'node_id': 'MDU6TGFiZWwxNjAyMzM0NDcy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20MEDIUM', 'name': 'impact MEDIUM', 'color': '7af49f', 'default': False, 'description': 'Big annoyance for affected users'}, {'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",closed,2020-09-09 07:20:19+00:00,,Fix deprecations in SoftCosineSimilarity,"When running our CI test suite, I see an array of deprecation warnings:

https://dev.azure.com/rare-technologies/gensim-ci/_build/results?buildId=287&view=logs&jobId=f9575ddc-dec8-54e6-9d26-abb8bdd9bed7&j=f9575ddc-dec8-54e6-9d26-abb8bdd9bed7&t=180156a9-2bf9-537d-c84a-ef9e808c0367

Some are from gensim, some from scipy:
<img width=""1440"" alt=""Screen Shot 2020-09-09 at 09 16 00"" src=""https://user-images.githubusercontent.com/610412/92567026-635b8f00-f27d-11ea-9d5f-c56f3ba7c08b.png"">

@Witiko could you please have a look? Is it something your existing PR already addresses?

If not, can you please fix those? Thanks."
763,https://github.com/RaRe-Technologies/gensim/issues/2941,2941,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 1602257032, 'node_id': 'MDU6TGFiZWwxNjAyMjU3MDMy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20HIGH', 'name': 'impact HIGH', 'color': 'b60205', 'default': False, 'description': 'Show-stopper for affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",open,2020-09-10 15:46:05+00:00,,Clean up data streaming in topic coherence,"#### Problem description

The topic coherence functionality seems to require the entire input corpus to be in RAM. This is bad because:

a) Unnecessary and wasteful: The input is only accessed as `for doc in texts:` so streamed iterables would work fine.
b) Not in line in Gensim's core interfaces, which stream data and expect iterables, precisely to be memory-efficient.

#### Steps/code/corpus to reproduce

See https://groups.google.com/g/gensim/c/tZ_qV5wsBDw for a user report. 

OTOH, @gojomo reports [another code path](https://stackoverflow.com/questions/63769246/topic-modeling-memory-error-how-to-do-gensim-topic-modelling-when-with-large-am/63782260#63782260) where it seems that iterables on input should work. So IDK. Investigate & clean up the docs to not require a ""list of lists"", at the very least. And if something doesn't support streaming of large data, it doesn't belong in Gensim."
764,https://github.com/RaRe-Technologies/gensim/issues/2942,2942,[],closed,2020-09-10 22:59:30+00:00,,Segfault when training doc2vec,"#### Problem description

When attempting to train doc2vec, gensim segfaults.

#### Steps/code/corpus to reproduce

I run the code:
```
import faulthandler
import gensim
faulthandler.enable()
model = gensim.models.doc2vec.Doc2Vec(corpus_file = ""yelp_tripadvisor_linesentence.txt"", vector_size=250, min_count=10, epochs=40, workers = 5)
```
I get the output:
```
Fatal Python error: Segmentation fault

Current thread 0x00007f2d9effd700 (most recent call first):
  File ""/home/paul/.local/lib/python3.8/site-packages/gensim/models/doc2vec.py"", line 431 in _do_train_epoch
  File ""/home/paul/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py"", line 172 in _worker_loop_corpusfile
  File ""/usr/lib/python3.8/threading.py"", line 870 in run
  File ""/usr/lib/python3.8/threading.py"", line 932 in _bootstrap_inner
  File ""/usr/lib/python3.8/threading.py"", line 890 in _bootstrap

Thread 0x00007f2d9f7fe700 (most recent call first):
  File ""/home/paul/.local/lib/python3.8/site-packages/gensim/models/doc2vec.py"", line 431 in _do_train_epoch
  File ""/home/paul/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py"", line 172 in _worker_loop_corpusfile
  File ""/usr/lib/python3.8/threading.py"", line 870 in run
  File ""/usr/lib/python3.8/threading.py"", line 932 in _bootstrap_inner
  File ""/usr/lib/python3.8/threading.py"", line 890 in _bootstrap

Thread 0x00007f2d9ffff700 (most recent call first):
  File ""/home/paul/.local/lib/python3.8/site-packages/gensim/models/doc2vec.py"", line 431 in _do_train_epoch
  File ""/home/paul/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py"", line 172 in _worker_loop_corpusfile
  File ""/usr/lib/python3.8/threading.py"", line 870 in run
  File ""/usr/lib/python3.8/threading.py"", line 932 in _bootstrap_inner
  File ""/usr/lib/python3.8/threading.py"", line 890 in _bootstrap

Thread 0x00007f2da48df700 (most recent call first):
  File ""/home/paul/.local/lib/python3.8/site-packages/gensim/models/doc2vec.py"", line 431 in _do_train_epoch
  File ""/home/paul/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py"", line 172 in _worker_loop_corpusfile
  File ""/usr/lib/python3.8/threading.py"", line 870 in run
  File ""/usr/lib/python3.8/threading.py"", line 932 in _bootstrap_inner
  File ""/usr/lib/python3.8/threading.py"", line 890 in _bootstrap

Thread 0x00007f2da50e0700 (most recent call first):
  File ""/home/paul/.local/lib/python3.8/site-packages/gensim/models/doc2vec.py"", line 431 in _do_train_epoch
  File ""/home/paul/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py"", line 172 in _worker_loop_corpusfile
  File ""/usr/lib/python3.8/threading.py"", line 870 in run
  File ""/usr/lib/python3.8/threading.py"", line 932 in _bootstrap_inner
  File ""/usr/lib/python3.8/threading.py"", line 890 in _bootstrap

Thread 0x00007f3055bd1740 (most recent call first):
  File ""/usr/lib/python3.8/threading.py"", line 302 in wait
  File ""/usr/lib/python3.8/queue.py"", line 170 in get
  File ""/home/paul/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py"", line 345 in _log_epoch_progress
  File ""/home/paul/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py"", line 430 in _train_epoch_corpusfile
  File ""/home/paul/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py"", line 554 in train
  File ""/home/paul/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py"", line 1063 in train
  File ""/home/paul/.local/lib/python3.8/site-packages/gensim/models/doc2vec.py"", line 554 in train
  File ""/home/paul/.local/lib/python3.8/site-packages/gensim/models/doc2vec.py"", line 360 in __init__
  File ""reproduce_segfault.py"", line 4 in <module>
Segmentation fault (core dumped)

```

When run in gdb I get:

```
Thread 36 ""python3"" received signal SIGSEGV, Segmentation fault.
[Switching to Thread 0x7ffd450ca700 (LWP 112905)]
0x00007fffc9347737 in saxpy_kernel_16 ()
   from /home/paul/.local/lib/python3.8/site-packages/scipy/spatial/../../scipy.libs/libopenblasp-r0-085ca80a.3.9.so
```

The backtrace I get is:

```
(gdb) backtrace
#0  0x00007fffc9347737 in saxpy_kernel_16 ()
   from /home/paul/.local/lib/python3.8/site-packages/scipy/spatial/../../scipy.libs/libopenblasp-r0-085ca80a.3.9.so
#1  0x00007fffc934792f in saxpy_k_ZEN ()
   from /home/paul/.local/lib/python3.8/site-packages/scipy/spatial/../../scipy.libs/libopenblasp-r0-085ca80a.3.9.so
#2  0x00007fffc84402cb in saxpy_ ()
   from /home/paul/.local/lib/python3.8/site-packages/scipy/spatial/../../scipy.libs/libopenblasp-r0-085ca80a.3.9.so
#3  0x00007fffa0e81782 in ?? ()
   from /home/paul/.local/lib/python3.8/site-packages/gensim/models/doc2vec_corpusfile.cpython-38-x86_64-linux-gnu.so
#4  0x00007fffa0e8243f in ?? ()
   from /home/paul/.local/lib/python3.8/site-packages/gensim/models/doc2vec_corpusfile.cpython-38-x86_64-linux-gnu.so
#5  0x00000000005f17e5 in cfunction_call_varargs (kwargs=<optimized out>, args=<optimized out>, 
    func=<built-in function d2v_train_epoch_dm>) at ../Objects/call.c:772
#6  PyCFunction_Call (func=<built-in function d2v_train_epoch_dm>, args=<optimized out>, kwargs=<optimized out>) at ../Objects/call.c:772
#7  0x00000000005f2406 in _PyObject_MakeTpCall (callable=<built-in function d2v_train_epoch_dm>, args=<optimized out>, 
    nargs=<optimized out>, keywords=<optimized out>) at ../Include/internal/pycore_pyerrors.h:13
#8  0x000000000056cfd4 in _PyObject_Vectorcall (kwnames=('doctag_vectors', 'doctag_locks'), nargsf=<optimized out>, 
    args=<optimized out>, callable=<built-in function d2v_train_epoch_dm>) at ../Include/cpython/abstract.h:125
#9  _PyObject_Vectorcall (kwnames=('doctag_vectors', 'doctag_locks'), nargsf=<optimized out>, args=<optimized out>, 
    callable=<built-in function d2v_train_epoch_dm>) at ../Include/cpython/abstract.h:115
#10 call_function (kwnames=('doctag_vectors', 'doctag_locks'), oparg=<optimized out>, pp_stack=<synthetic pointer>, 
    tstate=<optimized out>) at ../Python/ceval.c:4987
#11 _PyEval_EvalFrameDefault (f=<optimized out>, throwflag=<optimized out>) at ../Python/ceval.c:3515
#12 0x0000000000565972 in PyEval_EvalFrameEx (throwflag=0, 
    f=Frame 0x7ffd34001710, for file /home/paul/.local/lib/python3.8/site-packages/gensim/models/doc2vec.py, line 1199, in _do_train_epoch (self=<Doc2Vec(sg=0, alpha=<float at remote 0x7fffa19bd8d0>, window=5, random=<numpy.random.mtrand.RandomState at remote 0x7fffa09f4640>, min_alpha=<float at remote 0x7fffa19bd910>, hs=0, negative=5, ns_exponent=<float at remote 0x7fffa19bd930>, cbow_mean=1, compute_loss=False, running_training_loss=<float at remote 0x7fffa19bd870>, min_alpha_yet_reached=<float at remote 0x7fffa19bd8d0>, corpus_count=9643078, corpus_total_words=1099181249, vector_size=250, workers=5, epochs=40, train_count=0, total_train_time=0, batch_words=10000, model_trimmed_--Type <RE--Type <RET> for more, q to quit, c to contin--Type <RET> for more, q to quit, c to continue without--Type <RET> for more, q --Type <RET> fo--Typ--Typ--Type <RET> for more, q to quit, c to continue without paging--
post_training=False, callbacks=(), load=<function at remote 0x7ffff412f310>, dbow_words=0, dm_concat=0, dm_tag_count=1, vocabulary=<Doc2VecVocab(max_vocab_size=None, min_count=10, sample=<float at remote 0x7fffa12f9670>, sorted_vocab=True, null_word=0, cum_table=<numpy.ndarray at remote 0x7fffa0998c10>, raw_vocab={}, max_final_vocab=None,...(truncated)) at ../Python/ceval.c:741
#13 _PyEval_EvalCodeWithName (_co=<optimized out>, globals=<optimized out>, locals=<optimized out>, args=<optimized out>, argcount=<optimized out>, 
    kwnames=<optimized out>, kwargs=0x7fffa0a01d68, kwcount=<optimized out>, kwstep=1, defs=0x7fffa12ad0f8, defcount=4, kwdefs=0x0, closure=0x0, name='_do_train_epoch', 
    qualname='Doc2Vec._do_train_epoch') at ../Python/ceval.c:4298
#14 0x00000000005f1d85 in _PyFunction_Vectorcall (func=<optimized out>, stack=0x7fffa0a01d30, nargsf=<optimized out>, kwnames=<optimized out>) at ../Objects/call.c:435
#15 0x0000000000507729 in _PyObject_Vectorcall (
    kwnames=('total_examples', 'total_words', 'start_alpha', 'end_alpha', 'word_count', 'compute_loss', 'offsets', 'start_doctags'), nargsf=7, args=0x7fffa0a01d30, 
    callable=<function at remote 0x7fffa12ba3a0>) at ../Include/cpython/abstract.h:127
#16 method_vectorcall (method=<optimized out>, args=<optimized out>, nargsf=<optimized out>, 
    kwnames=('total_examples', 'total_words', 'start_alpha', 'end_alpha', 'word_count', 'compute_loss', 'offsets', 'start_doctags')) at ../Objects/classobject.c:89
#17 0x00000000005f1107 in PyVectorcall_Call (kwargs=<optimized out>, tuple=<optimized out>, callable=<method at remote 0x7fff9d8c7600>) at ../Objects/call.c:199
#18 PyObject_Call (callable=<method at remote 0x7fff9d8c7600>, args=<optimized out>, kwargs=<optimized out>) at ../Objects/call.c:227
#19 0x0000000000568e1f in do_call_core (
    kwdict={'total_examples': 9643078, 'total_words': 1099181249, 'start_alpha': <float at remote 0x7fffa19bd8d0>, 'end_alpha': <float at remote 0x7fffa19bd910>, 'word_count': 0, 'compute_loss': False, 'offsets': [0, 1186792315, 2373585688, 3560378663, 4747171525], 'start_doctags': [0, 1296629, 3235497, 5388103, 7520884]}, 
    callargs=('yelp_tripadvisor_linesentence.txt', 4, <float at remote 0x7fff98254b10>, <gensim.models.word2vec_corpusfile.CythonVocab at remote 0x7fff9dde38e0>, (<numpy.ndarray at remote 0x7fff9de26170>, <numpy.ndarray at remote 0x7fff9de26990>), 0), func=<method at remote 0x7fff9d8c7600>, tstate=<optimized out>)
    at ../Python/ceval.c:5034
#20 _PyEval_EvalFrameDefault (f=<optimized out>, throwflag=<optimized out>) at ../Python/ceval.c:3559
#21 0x0000000000565972 in PyEval_EvalFrameEx (throwflag=0, 
    f=Frame 0x7ffd34000ba0, for file /home/paul/.local/lib/python3.8/site-packages/gensim/models/base_any2vec.py, line 940, in _worker_loop_corpusfile (self=<Doc2Vec(sg=0, alpha=<float at remote 0x7fffa19bd8d0>, window=5, random=<numpy.random.mtrand.RandomState at remote 0x7fffa09f4640>, min_alpha=<float at remote 0x7fffa19bd910>, hs=0, negative=5, ns_exponent=<float at remote 0x7fffa19bd930>, cbow_mean=1, compute_loss=False, running_training_loss=<float at remote 0x7fffa19bd870>, min_alpha_yet_reached=<float at remote 0x7fffa19bd8d0>, corpus_count=9643078, corpus_total_words=1099181249, vector_size=250, workers=5, epochs=40, train_count=0, total_train_time=0, batch_words=10000, model_trimmed_post_training=False, callbacks=(), load=<function at remote 0x7ffff412f310>, dbow_words=0, dm_concat=0, dm_tag_count=1, vocabulary=<Doc2VecVocab(max_vocab_size=None, min_count=10, sample=<float at remote 0x7fffa12f9670>, sorted_vocab=True, null_word=0, cum_table=<numpy.ndarray at remote 0x7fffa0998c10>, raw_vocab={}, max_final...(truncated)) at ../Python/ceval.c:741
#22 _PyEval_EvalCodeWithName (_co=<optimized out>, globals=<optimized out>, locals=<optimized out>, args=<optimized out>, argcount=<optimized out>, 
    kwnames=<optimized out>, kwargs=0x7fffa0a01ce0, kwcount=<optimized out>, kwstep=1, defs=0x7fffa178ba58, defcount=3, kwdefs=0x0, closure=0x0, 
    name='_worker_loop_corpusfile', qualname='BaseAny2VecModel._worker_loop_corpusfile') at ../Python/ceval.c:4298
#23 0x00000000005f1d85 in _PyFunction_Vectorcall (func=<optimized out>, stack=0x7fffa0a01cb0, nargsf=<optimized out>, kwnames=<optimized out>) at ../Objects/call.c:435
#24 0x0000000000507729 in _PyObject_Vectorcall (
    kwnames=('start_alpha', 'end_alpha', 'word_count', 'compute_loss', 'offsets', 'start_doctags', 'cur_epoch', 'total_examples', 'total_words'), nargsf=6, 
    args=0x7fffa0a01cb0, callable=<function at remote 0x7fffa17970d0>) at ../Include/cpython/abstract.h:127
#25 method_vectorcall (method=<optimized out>, args=<optimized out>, nargsf=<optimized out>, 
    kwnames=('start_alpha', 'end_alpha', 'word_count', 'compute_loss', 'offsets', 'start_doctags', 'cur_epoch', 'total_examples', 'total_words'))
    at ../Objects/classobject.c:89
#26 0x00000000005f1107 in PyVectorcall_Call (kwargs=<optimized out>, tuple=<optimized out>, callable=<method at remote 0x7fff9d84cdc0>) at ../Objects/call.c:199
#27 PyObject_Call (callable=<method at remote 0x7fff9d84cdc0>, args=<optimized out>, kwargs=<optimized out>) at ../Objects/call.c:227
#28 0x0000000000568e1f in do_call_core (
    kwdict={'start_alpha': <float at remote 0x7fffa19bd8d0>, 'end_alpha': <float at remote 0x7fffa19bd910>, 'word_count': 0, 'compute_loss': False, 'offsets': [0, 1186792315, 2373585688, 3560378663, 4747171525], 'start_doctags': [0, 1296629, 3235497, 5388103, 7520884], 'cur_epoch': 0, 'total_examples': 9643078, 'total_words': 1099181249}, 
    callargs=('yelp_tripadvisor_linesentence.txt', 4, <float at remote 0x7fff98254b10>, <gensim.models.word2vec_corpusfile.CythonVocab at remote 0x7fff9dde38e0>, <Queue(maxsize=0, queue=<collections.deque at remote 0x7fff9dde3d00>, mutex=<_thread.lock at remote 0x7fff98710420>, not_empty=<Condition(_lock=<_thread.lock at remote 0x7fff98710420>, acquire=<built-in method acquire of _thread.lock object at remote 0x7fff98710420>, release=<built-in method release of _thread.lock object at remote 0x7fff98710420>, _waiters=<collections.deque at remote 0x7fff9dde3ca0>) at remote 0x7fff98710460>, not_full=<Condition(_lock=<_thread.lock at remote 0x7fff98710420>, acquire=<built-in method acquire of _thread.lock object at remote 0x7fff98710420>, release=<built-in method release of _thread.lock object at remote 0x7fff98710420>, _waiters=<collections.deque at remote 0x7fff9dde3c40>) at remote 0x7fff987104c0>, all_tasks_done=<Condition(_lock=<_thread.lock at remote 0x7fff98710420>, acquire=<built-in method acquire of _thre--Type <RET> for more, q to quit, c to continue without paging--
ad.lock objec...(truncated), func=<method at remote 0x7fff9d84cdc0>, tstate=<optimized out>) at ../Python/ceval.c:5034
#29 _PyEval_EvalFrameDefault (f=<optimized out>, throwflag=<optimized out>) at ../Python/ceval.c:3559
#30 0x00000000005f1b8b in PyEval_EvalFrameEx (throwflag=0, 
    f=Frame 0x7fff9f3ee740, for file /usr/lib/python3.8/threading.py, line 870, in run (self=<Thread(_target=<method at remote 0x7fff9d84cdc0>, _name='Thread-5', _args=('yelp_tripadvisor_linesentence.txt', 4, <float at remote 0x7fff98254b10>, <gensim.models.word2vec_corpusfile.CythonVocab at remote 0x7fff9dde38e0>, <Queue(maxsize=0, queue=<collections.deque at remote 0x7fff9dde3d00>, mutex=<_thread.lock at remote 0x7fff98710420>, not_empty=<Condition(_lock=<_thread.lock at remote 0x7fff98710420>, acquire=<built-in method acquire of _thread.lock object at remote 0x7fff98710420>, release=<built-in method release of _thread.lock object at remote 0x7fff98710420>, _waiters=<collections.deque at remote 0x7fff9dde3ca0>) at remote 0x7fff98710460>, not_full=<Condition(_lock=<_thread.lock at remote 0x7fff98710420>, acquire=<built-in method acquire of _thread.lock object at remote 0x7fff98710420>, release=<built-in method release of _thread.lock object at remote 0x7fff98710420>, _waiters=<collections.deque at remote 0x7fff9dd...(truncated)) at ../Python/ceval.c:741
#31 function_code_fastcall (globals=<optimized out>, nargs=<optimized out>, args=<optimized out>, co=<optimized out>) at ../Objects/call.c:283
#32 _PyFunction_Vectorcall (func=<optimized out>, stack=<optimized out>, nargsf=<optimized out>, kwnames=<optimized out>) at ../Objects/call.c:410
#33 0x00000000005677c7 in _PyObject_Vectorcall (kwnames=0x0, nargsf=<optimized out>, args=0x7fff9f35c7b8, callable=<function at remote 0x7ffff732e9d0>)
    at ../Include/cpython/abstract.h:127
#34 call_function (kwnames=0x0, oparg=<optimized out>, pp_stack=<synthetic pointer>, tstate=0xac0530) at ../Python/ceval.c:4987
#35 _PyEval_EvalFrameDefault (f=<optimized out>, throwflag=<optimized out>) at ../Python/ceval.c:3486
#36 0x00000000005f1b8b in PyEval_EvalFrameEx (throwflag=0, 
    f=Frame 0x7fff9f35c640, for file /usr/lib/python3.8/threading.py, line 932, in _bootstrap_inner (self=<Thread(_target=<method at remote 0x7fff9d84cdc0>, _name='Thread-5', _args=('yelp_tripadvisor_linesentence.txt', 4, <float at remote 0x7fff98254b10>, <gensim.models.word2vec_corpusfile.CythonVocab at remote 0x7fff9dde38e0>, <Queue(maxsize=0, queue=<collections.deque at remote 0x7fff9dde3d00>, mutex=<_thread.lock at remote 0x7fff98710420>, not_empty=<Condition(_lock=<_thread.lock at remote 0x7fff98710420>, acquire=<built-in method acquire of _thread.lock object at remote 0x7fff98710420>, release=<built-in method release of _thread.lock object at remote 0x7fff98710420>, _waiters=<collections.deque at remote 0x7fff9dde3ca0>) at remote 0x7fff98710460>, not_full=<Condition(_lock=<_thread.lock at remote 0x7fff98710420>, acquire=<built-in method acquire of _thread.lock object at remote 0x7fff98710420>, release=<built-in method release of _thread.lock object at remote 0x7fff98710420>, _waiters=<collections.deque at rem...(truncated)) at ../Python/ceval.c:741
#37 function_code_fastcall (globals=<optimized out>, nargs=<optimized out>, args=<optimized out>, co=<optimized out>) at ../Objects/call.c:283
#38 _PyFunction_Vectorcall (func=<optimized out>, stack=<optimized out>, nargsf=<optimized out>, kwnames=<optimized out>) at ../Objects/call.c:410
#39 0x00000000005677c7 in _PyObject_Vectorcall (kwnames=0x0, nargsf=<optimized out>, args=0x7fff9f3ee6f8, callable=<function at remote 0x7ffff732eca0>)
    at ../Include/cpython/abstract.h:127
#40 call_function (kwnames=0x0, oparg=<optimized out>, pp_stack=<synthetic pointer>, tstate=0xac0530) at ../Python/ceval.c:4987
#41 _PyEval_EvalFrameDefault (f=<optimized out>, throwflag=<optimized out>) at ../Python/ceval.c:3486
#42 0x00000000005f1b8b in PyEval_EvalFrameEx (throwflag=0, 
    f=Frame 0x7fff9f3ee580, for file /usr/lib/python3.8/threading.py, line 890, in _bootstrap (self=<Thread(_target=<method at remote 0x7fff9d84cdc0>, _name='Thread-5', _args=('yelp_tripadvisor_linesentence.txt', 4, <float at remote 0x7fff98254b10>, <gensim.models.word2vec_corpusfile.CythonVocab at remote 0x7fff9dde38e0>, <Queue(maxsize=0, queue=<collections.deque at remote 0x7fff9dde3d00>, mutex=<_thread.lock at remote 0x7fff98710420>, not_empty=<Condition(_lock=<_thread.lock at remote 0x7fff98710420>, acquire=<built-in method acquire of _thread.lock object at remote 0x7fff98710420>, release=<built-in method release of _thread.lock object at remote 0x7fff98710420>, _waiters=<collections.deque at remote 0x7fff9dde3ca0>) at remote 0x7fff98710460>, not_full=<Condition(_lock=<_thread.lock at remote 0x7fff98710420>, acquire=<built-in method acquire of _thread.lock object at remote 0x7fff98710420>, release=<built-in method release of _thread.lock object at remote 0x7fff98710420>, _waiters=<collections.deque at remote 0x...(truncated)) at ../Python/ceval.c:741
#43 function_code_fastcall (globals=<optimized out>, nargs=<optimized out>, args=<optimized out>, co=<optimized out>) at ../Objects/call.c:283
#44 _PyFunction_Vectorcall (func=<optimized out>, stack=<optimized out>, nargsf=<optimized out>, kwnames=<optimized out>) at ../Objects/call.c:410
#45 0x000000000050722c in _PyObject_Vectorcall (kwnames=<optimized out>, nargsf=<optimized out>, args=<optimized out>, callable=<optimized out>)
    at ../Include/cpython/abstract.h:127
#46 method_vectorcall (method=<optimized out>, args=0x7ffff7634058, nargsf=<optimized out>, kwnames=<optimized out>) at ../Objects/classobject.c:89
#47 0x00000000005f1107 in PyVectorcall_Call (kwargs=<optimized out>, tuple=<optimized out>, callable=<method at remote 0x7fff9d8c7540>) at ../Objects/call.c:199
#48 PyObject_Call (callable=<method at remote 0x7fff9d8c7540>, args=<optimized out>, kwargs=<optimized out>) at ../Objects/call.c:227
#49 0x000000000064fb98 in t_bootstrap (boot_raw=boot_raw@entry=0x7fff9f33a150) at ../Modules/_threadmodule.c:1002
#50 0x000000000066ee14 in pythread_wrapper (arg=<optimized out>) at ../Python/thread_pthread.h:237
#51 0x00007ffff7d96609 in start_thread (arg=<optimized out>) at pthread_create.c:477
#52 0x00007ffff7ed2103 in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95
```

I can provide the corpus at request.

#### Versions

```
Linux-5.4.0-45-generic-x86_64-with-glibc2.29
Python 3.8.2 (default, Jul 16 2020, 14:00:26) 
[GCC 9.3.0]
Bits 64
NumPy 1.19.2
SciPy 1.5.2
gensim 3.8.3
FAST_VERSION 1
```
"
765,https://github.com/RaRe-Technologies/gensim/issues/2943,2943,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 1602257032, 'node_id': 'MDU6TGFiZWwxNjAyMjU3MDMy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20HIGH', 'name': 'impact HIGH', 'color': 'b60205', 'default': False, 'description': 'Show-stopper for affected users'}, {'id': 1602279836, 'node_id': 'MDU6TGFiZWwxNjAyMjc5ODM2', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20MEDIUM', 'name': 'reach MEDIUM', 'color': 'ef7a1a', 'default': False, 'description': 'Affects a significant number of users'}]",closed,2020-09-12 07:50:05+00:00,,Issue with calculation of `new_words` and `pre_exist_words`,"https://github.com/RaRe-Technologies/gensim/blob/bb947b38a23f10c40948ec6876bc0a850eafbcf6/gensim/models/word2vec.py#L602

`new_words` and `pre_exist_words` are initialized by reference as follows:
```python
new_words = pre_exist_words = []
```
This has a result every time an append happens to one of the two, both variables change because they refer to the same underlying list. Therefore, the calculation of `new_words` and `pre_exist_words` is not correct.

The solution would simply be:
```python
new_words = []
pre_exist_words = []
```

This has downstream implications. The calculation of `retain_words` (`retain_words = new_words + pre_exist_words`)  is also not correct because of that.
"
766,https://github.com/RaRe-Technologies/gensim/issues/2948,2948,[],closed,2020-09-16 08:21:41+00:00,,rename 8.6 tag to 0.8.6,"#### Problem description

There is a tag ""8.6"" in the repository that is between 0.8.7 and 0.8.5 in terms of when it was created, but it is missing the 0 at the start.

#### Steps/code/corpus to reproduce

```
git clone https://github.com/RaRe-Technologies/gensim.git
cd gensim
git tag | grep -v '^[0-3]'
```

Or load the github tags page:

https://github.com/RaRe-Technologies/gensim/tags?after=0.8.9

#### Versions

0.8.6

#### Suggested fix

```
git tag 0.8.6 8.6
git tag -d 8.6
git push --delete origin 8.6
git push --tags
```"
767,https://github.com/RaRe-Technologies/gensim/issues/2949,2949,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175986, 'node_id': 'MDU6TGFiZWwxNzU5ODY=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/testing', 'name': 'testing', 'color': '444444', 'default': False, 'description': 'Issue related with testing (code, documentation, etc)'}, {'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",open,2020-09-16 11:51:29+00:00,,test_lda_callback.py test stalls,"I've seen multiple PRs fail (red) with the same problem in log, e.g. in #2947:
https://travis-ci.org/github/RaRe-Technologies/gensim/jobs/727593115
https://travis-ci.org/github/RaRe-Technologies/gensim/jobs/727515466

<img width=""1440"" alt=""Screen Shot 2020-09-16 at 13 49 59"" src=""https://user-images.githubusercontent.com/610412/93333393-8a890200-f823-11ea-9605-944b7641b70f.png"">

Restarting the build job helps = the re-run succeeds.

This only seems to affect Travis and py3.6; I never saw this problem in our Azure (windows) tests or other Pythons."
768,https://github.com/RaRe-Technologies/gensim/issues/2950,2950,[],open,2020-09-16 18:10:33+00:00,,Overflow error after unicode errors when loading a 'large' model built with gensim,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? 
I am loading a `fasttext` model built with `gensim`, using `gensim.models.fasttext.load_facebook_model` so I can use the model.

What is the expected result?
The model loads correctly. 

 What are you seeing instead?
Overflow error, preceded by unicode parsing errors.

#### Steps/code/corpus to reproduce

I get an overflow error when I try to load a `fasttext` model which I built with `gensim`. I have tried with versions 3.8.3 and then rebuild and load with the head of the code 4.0.0-dev as of yesterday. It's not reproducible because I cannot share the corpus.

Here is the stack trace:


      In [21]: ft = load_facebook_model('data/interim/ft_model.bin')
      2020-09-16 15:59:59,526 : MainThread : INFO : loading 582693 words for fastText model from data/interim/ft_model.
      bin
      2020-09-16 15:59:59,626 : MainThread : ERROR : failed to decode invalid unicode bytes b'\x8a\x08'; replacing in
      lid characters, using '\\x8a\x08'
      2020-09-16 15:59:59,684 : MainThread : ERROR : failed to decode invalid unicode bytes b'\xb0\x03'; replacing in
      lid characters, using '\\xb0\x03'
      2020-09-16 15:59:59,775 : MainThread : ERROR : failed to decode invalid unicode bytes b'\xb5\x01'; replacing in
      lid characters, using '\\xb5\x01'
      2020-09-16 15:59:59,801 : MainThread : ERROR : failed to decode invalid unicode bytes b'\x99\xe9\xa2\x9d'; repl
      ing invalid characters, using '\\x99额'
      ---------------------------------------------------------------------------
      OverflowError                             Traceback (most recent call last)
      <ipython-input-21-3b4a7ad71a41> in <module>
      ----> 1 ft = load_facebook_model('data/interim/ft_model.bin')

      /m/virtualenvs/<snip>/lib/python3.6/site-packages/gensim/models/fasttext.py in load_f
      ebook_model(path, encoding)
         1140
         1141     """"""
      -> 1142     return _load_fasttext_format(path, encoding=encoding, full_model=True)
         1143
         1144

      /m/virtualenvs/<snip>/lib/python3.6/site-packages/gensim/models/fasttext.py in _load_
      sttext_format(model_file, encoding, full_model)
         1220     """"""
         1221     with gensim.utils.open(model_file, 'rb') as fin:
      -> 1222         m = gensim.models._fasttext_bin.load(fin, encoding=encoding, full_model=full_model)
         1223
         1224     model = FastText(

      /m/virtualenvs/<snip>/python3.6/site-packages/gensim/models/_fasttext_bin.py in l
      d(fin, encoding, full_model)
          342     model.update(raw_vocab=raw_vocab, vocab_size=vocab_size, nwords=nwords, ntokens=ntokens)
          343
      --> 344     vectors_ngrams = _load_matrix(fin, new_format=new_format)
          345
          346     if not full_model:

      /m/virtualenvs/<snip>/lib/python3.6/site-packages/gensim/models/_fasttext_bin.py in _
      ad_matrix(fin, new_format)
          276         matrix = _fromfile(fin, _FLOAT_DTYPE, count)
          277     else:
      --> 278         matrix = np.fromfile(fin, _FLOAT_DTYPE, count)
          279
          280     assert matrix.shape == (count,), 'expected (%r,),  got %r' % (count, matrix.shape)

      OverflowError: Python int too large to convert to C ssize_t

* There are no errors or warnings in the model building using the same . 
* A quick check showed there are no unicode errors in the input file, but very well possible that there are Chinese characters. 
* The `count` variable is calculated as `count = num_vectors * dim`. Both of these are astronomical at 10^23, `dim` should be 100, so there must be some unpacking problem here already. The unpacking of model params pre vocab look ok. 
* The input dataset is somewhat large at 26 GB, one epoch is sufficient. 
* The build and load works with a truncated file which is 4.8 GB. So change in size as well as corpus -- could be that the problematic input is not included. 
* The same input file works when running with the python `fasttext` module, so I have a workaround. 

The count of the erroneous words are also off the scale:

      In [41]: raw_vocab['\\x8a\x08']
      Out[41]: 7088947288457871360

      In [42]: raw_vocab['\\xb0\x03']
      Out[42]: 3774297962713186304

      In [43]: raw_vocab['\\xb5\x01']
      Out[43]: 7092324988178399232


I saw that there were many changes from `int` to `long long` both in 3.8.3 and also in 4.0.0-dev so my hypothesis was that it would be resolved when updating but I got the same error. 

I don't know if this is sufficient information to go in in order to pin it down, please let me know if I can help with more information. 

#### Versions

Please provide the output of:

```python
>>> import platform; print(platform.platform())
Linux-2.6.32-754.3.5.el6.x86_64-x86_64-with-centos-6.10-Final
>>> import sys; print(""Python"", sys.version)
Python 3.6.10 (default, Jul  8 2020, 16:15:16) 
[GCC 4.4.7 20120313 (Red Hat 4.4.7-23)]
>>> import struct; print(""Bits"", 8 * struct.calcsize(""P""))
Bits 64
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.19.2
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.5.2
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.8.3
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1
```
"
769,https://github.com/RaRe-Technologies/gensim/issues/2951,2951,[],open,2020-09-16 19:04:43+00:00,,calculation of downsampling .sample_int after vocab-updates looks wrong,"The updating of `.sample_int` after a `build_vocab(..., update=True)` looks wrong at:

https://github.com/RaRe-Technologies/gensim/blob/3.8.3/gensim/models/word2vec.py#L1534-L1544

In particular, by only consulting the `raw_vocab` (which in this case is only the new vocab-survey), in many cases it may be failing to recognize truly high-frequency words, and may even (for small unrepresentative updates) be downsampling overall-rare words that are just overrepresented in the new batch. Unsure if this is a prpblem in practice; the whole update-vocab functionality is a poorly-grounded & underanalyzed mess."
770,https://github.com/RaRe-Technologies/gensim/issues/2955,2955,[],open,2020-09-23 19:44:43+00:00,,"Ensure 2Vec classes (KeyedVectors, Word2Vec, Doc2Vec, FastText) support desired level of mmap support","There's been some useful ability of these classes to work from mmemapped underlying numpy arrrays - but such functionality is not deeply tested in unit-tests, and I thus strongly suspect it has regressed a bit from recent refactorings. (In particular, #2944 when applied removes any pretense that the still-present `memmap_path` parameter has any effect.)

We should inventory what the classes should be reasonably expected to do. 

For example: in what cases should they be initializable to use mmapping from the get-go, or is it sufficient that they do so only when loaded from a prior save? Will they smartly maintain mmapping when undergoing some of the newer vocab-expansion options? That's a tricky thing to do efficiently - I think existing code has just ignored that case, which could just be documented as a limitation. Model classes have multiple underlying arrays that presumably could each be memmapped or not - do we expand method signatures to specify multiple options/paths, or just make it all-or-nothing per model, and in which cases are the mmapped paths specified explicitly ot just mechanistically calculated from a model's 'root name' (as with saving `.npy` files). 

With a reasonable set of officially-supported capabilities decided, we should ensure tests cover exactly those cases, so we catch any current or future collateral damage. "
771,https://github.com/RaRe-Technologies/gensim/issues/2956,2956,"[{'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}, {'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",open,2020-09-24 09:35:23+00:00,,Move BrownCorpus from word2vec to gensim.corpora,"Not a high-priority at all, but it'd be more sensible for such a tutorial/testing utility corpus to be implemented elsewhere - maybe under `/test/` or some other data- or doc- related module – rather than in `gensim.models.word2vec`.

_Originally posted by @gojomo in https://github.com/RaRe-Technologies/gensim/pull/2939#discussion_r493820305_"
772,https://github.com/RaRe-Technologies/gensim/issues/2957,2957,"[{'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",open,2020-09-24 10:09:00+00:00,,Clean up OOP / stub methods,"Do we really need such stub methods that only call the same superclass method with the same arguments? That's already the default which occurs if no method is present. By my understanding, doc-comment tools like Sphinx will, in their current versions, already propagate superclass API docs down to subclasses.

The only thing that's varying is the comment, and while it expresses a different expected-type from the superclass, in practice that doc may be misleading: I **think** (but have not recently checked) that these `SaveLoad` `.load()` methods can return objects that **may not be** what the caller expects. They return **the class that's in the file**, not the class-that-`.load()`-was-called-on.

If so, it might be a worthwhile short-term step as soon as 4.0.0 – for limiting the risk of confusion & requirement for redundant/caveat-filled docs – to **deprecate the practice of calling *SpecificClass*.load(filename) entirely**, despite its common appearance in previously-idiomatic gensim example code. Instead, either (1) call it only on class `SaveLoad` itself, to express that the only expectation for the returned type is that it's a `SaveLoad` subclass; (2) promote load functionality to model-specific top-level functions in each relevant model – a bit more like the `load_facebook_model()` function for loading Facebook-FasttText-native-format models – which might themselves do some type-checking, so any docs which imply they return a certain type are true; (3) just make one `utils.py` generic `load()` or `load_model()`, perhaps with an optional class-enforcement parameter, and encourage its use. 

(For explicitness, I think I like this third option. In practice, it might appear in example code as:

```
from gensim.utils import load_model
from gensim.models import Word2Vec

w2v_model_we_hope = load_model('w2v.bin')
w2v_model_or_error = load_model('w2v.bin', expected_class=Word2Vec)
```
Plenty of code where the file is saved/loaded in the same example block, or under strong expectations & naming conventions, might skip the enforced-type-checking – but it'd be an option & true/explicit, rather than something that's implied-but-not-really-enforced in the current idiom `Word2Vec.load('kv.bin')`)

Despite the effort involved in making such changes, they could minimize duplicated code/comments & avoid some unintuitive gotchas in the current `SaveLoad` approach. They might also help make a future migration to some more standard big-model-serialization convention (as proposed by #2848) cleaner.

_Originally posted by @gojomo in https://github.com/RaRe-Technologies/gensim/pull/2939#discussion_r493807649_"
773,https://github.com/RaRe-Technologies/gensim/issues/2960,2960,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",closed,2020-09-28 12:10:46+00:00,,Update documentation for 4.0.0,"Internal checklist so I don't forget something:

- [x] Rewrite the landing page copy for the new website.
- [x] Restructure top-level TOC tree for the new website.
- [x] Make all `rst` docs up-to-date for the new website, check hyperlinks, update stats & copy.
- [x] Go over rendered API docs and check everything's up to date and makes sense: formatting, descriptions, notes, hyperlinks.
- [x] Migrate & regenerate all Tutorials and How-tos.
- [x] Write the [Migration guide](https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).
- [x] Write the 4.0.0 release notes.
- [x] Improve the [Developer page](https://github.com/RaRe-Technologies/gensim/wiki/Developer-page) with Gensim code-style: hanging indents, trailing commas, FIXME vs TODO, line length, etc."
774,https://github.com/RaRe-Technologies/gensim/issues/2961,2961,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",closed,2020-09-28 12:54:03+00:00,,Documentation of strip_punctuation vs strip_punctuation2 in gensim.parsing.preprocessing,"Thanks for all the hard work on this fantastic library. I found a small quirk today, not really a bug, just a bit of a rough edge:

In `gensim.parsing` [preprocessing.py ](https://github.com/RaRe-Technologies/gensim/blob/e210f73c42c5df5a511ca27166cbc7d10970eab2/gensim/parsing/preprocessing.py#L121) `strip_punctuation2` is defined: `strip_punctuation2 = strip_punctuation`.

In the [documentation](https://radimrehurek.com/gensim/parsing/preprocessing.html) the description of [`strip_punctuation2`](https://radimrehurek.com/gensim/parsing/preprocessing.html#gensim.parsing.preprocessing.strip_punctuation2) is a duplication of [`strip_punctuation`](https://radimrehurek.com/gensim/parsing/preprocessing.html#gensim.parsing.preprocessing.strip_punctuation) rather than a statement of equality.

I noticed this while reading the documentation and, assuming I was missing an obvious distinction, attempting to hand diff the the docs for the two functions. When I gave up and flipped to the source it became obvious how the two functions are related.
"
775,https://github.com/RaRe-Technologies/gensim/issues/2962,2962,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}]",open,2020-09-28 13:33:46+00:00,,preprocessing.strip_punctuation does not handle Unicode,"
#### Problem description

`RE_PUNCT` in [`parsing/preprocessing.py`](https://github.com/RaRe-Technologies/gensim/blob/e210f73c42c5df5a511ca27166cbc7d10970eab2/gensim/parsing/preprocessing.py#L62), which is the substance of [`preprocessing.strip_punctuation`](https://github.com/RaRe-Technologies/gensim/blob/e210f73c42c5df5a511ca27166cbc7d10970eab2/gensim/parsing/preprocessing.py#L96) does not consider Unicode punctuation.

`RE_PUNCT` (=`re.compile(r'([%s])+' % re.escape(string.punctuation), re.UNICODE)`) depends on the standard library string module's punctuation string which is limited to ascii punctuation.

#### Steps/code/corpus to reproduce

```
>>> from gensim.parsing import preprocessing
>>> preprocessing.strip_punctuation('This is a “quoted string” which has the typographic quotes whereas ""this one"" does not.')
'This is a “quoted string” which has the typographic quotes whereas  this one  does not '
```

For the above input I think the correct output would be: 
```
'This is a  quoted string  which has the typographic quotes whereas  this one  does not '
```

#### Possible solutions

In the above example my choice of typographic quotes was unimportant but dodges the hard part of a solution which will be a suitable definition of punctuation given the number of possibilities in unicode and ambiguity around some associated uses of those possibilities.

I can think of three large classes of response:

 - Anything other than ascii is ambiguous, leave it as is and document
 - Use a hand defined map of Unicode equivalency to ascii punctuation, e.g. [Unidecode](https://pypi.org/project/Unidecode/)
 - Exclude based on database category, e.g. this [SO answer](https://stackoverflow.com/questions/11066400/remove-punctuation-from-unicode-formatted-strings/21635971#21635971)

I found this helpful in exploring possible answers to my particular use case:

```
import unicodedata
import sys

to_look_at = [(i, chr(i)) for i in range(sys.maxunicode) if unicodedata.category(chr(i))[0] in ('P', 'S')]
```

Thanks for all the hard work on this great library.
"
776,https://github.com/RaRe-Technologies/gensim/issues/2963,2963,"[{'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",open,2020-09-29 02:32:45+00:00,,Proposal: do one or more 4.0.0 test releases before official release,"I know that prior experience suggests that a new release is only 'battle-tested' by the larger community when it becomes official, & thus installed by a default `pip install gensim`. 

However, there are enough changes in recent work, and I suspect large enough gaps in our testing & understanding of actual user patterns, that I think we'd gain a lot by having at least one, and perhaps several, 'soft releases' (tests labeled `dev` or `beta` or `release-candidate` where only eager/advanced users try it out. 

I wouldn't expect an instant race-to-install & voluminous feedback. But, I think if it's announced a few times over a few weeks, with both teasers of improvements-needing-testing, and an explicit request for feedback (even if it's just ""all was great""), we'd get actionable feedback. 

We wouldn't need to coach people about working with git checkouts: the pip/PyPI/Python versions infrastructure should support this. As I understand it, we can push a release with the version `4.0.0.dev1` or `4.0.0b1` – or any of the other dev/prerelease formats in [PEP440](https://www.python.org/dev/peps/pep-0440/#pre-releases). Then, anyone who explicitly tries `pip install gensim` still gets only the official release, but anyone who does `pip install --pre gensim`, or an installation explicitly naming the exact release, will get the pre-release version.

We would create a Wiki page about the availability of a 4.0.0 pre-release, with info about how to install it (or roll-back if things go wrong). It'd also link to the migration tips. We'd announce on project list, project twitter, gitter, etc and encourage feedback via replies or new issues. 

Some big ways I think it would help include:

* We almost certainly have some little issues that will be easy to fix as soon as reported; we might have some bigger ones because use-in-the-field is different than we expect or unit-test for. (I'm especially concerned about users who've done customization, or deployment optimizations around mmap, FastText, or multi-step/retraining workflows.) We almost certainly have some outdated docs/tutorials, in project materials or 3rd party sites. If these are 1st hit by naive/beginner/unaware users, they'll generate much more frustration (including for us in incomplete reports of problems) than if they're 1st hit by users who know what it means to try a new version, who'll make better issue reports and be more patient handling issues. 
* While we could fix such issues in little `4.0.1`, `4.0.2`, etc releases, that involves more mess & pressure. If there's a serious or embarrassing issue, I'd like to be able to think about it and fix it right over the course of a day/week, rather than rush a micro release ASAP (which might then miss something that comes up one day later). 
* It lets any attentive users feel a bit special & helpful, whether they find bugs or simply report ""all smooth"" - and might contribute to more positive attention in a slightly-later improved release, as they chime in with any variant of ""been working great for me for weeks"" or ""I found a big and I'm happy to say it's fixed"". 
* There are still a few festering things that may be best to change, due to API disruption, coincident with the 'major' revision than in a `4.0.1` or `4.1.0`. Ensuring mmap is still up to snuff is one already on your list, but I'd also like to restore the distinct stages of `build_vocab()` that were once more amenable to saving-the-vocab, then trying multiple train-parameters, than they are now. (I have some interim work on this I can show in a PR tomorrow.) I'll highlight a few other things that might fit this category on other issues. 

Overall, my sense is that a good process for polish & positive launch attention could be something like: (1) test release this week, see what feedback comes back; (2) 2nd test release in a couple weeks, see what feedback comes back; (3) official release a couple weeks later; (4) `4.0.1` a month after that. 

But if we don't do that, we might find ourself in something like: (1) `4.0.0` release ASAP; (2) bugs & complaints along the ""why wasn't I warned"" theme; (3) scrambles to do `4.0.1`, `4.0.2` soon after; (4) eventually a `4.0.3` a couple weeks after, that's the 1st release that's actually reasonable for non-experts to risk. But that's then based more on reactive feedback from whoever stepped on things than users who consciously chose to affect an upcoming release, and many less-attentive users still have the 4.0.0/4.0.1/4.0.2 for a while, until they hit some new urgent reason to update. "
777,https://github.com/RaRe-Technologies/gensim/issues/2967,2967,[],open,2020-09-30 08:59:24+00:00,,Adopting a (narrow) backward-compatibility standard; implications for 4.0.0,"From #2939:

> # Decisions
> 
> 1. Support loading of pre-3.8.3 models?
>    - Misha: better: a stand-alone script to upgrade models to the latest version… rather than class methods doing the work on each load
>    - Misha: also in favour of limited backward compatibility loading (just 3.8.3)
>    - Radim: in favour of keeping existing compatibility code; why remove it? pros/cons unclear
>    => **decision**: talk to Gordon, make the costs (pros/cons) more explicit.

_Originally posted by @piskvorky in https://github.com/RaRe-Technologies/gensim/pull/2939#issuecomment-698247945_

OK, compiled long thoughts here on both general issues & specifics:

As far as I can tell, Gensim hasn't had any formal backward-compatibility policy other than ""we'll try to maintain the ability to load older models"". 

This is generous, and easy when things change very little. 

But always considering older models makes larger improvements via refactoring & new ideas harder. In addition to making a system that's simply better for commmon/tested tasks, such work then also has to write translation code that brings old data into the newer format (perhaps with compromises/limits). That code may have to retain/alias/work-around older class/property names, and include long-blocks of special-case handling.

But our features are often a grab-bag of things of wildly-different importance: some flags/options are seldom used (or probably *shouldn't* be used), while others are central. And our `test_data` directory is filled with droppings of unclear origin & purpose. (What versions/features are tested by 'doc2vec_old' or 'ldamodel_python_2_7'?)

What attempts there have been to check backward-compatibility are far shallower than they may look. There's a bunch of version-labeled Word2Vec and Doc2Vec models, but only one per version, likely created with default parameters & tiny toy data. (I don't think the source code that created them is committed/referenceable anywhere.) The load-check they get is just a few rudimentary steps, so whether the real range of functionality has been maintained is unclear. 

So this compatibility logic is error-prone code, hard-to-test, and under-tested – even in the best of conditions. And such code just keeps growing, barely tested & maybe unused, as long as it's not directly implicated in some reported bug/test-failure. And sometimes the impulse to ""just make the test pass"" or ""just get the PR merged"" has led to unthinkingly adding & duplicating code until it superficially works - as when #1777 added a giant `deprecated` subdirectory (https://github.com/RaRe-Technologies/gensim/tree/3.8.3/gensim/models/deprecated) of entirely-copied obsolete code. This was just to make passing a few back-compatibility tests a little easier, without actually thinking through the object-shape changes. 

And against this, there may not even be that many people using older models in a way that they'd need to load them in fresh code! If the model is trained & deployed and only using older features, it can and perhaps should keep running in older libraries. Many newer optimizations/features are only relevant when repeating creation/training from scratch, not when simply consulting or incrementally-changing an older model. Many users already have a workflow that refreshes models regularly, or would be better served by truly repeating model-creation in the latest code. 

Or if they absolutely need to bring an old model forward, we should often accommodate that via multiple steps – load each model forward a short hop, then re-save, then another short-hop. Theoretically, this should work. In real cases, this might already be broken. But it's a more realistic incremental goal, to at each new version ensure that one hop works, than to maintain a many-versions-back growing hairball for (maybe but probably not really) handling anything. Users could also ask for, or hire, specific help for thorny but important situations - if they even arise. But many-version-hop situations that aren't best served by ""train a new model"" might be entirely theoretical.

In the meantime, we can make beneficial changes faster, & ease maintenance by:

**First**, adopting general guidelines about project goals that (a) let users know that only smallish-version-increment later-loads are within project aims, so they have reasonable expectations; and (b) give developers freedom to focus on a well-defined, minimal back-compatibility target - and when that's met, aggressively remove older code debt/complications. I'll say more about the guideline I think would be best further below in the 1-2-3. 

(As far back as [January I requested](https://github.com/RaRe-Technologies/gensim/pull/2698#issuecomment-580518691): ""in particular, it would help to say either: 'gensim 4.0 is only compatible with models saved from 3.x versions; if you have older models, load them in 3.x, re-save them, to bring them to 4.0' - or perhaps even more aggressively: 'gensim-4.0 only tries to support models that were saved from gensim-3.8.1; older models may be loaded & re-saved in 3.8.1 to be brought to 4.0'"".

It's been frustrating that when I've been 'warm on the code' & ready to clear out low-value old cruft, I've repeatedly asked about making such a clarifying compatibility decision - but no opinions either way have been shared until just recently. Having a reasoned-out standing policy would avoid this frustration & stunted progress.)

**Second**, clearing out the old, poorly-labeled, poor-coverage test-files and test-methods, and replacing them with a tighter set of current tests. Some steps in this process could be:

* deleting older-version/unclear-version test methods
* running the full test suite against a `test_data` directory where we're logging file-touches - so that obsolete, untouched files can be finally discarded
* creating a new script with code *in project source control* for creating the full suite of well-labeled test files *from* a specific version. Those would then made part of `test_data`, and new with load/functionality test methods against them added. But, these files would only be retained as long as that specific source version is within the stated back-compatibility goals, and promptly pruned when it moves out of the window.
* (maybe coincident with this cleanup: run the whole test suite with a code-coverage tool, to find any methods/functionality that are totally missed by testing - then either eliminate that functionality or add tests)

**So, what could the default cross-version compatibility policy be?** 

I suggest the following as a baseline, subject to only rare exceptions:

1.  Loading of models saved from newer versions, backward into older versions, is *never* an explicit goal, and will only happen by luck. That is, a save from version MAJOR.MINOR.MICRO *might* load in MAJOR.MINOR.(MICRO-N), or MAJOR.(MINOR-N).M or (MAJOR-N).M.P. But it's never a requirement, and always OK for development-in-progress to assume saved models need only be loaded into the same or later versions. (I believe this is pretty much assumed already.)

2. Fully-functional loading of models saved from older versions, into newer versions, is a strong goal when the MICRO version has incremented by any amount, or the MINOR by 1. That is, if the save is from version MAJOR.MINOR.MICRO, users should expect, and developers should try maintain, that it can be loaded into any MAJOR.MINOR.(MICRO+N) or MAJOR.(MINOR+1).N version. (Any exceptions, as perhaps if a feature is necessarily discontinued or onerous to maintain, would be the kind of thing to be highlighted prominently in release-notes.) Many times – indeed most of the time given that lots of code doesn't change much – models will successfully load in much-later versions. But this is the minimum we're aiming for, and it's generally OK when devs making other substantive improvements break any loads into a (MINOR+2)-or-more future version.

3. When the MAJOR version increments, it is only a strong goal for saves from the final release of the prior MAJOR version to load with full-functionality. That is, in versions MAJOR.0.N, only saves from (MAJOR-1).LAST_MINOR.LAST_MICRO are by default considered must-loads. Earlier saves *might* load, but if they don't, the recommended strategy will be to load them in the latest version that supports them, then re-save, & repeat until reaching MAJOR.0.N. 

In the context of the current situation with a pending 4.0.0 release, adopting this policy as-is would mean: 

* we discard all tests/files of pre-gensim.3.8.3 loading
* we add new better-labeled/more-coverage test files & methods for just testing things saved from gensim-3.8.3, & consider 4.0.0 meeting its backward-compatibility goals when all those focused tests pass
* as soon as 4.0.0 is finalized, its set of future-backward-compatibility test files should be generated and added to the 4.0.1-dev project tree

In the future, having this as a standing policy – rather than something to be re-discussed each release or PR – will make it easier to improve things with confidence about how much backward-compatibility work is expected, and to know when older tests/test-files can be retired. It means any contributor, whether an old-hand or newbie, has a much more narrow & comprehensible set of things to consider. They then have a chance of improving things rather than ""typing & hoping"" around scary blocks of ""who knows what might break if I change this"" code. "
778,https://github.com/RaRe-Technologies/gensim/issues/2969,2969,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 1602279836, 'node_id': 'MDU6TGFiZWwxNjAyMjc5ODM2', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20MEDIUM', 'name': 'reach MEDIUM', 'color': 'ef7a1a', 'default': False, 'description': 'Affects a significant number of users'}, {'id': 1602334472, 'node_id': 'MDU6TGFiZWwxNjAyMzM0NDcy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20MEDIUM', 'name': 'impact MEDIUM', 'color': '7af49f', 'default': False, 'description': 'Big annoyance for affected users'}]",open,2020-09-30 21:04:09+00:00,,Load full native fastText Facebook model is partial,"#### Problem description

Hidden vectors are bad. I'm using the gensim.models.fasttext.load_facebook_model function to load the .bin file, but the syn1 fails loading. Also trainables.syn1neg is full of zeros.

'FastTextTrainables' object has no attribute 'syn1'

#### Steps/code/corpus to reproduce

Simply using `ft = gensim.models.fasttext.load_facebook_model(fname)`  on Facebook's model.
Then `ft.syn1` or `ft.trainables.syn1neg` which returns the zero array.

#### Versions

Please provide the output of:
Windows-2012ServerR2-6.3.9600-SP0
Python 3.7.1 (default, Dec 10 2018, 22:54:23) [MSC v.1915 64 bit (AMD64)]
Bits 64
NumPy 1.18.3
SciPy 1.4.1
gensim 3.8.3
FAST_VERSION 0

"
779,https://github.com/RaRe-Technologies/gensim/issues/2973,2973,[],closed,2020-10-06 03:28:57+00:00,,phrases.export_phrases() doesn't yield all bigrams,"Hallo and thank you for this tool,

phrases.export_phrases() doesn't yield all bigrams when some are part of a bigger n-gram.

If I create a Phrases object with 

`phrases = gensim.models.phrases.Phrases(sentences, min_count=1, threshold=10, delimiter=b' ', scoring='default')`

on the following two sentences

New York City has the largest population of all the cities in the United States .
Every year, many travelers come to the United States to visit New York City .

`print(dict(phrases.export_phrases(sentences)))` only returns {b'New York': 11.5, b'United States': 11.5}. It should also return {b'York City': 11.5} however.

line 187 of phrases.py should probably be changed to `last_uncommon = word` . It fixes the problem on my side and seems to be what the code was intended to be.

Thank you,
Olivier NC


macOS-10.14.5-x86_64-i386-64bit
Python 3.8.5 (v3.8.5:580fbb018f, Jul 20 2020, 12:11:27) 
[Clang 6.0 (clang-600.0.57)]
Bits 64
NumPy 1.19.2
SciPy 1.5.2
gensim 3.8.3
FAST_VERSION 0
"
780,https://github.com/RaRe-Technologies/gensim/issues/2974,2974,"[{'id': 175642, 'node_id': 'MDU6TGFiZWwxNzU2NDI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/wishlist', 'name': 'wishlist', 'color': 'd7e102', 'default': False, 'description': 'Feature request'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}]",open,2020-10-06 09:57:58+00:00,,Introduce type annotations,"Following @mpenkov's effort for smart_open in https://github.com/RaRe-Technologies/smart_open/pull/545, we could also introduce type annotations into Gensim.

The benefits are mild (nothing much gained), so this would be mostly for the documentation and CI.

Ticket only relevant once we drop py3.6, because without [PEP 585](https://www.python.org/dev/peps/pep-0585/) the annotations are too ugly and code-obfuscating, and PEP585 is py3.7+ only."
781,https://github.com/RaRe-Technologies/gensim/issues/2975,2975,[],open,2020-10-06 20:37:14+00:00,,Restore/improve/streamline hooks for controlling/reusing build_vocab() steps,"**Background**:

My ""2Vec refactor wishlist"" (#1623) suggested among other things:

> 7. separating vocabulary-management into explicitly different classes/objects, for more control/customization, perhaps including closer integration with new n-gram (phrasing) options

I had made a few tiny steps for enabling more control with a segmenting of the `build_vocab()` step into 3 distinct, sequential steps:
* `scan_vocab()`: survey the corpus only, without few model-specific influences, so that you'd have a reusable model that could be saved & resude with alternate downstream params
* `prepare_vocab()`: start specializing the model by vocabulary, with reporting of the memory effects of different choices
* `finalize_vocab()`: actually allocate vectors & support data-structures dependent on a frozen, final vocabulary 

The #1777 refactoring both destroyed that distinct 3-step definition of `build_vocab()`, and moved away from actually-separable/reusable vocabulary-objects (despite claiming to do the opposite) - as per some of the [problems I highlighted at the time](https://github.com/RaRe-Technologies/gensim/issues/1623#issuecomment-363561043).

Most of the complexifying damage from #1777 has been reversed, but the clean 3-steps hasn't yet been restored. And, it had been my hope that the 'KeyedVectors & other undoing of #1777' #2698 might also address this vocab-reuse concern, as per [my status & wishlist comment Jan 30](https://github.com/RaRe-Technologies/gensim/pull/2698#issuecomment-580518691):

> Functionally I'd also like to:
> 
> * formally ensure the prior decomposition of build_vocab() into distinct scan/scale/finalize steps again works (or something similar/better, for people wanting to do finicky things with their vocabulary)
> 
> ...and then if I see a path that's not too complex...
> 
> * perhaps add an alternate initialization path from existing KeyedVectors – providing an official path to the oft-repeated ""re-use other word-vectors to initialized my X model"" request
> * maybe add a more rational & better-supported way to modify the vocabulary of an existing model between training runs

There's been a little improvement here in #2698 and since (including #2944) - far fewer methods & lines of code achieving the same things, some things that used to fail (#2853) & segfault (#1019) no longer doing so. But nothing matching the specific hopes above.

**Now**:

Still, cleaning up the FastText & related initialization recently led me to dust-off some earlier false-start code & I now have an approach I like, that's working for `Word2Vec` & `Doc2Vec` ( & should be working for `FastText` soon.)

The top-level summary is that `build_vocab()` becomes, in the initial run, abstractly & essentially:

```
def build_vocab(self, corpus, **etc):
    survey = self.scan_vocab(corpus)  # do only corpus-surveying
    self.allocate_model(survey)  # do only model-initialization
```

The `survey` is an instance of a new vocab-and-other-corpus-stats utility class – currently named `TokenSurvey`, & mainly a frequency dict like the old `raw_vocab` wrapped with a few other things. Notably, this *can* be used outside of the 2Vec classes, essentially to do the (long, costly) corpus-analysis 1st, once, and save it aside. Then, possibly examine/alter it in arbitrary ways, and also reuse it multiple times later. 

And, while `TokenSurvey` currently replicates the crude capped-size pruning (#2024) we've historically used to prevent a vocab-scan from overflowing memory, it'd be amenable to a workalike swap-out that just uses disk scratch space to do a precise vocabulary count, or an approximate counting process (#1962). Similarly, it'd be amenable to users doing whatever other corpus-surveys they want - multithreaded, Hadoop-backed, whatever – and just knowing, if they can construct a `TokenSurvey`-workalike from their results, they can hand it to the *2Vec classes to make their model from that. 

The API impacts are:
* no external effect on people who are only using the corpus-in-constructure, or simple `build_vocab()` then `train()` patterns
* people who were doing custom things before/during/after `build_vocab()`, especially related to the memory-estimations once available from `prepare_vocab()`, or doing any direct access to the old `.raw_vocab`, will need to update their code. But, I think this is 1-in-a-hundred of users, and more advanced users, who'll be happy with the new separable extension/save points.
* slight back-compat work needed, as old models with `raw_vocab` will need some hot-upgrade to `survey` objects whereever possible

PR forthcoming as soon as I have it working for `FastText` 



"
782,https://github.com/RaRe-Technologies/gensim/issues/2977,2977,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 175986, 'node_id': 'MDU6TGFiZWwxNzU5ODY=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/testing', 'name': 'testing', 'color': '444444', 'default': False, 'description': 'Issue related with testing (code, documentation, etc)'}]",open,2020-10-08 22:57:57+00:00,,Improve/prune docs/tutorial of TranslationMatrix functionality,"The [concerning test failure](https://github.com/RaRe-Technologies/gensim/pull/2944#issuecomment-704512389) at #2944 now seems to me to be a false alarm. With more testing across many seeds, it appears the extremely flimsy `BackMappingTranslationTest.test_infer_vector()` was only passing in the base case (`float64` randoms downcast to `float32`s) due to a lucky seeding, and only failing in the changed case due to unlucky seeding of the slightly-different stream of (`float32` from the start) random numbers. 

I've disabled the flimsy test, and it's questionable whether the `BackMappingTranslationMatrix` should even exist. It's perhaps 10 lines of *using* (not specializing-via-subclass) the actual `TranslationMatrix` class, and over-specialized on `Doc2Vec` models  – whereas the `TranslationMatrix` functionality could and should be general to any vector-set, requiring just a few lines to apply to word-vectors, doc-vectors, or others. (And, calling the translation/projection `infer_vector` is unnecessarily prone to confusion with the different 'inference' that's native to `Doc2Vec`.) 

I still think the `TranslationMatrix` itself is an under-appreciated bit of functionality, and I even strongly suspect – subject to experimentation – it could be part of a recommended solution for evolving a model to include more words that's far more robust/theoretically-defensible/performant than the `build_vocab(..., update=True)` & then incrementally `.train()` approach. 

But, it'll need at the very least better docs/tutorial examples. The existing `docs/notebook/tranlsation_matrix.ipynb` is muddled & hard to run. (The test data it's using links to an all-in-Chinese Baidu download page that seems to require a login before raw `.txt` download.) It demos the `BackmappingTranslationMatrix` class in a later 'experimental' area I have trouble following even though it reuses some of the IMDB-dataset `Doc2Vec` tutorial I wrote. 

I only have time to disable the `BackMappingTranslationTest.test_infer_vector` test right now, and this is pretty fringe functionality, so there's no urgency to clean it up - but this issue it to keep it under consideration, when the right person comes along. "
783,https://github.com/RaRe-Technologies/gensim/issues/2983,2983,[],open,2020-10-18 14:18:58+00:00,,track training loss while using doc2vec issue.,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I am trying to track training loss using doc2vec algorithm. And it failed. Is there a way to track training loss in doc2vec?
Also, I didnt find any documentation related to performing early stopping while do2vec training phase?

the similarity score is varying a lot based on epochs, and I want to stop training when it has reached optimal capacity with callbacks. I have used keras, it has earlystopping feature. Not sure how to do it using gensim models. 

Any response is appreciated. Thank you!

#### Steps/code/corpus to reproduce
```
class EpochLogger(CallbackAny2Vec):
    '''Callback to log information about training'''

    def __init__(self):
        self.epoch = 0

    def on_epoch_begin(self, model):
        print(""Epoch #{} start"".format(self.epoch))

    def on_epoch_end(self, model):
        print(""Epoch #{} end"".format(self.epoch))
        self.epoch += 1

epoch_logger = EpochLogger()

class LossLogger(CallbackAny2Vec):
    '''Output loss at each epoch'''
    def __init__(self):
        self.epoch = 1
        self.losses = []

    def on_epoch_begin(self, model):
        print(f'Epoch: {self.epoch}', end='\t')

    def on_epoch_end(self, model):
        loss = model.get_latest_training_loss()
        self.losses.append(loss)
        print(f'  Loss: {loss}')
        self.epoch += 1

loss_logger = LossLogger()

def train_model(data, ids, destination, alpha):

    print('\tTagging data .. ')
    tagged_data = [TaggedDocument(words=word_tokenize(str(_d).lower()), tags=[str(ids[i])]) for i, _d in enumerate(data)]

    print('\tPreparing model with the following parameters: epochs = {}, vector_size = {}, alpha = {} .. '.
          format(max_epochs, vec_size, alpha))

    model = Doc2Vec(vector_size=vec_size,
                    workers=cores//2,
                    alpha=alpha,  # initial learning rate
                    min_count=2,  # Ignore words having a total frequency below this
                    dm_mean=1,  # take mean of of word2vec and doc2vec
                    dm=1,
                    callbacks=[epoch_logger, loss_logger])  # PV-DM over PV-DBOW

    model.build_vocab(tagged_data, keep_raw_vocab=False, progress_per=100000)
```
#### Versions

Please provide the output of:

```
2017 4673
        Tagging data ..
        Preparing model with the following parameters: epochs = 50, vector_size = 100, alpha = 0.01 ..
        Beginning model training ..
                Iteration 0
                Learning Rate =  0.01
Epoch #0 start
Epoch: 1        Epoch #0 end
Traceback (most recent call last):
    loss = model.get_latest_training_loss()
AttributeError: 'Doc2Vec' object has no attribute 'get_latest_training_loss'

```
"
784,https://github.com/RaRe-Technologies/gensim/issues/2985,2985,[],closed,2020-10-19 06:31:07+00:00,,Bug report of gensim official webpage,"https://radimrehurek.com/gensim/auto_examples/core/run_similarity_queries.html#sphx-glr-auto-examples-core-run-similarity-queries-py

In this page, at the last second code part,  the original code is :
sims = sorted(enumerate(sims), key=lambda item: -item[1])
for i, s in enumerate(sims):
    print(s, documents[i])

However, I guess here code should be:
sims = sorted(enumerate(sims), key=lambda item: -item[1])
for i, s in enumerate(sims):
    print(s, documents[s[0]])"
785,https://github.com/RaRe-Technologies/gensim/issues/2986,2986,[],closed,2020-10-19 21:53:32+00:00,,Faster evaluation metrics (baked into the library?),"Before getting into the issue, I'd like to thank you all for maintaining this library! It's been great so far, and I really appreciate the thorough documentation.

---

#### Problem description

I'm trying to train Word2Vec embedding vectors on my own dataset. Things have been going well so far, but as I've started to add in certain features to the training loop, it's become more and more difficult to continue.

Our scenario is that we'd like to adapt [Twitter's recent paper](https://dl.acm.org/doi/abs/10.1145/3383313.3418486) (and its reference on [Word2Vec for recommendation systems](https://arxiv.org/abs/1804.04212)) for our own use-case. Put simply, I have three files (`train.jsonl`, `valid.jsonl`, `test.jsonl`) with samples of our full training dataset (~275k, 110k, and 110k examples, respectively).

Using `gensim`, I can successfully train a Word2Vec model for many epochs and get a proper output. Since Gensim doesn't come out-of-the-box with certain callbacks and metrics, I've rolled my own and applied them successfully—not a problem.

The problem comes when one of those callbacks is a metric that has to do some inference work on many sequences. For example, in the latter paper linked above, the authors describe a `Hit Ratio @ K` metric, which is doing next-token-prediction on a sequence of `n` tokens: the context consists of tokens `0, ..., n-1` and the token to be predicted is `n`. I've implemented it below:

```python
from math import inf
from typing import List
from typing import Optional
from typing import Sequence
from typing import Set
from typing import Tuple

import gensim

def hit_ratio_at_k(
        model: gensim.models.Word2Vec,
        sequence: Sequence[str],
        k: int,
        verbose: bool = False
) -> float:
    if verbose:
        logger.debug(f""Called with `k={k}` on `sequence={sequence}`"")

    # Exit early: if we don't have enough data to make separate context from target.
    if len(sequence) < 2:
        return inf

    # Isolate tokens `t_0, ..., t_{n-1}` as context, and `t_n` as target.
    context: List[str] = [*sequence[:-1]]
    target: str = sequence[-1]

    # Get our top `k` predictions for the next token.
    # Note: `gensim` returns None if all context words are OOV.
    preds: Optional[List[Tuple[str, float]]] = model.predict_output_word(
        context_words_list=context, topn=k
    )
    if not preds:
        return inf

    # If we have valid predictions, isolate the unordered tokens.
    pred_tokens: Set[str] = {word for word, _ in preds}

    # Hit Ratio is 1 if the target appears in the list of `k` predicted items, else 0.
    hit_ratio: float = 1.0 if target in pred_tokens else 0.0
    return hit_ratio
```

I wanted to track _Hit Ratio @ 1_ on both the training and validation sets after each epoch, so I made a callback that can do that for any of my general metric functions:

```python
from dataclasses import dataclass
from dataclasses import field
from math import isfinite
from typing import Callable
from typing import List
from typing import Sequence
from typing import Tuple

import gensim
import tqdm
from gensim.models.callbacks import CallbackAny2Vec

from myrepo.models.data import DataLoader

logger = ...


@dataclass
class MetricTracker(CallbackAny2Vec):
    dl: DataLoader
    name: str
    func: Callable[[gensim.models.Word2Vec, Sequence[str]], float]
    value: List[float] = field(default_factory=list, init=False)

    def on_epoch_end(self, model: gensim.models.Word2Vec) -> None:
        logger.debug(f""Computing {self.name} via `{self.func.__name__}`"")

        # Compute our evaluation metric on each sequence in our data loader.
        per_line_values: Tuple[float, ...] = tuple(
            self.func(model, seq) for seq in tqdm.tqdm(self.dl, total=len(self.dl))
        )

        # Adjust for any invalid values returned by our evaluation metric.
        valid_line_values: Tuple[float, ...] = tuple(
            value for value in per_line_values if isfinite(value)
        )
        avg_value: float = sum(valid_line_values) / len(valid_line_values)
        self.value.append(avg_value)
        logger.debug(f""Finished computing `{self.name}`: {avg_value:.3f}"")
```

This _works_ just fine, except that you quickly run into performance problems: Gensim's training loop is parallelized and fast, but (understandably) callbacks are called within a single process.

To try and mitigate this, I tried using Python's multi-processing (via `multiprocessing.dummy` and `concurrent.futures` packages) to make parallel calls to `self.func(model, seq)`. This helps when the data loader is small (a sample of ~3-5k sequences), but when passing the full train/validation data loader, performance isn't so great. For reference, `hit_ratio_at_k` (=`self.func`) on a single process can do about 30 iterations per second.

I suppose I'd want to know if you've dealt with this issue before. Ideally, I'd love to have a Gensim-approved way of doing inference on many documents/word sequences.

#### Steps/code/corpus to reproduce

This isn't a bug, but the relevant code blocks are above. Happy to provide any other code that would help clarify. I thought of potentially ""freezing"" the model's `KeyedVectors` instance (just for evaluation) to see if there's a significant speed-up, but I'm not sure what side effects I might be incurring (if any) by doing so.

#### Versions

Here's what I'm working with:

```python
Linux-4.15.0-65-generic-x86_64-with-debian-9.13
Python 3.7.9 (default, Oct 13 2020, 21:28:14) 
[GCC 6.3.0 20170516]
Bits 64
NumPy 1.19.2
SciPy 1.5.3
gensim 3.8.3
FAST_VERSION 1
```

Thank you!"
786,https://github.com/RaRe-Technologies/gensim/issues/2987,2987,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 175642, 'node_id': 'MDU6TGFiZWwxNzU2NDI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/wishlist', 'name': 'wishlist', 'color': 'd7e102', 'default': False, 'description': 'Feature request'}, {'id': 708430967, 'node_id': 'MDU6TGFiZWw3MDg0MzA5Njc=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/performance', 'name': 'performance', 'color': 'd93f0b', 'default': False, 'description': 'Issue related to performance (in HW meaning)'}]",open,2020-10-20 18:54:23+00:00,,Support multiple `most_similar()` queries in one call,"SpaCy's `most_similar` (https://spacy.io/api/vectors#most_similar) accepts multiple queries at a time, and further may then break them into batches. In so doing, the expensive `dot` call at the heart of the calculation can work on larger chunks of data at a time, and visit each row of a large source array just once for multiple results - potentially a noticeable speedup. 

Gensim could consider upgrading `most_similar()` to offer the same batch efficiency. 

(Thought inspired by #2986's hopes-for-certain optimizations.)"
787,https://github.com/RaRe-Technologies/gensim/issues/2988,2988,[],closed,2020-10-22 20:07:33+00:00,,`word2vec.doesnt_match` numpy vstack deprecation warning ,"#### Problem description

I followed [this instruction](https://radimrehurek.com/gensim/scripts/glove2word2vec.html) to load GloVe model. When I run:  `model.doesnt_match(""breakfast cereal dinner lunch"".split())` from the [tutorial](https://rare-technologies.com/word2vec-tutorial/), it produces FutureWarning on the `vstack` function. It seems that [I am not the first person to encounter this error as well](https://stackoverflow.com/questions/56593904/word2vec-doesnt-match-function-throws-numpy-warning). It might also be similar to [Issue 2432](https://github.com/RaRe-Technologies/gensim/issues/2432). The error reads:  

> C:\Path_to_gensim\keyedvectors.py:877:  FutureWarning: arrays to stack must be passed as a ""sequence"" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.  
> vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)   

#### Steps/code/corpus to reproduce

```python  
from gensim.test.utils import datapath, get_tmpfile  
from gensim.models import KeyedVectors  
from gensim.scripts.glove2word2vec import glove2word2vec  

glove_file = datapath('test_glove.txt')  
tmp_file = get_tmpfile(""test_word2vec.txt"")  
_ = glove2word2vec(glove_file, tmp_file)  
model = KeyedVectors.load_word2vec_format(tmp_file)  
model.doesnt_match(""breakfast cereal dinner lunch"".split())

```

#### Versions

```python
Windows-10-10.0.17763-SP0   
python 3.8.2   (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)]   
Bits 64   
NumPy 1.19.0   
SciPy 1.5.2   
gensim 3.8.3   
FAST_VERSION 0
```"
788,https://github.com/RaRe-Technologies/gensim/issues/2989,2989,[],closed,2020-10-23 22:08:00+00:00,,Runtime error when producing topic document matrix (MALLET) ,"

#### Problem description

I'm using the gensim's mallet wrapper to infer the topic modeling results. I came across `RuntimeError: invalid doc topics format at line 2 in .../...doctopics.txt` and I thought the error only occurred in mallet==2.0.7 (it seems there's sth wrong with the `read_doctopics()`). I can read the output using revised function in #599 but I wonder why they are again not compatible... Did anyone run into the same issue and have a solution for this? (Thanks in advance!)


#### Versions
gensim==3.8.0
mallet==2.0.8

The error message:

```python---------------------------------------------------------------------------

RuntimeError                              Traceback (most recent call last)
<ipython-input-16-090396c3cd0e> in <module>
----> 1 fetch_topic_doc(model)

<ipython-input-7-db74820da1a0> in fetch_topic_doc(model)
      1 def fetch_topic_doc(model):
      2     model.prefix = f""{ROOT_PATH}/temp/2666_""
----> 3     matrix = [*model.load_document_topics()]
      4     print(f""# of docs: {len(matrix)}"")
      5     return matrix

~/.local/lib/python3.7/site-packages/gensim/models/wrappers/ldamallet.py in read_doctopics(self, fname, eps, renorm)
    559                                     count += 1
    560                     else:
--> 561                         raise RuntimeError(""invalid doc topics format at line %i in %s"" % (lineno + 1, fname))
    562 
    563                 if renorm:

```
"
789,https://github.com/RaRe-Technologies/gensim/issues/2990,2990,"[{'id': 2460503557, 'node_id': 'MDU6TGFiZWwyNDYwNTAzNTU3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/question', 'name': 'question', 'color': 'e098e2', 'default': True, 'description': 'Discussions that are generally off-topic for the github issue tracker'}]",closed,2020-10-24 19:00:05+00:00,,No explanation of the languages supported by Gensim various modules,"#### Problem description

Many NLP libraries exist today that support many NLP related tasks. Unfortunately not all of them support more beyond English and few other languages. My GUESS here is Gensim does support more languages. But Does it?
It would be nice if anywhere in the docs it would be specified that Gensim supports languages X.Y.Z (supports Unicode, has language models, ...) - or even better - language agnostic.

#### Reproduce

A usual search would be ""gensim supported languages"".

#### Versions

<= 3.8.3"
790,https://github.com/RaRe-Technologies/gensim/issues/2994,2994,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}, {'id': 1602334472, 'node_id': 'MDU6TGFiZWwxNjAyMzM0NDcy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20MEDIUM', 'name': 'impact MEDIUM', 'color': '7af49f', 'default': False, 'description': 'Big annoyance for affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",open,2020-11-02 08:33:12+00:00,,Wheel support for linux aarch64,"**Summary**
Installing gensim on aarch64 via pip using command ""pip3 install gensim"" tries to build wheel from source code.

**Problem description**
gensim doesn't have wheel for aarch64 on PyPI repository. So, while installing gensim via pip on aarch64, pip builds wheel for same resulting in it takes more time to install gensim. Making wheel available for aarch64 will benefit aarch64 users by minimizing gensim installation time.

**Expected Output**
Pip should be able to download gensim wheel from PyPI repository rather than building it from source code.

@gensim-team, please let me know if I can help you building wheel/uploading to PyPI repository. I am curious to make gensim wheel available for aarch64. It will be a great opportunity for me to work with you.

"
791,https://github.com/RaRe-Technologies/gensim/issues/2995,2995,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",closed,2020-11-04 00:03:47+00:00,,Make the link to the Gensim 3.8.3 documentation dynamic,"Clicking on the ""Gensim 3.8.3 documentation"" link in the header of the Gensim 4.0.0 documentation redirects the user to [the index page of the Gensim 3.8.3 documentation](https://radimrehurek.com/gensim_3.8.3/) rather than to the corresponding page, which is an unpleasant user experience. For example, try getting from [the 4.0.0 documentation of `gensim.models.phrases`](https://radimrehurek.com/gensim/models/phrases.html) to its 3.8.3 documentation.

A quick fix would be to set an ID attribute on the link and add inline JavaScript code that would update the HREF attribute of the link according to the current value of `location.pathname`.

https://github.com/RaRe-Technologies/gensim/blob/60a8f7f5599e241779b82f97d375a5046cb730c9/docs/src/sphinx_rtd_theme/notification.html#L2"
792,https://github.com/RaRe-Technologies/gensim/issues/2997,2997,[],closed,2020-11-12 06:26:58+00:00,,使用word2vec的时候，对英文训练，如何指定切词后的分隔符不为空格呢,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? What is the expected result? What are you seeing instead?

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import struct; print(""Bits"", 8 * struct.calcsize(""P""))
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```

主要想咨询一下，我在训练之前使用jieba生成了英文的自定义词典，比如""Tangible symbol systems"" ,但是jieba将所有英文句子切分之后也还是空格，所以，在word2vec训练的时候还是没有把这个当成一个词来进行训练，请问一下， 这个需要怎么解决呢

"
793,https://github.com/RaRe-Technologies/gensim/issues/2998,2998,[],closed,2020-11-14 01:33:56+00:00,,KeyedVectors.most_similar() API has a confusing wrinkle,"There is a shorthand written into the API for `KeyedVectors.most_similar()` that can result in confusion:

https://github.com/RaRe-Technologies/gensim/blob/a28a3e79f4c4cbd97106fc9b35034707295994cd/gensim/models/keyedvectors.py#L745-L747

I imagine this reduces more confusion than it causes, but it can cause the unexpected result that 
```python
model.mv.most_similar(positive=""dog"")
```
works as expected, but 
```python
model.wv.most_similar(negative=""dog"")
```
raises a potentially confusion exception.  While neither is ""correct"" according to the docs, this result can be unexpected (see https://twitter.com/quinnanya/status/1318398096041078784).

It seems like it would be straightforward to either accept a `KEY_TYPES` argument in *either* case, or to catch the error earlier and return a more helpful error message."
794,https://github.com/RaRe-Technologies/gensim/issues/2999,2999,[],open,2020-11-16 15:26:41+00:00,,evaluate_word_analogies deviates from reference implementation and is locale-dependent,"The [reference implementation](https://github.com/facebookresearch/fastText/blob/master/python/doc/examples/compute_accuracy.py) of the word analogy task evaluation lower-cases the query words to match [the lower-cased corpus of fastText](https://github.com/facebookresearch/fastText/blob/master/get-wikimedia.sh). Gensim's [`evaluate_word_analogies`](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.KeyedVectors.evaluate_word_analogies) method offers similar functionality with its `case_insensitive` parameter, but it upper-cases the query words instead. The issue is that Unicode case is [among other things](https://www.b-list.org/weblog/2018/nov/26/case/) (1) locale-dependent and (2) not transitive:

1. Lower-casing maps I to ı in Turkish and to i in most other locales.
2. Upper-casing maps ß to SS, and lower-casing maps SS to ss (not ß).

As a result, Gensim's `evaluate_word_analogies` method deviates from the reference implementation and depends on the current locale. For languages such as Turkish, the impact on the word analogy accuracies is significant, see the table below, which reproduces the results of [the *Learning Word Vectors for 157 Languages* 2018 article][grave]: 

|                                          | Cs | De | Es | Fi | Fr | Hi | It | Pl | Pt | *Tr* | Zh |
|------------------------------------------|--------|--------|--------|--------|--------|--------|--------|--------|--------|--------|--------|
| [Grave et al. (2018)][grave] | 69.9 | 72.9 | 65.4 | 70.3 | 73.6 | 32.1 | 69.8 | 67.9 | 66.7 | | 78.4 |
| [Our results][], no case transformation | 69.9 | 74.9 | 63.9 | 53.3 | 76.7 | 32.2 | 71.9 | 71.4 | 67.5 | *58.2* | 78.5
| [Our results][], upper-casing, U.S. English | 70.7 | 73.4 | 65.6 | 71.2 | 73.7 | 32.2 | 73.0 | 68.5 | 67.0 | *57.0* | 78.5
| [Our results][], upper-casing, corresponding locales | 70.7 | 73.4 | 65.6 | 71.2 | 73.7 | 32.2 | 73.0 | 68.5 | 67.0 | *61.0* | 78.5
| [Our results][], lower-casing., U.S. English | 70.7 | 73.4 | 65.6 | 71.2 | 73.7 | 32.2 | 73.0 | 68.5 | 67.0 | *56.9* | 78.5
| [Our results][], lower-casing, corresponding locales | 70.7 | 73.4 | 65.6 | 71.2 | 73.7 | 32.2 | 73.0 | 68.5 | 67.0 | *61.0* | 78.5

[grave]: https://arxiv.org/pdf/1802.06893.pdf#page=4
[our results]: https://github.com/MIR-MU/reproducible-ml/blob/main/word-analogy.ipynb

I suggest we replace upper-casing with [case-folding](https://docs.python.org/3.10/library/stdtypes.html?highlight=casefold#str.casefold), which corresponds to lower-casing, but it's transitive and locale-independent:

3. Case-folding maps I to i in all locales, although implementations such as [PyICU](https://pypi.org/project/PyICU/) can map I to ı for Turkish and Azari.
4. Case-folding maps ß, SS, and ss to ss.

|                                          | Cs | De | Es | *Fi* | *Fr* | Hi | It | Pl | Pt | *Tr* | Zh |
|------------------------------------------|--------|--------|--------|--------|--------|--------|--------|--------|--------|--------|--------|
| [Our results][], case-folding | 70.7 | 73.4 | 65.6 | *71.2* | *73.7* | 32.2 | 73.0 | 68.5 | 67.0 | *61.0* | 78.5"
795,https://github.com/RaRe-Technologies/gensim/issues/3001,3001,[],open,2020-11-19 09:35:55+00:00,,save_word2vec_format TypeError when specifying count in KeyedVectors initialization,"#### Problem description

When using preallocation for the initialization of KeyedVectors, the model cannot be stored with `save_word2vec_format`.
This prevents iteratively filling the model with `add_vector` as it would incur a big performance hit.

#### Steps/code/corpus to reproduce

Minimal example:
```python
from gensim.models import KeyedVectors
from gensim.test.utils import get_tmpfile
import numpy as np

keys = [str(x) for x in range(0, 100)]
vectors = np.random.rand(100, 25)

# This works as expected
model_1= KeyedVectors(vector_size=25)
model_1.add_vectors(keys, vectors)
model_1.save_word2vec_format(get_tmpfile(""test1.w2v""))

# But this fails during storing
model_2= KeyedVectors(vector_size=25, count=100)
model_2.add_vectors(keys, vectors)
model_2.save_word2vec_format(get_tmpfile(""test2.w2v""))
```

Traceback of model 2:
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-34-687b0e2e8c4f> in <module>
     15 model_2= KeyedVectors(vector_size=25, count=100)
     16 model_2.add_vectors(keys, vectors)
---> 17 model_2.save_word2vec_format(get_tmpfile(""test2.w2v""))

~/miniconda3/envs/myenv/lib/python3.8/site-packages/gensim/models/keyedvectors.py in save_word2vec_format(self, fname, fvocab, binary, total_vec, write_header, prefix, append, sort_attr)
   1573                 fout.write(f""{total_vec} {self.vector_size}\n"".encode('utf8'))
   1574             for key in keys_to_write:
-> 1575                 key_vector = self[key]
   1576                 if binary:
   1577                     fout.write(f""{prefix}{key} "".encode('utf8') + key_vector.astype(REAL).tobytes())

~/miniconda3/envs/myenv/lib/python3.8/site-packages/gensim/models/keyedvectors.py in __getitem__(self, key_or_keys)
    382             return self.get_vector(key_or_keys)
    383 
--> 384         return vstack([self.get_vector(key) for key in key_or_keys])
    385 
    386     def get_index(self, key, default=None):

TypeError: 'NoneType' object is not iterable
```

#### Versions

```
Linux-3.10.0-1062.9.1.el7.x86_64-x86_64-with-glibc2.10
Python 3.8.5 | packaged by conda-forge | (default, Aug 21 2020, 18:21:27) 
[GCC 7.5.0]
Bits 64
NumPy 1.19.1
SciPy 1.5.2
gensim 4.0.0beta
FAST_VERSION 1
```
"
796,https://github.com/RaRe-Technologies/gensim/issues/3002,3002,[],closed,2020-11-19 16:54:04+00:00,,TypeError: cannot unpack non-iterable numpy.float32 object in gensim 3.8.3,"I am using the gensim 3.8.3 implementation of gensim.models.doc2vec.Doc2Vec and even after seeing the issue already fixed and resolved I have encountered the same problem:

After training the model, I have passed a list of 2 words (present in the vocabulary) to find most similar doctags. 
vec= model.infer_vector(['culture', 'livre'])
model.docvecs.most_similar(positive= vec, topn= 10)[1:]
In the 1st line, the vector is correctly inferred with given vector size and after executing most_similar(), it throws: 

line 1725 in most_similar of keyedvector.py    
    for doc, weight in positive + negative:

TypeError: cannot unpack non-iterable numpy.float32 object

I have looked into solutions given in earlier posts but none of them seems to solve it. I shall be delighted to hear from the team about the issue. My python version is 3.8.5


"
797,https://github.com/RaRe-Technologies/gensim/issues/3008,3008,[],closed,2020-11-27 09:42:37+00:00,,"In softmax layer of word2vec, do we use cosine similarity or dot product?","<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I have read the paper ""Efficient Estimation of Word Representation in Vector Space"".  This article says that, we use **cosine similarity**  in softmax layer of word2vec. But someone says that gensim uses **dot product** in softmax layer of word2vec while uses **cosine similarity** between word vectors which have been trained. I have not read the source code, and I wanted to confirm  whether use  dot product in softmax layer and use cosine similarity after trained.

"
798,https://github.com/RaRe-Technologies/gensim/issues/3009,3009,[],closed,2020-11-27 10:27:22+00:00,,suppress log output for mallet LDA,"I am running gensim LDA wrapper  in a Google Cloud Run instance and I would like to suppress the logging during LDA build because it pollutes the logging output of the cloud run instance. It would be possible to add such an option to the gensim wrapper to mallet LDA?
"
799,https://github.com/RaRe-Technologies/gensim/issues/3010,3010,[],closed,2020-12-02 10:35:35+00:00,,clarification on DM / DBOW in gensim corresponding to original implementation by Mikolov,"I'm presuming doc2vec is gensim is a variant of the original code at https://groups.google.com/g/word2vec-toolkit/c/Q49FIrNOQRo/m/J6KG8mUj45sJ namely https://03685169118318071335.googlegroups.com/attach/9be32365f286a227/word2vec.c?part=0.1&view=1&vt=ANaJVrGehlFBJs1M13VrxygRr6SeaBU66Nb7lJiHrohilyEFoIJFUdQON-sAIMJFaSHt9rxn7HfnbX64-w8W7f_LMk7Xi_u2cwrqg6zdune49gLT81uYWkw

- Does the Distributed Memory (DM) option you have in gensim correspond to training that original word2vec.c 'doc2vec' implementation to specifying cbow = 1 or to cbow = 0 or something else
- Does the Distributed Bag Of Words (DBOW) option you have in gensim  correspond to training that original word2vec.c 'doc2vec' implementation to specifying cbow = 1 or to cbow = 0 or something else"
800,https://github.com/RaRe-Technologies/gensim/issues/3011,3011,[],closed,2020-12-08 21:59:48+00:00,,Dictionary.filter_extremes() creates an Index error in LdaModel.inference() ,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? What is the expected result? What are you seeing instead?

I'm trying to train a an LDA model created from a dictionary and corpus after calling dictionary.filter_extremes(). Note that the code works fine if I remove the filter_extremes() command from the code pipeline. 

#### Steps/code/corpus to reproduce
Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").
```
dct = corpora.Dictionary()
corpus = list(map(lambda x: dct.doc2bow(x,allow_update=True), word_list)) #word_list is a list of words
dct.filter_extremes()
lda_model = LdaModel(corpus=corpus,
                         id2word=dct,
                         random_state=2020,
                         num_topics=5,
                         passes=5,
                         chunksize=10,
                         alpha='asymmetric',
                         decay=0.5,
                         offset=64,
                         eta=None,
                         eval_every=0,
                         iterations=100,
                         gamma_threshold=0.0001,
                         per_word_topics=True,
                         callbacks=[perplexity_logger,convergence_logger,coherence_umass_logger])
```
ERROR: 
```
IndexError                                Traceback (most recent call last)
<ipython-input-70-372b0ac9890c> in <module>
     31                          gamma_threshold=0.0001,
     32                          per_word_topics=True,
---> 33                          callbacks=[perplexity_logger,convergence_logger,coherence_umass_logger])

~/anaconda3/lib/python3.7/site-packages/gensim/models/ldamodel.py in __init__(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)
    369         if corpus is not None:
    370             use_numpy = self.dispatcher is not None
--> 371             self.update(corpus, chunks_as_numpy=use_numpy)
    372 
    373     def init_dir_prior(self, prior, name):

~/anaconda3/lib/python3.7/site-packages/gensim/models/ldamodel.py in update(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)
    718                         pass_, chunk_no * chunksize + len(chunk), lencorpus
    719                     )
--> 720                     gammat = self.do_estep(chunk, other)
    721 
    722                     if self.optimize_alpha:

~/anaconda3/lib/python3.7/site-packages/gensim/models/ldamodel.py in do_estep(self, chunk, state)
    531         if state is None:
    532             state = self.state
--> 533         gamma, sstats = self.inference(chunk, collect_sstats=True)
    534         state.sstats += sstats
    535         state.numdocs += gamma.shape[0]  # avoids calling len(chunk) on a generator

~/anaconda3/lib/python3.7/site-packages/gensim/models/ldamodel.py in inference(self, chunk, collect_sstats)
    479             Elogthetad = Elogtheta[d, :]
    480             expElogthetad = expElogtheta[d, :]
--> 481             expElogbetad = self.expElogbeta[:, ids]
    482 
    483             # The optimal phi_{dwk} is proportional to expElogthetad_k * expElogbetad_w.

IndexError: index 2035 is out of bounds for axis 1 with size 2035
```
LOGS:
```
2020-12-08 16:57:21,412:INFO:using asymmetric alpha [0.33283758, 0.22998512, 0.17569299, 0.14213862, 0.11934563]
2020-12-08 16:57:21,416:INFO:using symmetric eta at 0.2
2020-12-08 16:57:21,420:INFO:using serial LDA version on this node
2020-12-08 16:57:21,424:INFO:running online (multi-pass) LDA training, 5 topics, 50 passes over the supplied corpus of 54 documents, updating model once every 54 documents, evaluating perplexity every 0 documents, iterating 100x with a convergence threshold of 0.000100
2020-12-08 16:57:21,586:INFO:PROGRESS: pass 0, at document #54/54
2020-12-08 16:57:21,586:DEBUG:performing inference on a chunk of 54 documents
```


#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import struct; print(""Bits"", 8 * struct.calcsize(""P""))
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
Run from my jupyter notebook:
```
Darwin-19.6.0-x86_64-i386-64bit
Python 3.7.3 | packaged by conda-forge | (default, Mar 27 2019, 15:43:19) 
[Clang 4.0.1 (tags/RELEASE_401/final)]
Bits 64
NumPy 1.19.4
SciPy 1.3.0
gensim 3.4.0
FAST_VERSION 1
```
"
801,https://github.com/RaRe-Technologies/gensim/issues/3013,3013,[],open,2020-12-20 15:40:00+00:00,,AttributeError: 'Word2Vec' object has no attribute 'trainables',"#### Problem description
Trying to load a previously trained word2vec model

#### Steps/code/corpus to reproduce
```
from gensim.models import Word2Vec
f= 'word2vec_siz300_win5_min5_itr50_v1.model'
model= Word2Vec.load(f)
```

```
  File ""/anaconda3/envs/py37_gensim383/lib/python3.7/site-packages/gensim/models/word2vec.py"", line 1141, in load
    model = super(Word2Vec, cls).load(*args, **kwargs)

  File ""/anaconda3/envs/py37_gensim383/lib/python3.7/site-packages/gensim/models/base_any2vec.py"", line 1230, in load
    model = super(BaseWordEmbeddingsModel, cls).load(*args, **kwargs)

  File ""/anaconda3/envs/py37_gensim383/lib/python3.7/site-packages/gensim/models/base_any2vec.py"", line 602, in load
    return super(BaseAny2VecModel, cls).load(fname_or_handle, **kwargs)

  File ""/anaconda3/envs/py37_gensim383/lib/python3.7/site-packages/gensim/utils.py"", line 436, in load
    obj._load_specials(fname, mmap, compress, subname)

  File ""/anaconda3/envs/py37_gensim383/lib/python3.7/site-packages/gensim/utils.py"", line 481, in _load_specials
    setattr(self, attrib, val)

  File ""/anaconda3/envs/py37_gensim383/lib/python3.7/site-packages/gensim/utils.py"", line 1461, in new_func1
    return func(*args, **kwargs)

  File ""/anaconda3/envs/py37_gensim383/lib/python3.7/site-packages/gensim/models/base_any2vec.py"", line 791, in syn1neg
    self.trainables.syn1neg = value

AttributeError: 'Word2Vec' object has no attribute 'trainables'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):

  File ""<ipython-input-1-924733eaebe1>"", line 3, in <module>
    model= Word2Vec.load(f)

  File ""/anaconda3/envs/py37_gensim383/lib/python3.7/site-packages/gensim/models/word2vec.py"", line 1152, in load
    return load_old_word2vec(*args, **kwargs)

  File ""/anaconda3/envs/py37_gensim383/lib/python3.7/site-packages/gensim/models/deprecated/word2vec.py"", line 169, in load_old_word2vec
    old_model = Word2Vec.load(*args, **kwargs)

  File ""/anaconda3/envs/py37_gensim383/lib/python3.7/site-packages/gensim/models/deprecated/word2vec.py"", line 1627, in load
    for v in model.wv.vocab.values():

AttributeError: 'EuclideanKeyedVectors' object has no attribute 'vocab'


````


#### Versions
```
Linux-5.8.0-29-generic-x86_64-with-debian-bullseye-sid
Python 3.7.9 (default, Aug 31 2020, 12:42:55) 
[GCC 7.3.0]
Bits 64
NumPy 1.19.4
SciPy 1.5.3
gensim 3.8.3
FAST_VERSION 0
```
"
802,https://github.com/RaRe-Technologies/gensim/issues/3014,3014,"[{'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}, {'id': 1602278675, 'node_id': 'MDU6TGFiZWwxNjAyMjc4Njc1', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20HIGH', 'name': 'reach HIGH', 'color': '229e03', 'default': False, 'description': 'Affects most or all Gensim users'}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}]",open,2020-12-20 21:20:36+00:00,,Deprecation warnings: `scipy.sparse.sparsetools` and `np.float` ,"#### Problem description

Run the test for the new version of [WEFE](https://github.com/raffaem/wefe)

#### Steps/code/corpus to reproduce

```
../../../../../../home/raffaele/.virtualenvs/gensim4/lib/python3.8/site-packages/scipy/sparse/sparsetools.py:21
  /home/raffaele/.virtualenvs/gensim4/lib/python3.8/site-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!
  scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.
    _deprecated()

../../../../../../home/raffaele/.virtualenvs/gensim4/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:34
  /home/raffaele/.virtualenvs/gensim4/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:34: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. Use `float` by itself, which is identical in behavior, to silence this warning. If you specifically wanted the numpy scalar type, use `np.float_` here.
    method='lar', copy_X=True, eps=np.finfo(np.float).eps,

../../../../../../home/raffaele/.virtualenvs/gensim4/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:164
  /home/raffaele/.virtualenvs/gensim4/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:164: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. Use `float` by itself, which is identical in behavior, to silence this warning. If you specifically wanted the numpy scalar type, use `np.float_` here.
    method='lar', copy_X=True, eps=np.finfo(np.float).eps,

../../../../../../home/raffaele/.virtualenvs/gensim4/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:281
  /home/raffaele/.virtualenvs/gensim4/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:281: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. Use `float` by itself, which is identical in behavior, to silence this warning. If you specifically wanted the numpy scalar type, use `np.float_` here.
    eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,

../../../../../../home/raffaele/.virtualenvs/gensim4/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:865
  /home/raffaele/.virtualenvs/gensim4/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:865: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. Use `float` by itself, which is identical in behavior, to silence this warning. If you specifically wanted the numpy scalar type, use `np.float_` here.
    eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,

../../../../../../home/raffaele/.virtualenvs/gensim4/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:1121
  /home/raffaele/.virtualenvs/gensim4/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:1121: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. Use `float` by itself, which is identical in behavior, to silence this warning. If you specifically wanted the numpy scalar type, use `np.float_` here.
    eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,

../../../../../../home/raffaele/.virtualenvs/gensim4/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:1149
  /home/raffaele/.virtualenvs/gensim4/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:1149: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. Use `float` by itself, which is identical in behavior, to silence this warning. If you specifically wanted the numpy scalar type, use `np.float_` here.
    eps=np.finfo(np.float).eps, positive=False):

../../../../../../home/raffaele/.virtualenvs/gensim4/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:1379
  /home/raffaele/.virtualenvs/gensim4/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:1379: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. Use `float` by itself, which is identical in behavior, to silence this warning. If you specifically wanted the numpy scalar type, use `np.float_` here.
    max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,

../../../../../../home/raffaele/.virtualenvs/gensim4/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:1621
  /home/raffaele/.virtualenvs/gensim4/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:1621: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. Use `float` by itself, which is identical in behavior, to silence this warning. If you specifically wanted the numpy scalar type, use `np.float_` here.
    max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,

../../../../../../home/raffaele/.virtualenvs/gensim4/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:1755
  /home/raffaele/.virtualenvs/gensim4/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:1755: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. Use `float` by itself, which is identical in behavior, to silence this warning. If you specifically wanted the numpy scalar type, use `np.float_` here.
    eps=np.finfo(np.float).eps, copy_X=True, positive=False):
```

#### Versions

Please provide the output of:

```python
Linux-5.8.0-33-generic-x86_64-with-glibc2.32
Python 3.8.6 (default, Sep 25 2020, 09:36:53) 
[GCC 10.2.0]
Bits 64
NumPy 1.20.0rc1
SciPy 1.6.0rc1
gensim 4.0.0beta
FAST_VERSION 1
```
"
803,https://github.com/RaRe-Technologies/gensim/issues/3015,3015,"[{'id': 175642, 'node_id': 'MDU6TGFiZWwxNzU2NDI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/wishlist', 'name': 'wishlist', 'color': 'd7e102', 'default': False, 'description': 'Feature request'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 1602279836, 'node_id': 'MDU6TGFiZWwxNjAyMjc5ODM2', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20MEDIUM', 'name': 'reach MEDIUM', 'color': 'ef7a1a', 'default': False, 'description': 'Affects a significant number of users'}, {'id': 1602334472, 'node_id': 'MDU6TGFiZWwxNjAyMzM0NDcy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20MEDIUM', 'name': 'impact MEDIUM', 'color': '7af49f', 'default': False, 'description': 'Big annoyance for affected users'}]",open,2020-12-21 22:17:26+00:00,,"Add convenience `get_sentence_vector()`-like methods for FastText, other models","Per <https://stackoverflow.com/questions/65397810/whats-the-equivalent-to-get-sentence-vector-for-gensims-fasttext>, the official Python FastText wrapper offers a `get_sentence_vector()` convenience method to averaging the word-vectors of a text. 

Gensim could offer something similar, for FastText & other models. Though, it should perhaps have a more generic name & clear docs that this is just one simple way to create a text-vector from a bunch of words. "
804,https://github.com/RaRe-Technologies/gensim/issues/3017,3017,[],closed,2020-12-27 13:07:01+00:00,,Inconsistency within documentation,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

Hi, I found inconsistency within your documentation. 
In some examples `AnnoyIndexer` is imported from `gensim.similarities.annoy` and in some from `gensim.similarities.index`.
I tried to import form both but only `gensim.similarities.index` works.

#### Steps/code/corpus to reproduce

Go to documentation: https://radimrehurek.com/gensim/similarities/annoy.html .

#### Versions
```
Windows-10-10.0.19041-SP0
Python 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]
Bits 64
NumPy 1.19.2
SciPy 1.5.2
gensim 3.8.3
FAST_VERSION 1
```

"
805,https://github.com/RaRe-Technologies/gensim/issues/3018,3018,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2021-01-02 23:54:53+00:00,,Gensim wrappers ldamallet is very slow when generating topics for unseen documents,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

Is there any way to accelerate generating topics for unseen documents using Gensim wrappers ldamallet model? I find it very slow compared to gensim.models.LdaMulticore model. And I would like to generate topics for 300k documents using ldamallet model.

I find the ldamallet model could boost the c_v performance of topic modelling from 0.46 to 0.58.

#### Steps/code/corpus to reproduce

mallet_model = LdaMallet(path_to_mallet_binary, corpus=bow_corpus, num_topics=47, id2word=dictionary)

#### Versions
Darwin-19.5.0-x86_64-i386-64bit
Python 3.7.4 (v3.7.4:e09359112e, Jul  8 2019, 14:54:52) 
[Clang 6.0 (clang-600.0.57)]
Bits 64
NumPy 1.17.2
SciPy 1.4.1
gensim 3.8.3
FAST_VERSION 0

"
806,https://github.com/RaRe-Technologies/gensim/issues/3019,3019,[],closed,2021-01-06 02:20:05+00:00,,can not import ENGLISH_CONNECTOR_WORDS from gensim.models.phrases,"#### Problem description
When I try to load the gensim ENGLISH_CONNECTOR_WORDS,  it seems to be missing in my current version. I am trying to use common stopwords in my Phrase detection training.

#### Steps/code/corpus to reproduce

Here is what I tried to do by following the [gensim Phrase Detection documnetation](https://radimrehurek.com/gensim/models/phrases.html).

```python
from gensim.models.phrases import Phrases, ENGLISH_CONNECTOR_WORDS
```
Here is the output:
```python
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
<ipython-input-5-f038e2aaf034> in <module>
----> 1 from gensim.models.phrases import Phrases, ENGLISH_CONNECTOR_WORDS

ImportError: cannot import name 'ENGLISH_CONNECTOR_WORDS' from 'gensim.models.phrases' (/project/venv/lib/python3.9/site-packages/gensim/models/phrases.py)
```

#### Versions
```python
macOS-10.15.7-x86_64-i386-64bit
Python 3.9.0 (default, Oct 30 2020, 16:46:27) 
[Clang 12.0.0 (clang-1200.0.32.2)]
Bits 64
NumPy 1.19.4
SciPy 1.6.0
gensim 3.8.3
FAST_VERSION 0
```
"
807,https://github.com/RaRe-Technologies/gensim/issues/3021,3021,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2021-01-08 10:50:10+00:00,,gensim 4.0 NameError: name 'string_types' is not defined,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? What is the expected result? What are you seeing instead?

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import struct; print(""Bits"", 8 * struct.calcsize(""P""))
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
"
808,https://github.com/RaRe-Technologies/gensim/issues/3022,3022,[],open,2021-01-10 14:13:56+00:00,,CalledProcessError,"os.environ.update({'MALLET_HOME':r'C:/Users/kanna/OneDrive/Desktop/mallet-2.0.8/'})
mallet_path = r'C:\Users\kanna\OneDrive\Desktop\mallet-2.0.8\bin\mallet'

ldamallet = LdaMallet(mallet_path, corpus = corpus, id2word = dictionary, iterations = 30)
ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=26, id2word=dictionary)

---------------------------------------------------------------------------
CalledProcessError                        Traceback (most recent call last)
<ipython-input-118-61f7624d1351> in <module>()
----> 1 ldamallet = LdaMallet(mallet_path, corpus = corpus, id2word = dictionary, iterations = 30)
      2 ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=26, id2word=dictionary)

3 frames
/usr/local/lib/python3.6/dist-packages/gensim/utils.py in check_output(stdout, *popenargs, **kwargs)
   1877             error = subprocess.CalledProcessError(retcode, cmd)
   1878             error.output = output
-> 1879             raise error
   1880         return output
   1881     except KeyboardInterrupt:

**CalledProcessError: Command 'C:\Users\kanna\OneDrive\Desktop\mallet-2.0.8\bin\mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex ""\S+"" --input /tmp/f25cd6_corpus.txt --output /tmp/f25cd6_corpus.mallet' returned non-zero exit status 127.**

I had this error. Kindly help me to resolve this."
809,https://github.com/RaRe-Technologies/gensim/issues/3025,3025,[],closed,2021-01-12 07:33:17+00:00,,Custom Keyword inclusion,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

Our need is the generated summary should have specific keywords from the input text.

#### Steps/code/corpus to reproduce

We need the summarize function to have accept keywords as input parameter.

output = summarize(text, word_count=9, **custom_keywords=keywords**)

**For example,**
```
from gensim.summarization.summarizer import summarize

keywords = ['apple', 'red', 'yellow']
text = ""Apple is red. Grape is black. Banana is yellow""

output = summarize(text, word_count=9, custom_keywords=keywords)

print(output) 

```
#### Output

**Apple** is **red.** 
Banana is **yellow**

As in above example, we need a parameter to include custom keywords and those keywords must be present in the summarized text.
(i.e) The sentences with the keywords should be present in the output.


"
810,https://github.com/RaRe-Technologies/gensim/issues/3027,3027,[],closed,2021-01-16 09:16:24+00:00,,text8 download is super slow,"#### Problem description

I get ~40KB/sec for https://github.com/RaRe-Technologies/gensim-data/releases/download/text8/text8.gz

Could it be hosted on https://radimrehurek.com/gensim/ instead?

It's much faster today than a few days ago though.

#### Steps/code/corpus to reproduce

```
import gensim.downloader as api
docs = api.load('text8')
```

#### Versions

Linux-4.20.0-042000-generic-x86_64-with-glibc2.29
Python 3.8.5 (default, Jul 28 2020, 12:59:40) 
[GCC 9.3.0]
Bits 64
NumPy 1.17.4
SciPy 1.3.3
gensim 4.0.0.dev0
FAST_VERSION 1
"
811,https://github.com/RaRe-Technologies/gensim/issues/3028,3028,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",closed,2021-01-19 08:44:24+00:00,,AttributeError: 'Word2Vec' object has no attribute 'most_similar',"
#### Problem description

When I was trying to use a trained word2vec model to find the similar word, it showed that 'Word2Vec' object has no attribute 'most_similar'.

I haven't seen that what are changed of the 'most_similar' attribute from gensim 4.0. When I was using the gensim in Earlier versions, most_similar() can be used as:

model_hasTrain=word2vec.Word2Vec.load(saveBinPath)
y=model_hasTrain.most_similar('price',topn=100)


I don't know that are most_similar() removed or changed? Or do I need to reinstall the gensim? Thank you for solving my problem. Thanks very much.





#### Versions

Please provide the output of:

```python
Windows-2012Server-6.2.9200-SP0
Python 3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]
Bits 64
NumPy 1.18.5
SciPy 1.5.0
gensim 4.0.0beta
FAST_VERSION 1
```
"
812,https://github.com/RaRe-Technologies/gensim/issues/3029,3029,"[{'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 708430967, 'node_id': 'MDU6TGFiZWw3MDg0MzA5Njc=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/performance', 'name': 'performance', 'color': 'd93f0b', 'default': False, 'description': 'Issue related to performance (in HW meaning)'}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",open,2021-01-19 08:47:30+00:00,,SECURITY: bad regex pattern in 'gensim/corpora/wikicorpus.py' maybe cause 'ReDos' security problem.,"#### Problem description

i found two bad regex pattern in 'gensim/corpora/wikicorpus.py' 

```
RE_P7 = re.compile(r'\n\[\[[iI]mage(.*?)(\|.*?)*\|(.*?)\]\]', re.UNICODE)
""""""Keep description of images.""""""
RE_P8 = re.compile(r'\n\[\[[fF]ile(.*?)(\|.*?)*\|(.*?)\]\]', re.UNICODE)
""""""Keep description of files.""""""
```

those pattern will cause 'ReDos' security problem,  proof of code like below

```
import re
RE_P8 = re.compile(r'\n\[\[[fF]ile(.*?)(\|.*?)*\|(.*?)\]\]', re.UNICODE)
re.findall(RE_P8, ""\n[[file""+""|a""*1000+""|]"")
```

run the above code, cpu utilization will be 100% in a very long period.


more detail about 'ReDos' please see [owasp](https://owasp.org/www-community/attacks/Regular_expression_Denial_of_Service_-_ReDoS).

#### effect of this security problem 
because i did not see anywhere use 'RE_P7' and 'RE_P8' pattern, and not familiar with gensim api, so i can not decide what's the effect of this security problem."
813,https://github.com/RaRe-Technologies/gensim/issues/3031,3031,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}]",closed,2021-01-20 07:11:54+00:00,,Runtime error in phrases.py,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

Trying to use export_phrases function on a phrases model.    
Instead getting Runtime error

#### Steps/code/corpus to reproduce

```python
from gensim.models.phrases import Phrases, ENGLISH_CONNECTOR_WORDS

documents = [""I am interested in machine learning projects"", 
             ""machine learning projects can be useful sometimes"",
            ""I love working on machine learning projects"",
            ""interested does not mean the same thing as likes"",
            ""i am interested in blockchain""]

sentence_stream = [doc.split("" "") for doc in documents]
bigrams = Phrases(sentence_stream, min_count=2, threshold=1, connector_words=ENGLISH_CONNECTOR_WORDS)
trigrams = Phrases(bigrams[sentence_stream], min_count=2, threshold=1)
trigrams.export_phrases()
```

```
RuntimeError                              Traceback (most recent call last)
<ipython-input-190-0f7e41471301> in <module>
----> 1 trigrams.export_phrases()

~\Anaconda3\lib\site-packages\gensim\models\phrases.py in export_phrases(self)
    716         """"""
    717         result, source_vocab = {}, self.vocab
--> 718         for token in source_vocab:
    719             unigrams = token.split(self.delimiter)
    720             if len(unigrams) < 2:

RuntimeError: dictionary changed size during iteration
```



#### Versions

Please provide the output of:

```python
Windows-10-10.0.17763-SP0
Python 3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]
Bits 64
NumPy 1.19.5
SciPy 1.5.2
gensim 4.0.0beta
FAST_VERSION 0
```
"
814,https://github.com/RaRe-Technologies/gensim/issues/3032,3032,[],closed,2021-01-20 14:24:50+00:00,,build_vocab_from_freq cannot be called with update=True,"#### Problem description

If I try to use Word2Vec or FastText with a pre-supplied frequency dictionary using build_vocab_from_freq and update it with new words, the following error is emitted:

AttributeError: 'FastTextVocab' object has no attribute 'old_vocab_len'

Perhaps this isn't the intended use, but there should at least be a better way of handling this. I have found that adding the following line to the end of the method build_vocab_from_freq in the class BaseWordEmbeddingsModel fixes the bug.

self.vocabulary.old_vocab_len = len(raw_vocab)

#### Steps/code/corpus to reproduce

from gensim.models.fasttext import FastText
g1_dict = {'hello':14, 'machine':3}
g2_dict = {'goodbye':9, 'world':2}
model = FastText() # A similar error if Word2Vec is used
model.build_vocab_from_freq(word_freq=g1_dict)
model.build_vocab_from_freq(word_freq=g2_dict,update=True)

#### Versions

Linux-4.14.209-160.339.amzn2.x86_64-x86_64-with-glibc2.10
Python 3.8.3 (default, Jul  2 2020, 16:21:59) 
[GCC 7.3.0]
Bits 64
NumPy 1.18.5
SciPy 1.5.0
gensim 3.8.3
FAST_VERSION 1
"
815,https://github.com/RaRe-Technologies/gensim/issues/3034,3034,[],closed,2021-01-27 04:20:03+00:00,,keyword argument 'vector_size' not in Word2Vec,"```
Linux-4.15.0-106-generic-x86_64-with-debian-buster-sid
Python 3.7.9 (default, Aug 31 2020, 12:42:55) 
[GCC 7.3.0]
Bits 64
NumPy 1.19.2
SciPy 1.5.2
gensim 3.8.3
FAST_VERSION 1
```

Error:

```
----> 4 model = Word2Vec(sentences=docs, vector_size=200, min_count=5, workers=40)

TypeError: __init__() got an unexpected keyword argument 'vector_size'
```"
816,https://github.com/RaRe-Technologies/gensim/issues/3036,3036,[],open,2021-01-30 23:43:22+00:00,,"import gensim segmentation fault (macOS Big Sur, Apple M1/Apple Silicon/ARM)","#### Problem description

I want to use gensim on a new Apple M1 machine but I can't import gensim because of a segmentation fault.

#### Steps/code/corpus to reproduce

```bash
brew install openblas

cd ~/Library/python_enviroments
rm -r test
virtualenv -p /opt/homebrew/bin/python3 test
source ~/Library/python_enviroments/test/bin/activate
pip cache purge
pip install --upgrade pip

OPENBLAS=""$(brew --prefix openblas)"" MACOSX_DEPLOYMENT_TARGET=11.1 python -m pip install cython --no-use-pep517
OPENBLAS=""$(brew --prefix openblas)"" MACOSX_DEPLOYMENT_TARGET=11.1 python -m pip install numpy --no-use-pep517
OPENBLAS=""$(brew --prefix openblas)"" MACOSX_DEPLOYMENT_TARGET=11.1 python -m pip install pybind11 --no-use-pep517
OPENBLAS=""$(brew --prefix openblas)"" MACOSX_DEPLOYMENT_TARGET=11.1 python -m pip install scipy --no-use-pep517
OPENBLAS=""$(brew --prefix openblas)"" MACOSX_DEPLOYMENT_TARGET=11.1 python -m pip install gensim --no-use-pep517
```

Now I am running a python shell and run this import command:
```python
import gensim
```

Output:
```python
Python 3.9.1 (default, Jan  8 2021, 12:11:08) 
[Clang 12.0.0 (clang-1200.0.32.28)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import gensim
zsh: segmentation fault  python
```

Note: `import numpy` and `import scipy` are working.

#### Versions

* macOS Big Sur 11.1 (20C69)
* openblas/0.3.13 (homebrew)
* Python 3.9.1 (homebrew)

```
Package    Version
---------- -------
Cython     0.29.21
gensim     3.8.3
numpy      1.20.0
pip        21.0.1
pybind11   2.6.2
scipy      1.6.0
setuptools 51.3.3
six        1.15.0
smart-open 4.1.2
wheel      0.36.2
```

```
>>> import platform; print(platform.platform())
macOS-11.1-arm64-arm-64bit
>>> import sys; print(""Python"", sys.version)
Python 3.9.1 (default, Jan  8 2021, 12:11:08) 
[Clang 12.0.0 (clang-1200.0.32.28)]
>>> import struct; print(""Bits"", 8 * struct.calcsize(""P""))
Bits 64
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.20.0
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.6.0
```"
817,https://github.com/RaRe-Technologies/gensim/issues/3037,3037,[],closed,2021-01-31 11:30:11+00:00,,How does Gensim handling pad index and UNK index in W2V models? ,"I'm using Gensim for building W2V models and, I didn't find a way for adding a vector for Unkown words or padding parts in Gensim and, I have to do it manually.
I also check the index of 0 in the created embedding and, it is also used for a specific word. This matter could cause a problem for padding words because they have the same index.

Am I missing something in here? Is Gensim handle this problem?

P.S: For handling this issue, I always append two vectors in the model weights after I train the model."
818,https://github.com/RaRe-Technologies/gensim/issues/3038,3038,[],closed,2021-02-01 07:34:47+00:00,,Gensim Mallet error: Non-zero exit status 1,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I am trying to use Mallet in Gensim with Spyder. Initially, I had non-zero exit status 1 error but everything ran smoothly after I installed Java Developers Kit. However, after I started a new kernel and ran the exactly same set of code, the non-zero exit status 1 error popped up again. Then I restarted the kernel and repeatedly ran the same code and sometimes Mallet worked and sometimes doesn't. May I ask if there is a stable way to do it?
Will really appreciate your suggestions!

### Here is the code I used.
import os
from gensim.models.wrappers import LdaMallet
os.environ['MALLET_HOME'] = r'C:\mallet'
mallet_path = r'C:\mallet\bin\mallet'
ldamallet = gensim.models.wrappers.LdaMallet(mallet_path=mallet_path, corpus=corpus, num_topics=10, id2word=id2word)

#### Versions

Here is the error message.
```python
Command 'C:\mallet\bin\mallet train-topics --input C:\Users\(username omitted)\AppData\Local\Temp\b3098b_corpus.mallet --num-topics 0  --alpha 50 --optimize-interval 0 --num-threads 4 --output-state C:\Users\(username omitted)\AppData\Local\Temp\b3098b_state.mallet.gz --output-doc-topics C:\Users\\AppData\Local\Temp\b3098b_doctopics.txt --output-topic-keys C:\Users\(username omitted)\AppData\Local\Temp\b3098b_topickeys.txt --num-iterations 1000 --inferencer-filename C:\Users\(username omitted)\AppData\Local\Temp\b3098b_inferencer.mallet --doc-topics-threshold 0.0  --random-seed 0' returned non-zero exit status 1.
```
"
819,https://github.com/RaRe-Technologies/gensim/issues/3039,3039,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 1602334472, 'node_id': 'MDU6TGFiZWwxNjAyMzM0NDcy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20MEDIUM', 'name': 'impact MEDIUM', 'color': '7af49f', 'default': False, 'description': 'Big annoyance for affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",open,2021-02-02 01:27:23+00:00,,Documentation Notebooks,"Hello, I was going through some documentation notebooks, and noticed that many of them ([Poincare Embeddings](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/Poincare%20Tutorial.ipynb), [WikiNews](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/wikinews-bigram-en.ipynb), [Varembed](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/Varembed.ipynb)) have been uploaded without being run to the end, they fail with errors halfway through.

@piskvorky (and others), would it be useful to have these updated? Or is someone from the RaRe / gensim team in charge of documentation?"
820,https://github.com/RaRe-Technologies/gensim/issues/3040,3040,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 234670, 'node_id': 'MDU6TGFiZWwyMzQ2NzA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20medium', 'name': 'difficulty medium', 'color': '00d000', 'default': False, 'description': 'Medium issue: required good gensim understanding & python skills'}, {'id': 1602257032, 'node_id': 'MDU6TGFiZWwxNjAyMjU3MDMy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20HIGH', 'name': 'impact HIGH', 'color': 'b60205', 'default': False, 'description': 'Show-stopper for affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",open,2021-02-04 17:38:10+00:00,,'nan' output for CoherenceModel when calculating 'c_v',"#### Problem description

I'm using LDA Multicore from gensim 3.8.3. I'm training on my train corpus and I'm able to evaluate the train corpus using the CoherenceModel within Gensim, to calculate the 'c_v' value. However, when I'm trying to calculate the 'c_v' over my test set, it throws the following warning: 

/Users/xxx/env/lib/python3.7/site-packages/gensim/topic_coherence/direct_confirmation_measure.py:204: RuntimeWarning: divide by zero encountered in double_scalars
  m_lr_i = np.log(numerator / denominator)
/Users/xxx/lib/python3.7/site-packages/gensim/topic_coherence/indirect_confirmation_measure.py:323: RuntimeWarning: invalid value encountered in double_scalars
  return cv1.T.dot(cv2)[0, 0] / (_magnitude(cv1) * _magnitude(cv2))

Furthermore, the output value of the CoherenceModel is 'nan' for some of the topics and therefore I'm not able to evaluate my model on a heldout test set. 

#### Steps/code/corpus to reproduce

I run the following code:

```python
coherence_model_lda = models.CoherenceModel(model=lda_model,
                                            topics=topic_list,
                                            corpus=corpus,
                                            texts=texts,
                                            dictionary=train_dictionary,
                                            coherence=c_v,
                                            topn=20
                                            )

coherence_model_lda.get_coherence() = nan  # output of aggregated cv value

coherence_model_lda.get_coherence_per_topic() = [0.4855137269180713, 0.3718866594914528, nan, nan, nan, 0.6782845928414825, 0.21638660621444444, 0.22337594485796397, 0.5975773184175942, 0.721341268732559, 0.5299883104816663, 0.5057903454344682, 0.5818051100304473, nan, nan, 0.30613393712342557, nan, 0.4104488627000527, nan, nan, 0.46028708148750963, nan, 0.394606654755219, 0.520685457293826, 0.5918440959767729, nan, nan, 0.4842068862650447, 0.9350644411891258, nan, nan, 0.7471151926054456, nan, nan, 0.5084926961568169, nan, nan, 0.4322957454944861, nan, nan, nan, 0.6460815758337844, 0.5810936860540964, 0.6636319471764807, nan, 0.6129884526648472, 0.48915614063099017, 0.4746167359622748, nan, 0.6826979166639224] # output of coherence value per topic 
```

I've tried to increase the EPSILON value within:
gensim.topic_coherence.direct_confirmation_measure, however, this doesn't have any effect. 

Furthermore, I've tried to change the input arguments (e.g. exclude the dictionary argument) but this also doesn't have any effect. I think the error has to do something with the fact that quite a large portion of the words within the test set is not available in the train set, however, the EPSILON value should be able to handle this. 

#### Versions

```
python
Python 3.7.2 (default, Dec  2 2020, 09:47:26) 
[Clang 9.0.0 (clang-900.0.39.2)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import platform; print(platform.platform())
Darwin-18.7.0-x86_64-i386-64bit
>>> import sys; print(""Python"", sys.version)
Python 3.7.2 (default, Dec  2 2020, 09:47:26) 
[Clang 9.0.0 (clang-900.0.39.2)]
>>> import struct; print(""Bits"", 8 * struct.calcsize(""P""))
Bits 64
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.18.5
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.5.2
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.8.3
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```"
821,https://github.com/RaRe-Technologies/gensim/issues/3042,3042,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",open,2021-02-09 12:04:17+00:00,,Phraser max NPMI score > 1,"#### Problem description

I trained a NMPI phraser on the latest wikipedia dump. It is my understanding that scores should be <= 1.0, but I get a higher score.  

#### Steps/code/corpus to reproduce

```python
from gensim.corpora import WikiCorpus
from gensim.models import Phrases
from gensim.models.phrases import Phraser

wiki_corpus = WikiCorpus(""enwiki-latest-pages-articles-multistream.xml.bz2"", dictionary={})

ENGLISH_CONNECTOR_WORDS = frozenset(
    "" a an the ""  # articles; we never care about these in MWEs
    "" for of with without at from to in on by ""  # prepositions; incomplete on purpose, to minimize FNs
    "" and or ""  # conjunctions; incomplete on purpose, to minimize FNs
    .split()
)

phrases = Phrases(wiki_corpus.get_texts(), scoring='npmi', threshold=0.75, min_count=5, common_terms=ENGLISH_CONNECTOR_WORDS, max_vocab_size=80000000)
phraser = Phraser(phrases)
```
Then:
```
In[2]: max(phraser.phrasegrams.values())
Out[2]: 1.2003355030351979
```

#### Versions

```python
Linux-3.10.0-1160.6.1.el7.x86_64-x86_64-with-centos-7.9.2009-Core
Python 3.7.9 (default, Aug 31 2020, 12:42:55)
[GCC 7.3.0]
Bits 64
NumPy 1.19.2
gensim 3.8.0
FAST_VERSION 1
```

"
822,https://github.com/RaRe-Technologies/gensim/issues/3043,3043,[],closed,2021-02-11 07:32:37+00:00,,gensim.scripts.word2vec2tensor results in UnicodeDecodeError,"#### Problem description

- I created a word2vec model from the tokens read from 1.4L files using the following call
model.wv.save_word2vec_format(f""{folder}/wvmodel.wv"", binary=True)
- Ran the following command to convert word-vectors from word2vec format into Tensorflow 2D tensor format
python -m gensim.scripts.word2vec2tensor -i model/wvmodel.wv -o model/ -b

The above command works for tokens read from 5000 files. But it fails when I read the tokens from 6000 files. Looks like there is some content in the one of the files (5000 to 6000) that the **word2vec2tensor** script has problems with.

Is there anyway I can fix this issue? Or atleast identify the offending file and remove it?

#### Steps/code/corpus to reproduce

Unfortunately I cannot share the dataset as it is huge.

2021-02-11 05:28:33,305 - utils_any2vec - INFO - loading projection weights from model/wvmodel.wv
**Traceback** (most recent call last):
  File ""/usr/local/lib/python3.9/runpy.py"", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File ""/usr/local/lib/python3.9/runpy.py"", line 87, in _run_code
    exec(code, run_globals)
  File ""/usr/local/lib/python3.9/site-packages/gensim/scripts/word2vec2tensor.py"", line 94, in <module>
    word2vec2tensor(args.input, args.output, args.binary)
  File ""/usr/local/lib/python3.9/site-packages/gensim/scripts/word2vec2tensor.py"", line 68, in word2vec2tensor
    model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_model_path, binary=binary)
  File ""/usr/local/lib/python3.9/site-packages/gensim/models/keyedvectors.py"", line 1547, in load_word2vec_format
    return _load_word2vec_format(
  File ""/usr/local/lib/python3.9/site-packages/gensim/models/utils_any2vec.py"", line 285, in _load_word2vec_format
    _word2vec_read_binary(fin, result, counts,
  File ""/usr/local/lib/python3.9/site-packages/gensim/models/utils_any2vec.py"", line 204, in _word2vec_read_binary
    processed_words, chunk = _add_bytes_to_result(
  File ""/usr/local/lib/python3.9/site-packages/gensim/models/utils_any2vec.py"", line 186, in _add_bytes_to_result
    word = chunk[start:i_space].decode(""utf-8"", errors=unicode_errors)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xbf in position 0: invalid start byte

#### Versions

Linux-4.14.214-160.339.amzn2.x86_64-x86_64-with-debian-10.6
Python 3.6.12 (default, Nov 18 2020, 14:46:32) 
[GCC 8.3.0]
Bits 64
NumPy 1.19.5
SciPy 1.5.4
gensim 3.8.3
FAST_VERSION 1"
823,https://github.com/RaRe-Technologies/gensim/issues/3044,3044,[],closed,2021-02-12 07:56:50+00:00,,Understanding the topic significance of LDA,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

Hi there, I noticed that the print_topics() of LDA models says ""Get the most significant topics"" and ""The number of topics to be selected, if -1 - all topics will be in result (ordered by significance)"" in the documentation https://radimrehurek.com/gensim/models/ldamodel.html. However, I failed to identify the logic behind it. May I know what mechanisms are utilised to calculate the topic significance? Much appreciated :)"
824,https://github.com/RaRe-Technologies/gensim/issues/3045,3045,[],closed,2021-02-12 20:21:17+00:00,,Understanding the topic significance of LDA,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

Hi there, I noticed that the print_topics() of LDA models says ""Get the most significant topics"" and ""The number of topics to be selected, if -1 - all topics will be in result (ordered by significance)"" in the documentation https://radimrehurek.com/gensim/models/ldamodel.html. However, I failed to identify the logic behind it. May I know what mechanisms are utilised to calculate the topic significance? Much appreciated :)

#### Steps/code/corpus to reproduce

Sorry. This is not an issue to reproduce.

#### Versions

Sorry. This is not an issue related to environment versions. The documentation I'm reading is for Gensim 4.0.0.
"
825,https://github.com/RaRe-Technologies/gensim/issues/3046,3046,[],open,2021-02-17 19:05:01+00:00,,Possible unexplainable segfault after save/load cycles of KeyedVectors or Word2Vec,"Via: https://stackoverflow.com/questions/66040594/in-gensim-word2vec-is-it-safe-to-resume-training-using-keyedvectors-if-model-is?noredirect=1#comment116793635_66040594

In that SO question, reliable cases of getting a segfault are described after either (1) saving/reloading just a model's `KeyedVectors`; or (2) saving/reloading a full model after `build_vocab()` & before `train()`. Size of training data may be involved, per user's report that problem didn't recur when same steps were tried on a small subset of their full data. 

Needs full reproduction case on local (even if synthetic) dataset. "
826,https://github.com/RaRe-Technologies/gensim/issues/3047,3047,[],open,2021-02-19 21:12:09+00:00,,Gensim Downloader error,"I am getting below error when I am using gensim downloader inside docker 

  File ""/usr/local/lib/python3.8/site-packages/gensim/downloader.py"", line 408, in _download
    os.rename(data_folder_dir_tmp, data_folder_dir)
OSError: [Errno 39] Directory not empty: 'tmp/gensim-data/glove-wiki-gigaword-50_tmp' -> 'tmp/gensim-data/glove-wiki-gigaword-50'

"
827,https://github.com/RaRe-Technologies/gensim/issues/3048,3048,[],closed,2021-02-23 07:58:21+00:00,,Can we limit the threads of operation instead of automatic selection by lsi based on the number of cores available ?,"we are trying to use the lsi in openshift platform where the model is taking more time than usual (what it takes on a windows VM) when we are analysing the issue we found that it it trying to allot all the available 128 threadswhile the actual standard on windows was 8 threads 

So is there any way to limit this allocation of threads?"
828,https://github.com/RaRe-Technologies/gensim/issues/3049,3049,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2021-02-25 00:46:05+00:00,,pip install -i still pull dependencies from pypi,"#### Problem description

`pip install -i ${some_source} gensim` would still install dependencies like numpy from pypi instead of {some_resource}
"
829,https://github.com/RaRe-Technologies/gensim/issues/3051,3051,[],closed,2021-02-25 22:25:57+00:00,,Release 3.8.3: vector_size in docs doesn't match release constructor argument for word2vec and fasttext,"A fix seems to be currently in the develop branch, but the pypi release branch (release-3.8.3) [Word2Vec](https://github.com/RaRe-Technologies/gensim/blob/release-3.8.3/gensim/models/word2vec.py#L477) and [FastText](https://github.com/RaRe-Technologies/gensim/blob/release-3.8.3/gensim/models/fasttext.py#L355) files use 'size' as their constructor argument not 'vector_size'. [doc link here](https://radimrehurek.com/gensim/models/word2vec.html)

Marginally related, the  [developer's guide](https://github.com/RaRe-Technologies/gensim/wiki/Developer-page#git-flow) suggests the master branch head is the latest release, but it looks like release-3.8.3 is the one I would get from `pip install gensim` (note, the [master branch](https://github.com/RaRe-Technologies/gensim/blob/8624aa2822f885c56996f9a2f84490c9166c84ca/gensim/models/fasttext.py#L274) correctly uses vector_size).  

Minimal code to test:
```
from gensim.test.utils import common_texts
from gensim.models import Word2Vec

# this is currently on the doc website. Will fail for the pip install gensim version
model = Word2Vec(sentences=common_texts, vector_size=100, window=5, min_count=1, workers=4)

# Using 'size' instead will pass for the default release
model = Word2Vec(sentences=common_texts, size=100, window=5, min_count=1, workers=4)
```

In case it helps:
Linux-5.8.0-43-generic-x86_64-with-glibc2.29
Python 3.8.5 (default, Jul 28 2020, 12:59:40) 
[GCC 9.3.0]
Bits 64
NumPy 1.19.2
SciPy 1.4.1
gensim 3.8.3
FAST_VERSION 1
"
830,https://github.com/RaRe-Technologies/gensim/issues/3052,3052,[],closed,2021-02-26 07:59:20+00:00,,FastTextKeyedVectors' object has no attribute 'key_to_index',"#### Problem description

I am doing some tests on the [italian fasttext model](https://fasttext.cc/docs/en/crawl-vectors.html) using the gensim library on version 3.8.3.
I would like to see if a word is present in the model vocabulary, but it seems that the function is not recognized.

I am using a kaggle notebook and the code to reproduce the error is the following:

```python
from gensim.models.fasttext import load_facebook_model

mod = load_facebook_model('path_to_model/wiki.it.bin')
model = mod.wv
print('sviluppatore' in model.key_to_index)
```
error:

> FastTextKeyedVectors' object has no attribute 'key_to_index'"
831,https://github.com/RaRe-Technologies/gensim/issues/3054,3054,"[{'id': 175640, 'node_id': 'MDU6TGFiZWwxNzU2NDA=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/feature', 'name': 'feature', 'color': '0b02e1', 'default': False, 'description': 'Issue described a new feature'}]",closed,2021-02-27 14:01:19+00:00,,Support for supervised models in FastText,"#### Problem description

This is a feature request for the supervised part of the FastText model

#### Steps/code/corpus to reproduce

No code. I just wonder why the supervised part of FastText is not available.

#### Versions
```zsh
>>> import platform; print(platform.platform())
Linux-5.4.0-47-generic-x86_64-with-glibc2.29
>>> import sys; print(""Python"", sys.version)
Python 3.8.5 (default, Jul 28 2020, 12:59:40) 
[GCC 9.3.0]
>>> import struct; print(""Bits"", 8 * struct.calcsize(""P""))
Bits 64
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.19.2
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.5.2
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.8.3
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1

```
"
832,https://github.com/RaRe-Technologies/gensim/issues/3056,3056,[],closed,2021-03-01 02:37:53+00:00,,Provide Python3.9 Wheels ,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I'm attempting to install this on Windows as it is a dependency for a program I wish to run however, to install from source Microsoft Visual C++ 14.0 is required. 

Would it be possible to provide wheels for this version? 

#### Steps/code/corpus to reproduce

do `pip install gensim` on Python3.9 Windows 10

```
Microsoft Visual C++ 14.0 is required. Get it with ""Build Tools for Visual Studio"": https://visualstudio.microsoft.com/downloads/   
```

#### Versions


Windows-10-10.0.19041-SP0
Python 3.9.2 (tags/v3.9.2:1a79785, Feb 19 2021, 13:44:55) [MSC v.1928 64 bit (AMD64)]
Bits 64
NumPy 1.20.1
SciPy 1.6.1
gensim N/A (attempting to install 3.8.3)



Thanks "
833,https://github.com/RaRe-Technologies/gensim/issues/3061,3061,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",open,2021-03-05 09:55:53+00:00,,Jupyter crashes on using Word2Vec most_similar,"When I load a Word2Vec model and call `most_similar` it takes some time and then the kernel gets restarted. The application doesn't throw any error and all that is logged by the jupyter server is:
```
 AsyncIOLoopKernelRestarter: restarting kernel (1/5), keep random ports kernel 34b5f234-0025-4950-bd88-ed1741fcd2d8 restarted
```

- I've created a new environment with only gensim and the ipython kernel installed and the issue persists. 
- The error occurs independently whether I load the original `word2vec-google-news-300` from the gensim api or if I use a very small model I trained myself (43MB). 
- No crash happens if the code is execute in the console. 

```
import gensim.downloader as api
model = api.load('word2vec-google-news-300')
model.most_similar('cat')
```

System Info:
Windows-10-10.0.19041-SP0
Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 15:50:08) [MSC v.1916 64 bit (AMD64)]
Bits 64
NumPy 1.20.1
SciPy 1.6.0
gensim 3.8.3
FAST_VERSION 1
"
834,https://github.com/RaRe-Technologies/gensim/issues/3062,3062,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}]",closed,2021-03-05 17:29:45+00:00,,Fix paper reference,"The linked pdf file is not available anymore (404).
https://github.com/RaRe-Technologies/gensim/blob/70fc15985572bc10cd4424a1ac7fd8650389d43f/gensim/models/lsimodel.py#L325"
835,https://github.com/RaRe-Technologies/gensim/issues/3064,3064,[],closed,2021-03-05 22:24:46+00:00,,Add +1 inside the math.log in the idf computation of bm25.,"https://github.com/RaRe-Technologies/gensim/blob/e889fa3d45a406cabbc7e180fa9a8ee3f76ac6f0/gensim/summarization/bm25.py#L137

As it is right now, you can end up with negative idf values. It's counter intuitive. The right formula for idf computation (from [https://en.wikipedia.org/wiki/Okapi_BM25]) is: 
![Screenshot from 2021-03-05 16-41-53](https://user-images.githubusercontent.com/48964470/110180235-63c18680-7dd7-11eb-9391-43bac72ca2ce.png)

You just need to add +1 inside the log.

Also, you won't need the warning in `if self.average_idf < 0:` anymore.
"
836,https://github.com/RaRe-Technologies/gensim/issues/3066,3066,[],closed,2021-03-09 14:55:50+00:00,,Warnings of deprecated functions ,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

In azure py3.9 there are rather a lot of warnings. A fair amount of these can be fixed with a find and replace as they are from using numpy's deprecated types. See https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations



#### Versions



```python
Python 3.9.1 x64

```
"
837,https://github.com/RaRe-Technologies/gensim/issues/3067,3067,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",closed,2021-03-09 16:41:50+00:00,,Update WMD documentation,"A user reported a documentation issue on the mailing list: https://groups.google.com/g/gensim/c/8nobtm9tu-g.

The report shows two problems:

1) Something changed with `wmdistance` between 3.8 and 4.0 that is not properly captured in the [Migration notes](https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).

2. The [WMD tutorial](https://radimrehurek.com/gensim_4.0.0/auto_examples/tutorials/run_wmd.html#normalizing-word2vec-vectors) contains instructions that are now outdated in 4.0: 

   > When using the wmdistance method, it is beneficial to normalize the word2vec vectors first, so they all have equal length. To do this, simply call model.init_sims(replace=True) and Gensim will take care of that for you.

   …And then our own tutorial logs a `WARNING : destructive init_sims(replace=True) deprecated & no longer required for space-efficiency`, which looks silly."
838,https://github.com/RaRe-Technologies/gensim/issues/3068,3068,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 1602257032, 'node_id': 'MDU6TGFiZWwxNjAyMjU3MDMy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20HIGH', 'name': 'impact HIGH', 'color': 'b60205', 'default': False, 'description': 'Show-stopper for affected users'}, {'id': 1602279836, 'node_id': 'MDU6TGFiZWwxNjAyMjc5ODM2', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20MEDIUM', 'name': 'reach MEDIUM', 'color': 'ef7a1a', 'default': False, 'description': 'Affects a significant number of users'}]",open,2021-03-09 22:13:12+00:00,,After model normalization wmdistance() isn't working (self trained fastText model),"#### Problem description
I want to calculate the Word Mover's Distance. After the normalization (`model.init_sims(replace=True)`) of my self made fastText model, the `wmdistance()` function isn't working as expected. Without the normalization the calculation is always possible.

There is a `RuntimeWarning` at/after the normalization of the model:
```
... keyedvectors.py:2386: RuntimeWarning: invalid value encountered in true_divide
  m /= dist
```

The current beta of gensim (`gensim 4.0.0beta`) behaves similarly. The `RuntimeWarning` is appearing right after the call of `wmdistance()`:
```
... fasttext.py:1117: RuntimeWarning: invalid value encountered in true_divide
  return word_vec / np.linalg.norm(word_vec)
```

#### Steps/code/corpus to reproduce
My fastText model: [model_mk1.bin](https://seafile.zfn.uni-bremen.de/f/b5fc86206e4048fb817a/)

```python
>>> import gensim
>>> model = gensim.models.fasttext.load_facebook_vectors(path='/Volumes/ai/fasttext/model_mk1.bin')
>>> model.init_sims(replace=True)
/home/matthias/Dokumente/python_enviroments/ba_env/lib/python3.8/site-packages/gensim/models/keyedvectors.py:2386: RuntimeWarning: invalid value encountered in true_divide
  m /= dist
>>> 
>>> tokenized_sentence_artificial = ['AI', 'means', 'artificial', 'intelligence']
>>> tokenized_sentence_artificially = ['AI', 'means', 'artificially', 'intelligence']
>>> 
>>> distance1 = model.wmdistance(tokenized_sentence_artificial, tokenized_sentence_artificially)
>>> print(distance1)
0.1122208870178163
>>> 
>>> tokenized_a = ['Polypeptides', 'containing', '.gamma.-amino', 'acids', 'Disclosed', 'are', 'polypeptide', 'compounds', 'containing', 'at', 'least', 'one', 'residue', 'comprising', 'a', 'cyclically-constrained', '.gamma.-amino', 'acid', 'residue', '.', 'The', 'compounds', 'have', 'the', 'formula', '#', '#', 'STR1', '#', '#', 'where', 'A', 'is', 'a', 'hydrogen', ',', 'hydroxy', ',', 'amino-', 'or', 'carboxy-protecting', 'group', ',', 'Y', 'is']
>>> tokenized_b = ['Two-Dimensional', 'Conjugated', 'Polymer', 'Assemblies']
>>> 
>>> distance2 = model.wmdistance(tokenized_a, tokenized_b)
```

There is no result after the last step. One cpu core @ 100%. Only way out is to kill the python process.

#### Versions
```python
>>> import platform; print(platform.platform())
Linux-5.8.0-44-generic-x86_64-with-glibc2.32
>>> import sys; print(""Python"", sys.version)
Python 3.8.6 (default, Jan 27 2021, 15:42:20) 
[GCC 10.2.0]
>>> import struct; print(""Bits"", 8 * struct.calcsize(""P""))
Bits 64
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.20.1
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.6.1
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 3.8.3
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1
```
"
839,https://github.com/RaRe-Technologies/gensim/issues/3070,3070,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233082, 'node_id': 'MDU6TGFiZWwyMzMwODI=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20hard', 'name': 'difficulty hard', 'color': '00a000', 'default': False, 'description': 'Hard issue: required deep gensim understanding & high python/cython skills'}, {'id': 575779925, 'node_id': 'MDU6TGFiZWw1NzU3Nzk5MjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/breaks%20backward-compatibility', 'name': 'breaks backward-compatibility', 'color': 'e96f1b', 'default': False, 'description': 'Change breaks backward compatibility'}, {'id': 1602278675, 'node_id': 'MDU6TGFiZWwxNjAyMjc4Njc1', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20HIGH', 'name': 'reach HIGH', 'color': '229e03', 'default': False, 'description': 'Affects most or all Gensim users'}, {'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",closed,2021-03-10 20:22:23+00:00,,Revisit save/load architecture,"_Originally posted by @gojomo in https://github.com/RaRe-Technologies/gensim/issues/3065#issuecomment-793064538_

> My understanding is that pickle v5 has the hooks needed for the sort of custom-separate-serialization of things like numpy arrays, but it's not yet automatic/standard. So it's not a simple matter of ""use v5 and we're done"". But, if we thought extending it soon in that manner, perhaps after seeing what other recent v5 users have done with numpy arrays, was likely, then doing a one-hop to v5 now, rather than hop-to-v4 now then hop-to-v5 soon after, might be a way to minimize interim states and catch any potential gotchas sooner rather than later. (AFAICT, 'pickle5' is an official backport by the same Python core contributor who wrote the v5 PEP and Python3.8+ implementation, so it should have fewer risks than relying on other arbitrary external libs.) 

> Even without 'upgrade-scripts', old-object-cleanup hooks that are analogous to `SaveLoad` 'specials'/etc seem possible via pickle - and if we relied on those instead, we might stay closer to other community Python practices. If we think that's the eventual future direction, we needn't break anything that works and is familiar right away - but we would want to discourage further growth/complexity in `SaveLoad` - so something like the recent lifecycle logging could move to a different superclass/mix-in.
"
840,https://github.com/RaRe-Technologies/gensim/issues/3072,3072,[],closed,2021-03-12 16:45:49+00:00,,How to compare the topic similarity between topics from two different Hdp Models?,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I am trying to compare the topic similarity between topics from two different Hdp Models. 
With LDA Models I have previously done so using the example below:
```
# lda_brand_last_week and lda_user_last_week are two LDA models 

topic_terms1 = sorted(lda_brand_last_week.show_topic_terms(0, topn=lda_brand_last_week.num_terms))
topic_terms2 = sorted(lda_user_last_week.show_topic_terms(0, topn=lda_user_last_week.num_terms))
gensim.matutils.hellinger(topic_terms1, topic_terms2)
```

When I try testing it out on Hdp Models with the same method I get this error:
```
AttributeError: 'HdpModel' object has no attribute 'show_topic_terms'
```
 I tried  checking the methods available and in fact it does not exist on the Hdp Model:
```
>>>[m for m in dir(lda_user_last_week) if not m.startswith('__')]
['_adapt_by_suffix',
 '_apply',
 '_load_specials',
 '_save_specials',
 '_smart_save',
 'chunksize',
 'corpus',
 'doc_e_step',
 'evaluate_test_corpus',
 'get_topics',
 'hdp_to_lda',
 'id2word',
 'inference',
 'lda_alpha',
 'lda_beta',
 'load',
 'm_D',
 'm_Elogbeta',
 'm_K',
 'm_T',
 'm_W',
 'm_alpha',
 'm_eta',
 'm_gamma',
 'm_kappa',
 'm_lambda',
 'm_lambda_sum',
 'm_num_docs_processed',
 'm_r',
 'm_rhot',
 'm_scale',
 'm_status_up_to_date',
 'm_tau',
 'm_timestamp',
 'm_updatect',
 'm_var_converge',
 'm_var_sticks',
 'm_varphi_ss',
 'max_chunks',
 'max_time',
 'optimal_ordering',
 'outputdir',
 'print_topic',
 'print_topics',
 'random_state',
 'save',
 'save_options',
 'save_topics',
 'show_topic',
 'show_topics',
 'suggested_lda_model',
 'update',
 'update_chunk',
 'update_expectations',
 'update_finished',
 'update_lambda']
```

But in the documentation this method `show_topic_terms` [exists](https://radimrehurek.com/gensim/models/hdpmodel.html#gensim.models.hdpmodel.HdpTopicFormatter.show_topic_terms).  

So how would I do this without using `show_topic_terms` to get the sequence of topic terms and their probabilities? 

#### Versions
Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic
Python 3.7.10 (default, Feb 20 2021, 21:17:23) 
[GCC 7.5.0]
Bits 64
NumPy 1.19.5
SciPy 1.4.1
gensim 3.8.3
FAST_VERSION 1
"
841,https://github.com/RaRe-Technologies/gensim/issues/3074,3074,[],closed,2021-03-15 11:16:36+00:00,,Unnessary workaround in LDA tutorial,"The documentation in the LDA tutorial mentions an already fixed issue (https://github.com/RaRe-Technologies/smart_open/issues/331).
What is now the proper way to read and untar the file on the fly?

https://github.com/RaRe-Technologies/gensim/blob/338ef330dea97c90c3180a9b570be9d0c9cef302/docs/src/auto_examples/tutorials/run_lda.py#L68-L91"
842,https://github.com/RaRe-Technologies/gensim/issues/3075,3075,[],closed,2021-03-15 14:36:53+00:00,,HPD random seed not working,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I am  trying to reproduce results using the same random seed (all other elements remain equal), but the results is different everytime I run the model.

#### Code

Here is my code :

```python
hdpmodel = HdpModel(corpus=bowCorpus, id2word=dictionary, alpha = 0.5, random_state = 1)
```

Is there any way to fix this on my side or it is a technical problem / missing developpement ?

Best Regards,
Evangelia ZVE"
843,https://github.com/RaRe-Technologies/gensim/issues/3079,3079,[],closed,2021-03-16 18:10:03+00:00,,getting disk quota exceeded error while  using this ldamallet[doc_term_matrix],"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? What is the expected result? What are you seeing instead?

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

If your problem is with a specific Gensim model (word2vec, lsimodel, doc2vec, fasttext, ldamodel etc), include the following:

```python
print(my_model.lifecycle_events)
```

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import struct; print(""Bits"", 8 * struct.calcsize(""P""))
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```
"
844,https://github.com/RaRe-Technologies/gensim/issues/3081,3081,[],open,2021-03-18 15:29:10+00:00,,Memory leaks when using doc_topics in LdaSeqModel,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I trained a large LdaSeqModel with 53,000 documents, 30 topics, and 18 timeslices.
I saved the model to disk because it ran for 7 days.

When extracting topic probabilities for 53,000 documents, memory usage rises above 120GB.
However, only extracting probabilities for 1,000 documents works flawlessly.
#### Steps/code/corpus to reproduce

1. Train LdaSeqModel
2. Save LdaSeqModel
2. Load LdaSeqModel from disk
4. Extract document-topic probabilities with `doc_topics`

ldaseq.corpus_len = 53,101 in the below MWE.

```python
from gensim.models import LdaSeqModel

ldaseq = LdaSeqModel.load(""/ldaseq_model"")

prob = (ldaseq.doc_topics(x) for x in range(ldaseq.corpus_len)) 

df = pd.DataFrame(prob, columns=[f""topic_{i}"" for i in range(30)])
```

#### Versions

macOS-10.16-x86_64-i386-64bit
Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:12:38) 
[Clang 11.0.1 ]
Bits 64
NumPy 1.20.1
SciPy 1.6.1
gensim 3.8.3
FAST_VERSION 1"
845,https://github.com/RaRe-Technologies/gensim/issues/3083,3083,"[{'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",closed,2021-03-19 12:58:53+00:00,,Handle migration away from travis-ci.org,"They are expecting projects to migrate from travis-ci.org to travis-ci.com. It looks like a free process for open-source projects.

We should consider whether to continue using Travis (and move to travis-ci.com) or use the opportunity to migrate everything possible to GitHub Actions.

We probably can't leave Travis entirely, because they support some platforms that GHA does not (IIRC)."
846,https://github.com/RaRe-Technologies/gensim/issues/3085,3085,[],closed,2021-03-20 13:20:56+00:00,,Prepare 4.0.0 release candidate 1,"https://github.com/RaRe-Technologies/gensim/issues/2963

Gentlemen, could you please review the https://github.com/RaRe-Technologies/gensim/tree/4.0.0.rc1 tag and let me know if you spot anything out of the ordinary?

It looks like the wheels are building fine on CI, so we can make this release pretty much any time from now."
847,https://github.com/RaRe-Technologies/gensim/issues/3086,3086,"[{'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",closed,2021-03-22 09:21:20+00:00,,Release 4.0.0,"- [x] Update CHANGELOG.md (@piskvorky)
- [x] Build wheels, release to PyPI (@mpenkov)
- [x] Champagne and cigars (everyone)"
848,https://github.com/RaRe-Technologies/gensim/issues/3087,3087,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",open,2021-03-22 09:38:04+00:00,,Streamline documentation contributions,"OK, so it sounds like we could improve our developer documentation a little bit and go with option 1, then.

_Originally posted by @mpenkov in https://github.com/RaRe-Technologies/gensim/issues/3074#issuecomment-803501251_"
849,https://github.com/RaRe-Technologies/gensim/issues/3089,3089,"[{'id': 708430967, 'node_id': 'MDU6TGFiZWw3MDg0MzA5Njc=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/performance', 'name': 'performance', 'color': 'd93f0b', 'default': False, 'description': 'Issue related to performance (in HW meaning)'}]",open,2021-03-25 17:00:18+00:00,,Using corpus_file does not speed up while the CPU utilization seems full.,"#### Problem description

I'm struggling with the issue of speeding up a doc2vec training using `corpus_file` after my institution introduced a new computing server system. With the previous system, I had/have no problem, but I found that the same script takes drastically different times, and I'm not enjoying the quasi-linear speed-up with the number of threads/cores anymore. I have not been able to find a solution for this issue, so I decided to post this here. 

#### Steps/code/corpus to reproduce

The script is simple as below. The `test.txt` file is in LineSentence format as [this page](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/Any2Vec_Filebased.ipynb) suggests. (The wide `windows`=240 is chosen to check out the CPU usage.)

```
import logging
import time
logging.basicConfig(level=logging.INFO)
from gensim.models.doc2vec import Doc2Vec

file = 'test.txt'

start_time = time.time()
model = Doc2Vec(vector_size=100, min_count=10, window=240, workers=24, seed=111, dm=0, dbow_words=1)
model.build_vocab(corpus_file=file)
print(time.time() - start_time, 'build vocab')

start_time = time.time()
model.train(corpus_file=file, total_examples=model.corpus_count, total_words=model.corpus_total_words, epochs=1)
print(time.time() - start_time, '1-epoch')
```

Running this with the previous server system, the 1-epoch time was

```
INFO:gensim.models.word2vec:EPOCH - 1 : training on 4182347 raw words (3516440 effective words) took 13.7s, 256302 effective words/s
```

While with the new system, the 1- epoch time was

```
INFO:gensim.models.word2vec:EPOCH - 1 : training on 4182347 raw words (3516440 effective words) took 88.8s, 39578 effective words/s
```

I checked out the CPU utilization from the new system (with the current issue) and it seemed that it was using 2400%.

![image](https://user-images.githubusercontent.com/18064995/112510313-4ee56c80-8d5f-11eb-817d-2f7c7c569858.png)


I tried to use 48 cores, it again used the full 48 cores as below.

![image](https://user-images.githubusercontent.com/18064995/112510482-750b0c80-8d5f-11eb-984a-fdefb66eb5f0.png)

But, the training time was identical from the 24 core training.

```
NFO:gensim.models.word2vec:EPOCH - 1 : training on 4184193 raw words (3518530 effective words) took 87.7s, 40107 effective words/s
```

While I'm not putting it here, this happens not only from Gensim 4.0 but also from 3.8.3. I understand a wrong hardware configuration might cause this, so I will close this issue if I can confirm that. But I wanted to know if any developers/other users encountered a case similar to what I have now...


#### Versions

From the new system (with the training speed issue)

```
Linux-4.18.0-193.el8.x86_64-x86_64-with-glibc2.10
Python 3.8.5 (default, Sep  4 2020, 07:30:14) 
[GCC 7.3.0]
Bits 64
NumPy 1.20.1
SciPy 1.5.2
gensim 4.0.0
FAST_VERSION 1
```

From the previous system (where the `corpus_file`  method worked.)

```
Linux-3.10.0-1127.8.2.el7.x86_64-x86_64-with-redhat-7.4-Nitrogen
Python 3.7.6 (default, Jan  8 2020, 19:59:22) 
[GCC 7.3.0]
Bits 64
NumPy 1.18.5
SciPy 1.5.0
gensim 4.0.0
FAST_VERSION 1
```
"
850,https://github.com/RaRe-Technologies/gensim/issues/3090,3090,[],closed,2021-03-25 20:24:50+00:00,,KeyError in LsiModel constructor,"#### Problem description

Hi, I'm trying to use an `LsiModel` to reduce a corpus.  When constructing the `LsiModel`, I sometimes see `KeyError`s raised by logging code (specifically, [here](https://github.com/RaRe-Technologies/gensim/blob/f8110c036f30e030e4c27101398e076cd1254819/gensim/models/lsimodel.py#L673) via [here](https://github.com/RaRe-Technologies/gensim/blob/f8110c036f30e030e4c27101398e076cd1254819/gensim/models/lsimodel.py#L522)).  If I manually remove that logging, I can generate the model without errors.

I found [a similar issue](https://github.com/RaRe-Technologies/gensim/issues/1995), where @menshikh-iv recommended ""removing gaps"" from my dictionary.  I definitely could do that, but it would require an extra pass over my input, which can be pretty large.  Instead, it would be trivial to do a more safe lookup into `id2word` than using `[val]`.  For example, this workaround fixes my problem:

```diff
diff --git i/gensim/models/lsimodel.py w/gensim/models/lsimodel.py
index 97cc921f..4b703dcf 100644
--- i/gensim/models/lsimodel.py
+++ w/gensim/models/lsimodel.py
@@ -670,7 +670,7 @@ class LsiModel(interfaces.TransformationABC, basemodel.BaseTopicModel):
         c = np.asarray(self.projection.u.T[topicno, :]).flatten()
         norm = np.sqrt(np.sum(np.dot(c, c)))
         most = matutils.argsort(np.abs(c), topn, reverse=True)
-        return [(self.id2word[val], 1.0 * c[val] / norm) for val in most]
+        return [(self.id2word.get(val, ""<None>""), 1.0 * c[val] / norm) for val in most]
 
     def show_topics(self, num_topics=-1, num_words=10, log=False, formatted=True):
         """"""Get the most significant topics.
```

#### Steps/code/corpus to reproduce

```python
>>> from gensim.models import LsiModel
>>>
>>> tfidf = [[(0, 0.0), (1, 1.0), (2, 2.0)]]
>>> id2word = {0: ""a"", 1: ""b"", 2: ""c"", 100: ""d""}  # note that there is a gap here!
>>> LsiModel(tfidf, id2word=id2word)
Traceback (most recent call last):
  File ""gensim_test.py"", line 5, in <module>
    LsiModel(tfidf, id2word=id2word)
  File ""/path/to/gensim/models/lsimodel.py"", line 445, in __init__
    self.add_documents(corpus)
  File ""/path/to/gensim/models/lsimodel.py"", line 518, in add_documents
    self.print_topics(5)
  File ""/path/to/gensim/models/basemodel.py"", line 36, in print_topics
    return self.show_topics(num_topics=num_topics, num_words=num_words, log=True)
  File ""/path/to/gensim/models/lsimodel.py"", line 699, in show_topics
    topic = self.print_topic(i, topn=num_words)
  File ""/path/to/gensim/models/basemodel.py"", line 18, in print_topic
    return ' + '.join('%.3f*""%s""' % (v, k) for k, v in self.show_topic(topicno, topn))
  File ""/path/to/gensim/models/lsimodel.py"", line 669, in show_topic
    return [(self.id2word[val], 1.0 * c[val] / norm) for val in most]
  File ""/path/to/gensim/models/lsimodel.py"", line 669, in <listcomp>
    return [(self.id2word[val], 1.0 * c[val] / norm) for val in most]
KeyError: 69
```

#### Versions

Please provide the output of:

```python
>>> import platform; print(platform.platform())
>>> import sys; print(""Python"", sys.version)
>>> import struct; print(""Bits"", 8 * struct.calcsize(""P""))
>>> import numpy; print(""NumPy"", numpy.__version__)
>>> import scipy; print(""SciPy"", scipy.__version__)
>>> import gensim; print(""gensim"", gensim.__version__)
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
Linux-5.4.0-64-generic-x86_64-with-debian-buster-sid
Python 3.7.10 (default, Feb 26 2021, 18:47:35) 
[GCC 7.3.0]
Bits 64
NumPy 1.19.1
SciPy 1.5.3
gensim 3.8.3
FAST_VERSION 0
```
"
851,https://github.com/RaRe-Technologies/gensim/issues/3092,3092,[],open,2021-03-28 13:20:48+00:00,,Fix broken Travis CI build,"Continued from #3083. The Travis build (for aarm64) is [failing](https://travis-ci.com/github/RaRe-Technologies/gensim/builds/221428340) for multiple reasons:

- Python 3.6: passes
- Python 3.7: failed unit test: TestTranslationMatrix.test_persistence, numpy raises ValueError
- Python 3.8: failed unit test, as above
- Python 3.9: missing BLAS/LAPACK

@janaknat Can you please investigate? "
852,https://github.com/RaRe-Technologies/gensim/issues/3093,3093,[],closed,2021-03-28 21:00:18+00:00,,randomness array in each execusion using gensim 4.0.0 r,"hi,

i have the problem of random values of the wor2vec numpy array in each iteration i have differents values and the values look like this

[-8.2428008e-03  9.2994776e-03 -1.9798672e-04 -1.9678262e-03
  4.6040486e-03 -4.0951525e-03  2.7427832e-03  6.9398358e-03
  6.0658492e-03 -7.5107692e-03  9.3822163e-03  4.6720100e-03
  3.9662290e-03 -6.2438129e-03  8.4602311e-03 -2.1501693e-03
  8.8252556e-03 -5.3621214e-03 -8.1291245e-03  6.8251640e-03
  1.6709357e-03 -2.1988999e-03  9.5134163e-03  9.4941529e-03
 -9.7744269e-03  2.5053187e-03  6.1569042e-03  3.8723361e-03
  2.0231656e-03  4.3065284e-04  6.7393208e-04 -3.8206491e-03
 -7.1407887e-03 -2.0886613e-03  3.9240932e-03  8.8188900e-03
  9.2590870e-03 -5.9758825e-03 -9.4028115e-03  9.7647989e-03
  3.4301477e-03  5.1660105e-03  6.2828050e-03 -2.8041711e-03
  7.3227654e-03  2.8304099e-03  2.8714100e-03 -2.3807921e-03
 -3.1285468e-03 -2.3705100e-03  4.2769113e-03  7.5900040e-05
 -9.5843915e-03 -9.6656363e-03 -6.1486219e-03 -1.2847317e-04
  1.9973496e-03  9.4323577e-03  5.5845254e-03 -4.2911354e-03
  2.7836411e-04  4.9645100e-03  7.6985597e-03 -1.1440248e-03
  4.3236283e-03 -5.8146389e-03 -8.0403656e-04  8.0998391e-03
 -2.3598999e-03 -9.6636890e-03  5.7792189e-03 -3.9302204e-03
 -1.2229439e-03  9.9810045e-03 -2.2564454e-03 -4.7571408e-03
 -5.3297863e-03  6.9811749e-03 -5.7088151e-03  2.1141327e-03
 -5.2556521e-03  6.1207935e-03  4.3572038e-03  2.6060962e-03
 -1.4909664e-03 -2.7461778e-03  8.9928163e-03  5.2160276e-03
 -2.1625054e-03 -9.4707683e-03 -7.4262242e-03 -1.0637412e-03
 -7.9504057e-04 -2.5630123e-03  9.6824588e-03 -4.5879601e-04
  5.8742040e-03 -7.4474830e-03 -2.5062521e-03 -5.5501163e-03]
"
853,https://github.com/RaRe-Technologies/gensim/issues/3094,3094,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}]",open,2021-03-29 05:05:38+00:00,,IndexError related to self.vectors_lockf in KeyedVectors.intersect_word2vec_format() in 4.0+,"Both lines containing `vectors_lockf` variable should be:
```python
self.vectors_lockf = lockf
```
Current (4.0.0) version is:
```python
self.vectors_lockf[self.get_index(word)] = lockf
```
And this gives us IndexError trying to make `intersect_word2vec_format()`"
854,https://github.com/RaRe-Technologies/gensim/issues/3095,3095,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 1602257032, 'node_id': 'MDU6TGFiZWwxNjAyMjU3MDMy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20HIGH', 'name': 'impact HIGH', 'color': 'b60205', 'default': False, 'description': 'Show-stopper for affected users'}, {'id': 1602278675, 'node_id': 'MDU6TGFiZWwxNjAyMjc4Njc1', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20HIGH', 'name': 'reach HIGH', 'color': '229e03', 'default': False, 'description': 'Affects most or all Gensim users'}]",closed,2021-03-30 08:27:38+00:00,,import gensim fails on Windows with numpy 1.19.5,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

After I upgraded to gensim `4.0.0` from `4.0.0beta`, I was no longer able to do `import gensim` (see numpy error message below). When I upgraded to numpy `1.20.2` the problem was solved.

#### Steps/code/corpus to reproduce

```
Python 3.8.6 (tags/v3.8.6:db45529, Sep 23 2020, 15:52:53) [MSC v.1927 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import gensim
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\user\Dev\code\venv\lib\site-packages\gensim\__init__.py"", line 11, in <module>
    from gensim import parsing, corpora, matutils, interfaces, models, similarities, utils  # noqa:F401
  File ""C:\Users\user\Dev\code\venv\lib\site-packages\gensim\corpora\__init__.py"", line 6, in <module>
    from .indexedcorpus import IndexedCorpus  # noqa:F401 must appear before the other classes
  File ""C:\Users\user\Dev\code\venv\lib\site-packages\gensim\corpora\indexedcorpus.py"", line 14, in <module>
    from gensim import interfaces, utils
  File ""C:\Users\user\Dev\code\venv\lib\site-packages\gensim\interfaces.py"", line 19, in <module>
    from gensim import utils, matutils
  File ""C:\Users\user\Dev\code\venv\lib\site-packages\gensim\matutils.py"", line 1024, in <module>
    from gensim._matutils import logsumexp, mean_absolute_difference, dirichlet_expectation
  File ""gensim\_matutils.pyx"", line 1, in init gensim._matutils
ValueError: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject
>>>
```

#### Versions


```
Windows-10-10.0.19041-SP0
Python 3.8.6 (tags/v3.8.6:db45529, Sep 23 2020, 15:52:53) [MSC v.1927 64 bit (AMD64)] on win32
Bits 64

NumPy 1.19.5
scipy 1.6.0
gensim 4.0.0
```
"
855,https://github.com/RaRe-Technologies/gensim/issues/3096,3096,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 1602257032, 'node_id': 'MDU6TGFiZWwxNjAyMjU3MDMy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20HIGH', 'name': 'impact HIGH', 'color': 'b60205', 'default': False, 'description': 'Show-stopper for affected users'}, {'id': 1602279836, 'node_id': 'MDU6TGFiZWwxNjAyMjc5ODM2', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20MEDIUM', 'name': 'reach MEDIUM', 'color': 'ef7a1a', 'default': False, 'description': 'Affects a significant number of users'}]",open,2021-03-30 15:27:11+00:00,,Segfault when training FastText model,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

Some hyper-parameter configurations for FastText seem to produce segfaults.

#### Steps/code/corpus to reproduce

Data & MRE available [here](https://github.com/TimotheeMickus/temp-git)

MRE:
```python
import datetime
import mmap
import multiprocessing

import gensim

class Restartable():
  """"""make generator 'restartable' for gensim""""""
  def __init__(self, g):
    self.g = g

  def __iter__(self):
    print(datetime.datetime.now(), ""iterating over corpus"")
    yield from self.g()

def get_sentences_in_file(filepath):
  """"""yield sentences in file""""""
  with open(filepath, ""r+b"") as istr:
    with mmap.mmap(istr.fileno(), 0, access=mmap.ACCESS_READ) as mmfh:
      yield from iter(mmfh.readline, b"""")

def read_tokens():
  """"""yield tokens per sentence in directory""""""
  yield from map(lambda s: s.decode(""utf-8"").strip().split(), get_sentences_in_file(""mini/corpus.txt""))

h_params = {
  'alpha': 1.0,
  'epochs': 11,
  'max_n': 5,
  'min_alpha': 0.00018265957307048248,
  'min_count': 10,
  'min_n': 3,
  'negative': 18,
  'ns_exponent': 3.972629499333897e-07,
  'sample': 0.005188593539343843,
  'window': 29
}
data = Restartable(read_tokens)
m = gensim.models.fasttext.FastText(vector_size=256, workers=multiprocessing.cpu_count(), **h_params)
m.build_vocab(corpus_iterable=data)
m.train(data, total_examples=m.corpus_count, epochs=m.epochs)
# segfault at the end of the first epoch
print(datetime.datetime.now(), ""passed"")
```

The above does not segfault with other configurations. Similar issues have been encountered with different hyper parameter configurations, the configuration in this MRE is just the first one I managed to consistently reproduce the segfault with.

#### Versions

```
>>> import platform; print(platform.platform())
Linux-5.4.0-70-generic-x86_64-with-glibc2.29
>>> import sys; print(""Python"", sys.version)
Python 3.8.5 (default, Jan 27 2021, 15:41:15) 
[GCC 9.3.0]
>>> import struct; print(""Bits"", 8 * struct.calcsize(""P""))
Bits 64
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.20.0
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.6.0
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 4.0.0beta
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1
```
"
856,https://github.com/RaRe-Technologies/gensim/issues/3097,3097,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 1602257032, 'node_id': 'MDU6TGFiZWwxNjAyMjU3MDMy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20HIGH', 'name': 'impact HIGH', 'color': 'b60205', 'default': False, 'description': 'Show-stopper for affected users'}, {'id': 1602278675, 'node_id': 'MDU6TGFiZWwxNjAyMjc4Njc1', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20HIGH', 'name': 'reach HIGH', 'color': '229e03', 'default': False, 'description': 'Affects most or all Gensim users'}]",open,2021-03-31 13:40:13+00:00,,Can't import gensim library - Python 3.8.5 + numpy 1.20.2,"Hi,

I was trying to run script that I created some time ago on Python 3.6.5 and it seems to don't work anymore. I can't import the library. Upgrading numpy didn't help. Can I ask for a solution to this problem?
```


> from gensim import corpora
> Traceback (most recent call last):
> 
>   File ""<ipython-input-5-0b009fd6379b>"", line 1, in <module>
>     from gensim import corpora
> 
>   File ""C:\Users\user\Anaconda3\lib\site-packages\gensim\__init__.py"", line 11, in <module>
>     from gensim import parsing, corpora, matutils, interfaces, models, similarities, utils  # noqa:F401
> 
>   File ""C:\Users\user\Anaconda3\lib\site-packages\gensim\corpora\__init__.py"", line 6, in <module>
>     from .indexedcorpus import IndexedCorpus  # noqa:F401 must appear before the other classes
> 
>   File ""C:\Users\user\Anaconda3\lib\site-packages\gensim\corpora\indexedcorpus.py"", line 14, in <module>
>     from gensim import interfaces, utils
> 
>   File ""C:\Users\user\Anaconda3\lib\site-packages\gensim\interfaces.py"", line 19, in <module>
>     from gensim import utils, matutils
> 
>   File ""C:\Users\user\Anaconda3\lib\site-packages\gensim\matutils.py"", line 1024, in <module>
>     from gensim._matutils import logsumexp, mean_absolute_difference, dirichlet_expectation
> 
>   File ""gensim\_matutils.pyx"", line 1, in init gensim._matutils
> 
> ValueError: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject
> 

```

> Python 3.8.5
> Numpy 1.20.2


Best regards,
Norbert"
857,https://github.com/RaRe-Technologies/gensim/issues/3098,3098,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",open,2021-04-01 07:20:36+00:00,,Signpost page for new issues,"BTW, Numpy have a nice signpost page for new issues: https://github.com/numpy/numpy/issues/new/choose
Let's see how they did it and do it for Gensim too :) Many don't read / respect our current issue template.

_Originally posted by @piskvorky in https://github.com/RaRe-Technologies/gensim/issues/3097#issuecomment-811699331_"
858,https://github.com/RaRe-Technologies/gensim/issues/3099,3099,"[{'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",open,2021-04-01 14:17:36+00:00,,Fix badge in PyPI,"Probably comes from the README. Needs to point to Github Actions, not Travis."
859,https://github.com/RaRe-Technologies/gensim/issues/3100,3100,[],closed,2021-04-01 16:07:57+00:00,,"word-vectors outside `train()`-update tokens being changed; also, `vectors_lockf` 0.0-values don't suppress changes","<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description
I have a task to update small numbers of words from the trained word2vec model.
Only a small number of target words should be updated. Thus, I trained the base model, then try to suppress update non-target vectors for the additional training with ```trainables.vectors_lockf=0```.
However, the behavior is wired and does not work as I expected.
Even if I set the ```vectors_lockf``` as 0.0 for the non-target words, the vectors of a small number of non-target words were still updated.

#### Steps/code/corpus to reproduce
I've found the problem during the train of real data at first. The data is consist of ~60,000,000 unique words.

I want to exclude the possibility that the error is from the dataset, thus I reproduced the problem with randomly generated sequences. 

For the test, I made the vocab of integers ranging from 0 to max_val, which I can adjust.
Base training sentence is drawn from vocab above, with a length of 30.

First, I trained the word2vec model with the randomly generated sentences.
Then, I update the model with the sequences, with a length of 10 generated from integers from 0 to 551000. I suppressed the update by setting ```vectors_lockf=0``` for all words, except odd numbers between 550000 and 551000.

* Thus, expected differences in word vectors between the original model and additionally tuned model are as follows:

```
[0:550000) : no vectors should be changed, because vectors_lockf = 0
[550000:551000), odd numbers:  all vectors are possibly changed because vectors_lockf = 1 
[550000:551000), even numbers: no vectors should be changed because vectors_lockf = 0
[551000:max_val): no vectors should be changed because these words are not in additional train sequences
```

* With vocab size of 100,000,000, vectors_lockf = 0 does not work normally. 
```
[0:550000) : 4 vectors changed
[550000:551000), odd numbers:  212 vectors changed (as expected)
[550000:551000), even numbers: no vectors changed (as expected)
[551000:max_val): 572 vectors changed
```

* With vocab size of 50,000,000, vectors_lockf = 0 does not work normally. 
```
[0:550000) : no vectors changed (as expected)
[550000:551000), odd numbers:  439 vectors changed (as expected)
[550000:551000), even numbers: no vectors changed (as expected)
[551000:max_val): 118 vectors changed
```

* With vocab size of 10,000,000, vectors_lockf = 0, it works well. 
```
[0:550000) : no vectors changed (as expected)
[550000:551000), odd numbers:  500 vectors changed (as expected)
[550000:551000), even numbers: no vectors changed (as expected)
[551000:max_val): no vectors changed (as expected)
```

* With vocab size of 5,000,000, vectors_lockf = 0, it works well. 
```
[0:550000) : no vectors changed (as expected)
[550000:551000), odd numbers:  500 vectors changed (as expected)
[550000:551000), even numbers: no vectors changed (as expected)
[551000:max_val): no vectors changed (as expected)
```

I may conclude that vectors_lockf works abnormally for the large vocab size. 

I use AMD Threadripper 3990X and 256GB ddr4 rams (without ECC). 
I haven't been tested with other systems.
I faced a similar situation for the Gensim 4 with the real data, yet I have not tested Gensim 4 with the randomly generated sequences 

Thanks!

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import struct; print(""Bits"", 8 * struct.calcsize(""P""))
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```

Linux-5.4.0-66-generic-x86_64-with-glibc2.10
Python 3.8.5 (default, Sep  4 2020, 07:30:14) 
[GCC 7.3.0]
Bits 64
NumPy 1.19.2
SciPy 1.5.2
gensim 3.8.3
FAST_VERSION 1
"
860,https://github.com/RaRe-Technologies/gensim/issues/3101,3101,[],open,2021-04-03 00:40:08+00:00,,Segfault running run-core-concepts-py against first lines of Shakespeare's sonnets,"*(Hi! Thanks for putting so much effort into the tutorials! Gensim looks amazing and I'm looking forward to experimenting more. Happy to help debug--anything you need. I know Python, CPython, and C/C++ pretty well, and I can drive GDB.)*

`run-core-concepts.py` crashes with `Segmentation fault (core dumped)` when I replace `text_corpus` with a list of first lines of Shakespeare's sonnets.

#### Steps/code/corpus to reproduce

1. Go to <https://radimrehurek.com/gensim/auto_examples/core/run_core_concepts.html>, scroll to the bottom, click ""Download Python source code"". Move the downloaded script into a new, empty directory.

2. cd to that directory, `python3 -m venv venv; source venv/bin/activate; pip install gensim`.

3. Note that `python run_core_concepts.py` now works fine, up until the end where it tries to import `matplotlib`.

4. Now edit `run_core_concepts.py` and replace the `text_corpus` with this:

    ```python
    text_corpus = [
        'From fairest creatures we desire increase,',
        'When forty winters shall besiege thy brow,',
        'Look in thy glass and tell the face thou viewest',
        'Unthrifty loveliness, why dost thou spend',
        'Those hours, that with gentle work did frame',
        ""Then let not winter's ragged hand deface,"",
        'Lo! in the orient when the gracious light',
        ""Music to hear, why hear'st thou music sadly?"",
        ""Is it for fear to wet a widow's eye,"",
        ""For shame deny that thou bear'st love to any,"",
        ""As fast as thou shalt wane, so fast thou grow'st"",
        'When I do count the clock that tells the time,',
        'O! that you were your self; but, love, you are',
        'Not from the stars do I my judgement pluck;',
        'When I consider every thing that grows',
        'But wherefore do not you a mightier way',
        'Who will believe my verse in time to come,',
        ""Shall I compare thee to a summer's day?"",
    ]
    ```

5. Note that `python run_core_concepts.py` now crashes; the output ends with

    ```console
     [(0, 1), (7, 1), (11, 1), (12, 1), (14, 1)],
     [(3, 1), (6, 1), (12, 1)],
     [(7, 1), (11, 1), (13, 1)],
     [(14, 1)],
     [(1, 1), (12, 1)]]
    []
    Segmentation fault (core dumped)
    ```

The crash occurs on the line:

```python
sims = index[tfidf[query_bow]]
```

The output of `index.lifecycle_events` here is:

```
[{'msg': 'calculated IDF weights for 18 documents and 15 features (39 matrix non-zeros)', 'datetime': '2021-04-02T19:33:36.428329', 'gensim': '4.0.1', 'python': '3.8.5 (default, Jan 27 2021, 15:41:15) \n[GCC 9.3.0]', 'platform': 'Linux-5.8.0-48-generic-x86_64-with-glibc2.29', 'event': 'initialize'}]
```

#### Versions

```
Linux-5.8.0-48-generic-x86_64-with-glibc2.29
Python 3.8.5 (default, Jan 27 2021, 15:41:15) 
[GCC 9.3.0]
Bits 64
NumPy 1.20.2
SciPy 1.6.2
/home/jorendorff/play/gensim-issue/venv/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.
  warnings.warn(msg)
gensim 4.0.1
FAST_VERSION 1
```
"
861,https://github.com/RaRe-Technologies/gensim/issues/3102,3102,[],closed,2021-04-03 16:35:04+00:00,,Getting CalledProcessError while getting each document topic probability from LdaMallet model,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? What is the expected result? What are you seeing instead?
To get the each document ,Topic Probabilities  from lda mallet. while doing this 
Getting this error:- 
CalledProcessError: Command '/home/b/bks46/covid_misinfo/Task2_with_LDA_Mallet/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex ""\S+"" --input /scratch/6699dc_corpus.txt --output /scratch/6699dc_corpus.mallet.infer --use-pipe-from /scratch/6699dc_corpus.mallet' returned non-zero exit status 1.

#### Steps/code/corpus to reproduce
os.environ['MALLET_HOME']='/home/b/bks46/covid_misinfo/Task2_with_LDA_Mallet/mallet-2.0.8' 

mallet_path = '/home/b/bks46/covid_misinfo/Task2_with_LDA_Mallet/mallet-2.0.8/bin/mallet'

ldamallet = gensim.models.wrappers.LdaMallet.load('/home/b/bks46/covid_misinfo/Task2_with_LDA_Mallet/lda_mallet/lda_mallet.model')
dictionary=gensim.corpora.Dictionary.load('/home/b/bks46/covid_misinfo/Task2_with_LDA_Mallet/lda_mallet/dictionary.dict')

doc_term_matrix=[dictionary.doc2bow(tokens) for tokens in task1_dataset['processed_text']]
topic_prob=ldamallet[doc_term_matrix]


Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

If your problem is with a specific Gensim model (word2vec, lsimodel, doc2vec, fasttext, ldamodel etc), include the following:

```python
print(my_model.lifecycle_events)
```

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())

Linux-3.10.0-1127.13.1.el7.x86_64-x86_64-with-centos-7.8.2003-Core
import sys; print(""Python"", sys.version)

Python 3.7.9 (default, Aug 31 2020, 12:42:55) 
[GCC 7.3.0]
import struct; print(""Bits"", 8 * struct.calcsize(""P""))
Bits 64
import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.19.2
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__) 
3.8.3
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```

CalledProcessError                        Traceback (most recent call last)
<ipython-input-17-24bf1b3b5c38> in <module>
----> 1 topic_prob=ldamallet[doc_term_matrix]

~/anaconda3/lib/python3.7/site-packages/gensim/models/wrappers/ldamallet.py in __getitem__(self, bow, iterations)
    312             bow = [bow]
    313 
--> 314         self.convert_input(bow, infer=True)
    315         cmd = \
    316             self.mallet_path + ' infer-topics --input %s --inferencer %s ' \

~/anaconda3/lib/python3.7/site-packages/gensim/models/wrappers/ldamallet.py in convert_input(self, corpus, infer, serialize_corpus)
    259             cmd = cmd % (self.fcorpustxt(), self.fcorpusmallet())
    260         logger.info(""converting temporary corpus to MALLET format with %s"", cmd)
--> 261         check_output(args=cmd, shell=True)
    262 
    263     def train(self, corpus):

~/anaconda3/lib/python3.7/site-packages/gensim/utils.py in check_output(stdout, *popenargs, **kwargs)
   1930             error = subprocess.CalledProcessError(retcode, cmd)
   1931             error.output = output
-> 1932             raise error
   1933         return output
   1934     except KeyboardInterrupt:

CalledProcessError: Command '/home/b/bks46/covid_misinfo/Task2_with_LDA_Mallet/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex ""\S+"" --input /scratch/6699dc_corpus.txt --output /scratch/6699dc_corpus.mallet.infer --use-pipe-from /scratch/6699dc_corpus.mallet' returned non-zero exit status 1."
862,https://github.com/RaRe-Technologies/gensim/issues/3104,3104,[],closed,2021-04-06 08:54:18+00:00,,lsi_dispatcher is not working from command-line when not specifying maxsize argument,"#### Problem description

When running `lsi_dispatcher` from the command-line, if you don't specify the `maxsize` argument explicitly, you get an error for the missing positional argument:

```
usage: lsi_dispatcher.py [-h] maxsize
lsi_dispatcher.py: error: the following arguments are required: maxsize
```

According to the documentation, this argument should be optional.

The issue seems to be that the nargs argument to `add_argument` is missing:

```python
    parser.add_argument(
        'maxsize', type=int, help='Maximum number of jobs to be kept pre-fetched in the queue.', default=MAX_JOBS_QUEUE
    )
 ```
In order to make this argument optional, this should be:

```python
    parser.add_argument(
        'maxsize', nargs='?', type=int, help='Maximum number of jobs to be kept pre-fetched in the queue.', default=MAX_JOBS_QUEUE
    )
```

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

If your problem is with a specific Gensim model (word2vec, lsimodel, doc2vec, fasttext, ldamodel etc), include the following:

```python
$ python3 -m gensim.models.lsi_dispatcher
usage: lsi_dispatcher.py [-h] maxsize
lsi_dispatcher.py: error: the following arguments are required: maxsize
```

#### Versions

```python
Linux-5.4.0-67-generic-x86_64-with-glibc2.2
Python 3.8.5 (default, Jan 27 2021, 15:41:15) 
[GCC 9.3.0]
Bits 64
NumPy 1.19.4
SciPy 1.6.0
gensim 4.0.1
FAST_VERSION 1
```
"
863,https://github.com/RaRe-Technologies/gensim/issues/3108,3108,[],open,2021-04-08 07:18:03+00:00,,For sponsors,"## Thank you for your [Gensim sponsorship](https://github.com/sponsors/piskvorky) ❤️

I don't know who you are, I can only see your Github handle. So please leave your desired Twitter handle here as a comment, for a mention in the monthly [@gensim_py](https://twitter.com/gensim_py) tweet.

If you chose one of the tiers where I send you stuff, **contact me [via email](mailto:me+sponsorship@radimrehurek.com) with your mailing address and T-shirt sizes / company logo**.

Thanks again!"
864,https://github.com/RaRe-Technologies/gensim/issues/3109,3109,[],closed,2021-04-08 14:42:43+00:00,,cannot import name 'softcossim' from 'gensim.matutils',"I get the following error when trying to running a tutorial script. First I attempted to upgrade gensim:

pip3 install --upgrade gensim
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: gensim in ./.local/lib/python3.7/site-packages (4.0.1)
Requirement already satisfied: smart-open>=1.8.1 in ./.local/lib/python3.7/site-packages (from gensim) (5.0.0)
Requirement already satisfied: scipy>=0.18.1 in /usr/lib/python3/dist-packages (from gensim) (1.1.0)
Requirement already satisfied: numpy>=1.11.3 in ./.local/lib/python3.7/site-packages (from gensim) (1.20.1)

Then attempted to run the script:

python3 kosinus.py
Traceback (most recent call last):
  File ""kosinus.py"", line 7, in <module>
    from gensim.matutils import softcossim 
ImportError: cannot import name 'softcossim' from 'gensim.matutils' (/home/user1/.local/lib/python3.7/site-packages/gensim/matutils.py)

python3 -m kosinus
Traceback (most recent call last):
  File ""/usr/lib/python3.7/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/usr/lib/python3.7/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/user1/kosinus.py"", line 7, in <module>
    from gensim.matutils import softcossim 
ImportError: cannot import name 'softcossim' from 'gensim.matutils' (/home/user1/.local/lib/python3.7/site-packages/gensim/matutils.py)

This is the script in question:

#!/usr/bin/python3
# -*- coding: utf-8 -*-

# upgrade gensim if you can't import softcossim

from gensim import corpora
from gensim.matutils import softcossim 
from gensim.utils import simple_preprocess
from sklearn.feature_extraction.text import CountVectorizer # nebo TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import gensim
import gensim.downloader as api
import numpy as np
import pandas as pd

print(gensim.__version__)


# Download the FastText model
fasttext_model300 = api.load('fasttext-wiki-news-subwords-300')




# Define the documents
doc_trump = ""Mr. Trump became president after winning the political election. Though he lost the support of some republican friends, Trump is friends with President Putin""

doc_election = ""President Trump says Putin had no political interference is the election outcome. He says it was a witchhunt by political parties. He claimed President Putin is a friend who had nothing to do with the election""

doc_putin = ""Post elections, Vladimir Putin became President of Russia. President Putin had served as the Prime Minister earlier in his political career""

doc_soup = ""Soup is a primarily liquid food, generally served warm or hot (but may be cool or cold), that is made by combining ingredients of meat or vegetables with stock, juice, water, or another liquid. ""

doc_noodles = ""Noodles are a staple food in many cultures. They are made from unleavened dough which is stretched, extruded, or rolled flat and cut into one of a variety of shapes.""

doc_dosa = ""Dosa is a type of pancake from the Indian subcontinent, made from a fermented batter. It is somewhat similar to a crepe in appearance. Its main ingredients are rice and black gram.""

documents = [doc_trump, doc_election, doc_putin]


# Create the Document Term Matrix
count_vectorizer = CountVectorizer(stop_words='english')
sparse_matrix = count_vectorizer.fit_transform(documents)

# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.
doc_term_matrix = sparse_matrix.todense()
df = pd.DataFrame(doc_term_matrix, 
                  columns=count_vectorizer.get_feature_names(), 
                  index=['doc_trump', 'doc_election', 'doc_putin'])

#df


# Compute Cosine Similarity
#print(cosine_similarity(df, df))
#> [[ 1.          0.48927489  0.37139068]
#>  [ 0.48927489  1.          0.38829014]
#>  [ 0.37139068  0.38829014  1.        ]]



################ soft kosinus

documents = [doc_trump, doc_election, doc_putin, doc_soup, doc_noodles, doc_dosa]

# Prepare a dictionary and a corpus.
dictionary = corpora.Dictionary([simple_preprocess(doc) for doc in documents])

# Prepare the similarity matrix
similarity_matrix = fasttext_model300.similarity_matrix(dictionary, tfidf=None, threshold=0.0, exponent=2.0, nonzero_limit=100)

# Convert the sentences into bag-of-words vectors.
sent_1 = dictionary.doc2bow(simple_preprocess(doc_trump))
sent_2 = dictionary.doc2bow(simple_preprocess(doc_election))
sent_3 = dictionary.doc2bow(simple_preprocess(doc_putin))
sent_4 = dictionary.doc2bow(simple_preprocess(doc_soup))
sent_5 = dictionary.doc2bow(simple_preprocess(doc_noodles))
sent_6 = dictionary.doc2bow(simple_preprocess(doc_dosa))

sentences = [sent_1, sent_2, sent_3, sent_4, sent_5, sent_6]


# Compute soft cosine similarity
#print(softcossim(sent_1, sent_2, similarity_matrix))
#> 0.567228632589


def create_soft_cossim_matrix(sentences):
    len_array = np.arange(len(sentences))
    xx, yy = np.meshgrid(len_array, len_array)
    cossim_mat = pd.DataFrame([[round(softcossim(sentences[i],sentences[j], similarity_matrix) ,2) for i, j in zip(x,y)] for y, x in zip(xx, yy)])
    return cossim_mat

#create_soft_cossim_matrix(sentences)

Would anyone happen to have any idea of what might be wrong please. Thank you very much in advance."
865,https://github.com/RaRe-Technologies/gensim/issues/3110,3110,[],closed,2021-04-08 22:18:31+00:00,,Cannot load pretrained Doc2Vec: AttributeError: Can't get attribute 'DocvecsArray' on <module 'gensim.models.doc2vec',"#### Problem description

I'm trying to load a pre-trained Doc2Vec model from this [https://github.com/jhlau/doc2vec](https://github.com/jhlau/doc2vec) 

#### Steps/code/corpus to reproduce

`
from gensim.models.doc2vec import Doc2Vec;
model = Doc2Vec.load(""enwiki_dbow/doc2vec.bin"")
`

This throws the following error:

`AttributeError: Can't get attribute 'DocvecsArray' on <module 'gensim.models.doc2vec' from 'PATH_TO_VIRTUAL_ENVIRONMENT/lib/python3.8/site-packages/gensim/models/doc2vec.py'>
`
#### Versions

As requested:

```python
macOS-10.16-x86_64-i386-64bit
Python 3.8.8 (default, Feb 24 2021, 13:46:16) 
[Clang 10.0.0 ]
Bits 64
NumPy 1.18.5
SciPy 1.6.2
gensim 4.0.1
FAST_VERSION 1
```
"
866,https://github.com/RaRe-Technologies/gensim/issues/3111,3111,[],closed,2021-04-09 11:33:49+00:00,,Coherence key error on held out set ,"Hi, I am trying to train a LDA model on a train set (80% of the data):

```
lda_model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus_train,
                                                                id2word=id2word_train,
                                                                 num_topics=n_topics, 
                                                                 random_state=100,
                                                                 chunksize=200,
                                                                 workers=20,
                                                                 iterations=100)
```

And get the coherence on a test set (20% held out test):

```
cv_coherence_model_lda = CoherenceModel(model=lda_model, texts=texts_test, dictionary=id2word_test, coherence='c_v')
cv_coherence_total = cv_coherence_model_lda.get_coherence()
```

I run this for n_topics from 1 to 30. 
However, it keeps crashing on random n_topics, with the error outlined below. The Key Error number changes all the time. Any help would be appreciated.


```
<ipython-input-8-8b4757057a4f> in find_optimal_topics_gensim(data, splits, test_size)
     87             #coherence models
     88             cv_coherence_model_lda = CoherenceModel(model=lda_model, texts=texts_test, dictionary=id2word_test, coherence='c_v')
---> 89             cv_coherence_total = cv_coherence_model_lda.get_coherence()
     90 

/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/models/coherencemodel.py in get_coherence(self)
    610 
    611         """"""
--> 612         confirmed_measures = self.get_coherence_per_topic()
    613         return self.aggregate_measures(confirmed_measures)
    614 

/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/models/coherencemodel.py in get_coherence_per_topic(self, segmented_topics, with_std, with_support)
    570             segmented_topics = measure.seg(self.topics)
    571         if self._accumulator is None:
--> 572             self.estimate_probabilities(segmented_topics)
    573 
    574         kwargs = dict(with_std=with_std, with_support=with_support)

/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/models/coherencemodel.py in estimate_probabilities(self, segmented_topics)
    542                 kwargs['model'] = self.keyed_vectors
    543 
--> 544             self._accumulator = self.measure.prob(**kwargs)
    545 
    546         return self._accumulator

/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/topic_coherence/probability_estimation.py in p_boolean_sliding_window(texts, segmented_topics, dictionary, window_size, processes)
    152         accumulator = WordOccurrenceAccumulator(top_ids, dictionary)
    153     else:
--> 154         accumulator = ParallelWordOccurrenceAccumulator(processes, top_ids, dictionary)
    155     logger.info(""using %s to estimate probabilities from sliding windows"", accumulator)
    156     return accumulator.accumulate(texts, window_size)

/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/topic_coherence/text_analysis.py in __init__(self, processes, *args, **kwargs)
    429 
    430     def __init__(self, processes, *args, **kwargs):
--> 431         super(ParallelWordOccurrenceAccumulator, self).__init__(*args)
    432         if processes < 2:
    433             raise ValueError(

/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/topic_coherence/text_analysis.py in __init__(self, relevant_ids, dictionary)
    285 
    286         """"""
--> 287         super(WindowedTextsAnalyzer, self).__init__(relevant_ids, dictionary)
    288         self._none_token = self._vocab_size  # see _iter_texts for use of none token
    289 

/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/topic_coherence/text_analysis.py in __init__(self, relevant_ids, dictionary)
    188         """"""
    189         super(UsesDictionary, self).__init__(relevant_ids)
--> 190         self.relevant_words = _ids_to_words(self.relevant_ids, dictionary)
    191         self.dictionary = dictionary
    192         self.token2id = dictionary.token2id

/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/topic_coherence/text_analysis.py in _ids_to_words(ids, dictionary)
     59     top_words = set()
     60     for word_id in ids:
---> 61         word = dictionary.id2token[word_id]
     62         if isinstance(word, set):
     63             top_words = top_words.union(word)

KeyError: 1094
```


Versions used

#### Versions
```

Darwin-20.3.0-x86_64-i386-64bit
Python 3.7.9 (v3.7.9:13c94747c7, Aug 15 2020, 01:31:08) 
[Clang 6.0 (clang-600.0.57)]
Bits 64
NumPy 1.19.1
SciPy 1.5.2
gensim 4.0.1
FAST_VERSION 0
```

"
867,https://github.com/RaRe-Technologies/gensim/issues/3112,3112,[],closed,2021-04-09 17:21:00+00:00,,No module named 'gensim.summarization',"i'm using gensim version 4.0

from gensim.summarization.bm25 import BM25

How do I implement BM25 or summarization using Genism.
"
868,https://github.com/RaRe-Technologies/gensim/issues/3114,3114,[],open,2021-04-11 19:44:43+00:00,,AttributeError: 'KeyedVectors' object has no attribute 'next_index',"#### Problem description

I try to add new vectors to a given model.

#### Steps/code/corpus to reproduce
Relevant traceback:
```
  File ""d:\projekte\foo\source\backend\venv\lib\site-packages\gensim\models\keyedvectors.py"", line 458, in add_vector
    target_index = self.next_index
AttributeError: 'KeyedVectors' object has no attribute 'next_index'
```

My code:
```python
class Foo:
    def __init__(self) -> None:
        self._model: KeyedVectors = gensim.models.KeyedVectors.load('C:\foo.bar')

   def is_word_known(word: str, language: str) -> bool:
       pass

    def add_word(self, word: str, synonym: str, language: str) -> None:
        if not self.is_word_known(word=synonym, language=language):
            raise ValueError(f'Word ""{word}"" cannot be added since synonym ""{synonym}"" is not known.')

        if self.is_word_known(word=word, language=language):
            raise ValueError(''Word ""{word}"" cannot be added since it is already known by the model.')

        vector = self._model.get_vector(key=word)
        self._model.add_vector(key=word, vector=vector)
```

#### Versions

```
Windows-7-6.1.7601-SP1
Bits 64
NumPy 1.20.2
SciPy 1.6.2
gensim 4.0.1
FAST_VERSION 0
```
"
869,https://github.com/RaRe-Technologies/gensim/issues/3119,3119,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",open,2021-04-15 15:56:14+00:00,,Partially missing documentation of __getitem__,"#### Problem description

I am wondering why some models have documented the `__getitem__` function and others are missing.
See below for a list of the models that provide the documentation of this function online.
I am confused because most (if not all) models provide this shortcut usage of `model[bow]` and have a docstring in the source code but it is not visible on the API docs website. 

Furthermore, I am not sure how to use the `eps` parameter, e.g. in TfidfModel or LDAModel:
https://github.com/RaRe-Technologies/gensim/blob/9f2a4acae21a9054213a6ba1afb043f9bd68b574/gensim/models/ldamodel.py#L1516
In my opinion this, parameter should be named `minimum_probability`.
In the case of LDA, `None` is the default value which leads to `max(self.minimum_probability, 1e-8)` used for inference.
My questions are:

1. Why is this part not displayed in the API docs, e.g. for LDAModel?
1. What is the  `__getitem__`  equivalent of `model.get_document_topics(bow, minimum_probability=0.1)` ?
1. If there is [no way](https://docs.python.org/3/reference/datamodel.html#object.__getitem__) to pass `eps` why not use `self.minimum_probability` directly?

``` python
def __getitem__(self, bow):
    model.get_document_topics(bow, self.minimum_probability, self.minimum_phi_value, self.per_word_topics)
```

In the case of Tfidf, `1e-12` is the default value and it is hard-coded and [`self.eps `](https://github.com/RaRe-Technologies/gensim/blob/9f2a4acae21a9054213a6ba1afb043f9bd68b574/gensim/models/tfidfmodel.py#L369)

https://github.com/RaRe-Technologies/gensim/blob/9f2a4acae21a9054213a6ba1afb043f9bd68b574/gensim/models/tfidfmodel.py#L475



Available `__getitem__` documentation:

- https://radimrehurek.com/gensim/models/tfidfmodel.html#gensim.models.tfidfmodel.TfidfModel.__getitem__
- https://radimrehurek.com/gensim/models/rpmodel.html#gensim.models.rpmodel.RpModel.__getitem__
- https://radimrehurek.com/gensim/models/normmodel.html#gensim.models.normmodel.NormModel.__getitem__

Missing `__getitem__` documentation:

- https://radimrehurek.com/gensim/models/ldamodel.html
- https://radimrehurek.com/gensim/models/ldamulticore.html
- https://radimrehurek.com/gensim/models/atmodel.html
- https://radimrehurek.com/gensim/models/nmf.html
- https://radimrehurek.com/gensim/models/lsimodel.html
- https://radimrehurek.com/gensim/models/logentropy_model.html


#### Versions
current [dev branch](https://github.com/RaRe-Technologies/gensim/tree/9f2a4acae21a9054213a6ba1afb043f9bd68b574)
"
870,https://github.com/RaRe-Technologies/gensim/issues/3122,3122,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",closed,2021-04-16 09:32:42+00:00,,Broken hyperlink in doc2vec tutorial,"The tutorial in the link inside the documentation for doc2vec  [here](https://radimrehurek.com/gensim/models/doc2vec.html#gensim.models.doc2vec.LabeledSentence) redirect to GitHub, but in that page the tutorial was removed. 

[here](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-lee.ipynb)

Best, 
Andrea
"
871,https://github.com/RaRe-Technologies/gensim/issues/3124,3124,[],closed,2021-04-20 18:00:56+00:00,,"Phrases model's saved connector_words not getting loaded, while loading saved phrases model","<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### If we have saved the trained phrases model in this version i.e gensim version 4.0.0 or 4.0.1, while giving non empty connector_words. And If we try to load the saved model in this version itself. Then the connector_words of the loaded phrases model will be wrongly assigned empty frozen set. This is a functional bug and will result in some of the words not getting grouped in ngram

PR has been sent for this bug here: https://github.com/RaRe-Technologies/gensim/pull/3116

What are you trying to achieve? What is the expected result? What are you seeing instead?

I am trying to save and load a phrases model with non empty connector words after freezing it.
Expectation is that connector_words won't become empty after loading it after saving it.
But they become empty
#### Steps/code/corpus to reproduce

Go to this PR: https://github.com/RaRe-Technologies/gensim/pull/3116
Go to this commit where test has been added: https://github.com/RaRe-Technologies/gensim/pull/3116/commits/49dfe1b56a6a2f16a85af374e69d2f78917c0ff3
This test will reproduce the bug

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import struct; print(""Bits"", 8 * struct.calcsize(""P""))
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```

Linux-5.4.0-72-generic-x86_64-with-debian-buster-sid
Python 3.7.3 (default, Mar 27 2019, 22:11:17) 
[GCC 7.3.0]
Bits 64
NumPy 1.19.4
SciPy 1.3.0
gensim 4.0.1
FAST_VERSION 1
"
872,https://github.com/RaRe-Technologies/gensim/issues/3127,3127,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}, {'id': 1602257032, 'node_id': 'MDU6TGFiZWwxNjAyMjU3MDMy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20HIGH', 'name': 'impact HIGH', 'color': 'b60205', 'default': False, 'description': 'Show-stopper for affected users'}, {'id': 1602279836, 'node_id': 'MDU6TGFiZWwxNjAyMjc5ODM2', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20MEDIUM', 'name': 'reach MEDIUM', 'color': 'ef7a1a', 'default': False, 'description': 'Affects a significant number of users'}]",open,2021-04-27 06:30:15+00:00,,AttributeError: 'Doc2Vec' object has no attribute 'dv’,"#### Problem description

A simple call to model.docvecs.most_similar results in an error. Seems to have forgotten about 'dv' as model.dv.most_similar results in a similar error:

```
DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).
  model.docvecs.most_similar(app, topn=topn)
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-8-051320dcdf92> in <module>
      2 topn = 10
      3 
----> 4 model.docvecs.most_similar(app, topn=topn)

~/.pyenv/versions/3.8.6/lib/python3.8/site-packages/gensim/utils.py in new_func1(*args, **kwargs)
   1517                     stacklevel=2
   1518                 )
-> 1519                 return func(*args, **kwargs)
   1520 
   1521             return new_func1

~/.pyenv/versions/3.8.6/lib/python3.8/site-packages/gensim/models/doc2vec.py in docvecs(self)
    316     @deprecated(""The `docvecs` property has been renamed `dv`."")
    317     def docvecs(self):
--> 318         return self.dv
    319 
    320     @docvecs.setter

AttributeError: 'Doc2Vec' object has no attribute 'dv’
```

#### Versions
Linux-5.4.0-66-generic-x86_64-with-glibc2.29
Python 3.8.6 (default, Dec 23 2020, 13:54:27) 
[GCC 9.3.0]
Bits 64
NumPy 1.20.1
SciPy 1.6.0
gensim 4.0.1
FAST_VERSION 1
"
873,https://github.com/RaRe-Technologies/gensim/issues/3130,3130,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",closed,2021-04-29 15:45:55+00:00,,NameError: name 'Nmf' is not defined,"#### Problem description

Trying to run NMF using gensim, but it doesn't work.

#### Steps/code/corpus to reproduce

I tried to run what documentation suggests:

```python
from gensim.test.utils import common_texts
from gensim.corpora.dictionary import Dictionary

# Create a corpus from a list of texts
common_dictionary = Dictionary(common_texts)
common_corpus = [common_dictionary.doc2bow(text) for text in common_texts]

# Train the model on the corpus.
nmf = Nmf(common_corpus, num_topics=10)
```
but it throws the error in subject. 

I tried to inspect the package and it seems it's not installed or doesn't exist. I don't understand why.

#### Versions

gensim 3.8.3

"
874,https://github.com/RaRe-Technologies/gensim/issues/3132,3132,[],open,2021-05-04 18:30:09+00:00,,Coherence Score Nan's Gensim LDA ,"Hello, I am working on my first topic modeling project with the gensim library. I am having an issue where the coherence score only returns a NAN, 

# model
`lda_model = gensim.models.ldamodel.LdaModel(corpus = corpus,
                                            id2word= id2word, 
                                            num_topics = 3,
                                            random_state = 100,
                                            update_every = 1,
                                            chunksize = 500,# num of texts used per train
                                            alpha = 'auto',
                                            per_word_topics = True,
                                            passes = 10
                                           )

from gensim.models import CoherenceModel 

# Compute Coherence Score
coherence_model_lda = CoherenceModel(model=lda_model, texts=lemmatized_posts, dictionary=id2word, coherence='c_v')
coherence_lda = coherence_model_lda.get_coherence()
print('\nCoherence Score: ', coherence_lda)
`

I've been struggling with this for awhile, still have a lot to do on my project, and topic modeling is only step 1! I really appreciate the work you all have put in to this wonderful toolkit and hope that I can get some help with this issue!

the error code i get read's 

/home/t0ad/anaconda3/envs/work/lib/python3.8/site-packages/gensim/topic_coherence/direct_confirmation_measure.py:202: RuntimeWarning: invalid value encountered in true_divide
  numerator = (co_occur_count / num_docs) + EPSILON
/home/t0ad/anaconda3/envs/work/lib/python3.8/site-packages/gensim/topic_coherence/direct_confirmation_measure.py:203: RuntimeWarning: invalid value encountered in true_divide
  denominator = (w_prime_count / num_docs) * (w_star_count / num_docs)
/home/t0ad/anaconda3/envs/work/lib/python3.8/site-packages/gensim/topic_coherence/direct_confirmation_measure.py:198: RuntimeWarning: invalid value encountered in true_divide
  co_doc_prob = co_occur_count / num_docs

I am unable to find a previous issue with this set of errors. Thank you  for your time.
"
875,https://github.com/RaRe-Technologies/gensim/issues/3134,3134,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",open,2021-05-07 15:05:48+00:00,,Wrong data in the topic_methods notebook,"I am looking at the example notebook [topic_methods](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/topic_methods.ipynb).

In the [get_term_topics](https://render.githubusercontent.com/view/ipynb?color_mode=auto&commit=0be98916dc2af5943696dd9a7efa8104f445e2a0&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f526152652d546563686e6f6c6f676965732f67656e73696d2f306265393839313664633261663539343336393664643961376566613831303466343435653261302f646f63732f6e6f7465626f6f6b732f746f7069635f6d6574686f64732e6970796e62&nwo=RaRe-Technologies%2Fgensim&path=docs%2Fnotebooks%2Ftopic_methods.ipynb&repository_id=1349775&repository_type=Repository#get_term_topics) part, there are several references to the words `bank` and `finance`, however they seem to be replaced by `firearm` and `car`. The numbers associated neither seem to be correct.
"
876,https://github.com/RaRe-Technologies/gensim/issues/3135,3135,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}]",open,2021-05-10 02:31:33+00:00,,demo in help documents of the class WmdSimilarity did not work,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I try to run the demo in help documents of the class WmdSimilarity, it did not work and put out an exception below:

AttributeError: 'Word2Vec' object has no attribute 'wmdistance'

the code I run in jupyter notebook below:

```python
from gensim.test.utils import common_texts
from gensim.models import Word2Vec
from gensim.similarities import WmdSimilarity

model = Word2Vec(common_texts, vector_size=20, min_count=1)

index = WmdSimilarity(common_texts, model)
query = ['trees']
sims = index[query]
```"
877,https://github.com/RaRe-Technologies/gensim/issues/3137,3137,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175986, 'node_id': 'MDU6TGFiZWwxNzU5ODY=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/testing', 'name': 'testing', 'color': '444444', 'default': False, 'description': 'Issue related with testing (code, documentation, etc)'}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",closed,2021-05-10 14:24:11+00:00,,Minimum required numpy version needs to be bumped to 1.17.0,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

gensim is declared to work with numpy >= 1.11.3, however it doesn't work with any version below 1.17.0.

#### Steps/code/corpus to reproduce

Install gensim and non-recent version of numpy:

```bash
$ pip install ""numpy<1.17.0"" gensim
```

Run python interpreter with the following code
```python
>>> import gensim
```

Observed error:
```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/private/tmp/.venv/lib/python3.7/site-packages/gensim/__init__.py"", line 11, in <module>
    from gensim import parsing, corpora, matutils, interfaces, models, similarities, utils  # noqa:F401
  File ""/private/tmp/.venv/lib/python3.7/site-packages/gensim/parsing/__init__.py"", line 4, in <module>
    from .preprocessing import (remove_stopwords, strip_punctuation, strip_punctuation2,  # noqa:F401
  File ""/private/tmp/.venv/lib/python3.7/site-packages/gensim/parsing/preprocessing.py"", line 26, in <module>
    from gensim import utils
  File ""/private/tmp/.venv/lib/python3.7/site-packages/gensim/utils.py"", line 62, in <module>
    default_prng = np.random.default_rng()
AttributeError: module 'numpy.random' has no attribute 'default_rng'
```

The solution is to bump the minimum version of numpy to be at least 1.17.0: https://github.com/RaRe-Technologies/gensim/blob/develop/setup.py#L318

#### Versions

```
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.16.6
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.6.3
```
"
878,https://github.com/RaRe-Technologies/gensim/issues/3138,3138,[],open,2021-05-11 16:47:02+00:00,,Wrong LDA hyperparameter offset (downweighting factor tau0)?,"I observed that the hyperparameter `offset` (introduced as `downweighting` factor in https://github.com/RaRe-Technologies/gensim/commit/aa56561a5c2e49ba699ba0f3468aa762112ad761) which corresponds to tau_0 from [Hoffman et al.](https://papers.neurips.cc/paper/2010/file/71f6278d140af599e06ad9bf1ba03cb0-Paper.pdf) is set differently compared to the [original algorithm](https://github.com/blei-lab/onlineldavb/blob/master/onlineldavb.py#L121) proposed by Hoffman.

        self._tau0 = tau0 + 1

When passing `tau0` to his algorithm, `tau0 + 1` is actually used in the calculation of rhot:

        rhot = pow(self._tau0 + self._updatect, -self._kappa)
This line is used [here](https://github.com/blei-lab/onlineldavb/blob/dee5dcf9492d2b2870ba5c1fc14ac41cbf83596c/onlineldavb.py#L281-L284) and [here](https://github.com/blei-lab/onlineldavb/blob/dee5dcf9492d2b2870ba5c1fc14ac41cbf83596c/onlineldavb.py#L321-L324).


The commit  https://github.com/RaRe-Technologies/gensim/commit/edc3ce5a7f74a2c2844c4d8afb66365596ae52b5 in gensim further changes the computation of `rho` (in order to pay attention to multi-pass algorithm as discussed in #298:

https://github.com/RaRe-Technologies/gensim/blob/351456b4f7d597e5a4522e71acedf785b2128ca1/gensim/models/ldamodel.py#L963-L967

I wonder if there is any rationale behind this decision to deviate from Hoffman's tau0 or if this was unintended?"
879,https://github.com/RaRe-Technologies/gensim/issues/3144,3144,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 1602334164, 'node_id': 'MDU6TGFiZWwxNjAyMzM0MTY0', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20LOW', 'name': 'impact LOW', 'color': '0052cc', 'default': False, 'description': 'Low impact on affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",closed,2021-05-15 18:12:30+00:00,,Fix documentation link to mycorpus.txt download,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

Trying to reproduce Corpora and Vector Space tutorial given in the documentation, but the link to download txt file is not working. The link given in the tutorial [here](https://radimrehurek.com/gensim/auto_examples/core/run_corpora_and_vector_spaces.html#corpus-streaming-one-document-at-a-time) is giving 404 error.

#### Steps/code/corpus to reproduce

Just visit this [link](https://radimrehurek.com/gensim/mycorpus.txt) which is used in the code given in the documentation, it is not working.
"
880,https://github.com/RaRe-Technologies/gensim/issues/3145,3145,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",open,2021-05-15 20:40:33+00:00,,The wiki page should be presented more prominently,"@mpenkov Thanks. The wiki page should (in my opinion) be presented more prominently.
I totally missed this benchmark page although I am using gensim for a while.

_Originally posted by @jonaschn in https://github.com/RaRe-Technologies/gensim/issues/3141#issuecomment-841700119_"
881,https://github.com/RaRe-Technologies/gensim/issues/3147,3147,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2021-05-16 02:24:46+00:00,,code run in gensim3.7 'Word2VecKeyedVectors' object has no attribute 'vocab'  ,"Errors will occur in the **embed_table** in the code, 
When I use gensim versions 3.7 and 3.8, I encountered the following error
'Word2VecKeyedVectors' object has no attribute'vocab'
In order to fix this problem I tried to use the latest 4.0 version of gensim. Similar errors
TypeError:'Word2Vec' object is not subscriptable

source code detail:
the type of **embed_table** is <class 'gensim.models.word2vec.Word2Vec'>

```python
class TextDataset(Dataset):
    def __init__(self, args,df):
        self.label=df['label'].values
        self.text_features=df[[x[1] for x in args.text_features]].values
        self.text_features_1=df[[x[1] for x in args.text_features_1]].values
        self.dense_features=df[args.dense_features].values
        self.embeddings_tables=[]
        for x in args.text_features:
            self.embeddings_tables.append(args.embeddings_tables[x[0]] if x[0] is not None else None)
        self.embeddings_tables_1=[]
        for x in args.text_features_1:
            self.embeddings_tables_1.append(args.embeddings_tables_1[x[0]] if x[0] is not None else None)            
        self.args=args
        self.df=df

    def __len__(self):
        return len(self.label)

    def __getitem__(self, i):  
        #lable 
        label=self.label[i]
        #BERT input
        if len(self.args.text_features)==0:
            text_features=0
            text_masks=0
            text_ids=0
        else:
            text_features=np.zeros((self.args.max_len_text,self.args.text_dim))
            text_masks=np.zeros(self.args.max_len_text)
            text_ids=np.zeros((self.args.max_len_text,len(self.args.text_features)),dtype=np.int64)
            begin_dim=0
            for idx,(embed_table,x) in enumerate(zip(self.embeddings_tables,self.text_features[i])):
                end_dim=begin_dim+self.args.text_features[idx][-1]              
                for w_idx,word in enumerate(x.split()[:self.args.max_len_text]):
                    text_features[w_idx,begin_dim:end_dim]=embed_table[word]
                    text_masks[w_idx]=1
                    _try:_
                        text_ids[w_idx,idx]=self.args.vocab[self.args.text_features[idx][1],word]
                    except:
                        text_ids[w_idx,idx]=self.args.vocab['unk']
                begin_dim=end_dim
```


Environment python3.6 torch-cpu


#------------------------error in  gensim versions 3.7 and 3.8---------------------------------------#
05/16/2021 09:58:35 - INFO - models.ctrNet -   ***** Running training *****
05/16/2021 09:58:35 - INFO - models.ctrNet -     Num examples = 720000
05/16/2021 09:58:35 - INFO - models.ctrNet -     Num Epochs = 5
05/16/2021 09:58:35 - INFO - models.ctrNet -     Total train batch size (w. parallel, distributed & accumulation) = 64
05/16/2021 09:58:35 - INFO - models.ctrNet -     Total optimization steps = 56250
Traceback (most recent call last):
  File ""run.py"", line 126, in <module>
    model.train(train_dataset,dev_dataset)
  File ""/mnt/usb/data/gg/competetion/tt/models/ctrNet.py"", line 76, in train
    for step, batch in enumerate(train_dataloader):
  File ""/home/hp/anaconda3/envs/tf_cpu/lib/python3.6/site-packages/torch/utils/data/dataloader.py"", line 345, in __next__
    data = self._next_data()
  File ""/home/hp/anaconda3/envs/tf_cpu/lib/python3.6/site-packages/torch/utils/data/dataloader.py"", line 856, in _next_data
    return self._process_data(data)
  File ""/home/hp/anaconda3/envs/tf_cpu/lib/python3.6/site-packages/torch/utils/data/dataloader.py"", line 881, in _process_data
    data.reraise()
  File ""/home/hp/anaconda3/envs/tf_cpu/lib/python3.6/site-packages/torch/_utils.py"", line 395, in reraise
    raise self.exc_type(msg)
AttributeError: Caught AttributeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File ""/home/hp/anaconda3/envs/tf_cpu/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py"", line 178, in _worker_loop
    data = fetcher.fetch(index)
  File ""/home/hp/anaconda3/envs/tf_cpu/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py"", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File ""/home/hp/anaconda3/envs/tf_cpu/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py"", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File ""/mnt/usb/data/gg/competetion/tt/src/data_loader.py"", line 66, in __getitem__
    text_features_1[w_idx,begin_dim:end_dim]=embed_table[word]
  File ""/home/hp/anaconda3/envs/tf_cpu/lib/python3.6/site-packages/gensim/models/keyedvectors.py"", line 353, in __getitem__
    return self.get_vector(entities)
  File ""/home/hp/anaconda3/envs/tf_cpu/lib/python3.6/site-packages/gensim/models/keyedvectors.py"", line 471, in get_vector
    return self.word_vec(word)
  File ""/home/hp/anaconda3/envs/tf_cpu/lib/python3.6/site-packages/gensim/models/keyedvectors.py"", line 459, in word_vec
    if word in self.vocab:
AttributeError: 'Word2VecKeyedVectors' object has no attribute 'vocab'

"
882,https://github.com/RaRe-Technologies/gensim/issues/3149,3149,[],closed,2021-05-16 10:11:08+00:00,,Python int too large to convert to C long,"import cv2
import numpy as np
import matplotlib.pyplot as plt

def make_coordinates(image, line_parameters):
    slope, intercept = line_parameters
    y1 = image.shape[0]
    y2 = int(y1 * (3/5))
    x1 = int((y1 - intercept)/slope)
    x2 = int((y2 - intercept)/slope)
    return np.array([x1, y1, x2, y2])

def average_slope_intercept(image, lines):
    left_fit = []
    right_fit = []
    for line in lines:
        x1, y1, x2, y2 = line.reshape(4)
        parameters = np.polyfit((x1, x2), (y1, y2), 1)
        slope = parameters[0]
        intercept = parameters[1]
        if slope < 0:
            left_fit.append((slope, intercept))
        else:
            right_fit.append((slope, intercept))
    left_fit_average = np.average(left_fit, axis = 0)
    right_fit_average = np.average(right_fit, axis = 0)
    left_line = make_coordinates(image, left_fit_average)
    right_line = make_coordinates(image, right_fit_average)
    return np.array([left_line, right_line])

def canny(image):
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    blur = cv2.GaussianBlur(gray, (5, 5), 0)
    canny = cv2.Canny(blur, 50, 150)
    return canny

def display_lines(image, lines):
    line_image = np.zeros_like(image)
    if lines is not None:
        for line in lines:
            x1, y1, x2, y2 = line.reshape(4)
            cv2.line(line_image, (x1, y1), (x2, y2), (255, 0, 0), 10)
    return line_image


def region_of_interest(image):
    height = image.shape[0]
    polygon = np.array([
    [(95, height), (1010, height), (450,250)]
    ])
    mask = np.zeros_like(image)
    cv2.fillPoly(mask, polygon, 255)
    masked_image = np.bitwise_and(canny, mask)
    return masked_image


#image = cv2.imread('Nagpur_image.jpg')
#lane_image = np.copy(image)
#canny = canny(lane_image)
#cropped_image = region_of_interest(canny)
#lines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength = 40, maxLineGap = 5)
#averaged_lines = average_slope_intercept(lane_image, lines)
#line_image = display_lines(lane_image, averaged_lines)
#combo_image = cv2.addWeighted(lane_image, 0.8, line_image, 1, 1)
#cv2.imshow(""result"", combo_image)
#cv2.waitKey(0)

cap = cv2.VideoCapture(""test3.mp4"")
while(cap.isOpened()):
    _, frame = cap.read()
    canny = canny(frame)
    cropped_image = region_of_interest(canny)
    lines = cv2.HoughLinesP(cropped_image, 2, np.pi/180, 100, np.array([]), minLineLength = 40, maxLineGap = 5)
    averaged_lines = average_slope_intercept(frame, lines)
    line_image = display_lines(frame, averaged_lines)
    combo_image = cv2.addWeighted(frame, 0.8, line_image, 1, 1)
    cv2.imshow(""result"", combo_image)
    cv2.waitKey(1)


**ERROR** : 
Traceback (most recent call last):
  File ""nagpurlanes.py"", line 75, in <module>
    line_image = display_lines(frame, averaged_lines)
  File ""nagpurlanes.py"", line 42, in display_lines
    cv2.line(line_image, (x1, y1), (x2, y2), (255, 0, 0), 10)
OverflowError: Python int too large to convert to C long"
883,https://github.com/RaRe-Technologies/gensim/issues/3150,3150,[],closed,2021-05-16 12:29:32+00:00,,Outdated Attribute in Word2Vec Documentation,"#### Problem description

I'm following the tutorial for Word2Vec given in the documentation [here](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html#word2vec-demo). 

There is this code snippet there.
```
for index, word in enumerate(wv.index_to_key):
    if index == 10:
        break
    print(f""word #{index}/{len(wv.index_to_key)} is {word}"")
```
Running this gives an error saying 

> Word2VecKeyedVectors' object has no attribute 'index_to_key'

I used `dir(wv)` and found that using the attribute `wv.index2word` will give the results as shown in the documentation instead of the outdated attribute used there. Please look into this.

EDIT: just realized that I was using older version of gensim so was getting that error, I apologize for this mistake."
884,https://github.com/RaRe-Technologies/gensim/issues/3151,3151,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",closed,2021-05-18 01:12:55+00:00,,Fix FastText documentation to reflect changed parameter names,"The docstring of `gensim.models.fasttext.FastText` says:

> size (int, optional) – Dimensionality of the word vectors.

Should be changed to:

> **vector_size** (int, optional) – Dimensionality of the word vectors."
885,https://github.com/RaRe-Technologies/gensim/issues/3152,3152,[],open,2021-05-18 13:40:01+00:00,,standardize 'corpus_iterable' (over 'sentences') everywhere,"I'd thought that after our discussion on the merits of changing `sentences` to `corpus_iterable` during other renaming/refactoring, I'd changed it everywhere. But after this SO question – https://stackoverflow.com/q/67573416/130288 – I see that `sentences` persists a bunch of places, like the `Word2Vec`/`FastText` initializers & some of the doc-comment examples, including the `FastText` doc-comment – but is not supported elsewhere, such as the `build_vocab()`/`train()` methods specifically shown as using it in the doc-comments.  

To TLDR that discussion: `sentences` often confuses users into thinking that they *must* run a sentences-splitter, as if the algorithms only work on true 'sentences'. It also seems slightly more likely for people to assume that any string-containing-a-sentence is ok, rather than a list-of-tokens. It also is somewhat in-apt with regard to `Doc2Vec`, or the common use of these algorithms on data that isn't literally natural-language sentences. Using `corpus_iterable` instead helps re-emphasize that the 'iterable' interface is all-important – a source of many usage erros – and has a useful parallelism to the `corpus_file` alternative, as only one or the other of `corpus_iterable` or `corpus_file` should be provided. (To the extent it then requires someone to look at the doc-comment, rather than assume the type of its individual items, it might also provide a better hook for communicating the requirement that each item be a list-of-tokens.)

I think for consitency all use of `sentences` should be eliminated, in method signatures & docs, in favor of `corpus_iterable`. "
886,https://github.com/RaRe-Technologies/gensim/issues/3154,3154,[],closed,2021-05-19 22:08:58+00:00,,"Yes, thanks. If it's really a bug with the FB model, not much we can do about it.","Yes, thanks. If it's really a bug with the FB model, not much we can do about it.

_Originally posted by @piskvorky in https://github.com/RaRe-Technologies/gensim/issues/2969#issuecomment-799811459_"
887,https://github.com/RaRe-Technologies/gensim/issues/3158,3158,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2021-05-28 03:40:01+00:00,,doc2vec's infer_vector has `epochs` and `steps` input parameters - `steps` not in use,"Refer to doc2vec.py, `infer_vector` function seems to be using `epochs` for the number of iterations and `steps` is not in used.

However, in the `similarity_unseen_docs` function, `steps` is used when calling the infer_vector function.

![image](https://user-images.githubusercontent.com/62754326/119926239-9085d400-bfa9-11eb-838b-dae98da26c3f.png)
"
888,https://github.com/RaRe-Technologies/gensim/issues/3159,3159,[],closed,2021-05-28 09:23:16+00:00,,Enable to master the window size variations during training,"**Context:** I am trying to use `gensim` on a corpus in which the order of words has no importance at all. So my idea is to give the constructor of the class `Word2Vec` a large window size, so that it trains each word with the full rest of the sentence (the iterable I give as parameter `sentences` to the `Word2Vec` constructor yields sentences in which word order is irrelevant).

I noticed [here](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/word2vec_inner.pyx#L572) in the code that during training, the window size was reduced of a size drawn uniformly at random. If I get it right, it feels like saying, if words are too far from one another, sometimes they carry less sense together. And at any rate, adding some randomness very often gives better results in machine learning in general. In general I agree with these two ideas.
- However, I find it too bad that this is hard-coded, and that the user cannot choose to keep the window fix-sized, with the size they enter. 
-  Another cool option would be to be able to input a minimal and a maximal size, instead of the current behaviour where the window size varies from the full length provided by the user to 0.

**Propositions:**
 From these observations I propose to do one or all of the following changes:
- Add a parameter to choose whether or not the window size randomly reduces. This could be something like `change_window_size`, set to `True` by default to be consistent with the current behaviour. 
- Add parameters for lower and higher bounds of the final window size. Note that if these bounds are equal, this amounts to no random reduction at all and this replaces the behaviour of the previous proposition.
- [Bonus] We could also imagine that instead of drawing sizes uniformly at random, the user could choose the probability distribution. But this is more of an idea I'm throwing into the air, rather than one I'm ready to implement right now. I don't know if it is relevant enough, considering the code changes it may imply.

What do you think of this ? If you're ok with it, I plan on doing the modifications myself."
889,https://github.com/RaRe-Technologies/gensim/issues/3160,3160,"[{'id': 708355863, 'node_id': 'MDU6TGFiZWw3MDgzNTU4NjM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/need%20info', 'name': 'need info', 'color': 'fbca04', 'default': False, 'description': 'Not enough information for reproduce an issue, need more info from author'}]",closed,2021-05-30 19:46:00+00:00,,"Inconsistency between versions 3.2.0, 3.8.1 and 4.0.1","Phrases and Phrases classes of the ""models"" package cannot be used; It is not accessible in the versions that specified the issue's title, at least in the latest version, this inconsistency should be removed.

"
890,https://github.com/RaRe-Technologies/gensim/issues/3161,3161,[],closed,2021-06-03 09:13:16+00:00,,Add homepage in Github About section,"Do you consider adding https://radimrehurek.com/gensim to the about section of the Github repo?

See https://stackoverflow.com/questions/7757751/how-do-you-change-a-repository-description-on-github"
891,https://github.com/RaRe-Technologies/gensim/issues/3162,3162,[],open,2021-06-04 05:54:12+00:00,,"Doc2Vec: when we have string tags, build_vocab with update removes previous index","<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I'm trying to resume training my Doc2Vec model with string tags, but `model.build_vocab` removes all previous index from `model.dv`.

#### Steps/code/corpus to reproduce

A simple example to reproduce this:

```python
import string

from gensim.test.utils import common_texts
from gensim.models.doc2vec import Doc2Vec, TaggedDocument

documents = [TaggedDocument(doc, [tag]) for tag, doc in zip(string.ascii_lowercase, common_texts)]
documents1 = documents[:6]
documents2 = documents[6:]

model = Doc2Vec(vector_size=5, window=2, min_count=1)

model.build_vocab(documents1)
model.train(documents1, total_examples=len(documents1), epochs=5)

model.save('model')
model = Doc2Vec.load('model')

print('Vector count after train:', len(model.dv))
print('Keys:', model.dv.index_to_key)

model.build_vocab(documents2, update=True)
model.train(documents2, total_examples=model.corpus_count, epochs=model.epochs)

print('Vector count after update:', len(model.dv))
print('Keys:', model.dv.index_to_key)

model.save('model')
model = Doc2Vec.load('model')

print('Vector count after load:', len(model.dv))
print('Keys:', model.dv.index_to_key)
```

Output:
```
Vector count after train: 6
Keys: ['a', 'b', 'c', 'd', 'e', 'f']
Vector count after update: 3
Keys: ['g', 'h', 'i']
Vector count after load: 3
Keys: ['g', 'h', 'i']
```

And we have an interesting behavior:
```python
print('b' in model.dv)
# True
print(model.dv['b'])
# [ 0.00524729 -0.19762747 -0.10339681 -0.19433555  0.04022206]
```

The tag seems still exists in the model after updating, but `len` and `index_to_key` do not show this.

At the same time the code with int tags works correctly (it seems to me):

```python
documents = [TaggedDocument(doc, [tag]) for tag, doc in enumerate(common_texts)]
documents1 = documents[:6]
documents2 = documents[6:]
...
```

```
Vector count after train: 6
Keys: [0, 1, 2, 3, 4, 5]
Vector count after update: 9
Keys: [0, 1, 2, 3, 4, 5, 6, 7, 8]
Vector count after load: 9
Keys: [0, 1, 2, 3, 4, 5, 6, 7, 8]
```

#### Versions

```
Windows-10-10.0.19041-SP0
Python 3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]
Bits 64
NumPy 1.20.3
SciPy 1.6.1
gensim 4.0.1
FAST_VERSION 0
```
"
892,https://github.com/RaRe-Technologies/gensim/issues/3164,3164,[],closed,2021-06-06 10:14:05+00:00,,mycorpus.txt gies 404,"The link:

https://radimrehurek.com/gensim/auto_examples/core/mycorpus.txt

provided [here](https://radimrehurek.com/gensim/auto_examples/core/run_corpora_and_vector_spaces.html) returns a 404 error"
893,https://github.com/RaRe-Technologies/gensim/issues/3165,3165,[],open,2021-06-06 14:04:15+00:00,,Streaming instead of online LDA,"The current implementation of LDA in gensim is not actually well suited for streaming.

Here is an interesting [publication:](http://proceedings.mlr.press/v37/theis15.pdf)
Theis, Lucas, and Matt Hoffman. ""A trust-region method for stochastic variational inference with applications to streaming data."" International Conference on Machine Learning. PMLR, 2015.

All LDA implementations can be found here: https://github.com/lucastheis/trlda/"
894,https://github.com/RaRe-Technologies/gensim/issues/3166,3166,[],closed,2021-06-06 17:42:02+00:00,,LSI gets stuck and connection to Jupyter is lost,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I want to achieve a LSI. But it gets stuck midway at every chunk, no matter how small the chunk size

#### Steps/code/corpus to reproduce

```python
lsi_model = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=300, chunksize=500)
```

Here is the log from loglevel=DEBUG:

```
2021-06-06 19:35:18,168 : INFO : using serial LSI version on this node
2021-06-06 19:35:18,169 : INFO : updating model with new documents

Processing 299/3332249 (0.01%)

2021-06-06 19:35:18,522 : INFO : preparing a new chunk of documents
2021-06-06 19:35:18,523 : DEBUG : converting corpus to csc format
2021-06-06 19:35:18,531 : INFO : using 100 extra samples and 2 power iterations
2021-06-06 19:35:18,532 : INFO : 1st phase: constructing (1542840, 400) action matrix

Processing 500/3332249 (0.02%)

2021-06-06 19:35:18,563 : INFO : orthonormalizing (1542840, 400) action matrix
2021-06-06 19:35:21,646 : DEBUG : computing QR of (1542840, 400) dense matrix
2021-06-06 19:35:44,717 : DEBUG : running 2 power iterations
2021-06-06 19:35:52,571 : DEBUG : computing QR of (1542840, 400) dense matrix
2021-06-06 19:36:21,354 : DEBUG : computing QR of (1542840, 400) dense matrix
2021-06-06 19:36:48,119 : INFO : 2nd phase: running dense svd on (400, 500) matrix
2021-06-06 19:36:49,419 : INFO : computing the final decomposition
2021-06-06 19:36:49,420 : INFO : keeping 300 factors (discarding 9.516% of energy spectrum)
```

Then it gets stuck and after some time Jupyter shows me the following error message:
```
Server Connection Error
A connection to the Jupyter server could not be established. JupyterLab will continue trying to reconnect. Check your network connection or Jupyter server configuration.
```

#### Versions

```
Python 3.9.5 (default, May 14 2021, 00:00:00) 
[GCC 11.1.1 20210428 (Red Hat 11.1.1-1)] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import platform; print(platform.platform())
Linux-5.12.8-300.fc34.x86_64-x86_64-with-glibc2.33
>>> import sys; print(""Python"", sys.version)
Python 3.9.5 (default, May 14 2021, 00:00:00) 
[GCC 11.1.1 20210428 (Red Hat 11.1.1-1)]
>>> import struct; print(""Bits"", 8 * struct.calcsize(""P""))
Bits 64
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.19.5
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.6.3
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 4.0.1
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1
```

### Additional info

```
>>> print(numpy.show_config())
blas_mkl_info:
  NOT AVAILABLE
blis_info:
  NOT AVAILABLE
openblas_info:
    libraries = ['openblas', 'openblas']
    library_dirs = ['/usr/local/lib']
    language = c
    define_macros = [('HAVE_CBLAS', None)]
blas_opt_info:
    libraries = ['openblas', 'openblas']
    library_dirs = ['/usr/local/lib']
    language = c
    define_macros = [('HAVE_CBLAS', None)]
lapack_mkl_info:
  NOT AVAILABLE
openblas_lapack_info:
    libraries = ['openblas', 'openblas']
    library_dirs = ['/usr/local/lib']
    language = c
    define_macros = [('HAVE_CBLAS', None)]
lapack_opt_info:
    libraries = ['openblas', 'openblas']
    library_dirs = ['/usr/local/lib']
    language = c
    define_macros = [('HAVE_CBLAS', None)]
None
>>> print(scipy.show_config())
lapack_mkl_info:
  NOT AVAILABLE
openblas_lapack_info:
    libraries = ['openblas', 'openblas']
    library_dirs = ['/usr/local/lib']
    language = c
    define_macros = [('HAVE_CBLAS', None)]
lapack_opt_info:
    libraries = ['openblas', 'openblas']
    library_dirs = ['/usr/local/lib']
    language = c
    define_macros = [('HAVE_CBLAS', None)]
blas_mkl_info:
  NOT AVAILABLE
blis_info:
  NOT AVAILABLE
openblas_info:
    libraries = ['openblas', 'openblas']
    library_dirs = ['/usr/local/lib']
    language = c
    define_macros = [('HAVE_CBLAS', None)]
blas_opt_info:
    libraries = ['openblas', 'openblas']
    library_dirs = ['/usr/local/lib']
    language = c
    define_macros = [('HAVE_CBLAS', None)]
None
```"
895,https://github.com/RaRe-Technologies/gensim/issues/3167,3167,[],closed,2021-06-06 19:55:11+00:00,,Initialize id2token when it is called directly,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

Given an id I want to retrieve the token from the dictionary.

There is a `dictionary.id2token` dictionary but it's empty.

The documentation [says](https://radimrehurek.com/gensim/corpora/dictionary.html):

```
Reverse mapping for token2id, initialized in a lazy manner to save memory (not created until needed).
```

I think that if the user calls it directly, it should be initialized

#### Versions

```python
>>> import platform; print(platform.platform())
Linux-5.12.8-300.fc34.x86_64-x86_64-with-glibc2.33
>>> import sys; print(""Python"", sys.version)
Python 3.9.5 (default, May 14 2021, 00:00:00) 
[GCC 11.1.1 20210428 (Red Hat 11.1.1-1)]
>>> import struct; print(""Bits"", 8 * struct.calcsize(""P""))
Bits 64
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.19.5
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.6.3
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 4.0.1
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1

```
"
896,https://github.com/RaRe-Technologies/gensim/issues/3168,3168,[],open,2021-06-09 06:00:23+00:00,,Error with older wiki dumps,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I am trying to load wiki dump and extract articles for word2vec training. This works well for more recent dumps. But for older dumps (e.g., 2010 dump), it fails. 

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

If your problem is with a specific Gensim model (word2vec, lsimodel, doc2vec, fasttext, ldamodel etc), include the following:

```python
import multiprocessing
from gensim.corpora.wikicorpus import WikiCorpus
from gensim.models.word2vec import Word2Vec
import logging

logging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s')
logging.root.setLevel(level=logging.INFO)

wiki_dump= './enwiki-20100312-pages-articles.xml.bz2'
wiki= WikiCorpus(fname= wiki_dump, 
                lower= False, 
                 lemmatize=False, 
                 dictionary={}, #not needed for word2vec (https://groups.google.com/u/1/g/gensim/c/aI7vbNCxhb8)
                 processes= max(1, multiprocessing.cpu_count() - 1), 
                 token_min_len=1, 
                 token_max_len=50) 

txt_file = './enwiki_20100312_extracted_articles_v1.txt'
with open(txt_file, 'w') as f:
    for i, text in enumerate(wiki.get_texts()):
        f.write("" "".join(text) + ""\n"")
        if i % 50000 == 0:
            logging.info(""Saved %d articles"" % i)
logging.info(""Finished extract wiki, Saved in %s"" % txt_file) 
```
`Process InputQueue-24:
Traceback (most recent call last):
  File ""/anaconda/envs/spacy_v3/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap
    self.run()
  File ""/home/user-sas01/.local/lib/python3.8/site-packages/gensim-4.0.0b0-py3.8-linux-x86_64.egg/gensim/utils.py"", line 1215, in run
    wrapped_chunk = [list(chunk)]
  File ""/home/user-sas01/.local/lib/python3.8/site-packages/gensim-4.0.0b0-py3.8-linux-x86_64.egg/gensim/corpora/wikicorpus.py"", line 679, in <genexpr>
    texts = (
  File ""/home/user-sas01/.local/lib/python3.8/site-packages/gensim-4.0.0b0-py3.8-linux-x86_64.egg/gensim/corpora/wikicorpus.py"", line 430, in extract_pages
    ns = elem.find(ns_path).text
AttributeError: 'NoneType' object has no attribute 'text'
`


#### Versions

Please provide the output of:

```python
Linux-5.4.0-1047-azure-x86_64-with-glibc2.10
Python 3.8.5 (default, Sep  4 2020, 07:30:14) 
[GCC 7.3.0]
Bits 64
NumPy 1.19.2
SciPy 1.6.0
gensim 4.0.0beta
FAST_VERSION 1

```
"
897,https://github.com/RaRe-Technologies/gensim/issues/3171,3171,"[{'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}]",closed,2021-06-12 18:04:12+00:00,,make `remove_stopwords()` behavior more consistent,"(triggered by SO question: https://stackoverflow.com/questions/67944732/using-my-own-stopword-list-with-gensim-corpora-textcorpus-textcorpus/67951592#67951592)

Gensim has two `remove_stopwords()` functions with similar, but slightly-different behavior that risks confusing users. 

`gensim.parsing.preprocessing.remove_stopwords` takes a space-delimited string, and always consults the *current* value of `gensim.parsing.preprocessing.STOPWORDS` (including any user reassignments). 

By contrast, `gensim.corpora.textcorpus.remove_stopwords` takes a list-of-tokens, allows the specification of an alternate list-of-stopwords, but if allowed to use its 'default' stopwords, uses only the value of `gensim.parsing.preprocessing.STOPWORDS` that was captured when the function was defined (which could miss later user redefinitions).

Avoiding the reuse of identical function names that take different argument-types would help avoid user/code-reviewer confusion. Also, capturing the value of a variable that might change leads to confusing function-behavior: the token version could just as easily consult `gensim.parsing.preprocessing.STOPWORDS` on each call (as the string version already does). "
898,https://github.com/RaRe-Technologies/gensim/issues/3173,3173,[],closed,2021-06-15 21:01:10+00:00,,Gensim 4.0 loading Phraser trained from Gensim 3.x,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

Gensim 4.0 cannot load Phraser model from Gensim 3.x

#### Steps/code/corpus to reproduce

```python
gemsim.model.load(""saved_phraser.pkl"") 
```
Will not be able to load phraser trained in gensim 3.x due to a bug in source code. See below.

#### Versions
This line of code from 4.0.1 (and also current development branch) need to be fixed:
https://github.com/RaRe-Technologies/gensim/blob/4.0.1/gensim/models/phrases.py#L367

```python
model.phrasegrams = {
  str(model.delimiter.join(component), encoding='utf8'): score
  for key, val in phrasegrams.items()
}
```
The existing code will only keep the first phrase. To upgrade and load all phrases, it should be replaced with:

```python
model.phrasegrams = {
  str(model.delimiter.join(key), encoding='utf8'): val
  for key, val in phrasegrams.items()
}
```
"
899,https://github.com/RaRe-Technologies/gensim/issues/3175,3175,[],closed,2021-06-17 14:14:52+00:00,,Issue importing gensim utils package ,"I am getting the following error while importing gensim utils package below is the error

 File ""C:\ProgramData\Anaconda3\lib\site-packages\gensim\parsing\preprocessing.py"", line 26, in <module>
    from gensim import utils

  File ""C:\ProgramData\Anaconda3\lib\site-packages\gensim\utils.py"", line 62, in <module>
    default_prng = np.random.default_rng()

AttributeError: module 'numpy.random' has no attribute 'default_rng'

This is the environment details of my setup:
Windows-10-10.0.19041-SP0
Python 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]
Bits 64
NumPy 1.16.5
SciPy 1.2.1
"
900,https://github.com/RaRe-Technologies/gensim/issues/3177,3177,[],closed,2021-06-21 18:25:05+00:00,,Incompatible types of unicode strings in `gensim.similarities.fastss.editdist`,"#### Problem description

In #3146, a new algorithm for fast Levenshtein distance computation has been added. However, the algorithm currently cannot cope with different internal representations of Unicode strings, resulting in cryptic errors:

#### Steps/code/corpus to reproduce

``` python
$ pip install git+https://github.com/RaRe-Technologies/gensim.git@develop
$ python3
>>> from gensim.similarities.fastss import editdist
>>>
>>> editdist('Žižka', 'šiška')
2
>>> editdist('Žižka', 'Zizka')
gensim/similarities/fastss.pyx in gensim.similarities.fastss.editdist()

ValueError: incompatible types of unicode strings
```

#### Suggested patch

See #3178.

#### Versions

```python
>>> import platform; print(platform.platform())
Linux-4.15.0-108-generic-x86_64-with-glibc2.10
>>> import sys; print(""Python"", sys.version)
Python 3.8.3 (default, Jul  2 2020, 16:21:59) 
[GCC 7.3.0]
>>> import struct; print(""Bits"", 8 * struct.calcsize(""P""))
Bits 64
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.20.3
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.6.3
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 4.1.0.dev0
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1
```
"
901,https://github.com/RaRe-Technologies/gensim/issues/3179,3179,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}, {'id': 1162250977, 'node_id': 'MDU6TGFiZWwxMTYyMjUwOTc3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/fasttext', 'name': 'fasttext', 'color': 'ad52ea', 'default': False, 'description': 'Issues related to the FastText model'}]",open,2021-06-22 01:55:10+00:00,,Gensim's FastText model reads in unsupported modes from Facebook's FastText,"In gensim/models/fasttext.py:

```python
    model = FastText(
        vector_size=m.dim,
        vector_size=m.dim,
        window=m.ws,
        window=m.ws,
        epochs=m.epoch,
        epochs=m.epoch,
        negative=m.neg,
        negative=m.neg,
        # FIXME: these next 2 lines read in unsupported FB FT modes (loss=3 softmax or loss=4 onevsall,
        # or model=3 supervised) possibly creating inconsistent gensim model likely to fail later. Displaying
        # clear error/warning with explanatory message would be far better - even if there might be some reason
        # to continue with the load - such as providing read-only access to word-vectors trained those ways. (See:
        # https://github.com/facebookresearch/fastText/blob/2cc7f54ac034ae320a9af784b8145c50cc68965c/src/args.h#L19
        # for FB FT mode definitions.)
        hs=int(m.loss == 1),
        hs=int(m.loss == 1),
        sg=int(m.model == 2),
        sg=int(m.model == 2),
        bucket=m.bucket,
        bucket=m.bucket,
        min_count=m.min_count,
        min_count=m.min_count,
        sample=m.t,
        sample=m.t,
        min_n=m.minn,
        min_n=m.minn,
        max_n=m.maxn,
        max_n=m.maxn,
    )
```"
902,https://github.com/RaRe-Technologies/gensim/issues/3181,3181,[],open,2021-06-22 09:42:36+00:00,,Mismatch get_coherence_per_topic and get_coherence for single topic,"#### Problem description

Hi! I am using Gensim to compute the NPMI coherence for each of my topics. I used the method `get_coherence_per_topic()` and also `get_coherence()` (in this case, just passing a list with a single topic), and I noticed that the coherences per topic do not match with the ones returned by `get_coherence()` of the corresponding topics. In my understanding, the NPMI of a topic should be independent of the number of topics or of the other input topics. 
This happens also with the other c_* coherences, not with the UMASS version. 

Thank you!

#### Steps/code/corpus to reproduce

```python
from gensim.test.utils import common_texts, common_dictionary
from gensim.models.ldamodel import LdaModel
from gensim.models.coherencemodel import CoherenceModel

topics = [
    ['human', 'computer', 'system', 'interface'],
    ['graph', 'minors', 'trees', 'eps']
]

cm = CoherenceModel(topics=topics, texts=common_texts, coherence='c_npmi', 
                    dictionary=common_dictionary)
coherence = cm.get_coherence_per_topic()  
print(coherence) # got [0.23583958321789514, -0.24456941091456053]

cm_topic0 = CoherenceModel(topics=[topics[0]], texts=common_texts, 
                           coherence='c_npmi', dictionary=common_dictionary)
coherence_topic0 = cm_topic0.get_coherence()  
print(coherence_topic0) # expect this to be == coherence[0] but got -0.14624062517782566

cm_topic1 = CoherenceModel(topics=[topics[1]], texts=common_texts, 
                           coherence='c_npmi', dictionary=common_dictionary)
coherence_topic1 = cm_topic1.get_coherence()  
print(coherence_topic1) # expect this to be == coherence[1] but got -0.31633310918174923

```

#### Versions

Linux-5.4.104+-x86_64-with-Ubuntu-18.04-bionic
Python 3.7.10 (default, May  3 2021, 02:48:31) 
[GCC 7.5.0]
Bits 64
NumPy 1.19.5
SciPy 1.4.1
gensim 3.8.3
FAST_VERSION 1"
903,https://github.com/RaRe-Technologies/gensim/issues/3183,3183,[],closed,2021-06-28 01:33:32+00:00,,Doc2Vec loss always showing 0,"```
class MonitorCallback(CallbackAny2Vec):
    def __init__(self, test_cui, test_sec):
        self.test_cui = test_cui
        self.test_sec = test_sec

    def on_epoch_end(self, model):
        print('Model loss:', model.get_latest_training_loss())
        for word in self.test_cui:  # show wv logic changes
             print(word, model.wv.most_similar(word))
        for word in self.test_sec:  # show dv logic changes
             print(word, model.dv.most_similar(word))
```

```
    model = Doc2Vec(vector_size=300, min_count=1, epochs=1, window=5, workers=32)
    print('Building vocab...')
    model.build_vocab(train_corpus)
    print(model.corpus_count, model.epochs)
    model.train(
        train_corpus, total_examples=model.corpus_count, compute_loss=True, epochs=model.epochs, callbacks=[monitor])
    print('Done training...')
    model.save('sec2vec.model')
```

Each time the callback prints, it prints 0.  The second issue is that after the first epoch, the model seems pretty good according to calls to most_similar.  Yet, after the second it appears random.  I have a fairly large dataset so I don't think dramatic overfitting is happening.  Is there a bug after the first epoch or is the learning rate getting messed up?  It's tough to know what's going on because there's no within-epoch logging and the training loss is always evaluating to 0."
904,https://github.com/RaRe-Technologies/gensim/issues/3184,3184,"[{'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",open,2021-06-29 05:44:26+00:00,,Reduce duplication in word2vec.pyx source code,"OK, we can deal with this separately.

_Originally posted by @mpenkov in https://github.com/RaRe-Technologies/gensim/pull/3169#discussion_r660297089_"
905,https://github.com/RaRe-Technologies/gensim/issues/3186,3186,[],closed,2021-07-02 11:49:39+00:00,,fasttext: KeyError raised for OOV words in predict_output_word,"`predict_output_word` with fasttext model behaviour on OOV words is not consistent with word2vec, since `w in self.wv` always returns `True` for fasttext.

```python
----> 1 model.predict_output_word(['a'])

~gensim\models\word2vec.py in predict_output_word(self, context_words_list, topn)
   1820             raise RuntimeError(""Parameters required for predicting the output words not found."")
   1821 
-> 1822         word2_indices = [self.wv.get_index(w) for w in context_words_list if w in self.wv]
   1823         if not word2_indices:
   1824             logger.warning(""All the input context words are out-of-vocabulary for the current model."")

~gensim\models\word2vec.py in <listcomp>(.0)
   1820             raise RuntimeError(""Parameters required for predicting the output words not found."")
   1821 
-> 1822         word2_indices = [self.wv.get_index(w) for w in context_words_list if w in self.wv]
   1823         if not word2_indices:
   1824             logger.warning(""All the input context words are out-of-vocabulary for the current model."")

~gensim\models\keyedvectors.py in get_index(self, key, default)
    394             return default
    395         else:
--> 396             raise KeyError(f""Key '{key}' not present"")
    397 
    398     def get_vector(self, key, norm=False):

KeyError: ""Key 'a' not present""
```

#### Versions

```python
Python 3.8.10 (default, May 19 2021, 13:12:57) [MSC v.1916 64 bit (AMD64)]
Bits 64
NumPy 1.20.2
SciPy 1.6.2
gensim 4.0.1
FAST_VERSION 1
```
"
906,https://github.com/RaRe-Technologies/gensim/issues/3187,3187,[],closed,2021-07-06 10:02:40+00:00,,how to use FastTextKeyedVectors.load_word2vec_format ,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

error to use FastTextKeyedVectors.load_word2vec_format to load word vector.


#### Steps/code/corpus to reproduce

Hi, i train a fasttext model and save wv by
```
model.wv.save_word2vec_format(""./test.vec"", binary=False)
```
when i use 
```
FastTextKeyedVectors.load_word2vec_format(""./test.vec"")
```
i get 
![image](https://user-images.githubusercontent.com/26429138/124581702-e771a980-de83-11eb-98e8-8382fc920416.png)
i don`t know how to make it work

However, this can load
```
KeyedVectors.load_word2vec_format(""./test.vec"")
```
but can not work with OOV problem,which is the most important feature of Fasttext

#### Versions

Please provide the output of:

```python
Windows-10-10.0.19041-SP0
Python 3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]
Bits 64
NumPy 1.21.0
SciPy 1.6.2
gensim 4.0.1
FAST_VERSION 1
```
"
907,https://github.com/RaRe-Technologies/gensim/issues/3189,3189,[],closed,2021-07-08 07:58:47+00:00,,cannot import name 'nmf' from 'gensim.models',"#### Problem description
Hi!
When I try to import NMF from gensim (version 3.6.0) using colab, I get an ImportError exception. It seems to happen on colab and not on Windows. And it doesn't happen if I use version 3.8.0. 

#### Steps/code/corpus to reproduce

```python
from gensim.models import nmf
```

I get this error:
```python
ImportError: cannot import name 'nmf' from 'gensim.models' (/usr/local/lib/python3.7/dist-packages/gensim/models/__init__.py)
```

#### Versions

```
Linux-5.4.104+-x86_64-with-Ubuntu-18.04-bionic
Python 3.7.10 (default, May  3 2021, 02:48:31) 
[GCC 7.5.0]
Bits 64
NumPy 1.19.5
SciPy 1.4.1
gensim 3.6.0
FAST_VERSION 1
```
"
908,https://github.com/RaRe-Technologies/gensim/issues/3191,3191,[],open,2021-07-13 15:41:06+00:00,,Similarity Interface of Gensim giving low similarity score for exact same documents with TfIdf + LdaModel,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I am trying to implement a document similarity API using the LDA Model of Gensim. To experiment with the performance, I tried implementing it by training the LDA Model with TfIdf vectors instead of the normal BoW corpus as described in the documentation. The problem which I am facing is that while using the Similarity API of Gensim for creating the index and finding out the similarity score, what I encountered is that if I try to match the same document with itself, sometimes, the Similarity values are not ~1. The values which I get are as low as ~0.06. This does not occur ALL the time, but for some documents only. I tested this again with 229 documents matching each document with itself, and I found that 45 of the documents give results less than 0.98, sometimes giving values like 0.65, 0.41 and similar. I would like some help on this, whether I am doing something wrong or is there a potential bug in the interface.

#### Steps/code/corpus to reproduce

##### Minimal Code used for testing:
NOTE: The corpus which I am using is confidential and limited to only the organization. So I would not be able to share the training corpus here, but for the reference, I will share the output of the LDA model which I am getting for 3 out of the 45 documents (these documents are getting the lowest score matching with themselves) which I used for testing. Hope that should be sufficient for debugging.
```python
docs = [ 'Document 1 as a string', 'Document 2 as a string', 'Document 3 as a string', 'and so on.....' ]
cleaned_docs = list(map(clean_function, docs))                 # Here, clean_function return tokens for each string. So, cleaned_docs is essentially a list of list of strings List[List[str]]
bow_corpus = [dictionary.doc2bow(i) for i in cleaned_docs]
tfidf_corpus = tfidf_model[bow_corpus]
lda_corpus = lda_model[tfidf_corpus]
index = Similarity(lda_corpus)
sims = index[lda_corpus]                   # Getting similarity for all combinations. Got a (229, 229) array for my case
final_sims = np.diag(sims)                 # Getting similarity with itself
print(final_sims)                          # Getting very low score with some docs
```
##### Output Vectors of LDAModel for 3 documents:
```python
[[(0, 0.17789464), (2, 0.03806097), (12, 0.2273234), (14, 0.08613937), (21, 0.13261063), (22, 0.17807047), (36, 0.058883864)],
[(1, 0.43381935), (2, 0.14317065), (3, 0.07986226), (36, 0.062136874)], 
[(0, 0.32848448), (2, 0.16667062), (14, 0.0485237), (15, 0.11480027), (18, 0.086506054), (35, 0.059970867)]]
```

```python
print(lda_model.lifecycle_events)
[{'msg': 'trained LdaModel(num_terms=100000, num_topics=40, decay=0.5, chunksize=2000) in 2080.85s', 'datetime': '2021-06-30T09:32:52.611017', 'gensim': '4.0.1', 'python': '3.6.12 (default, Jun 28 2021, 13:17:01) \n[GCC 5.4.0 20160609]', 'platform': 'Linux-4.4.0-1128-aws-x86_64-with-debian-stretch-sid', 'event': 'created'}, {'fname_or_handle': 'models/lda.model', 'separately': ""['expElogbeta', 'sstats']"", 'sep_limit': 10485760, 'ignore': ['state', 'dispatcher', 'id2word'], 'datetime': '2021-06-30T09:32:52.703852', 'gensim': '4.0.1', 'python': '3.6.12 (default, Jun 28 2021, 13:17:01) \n[GCC 5.4.0 20160609]', 'platform': 'Linux-4.4.0-1128-aws-x86_64-with-debian-stretch-sid', 'event': 'saving'}, {'fname_or_handle': 'models/lda.model', 'separately': ""['expElogbeta', 'sstats']"", 'sep_limit': 10485760, 'ignore': ['state', 'dispatcher', 'id2word'], 'datetime': '2021-06-30T09:32:58.758961', 'gensim': '4.0.1', 'python': '3.6.12 (default, Jun 28 2021, 13:17:01) \n[GCC 5.4.0 20160609]', 'platform': 'Linux-4.4.0-1128-aws-x86_64-with-debian-stretch-sid', 'event': 'saving'}, {'fname': 'models/lda.model', 'datetime': '2021-07-13T20:26:59.671845', 'gensim': '4.0.1', 'python': '3.8.10 (default, Jun  2 2021, 10:49:15) \n[GCC 9.4.0]', 'platform': 'Linux-5.8.0-59-generic-x86_64-with-glibc2.29', 'event': 'loaded'}]
```
```python
print(tfidf_model.lifecycle_events)
[{'msg': 'calculated IDF weights for 1174674 documents and 100000 features (100645197 matrix non-zeros)', 'datetime': '2021-06-30T08:58:10.744582', 'gensim': '4.0.1', 'python': '3.6.12 (default, Jun 28 2021, 13:17:01) \n[GCC 5.4.0 20160609]', 'platform': 'Linux-4.4.0-1128-aws-x86_64-with-debian-stretch-sid', 'event': 'initialize'}, {'fname_or_handle': 'models/tfidf.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2021-06-30T08:58:10.744733', 'gensim': '4.0.1', 'python': '3.6.12 (default, Jun 28 2021, 13:17:01) \n[GCC 5.4.0 20160609]', 'platform': 'Linux-4.4.0-1128-aws-x86_64-with-debian-stretch-sid', 'event': 'saving'}, {'fname': 'models/tfidf.model', 'datetime': '2021-07-13T20:27:03.663529', 'gensim': '4.0.1', 'python': '3.8.10 (default, Jun  2 2021, 10:49:15) \n[GCC 9.4.0]', 'platform': 'Linux-5.8.0-59-generic-x86_64-with-glibc2.29', 'event': 'loaded'}]
```

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
Linux-5.8.0-59-generic-x86_64-with-glibc2.29

import sys; print(""Python"", sys.version)
Python 3.8.10 (default, Jun  2 2021, 10:49:15) 
[GCC 9.4.0]

import struct; print(""Bits"", 8 * struct.calcsize(""P""))
Bits 64

import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.21.0

import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.7.0

import gensim; print(""gensim"", gensim.__version__)
gensim 4.0.1

from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1
```"
909,https://github.com/RaRe-Technologies/gensim/issues/3192,3192,[],open,2021-07-13 17:31:46+00:00,,FastText models `.save()`d from 4.0+ slower to load; gain less benefit from mmap,"[Reported in forum thread: https://groups.google.com/g/gensim/c/xaGvo0j8yv0/m/VI74_Fp7AAAJ]

User identically-trained models in `gensim-3.8.3` and `gensim-4.0.1`. As expected, the files on disk from from 4.0.1 save are much smaller. Unexpectedly, loading the 4.0.1 save, using the `mmap` option, takes a few minutes, while the 3.8.3 save loads in a matter of seconds. 

The likely cause is a change to the 4.0.0+ `.save()` routines to avoid saving the `.vectors` array - because it's fully re-calculable from the other `.vectors_vocab` and `.vectors_ngrams` data. The code in 4.0 first [ignores the `.vectors` array on save](https://github.com/RaRe-Technologies/gensim/blob/a93067d2ea78916cb587552ba0fd22727c4b40ab/gensim/models/fasttext.py#L1079), then [notices it's missing on load](https://github.com/RaRe-Technologies/gensim/blob/a93067d2ea78916cb587552ba0fd22727c4b40ab/gensim/models/fasttext.py#L1025), and then [uses `.adjust_vectors()` to re-fill the `.vectors` array](https://github.com/RaRe-Technologies/gensim/blob/a93067d2ea78916cb587552ba0fd22727c4b40ab/gensim/models/fasttext.py#L1172). 

In a larger model, those re-calculations take enough time to be noticeable. Further, because this new `.vectors` array was freshly-allocated, it will never get any of the benefits that memmapping it from disk might have provided (never loading unaccessed ranges; never page-out writing redundant unchanged data in low-memory conditions; sharing the same RAM between processes loading the same model). 

Despite the redundant storage involved, more users probably prefer fast-loads & the potential for interprocess sharing than strictly minimal on-disk formats. So the old behavior – writing `.vectors` to disk & reloading it – should be supported, and probably also the default. (Simply removing `vectors` from the `ignore` list in `FastTextKeyedVectors._save_specials()` is likely enough to restore the old behavior.)

Perhaps, a new option for smaller-but-slower-to-load saves could be supported, or a doc-note added with a way for users to achieve the same space efficiency another way. (I think, but have not tested, that manually adding `vectors` to the `.save()` method `ignore` parameter might be enough.)
"
910,https://github.com/RaRe-Technologies/gensim/issues/3193,3193,[],closed,2021-07-13 21:52:57+00:00,,doc2vec not producing all document vectors,"#### Problem description

I am trying to train doc2vec and running into a couple strange things. I have a collection on 128032 documents (derived from MIMIC CXR reports), but when I train doc2vec, I end up with just a fraction of the vectors:
```
model = Doc2Vec(documents, vector_size=5, window=2, min_count=2, workers=4)
print(model.wv.vectors.shape)
print(model.dv.vectors.shape)
```
produces:
```
(12801, 5)
(10,5)
```
According to documentation at: https://radimrehurek.com/gensim/models/doc2vec.html   'dv' is supposed to have document vectors. Why are there only 10? 

Document examples:
```
TaggedDocument(['no', 'acute', 'cardiopulmonary', 'process.', 'there', 'is', 'no', 'focal', 'consolidation,', 'pleural', 'effusion', 'or', 'pneumothorax.', 'bilateral', 'nodular', 'opacities', 'that', 'most', 'likely', 'represent', 'nipple', 'shadows.', 'cardiomediastinal', 'silhouette', 'is', 'normal.', 'clips', 'project', 'over', 'left', 'lung,', 'potentially', 'within', 'breast.', 'imaged', 'upper', 'abdomen', 'is', 'unremarkable.', 'chronic', 'deformity', 'posterior', 'left', 'sixth', 'seventh', 'ribs', 'are', 'noted.'], 50414267)
TaggedDocument(['no', 'acute', 'cardiopulmonary', 'process.', 'lungs', 'are', 'clear', 'focal', 'consolidation,', 'pleural', 'effusion', 'or', 'pneumothorax.', 'heart', 'size', 'is', 'normal.', 'mediastinal', 'contours', 'are', 'normal.', 'multiple', 'surgical', 'clips', 'project', 'over', 'left', 'breast,', 'old', 'left', 'rib', 'fractures', 'are', 'noted.'], 56699142)
TaggedDocument(['no', 'evidence', 'acute', 'cardiopulmonary', 'process.', 'as', 'compared', 'prior', 'examination', 'dated', '___,', 'there', 'has', 'been', 'no', 'significant', 'interval', 'change.', 'there', 'is', 'no', 'evidence', 'focal', 'consolidation,', 'pleural', 'effusion,', 'pneumothorax,', 'or', 'frank', 'pulmonary', 'edema.', 'cardiomediastinal', 'silhouette', 'is', 'within', 'normal', 'limits.', 'there', 'is', 'persistent', 'thoracic', 'kyphosis', 'with', 'mild', 'wedging', 'mid', 'thoracic', 'vertebral', 'body.'], 54205396)
```


#### Steps/code/corpus to reproduce

Model lifecycle:
```
[{'msg': 'effective_min_count=2 retains 12801 unique words (100.0%% of original 12801, drops 0)', 'datetime': '2021-07-13T17:40:07.046896', 'gensim': '4.0.1', 'python': '3.9.5 (default, May 18 2021, 14:42:02) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18363-SP0', 'event': 'prepare_vocab'}, {'msg': 'effective_min_count=2 leaves 6811903 word corpus (100.0%% of original 6811903, drops 0)', 'datetime': '2021-07-13T17:40:07.047886', 'gensim': '4.0.1', 'python': '3.9.5 (default, May 18 2021, 14:42:02) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18363-SP0', 'event': 'prepare_vocab'}, {'msg': 'downsampling leaves estimated 4932315.19961421 word corpus (72.4%% of prior 6811903)', 'datetime': '2021-07-13T17:40:07.268939', 'gensim': '4.0.1', 'python': '3.9.5 (default, May 18 2021, 14:42:02) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18363-SP0', 'event': 'prepare_vocab'}, {'msg': 'training model with 4 workers on 12801 vocabulary and 5 features, using sg=0 hs=0 sample=0.001 negative=5 window=2', 'datetime': '2021-07-13T17:40:07.857205', 'gensim': '4.0.1', 'python': '3.9.5 (default, May 18 2021, 14:42:02) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18363-SP0', 'event': 'train'}, {'msg': 'training on 68119030 raw words (59567377 effective words) took 440.6s, 135184 effective words/s', 'datetime': '2021-07-13T17:47:28.499426', 'gensim': '4.0.1', 'python': '3.9.5 (default, May 18 2021, 14:42:02) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18363-SP0', 'event': 'train'}, {'params': 'Doc2Vec(dm/m,d5,n5,w2,mc2,s0.001,t4)', 'datetime': '2021-07-13T17:47:28.501476', 'gensim': '4.0.1', 'python': '3.9.5 (default, May 18 2021, 14:42:02) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18363-SP0', 'event': 'created'}]
```

#### Versions

```
Windows-10-10.0.18363-SP0
Python 3.9.5 (default, May 18 2021, 14:42:02) [MSC v.1916 64 bit (AMD64)]
Bits 64
NumPy 1.20.2
SciPy 1.6.2
gensim 4.0.1
FAST_VERSION 1
```
"
911,https://github.com/RaRe-Technologies/gensim/issues/3195,3195,[],open,2021-07-19 22:24:33+00:00,,Updating W2V,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I am trying to update the pre-trained word2vec Google News model based on a corpus that I have. 
This code used to work when I was using gensim v3.x. After reading the [migrate notes](https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4#4-vocab-dict-became-key_to_index-for-looking-up-a-keys-integer-index-or-get_vecattr-and-set_vecattr-for-other-per-key-attributes) and applying changes still I get an error from intersect_word2vec_format. 
I would appreciate any help on this issue. 
```python
pretrained_path=""./GoogleNews-vectors-negative300.bin""
tokenizer = RegexpTokenizer(r'\w+')
sentences_tokenized = [['Hey', 'these', 'are', 'some', 'new', 'words'], ['Lets', 'expand', 'the', 'vocab']]
model_2 = Word2Vec(vector_size=300, min_count=1)
model_2.build_vocab(sentences_tokenized)
total_examples = model_2.corpus_count
model = KeyedVectors.load_word2vec_format(pretrained_path, binary=True)
model_2.build_vocab([list(model.key_to_index.keys())], update=True)
model_2.intersect_word2vec_format(pretrained_path, binary=True, lockf=1.0) # lockf=0.0 means no change
model_2.train(sentences_tokenized, total_examples=total_examples, epochs=model_2.epochs)
```

#### gensim==4.0.1
the output:

```python
 model_2.build_vocab([list(model.key_to_index.keys())], update=True)
  File ""/home/miniconda3/lib/python3.8/site-packages/gensim/models/word2vec.py"", line 486, in build_vocab
    self.prepare_weights(update=update)
  File ""/home/miniconda3/lib/python3.8/site-packages/gensim/models/word2vec.py"", line 844, in prepare_weights
    self.update_weights()
  File ""/home/miniconda3/lib/python3.8/site-packages/gensim/models/word2vec.py"", line 865, in update_weights
    raise RuntimeError(
RuntimeError: You cannot do an online vocabulary-update of a model which has no prior vocabulary. First build the vocabulary of your model with a corpus before doing an online update.
```
"
912,https://github.com/RaRe-Technologies/gensim/issues/3196,3196,[],open,2021-07-20 08:45:09+00:00,,Gensim sort_by_descending_frequency changes most_similar results,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

It seems that when retrieving the most similar word vectors, sorting by word frequency will change the results in `Gensim`. 

#### Steps/code/corpus to reproduce


Before sorting: 

    from gensim.models import FastText
    from gensim.test.utils import common_texts  # some example sentences
    print(len(common_texts))
    model = FastText(vector_size=4, window=3, min_count=1)  # instantiate
    model.build_vocab(corpus_iterable=common_texts)
    model.train(corpus_iterable=common_texts, total_examples=len(common_texts), epochs=1)  
    
    model.wv.most_similar(positive=[""human""])

>     [('interface', 0.7432922720909119),
>      ('minors', 0.6719315052032471),
>      ('time', 0.3513716757297516),
>      ('computer', 0.05815044790506363),
>      ('response', -0.11714297533035278),
>      ('graph', -0.15643596649169922),
>      ('eps', -0.2679084539413452),
>      ('survey', -0.34035828709602356),
>      ('trees', -0.63677978515625),
>      ('user', -0.6500451564788818)]

However, if I sort the vectors by descending frequency: 

    model.wv.sort_by_descending_frequency()
    
    model.wv.most_similar(positive=[""human""])

>     [('minors', 0.9638221263885498),
>      ('time', 0.6335864067077637),
>      ('interface', 0.40014874935150146),
>      ('computer', 0.03224882856011391),
>      ('response', -0.14850640296936035),
>      ('graph', -0.2249641716480255),
>      ('survey', -0.26847705245018005),
>      ('user', -0.45202943682670593),
>      ('eps', -0.497650682926178),
>      ('trees', -0.6367797255516052)]

The most similar word ranking as well as the word similarities change. Any idea why? 

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

If your problem is with a specific Gensim model (word2vec, lsimodel, doc2vec, fasttext, ldamodel etc), include the following:

```python
print(my_model.lifecycle_events)
[{'params': 'FastText(vocab=0, vector_size=4, alpha=0.025)', 'datetime': '2021-07-20T09:46:56.158863', 'gensim': '4.0.1', 'python': '3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31) \n[GCC 7.3.0]', 'platform': 'Linux-3.10.0-1160.31.1.el7.csd3.x86_64-x86_64-with-redhat-7.9-Nitrogen', 'event': 'created'}, {'msg': 'effective_min_count=1 retains 12 unique words (100.0%% of original 12, drops 0)', 'datetime': '2021-07-20T09:46:56.159995', 'gensim': '4.0.1', 'python': '3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31) \n[GCC 7.3.0]', 'platform': 'Linux-3.10.0-1160.31.1.el7.csd3.x86_64-x86_64-with-redhat-7.9-Nitrogen', 'event': 'prepare_vocab'}, {'msg': 'effective_min_count=1 leaves 29 word corpus (100.0%% of original 29, drops 0)', 'datetime': '2021-07-20T09:46:56.160040', 'gensim': '4.0.1', 'python': '3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31) \n[GCC 7.3.0]', 'platform': 'Linux-3.10.0-1160.31.1.el7.csd3.x86_64-x86_64-with-redhat-7.9-Nitrogen', 'event': 'prepare_vocab'}, {'msg': 'downsampling leaves estimated 3.5001157321504532 word corpus (12.1%% of prior 29)', 'datetime': '2021-07-20T09:46:56.160376', 'gensim': '4.0.1', 'python': '3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31) \n[GCC 7.3.0]', 'platform': 'Linux-3.10.0-1160.31.1.el7.csd3.x86_64-x86_64-with-redhat-7.9-Nitrogen', 'event': 'prepare_vocab'}, {'update': False, 'trim_rule': 'None', 'datetime': '2021-07-20T09:46:56.233809', 'gensim': '4.0.1', 'python': '3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31) \n[GCC 7.3.0]', 'platform': 'Linux-3.10.0-1160.31.1.el7.csd3.x86_64-x86_64-with-redhat-7.9-Nitrogen', 'event': 'build_vocab'}, {'msg': 'training model with 3 workers on 12 vocabulary and 4 features, using sg=0 hs=0 sample=0.001 negative=5 window=3', 'datetime': '2021-07-20T09:46:56.234068', 'gensim': '4.0.1', 'python': '3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31) \n[GCC 7.3.0]', 'platform': 'Linux-3.10.0-1160.31.1.el7.csd3.x86_64-x86_64-with-redhat-7.9-Nitrogen', 'event': 'train'}, {'msg': 'training on 29 raw words (3 effective words) took 0.0s, 1377 effective words/s', 'datetime': '2021-07-20T09:46:56.236277', 'gensim': '4.0.1', 'python': '3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31) \n[GCC 7.3.0]', 'platform': 'Linux-3.10.0-1160.31.1.el7.csd3.x86_64-x86_64-with-redhat-7.9-Nitrogen', 'event': 'train'}]
```

#### Versions

Linux-3.10.0-1160.31.1.el7.csd3.x86_64-x86_64-with-redhat-7.9-Nitrogen
Python 3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31) 
[GCC 7.3.0]
Bits 64
NumPy 1.18.1
SciPy 1.4.1
gensim 4.0.1
FAST_VERSION 0"
913,https://github.com/RaRe-Technologies/gensim/issues/3198,3198,[],closed,2021-07-21 14:35:26+00:00,,How do I predict a vector as a word?,"How do I predict a vector as a word?

If I have a vector, not equal to one of the vectors of the words in the model, then how do I find the best word for the vector? Dose there exists some API for that? For example `model.predict(v) -> w`"
914,https://github.com/RaRe-Technologies/gensim/issues/3199,3199,"[{'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",closed,2021-07-22 12:24:46+00:00,,Review change log for 4.1.0,"Gentlemen, I'm planning to do the next release in the immediate future.

One thing I'd like to do differently for this release is to review the change log _before_ we do the release. Previously, we updated the change log as part of the release project, which made review of the change log itself impossible, because by the time the changes were visible, the new version was already on PyPI and it was too late to make changes.

This time around, I've kept the change log up to date as we merged each PR. This has two benefits:

1. Anyone can spot errors in the change log and correct them.
2. Anyone can see how many of each issue type (bug fix, documentation, improvement, etc) we've made since the last release. Previously, this information was only visible via the issue tracker, and only a select few bother to dig around there.

Can you please have a look at the change log and make any required changes? Things like wording, omission of less relevant PRs, wrong PR category, missed PR, etc.

For the last part, here is the list of merged PRs since the last release: https://github.com/RaRe-Technologies/gensim/pulls?q=is%3Apr+is%3Aclosed+closed%3A%3E2021-04-01

"
915,https://github.com/RaRe-Technologies/gensim/issues/3200,3200,"[{'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",closed,2021-07-22 12:27:58+00:00,,Complete triage of PRs for version 4.1.0,"Gentlemen, there are 6 in-progress PRs that I initially marked for inclusion into the 4.1.0 release [here](https://github.com/RaRe-Technologies/gensim/projects/9).

I propose that we deal with them after the release, as they do not appear to be critical, and need not hold back the release. Can you please have a look at let me know?"
916,https://github.com/RaRe-Technologies/gensim/issues/3201,3201,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",open,2021-07-23 09:02:51+00:00,,Web documentation don't correpond to Jupyter notebooks,"I noticed that the web documentation sometimes don't correspond to what I see in the Jupyter notebooks.

For example, that's how I see it on the web:

![image](https://user-images.githubusercontent.com/54762742/126760168-4afdcf37-43f0-47c9-bd04-02385eecd5d7.png)

And that's what I see on the Jupyter notebooks:

![image](https://user-images.githubusercontent.com/54762742/126760372-0ee95732-661e-4384-93f2-e74e384c9eef.png)

Here  is another example:

On the web:

![image](https://user-images.githubusercontent.com/54762742/126760266-19c764a2-538d-4fb6-94c4-ed6f076cb6fc.png)

On Jupyter notebook (notice that the link to the python documentation is in full):

![image](https://user-images.githubusercontent.com/54762742/126760320-2854a010-fdbd-4c78-b492-e13a14c98680.png)


"
917,https://github.com/RaRe-Technologies/gensim/issues/3202,3202,[],open,2021-07-25 11:46:18+00:00,,KeyedVectors KeyError.args has incorrect/undesired behavior,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

Based on the [Python documentation](https://docs.python.org/3/tutorial/errors.html) KeyError.args should contain relevant arguments and KeyError.message should contain the formatted error message to display.

The current implementation has the formatted error message string output to KeyError.args. This adds unnecessary steps if one wants to keep track of problematic keys as you have to remove the formatting.

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

If your problem is with a specific Gensim model (word2vec, lsimodel, doc2vec, fasttext, ldamodel etc), include the following:

```python
from gensim.models import KeyedVectors

model_1= KeyedVectors(vector_size=1)
model_1.add_vectors('good_key', 1)

bad_keys = []
try:
    model_1['bad_key']
except KeyError as e:
    bad_keys.append(e.args[0])
    
print(bad_keys)
```
##### output
[""Key 'bad_key' not present""]
##### desired output
['bad_key']
#### Versions

Please provide the output of:

```
>>> Python 3.8.5 (default, Jul 21 2020, 10:41:41) 
[Clang 10.0.0 (clang-1000.11.45.5)]
>>> Bits 64
>>> NumPy 1.18.5
>>> SciPy 1.4.1
>>> gensim 4.0.1
>>> FAST_VERSION 0
```
"
918,https://github.com/RaRe-Technologies/gensim/issues/3204,3204,[],closed,2021-07-28 16:28:49+00:00,,mallet falls asleep,"i'm using mallet-2.0.8 with Python 3 and Jupyter Notebook. Recently it worked just fine. But now it falls asleep while showing it's still working even with a small dataset. 
The problem is with following function:
def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=1):
    """"""
    Compute c_v coherence for various number of topics
    Parameters:
    ----------
    dictionary : Gensim dictionary
    corpus : Gensim corpus
    texts : List of input texts
    limit : Max num of topics
    Returns:
    -------
    model_list : List of LDA topic models
    coherence_values : Coherence values corresponding to the LDA model with respective number of topics
    """"""
    coherence_values = []
    model_list = []
    for num_topics in range(start, limit, step):
        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)
        model_list.append(model)
        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')
        coherence_values.append(coherencemodel.get_coherence())
    return model_list, coherence_values"
919,https://github.com/RaRe-Technologies/gensim/issues/3205,3205,[],closed,2021-07-29 05:29:01+00:00,,Continue training existing fasttext model on multicore,"Is it possible to specify `workers` when continue training an existing fasttext model?

```
from gensim.models.fasttext import FastText
model = api.load(""fasttext-wiki-news-subwords-300"")
model.build_vocab(sentences, update=True)
total_words = model.corpus_total_words
model.train(sentences, total_examples=len(sentences), total_words=total_words, epochs=model.epochs)
```

It doesn't seem I can change the parameter of this existing model. Any advice would be much appreciated! Thanks!"
920,https://github.com/RaRe-Technologies/gensim/issues/3207,3207,[],closed,2021-07-31 04:45:23+00:00,,has anyone tried changing this codes to inverted dirchlet instead of just dirchlet?,"would like to ask if has anyone tried changing this codes to inverted dirchlet instead of just dirchlet?
[dirichlet_expectation.txt](https://github.com/RaRe-Technologies/gensim/files/6910689/dirichlet_expectation.txt)
[update_dir_prior.txt](https://github.com/RaRe-Technologies/gensim/files/6910690/update_dir_prior.txt)
"
921,https://github.com/RaRe-Technologies/gensim/issues/3210,3210,[],closed,2021-08-03 12:10:44+00:00,,Doc2Vec.load didn't work with xxx.dv.vectors.npy,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I used Dov2Vec.save to save my model on Linux and it generated three files which can't be loaded by Doc2Vec.load on Windows

#### Steps/code/corpus to reproduce

My codes are:

```python
texts = [TaggedDocument(texts[i], [i]) for i in range(len(texts))]
try:
    model = Doc2Vec.load('/data2/min_project/data/doc2vec_400w_epo10_size100')
    logging.info('Previous model loaded!')
    model.build_vocab(texts, update=True)
except:
    model = Doc2Vec(vector_size=100, min_count=2, epochs=10, workers=16)
    logging.info('New model generated!')
    model.build_vocab(texts)
model.train(texts, total_examples=model.corpus_count, epochs=model.epochs)
model.save('/data2/min_project/data/doc2vec_400w_epo10_size100')
```
It generated three files: 
doc2vec_400w_epo10_size100, 
doc2vec_400w_epo10_size100.dv.vectors.npy, 
doc2vec_400w_epo10_size100.syn1neg. 
And when I wanted to load them, error came out. 
```python
from gensim.models.doc2vec import Doc2Vec
model = Doc2Vec.load('./models/doc2vec_400w_epo10_size100')
```
**FileNotFoundError: [Errno 2] No such file or directory: './models/doc2vec_400w_epo10_size100.wv.vectors.npy'**

So how can I load my model?
Thank you very much!


#### Versions
I saved model here
```python
Linux-3.10.107-1-tlinux2_kvm_guest-0048-x86_64-with-glibc2.17
Python 3.9.5 (default, Jun  4 2021, 12:28:51) 
[GCC 7.5.0]
Bits 64
NumPy 1.21.0
SciPy 1.7.0
gensim 4.0.1
FAST_VERSION 1
```
I loaded model here
```python
Windows-10-10.0.19042-SP0
Python 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03)
[MSC v.1928 64 bit (AMD64)]
Bits 64
NumPy 1.18.0
SciPy 1.7.0
gensim 4.0.1
FAST_VERSION 0
```

"
922,https://github.com/RaRe-Technologies/gensim/issues/3211,3211,[],closed,2021-08-07 02:11:04+00:00,,NameError: name 'Similarity' is not defined,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? What is the expected result? What are you seeing instead?
1) I'm trying to use Similarity from the offcial document
2) but it shows the NameError: name 'Similarity' is not defined
3) I used the latest version of genism 4.0.1
<img width=""1114"" alt=""WeChat6b985efad4404452e7652c9a65ae08cd"" src=""https://user-images.githubusercontent.com/54015474/128584699-c3a34e18-491b-47cd-b0af-8b7210b0a95a.png"">


#### Steps/code/corpus to reproduce
`from gensim.test.utils import common_corpus, common_dictionary, get_tmpfile

index_tmpfile = get_tmpfile(""index"")
query = [(1, 2), (6, 1), (7, 2)]

index = Similarity(index_tmpfile, common_corpus, num_features=len(common_dictionary))  # build the index
similarities = index[query]`

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

If your problem is with a specific Gensim model (word2vec, lsimodel, doc2vec, fasttext, ldamodel etc), include the following:

```python
print(my_model.lifecycle_events)
```

#### Versions

Please provide the output of:

---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
<ipython-input-17-027d9974da56> in <module>
      4 query = [(1, 2), (6, 1), (7, 2)]
      5 
----> 6 index = Similarity(index_tmpfile, common_corpus, num_features=len(common_dictionary))  # build the index
      7 similarities = index[query]

NameError: name 'Similarity' is not defined

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import struct; print(""Bits"", 8 * struct.calcsize(""P""))
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```

macOS-10.16-x86_64-i386-64bit
Python 3.8.8 (default, Apr 13 2021, 12:59:45) 
[Clang 10.0.0 ]
Bits 64
NumPy 1.21.1
SciPy 1.7.0
gensim 4.0.1
FAST_VERSION 1
"
923,https://github.com/RaRe-Technologies/gensim/issues/3213,3213,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}]",open,2021-08-12 01:16:21+00:00,,summarize the way we update dependencies across the different files / subsystems,"Thanks! Shouldn't these versions match `setup.py` though?

I forgot what exactly needs to be updated where, so everything's in sync… @mpenkov could you please summarize the way we update dependencies across the different files / subsystems in [Gensim & Compatibility](https://github.com/RaRe-Technologies/gensim/wiki/Gensim-And-Compatibility).

_Originally posted by @piskvorky in https://github.com/RaRe-Technologies/gensim/issues/3209#issuecomment-891598074_"
924,https://github.com/RaRe-Technologies/gensim/issues/3216,3216,[],closed,2021-08-18 08:23:03+00:00,,Number of workers when working on multicore systems,"Hello,

I am trying to run FastText on huge corpus of newspaper text, and on a multicore server at my University. I have requested 48 cores to run this operation, and I wondering if in the FastText parameters I have to specify workers=48 too. I don't understand from the documentation whether it has to be like this.

`bsub -W 12:00 -n 48 -N -B -R ""rusage[mem=8GB]"" python scriptname.py`

Thanks a lot.
Sandra"
925,https://github.com/RaRe-Technologies/gensim/issues/3217,3217,"[{'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",closed,2021-08-18 12:20:44+00:00,,Get travis-ci.com working with this repo,"@piskvorky Could you please go through the steps described in the tutorial below? Only the project owner can do it, unfortunately.

https://docs.travis-ci.com/user/tutorial/#to-get-started-with-travis-ci-using-github

We need TravisCI to build for certain platforms that github actions does not support yet (e.g. aarm64)."
926,https://github.com/RaRe-Technologies/gensim/issues/3218,3218,[],open,2021-08-23 22:51:57+00:00,,seed for lda multicore not possible.,"Hi!

I don't seem to be able to set a seed for LDA multicore. This makes me get different cv coherence scores every time I run the model. I am using the following code. I am unsure whether this is a bug or if there are certain random processes which cannot be bypassed with a random seed. Please let me know what is happening! 

```
    #Create Dictionary
    id2word = corpora.Dictionary(data)

    # Create Corpus
    texts = data

    # Term Document Frequency
    corpus = [id2word.doc2bow(text) for text in texts]
    
    for i in topics_range:
        np.random.seed(100)
        n_topics = i
        
        t0 = time()

        #Model
        lda_model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,
                                                                id2word=id2word,
                                                                 num_topics=n_topics, 
                                                                 random_state=100,
                                                                 chunksize=200,
                                                                 passes=100,
                                                                 workers=20,
                                                                 iterations=150,
                                                                 minimum_probability=0)
                                                                 
        cv_coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')
        cv_coherence_total = cv_coherence_model_lda.get_coherence()
```"
927,https://github.com/RaRe-Technologies/gensim/issues/3221,3221,"[{'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",open,2021-08-28 23:46:50+00:00,,Migrate windows wheel building from gensim-wheels,"We can build Windows wheels under Github Actions now:

https://blog.devgenius.io/write-your-github-actions-workflow-for-build-windows-application-94e5a989f477

Currently, those wheels get built using Appveyor for the gensim-wheels repo."
928,https://github.com/RaRe-Technologies/gensim/issues/3224,3224,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 1602257032, 'node_id': 'MDU6TGFiZWwxNjAyMjU3MDMy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20HIGH', 'name': 'impact HIGH', 'color': 'b60205', 'default': False, 'description': 'Show-stopper for affected users'}, {'id': 1602279836, 'node_id': 'MDU6TGFiZWwxNjAyMjc5ODM2', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20MEDIUM', 'name': 'reach MEDIUM', 'color': 'ef7a1a', 'default': False, 'description': 'Affects a significant number of users'}]",open,2021-08-31 13:17:12+00:00,,Can't add vector to pretrained fasttext model via .add_vector,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I'm trying to add a new vector to a pretrained fasttext model via `.add_vector`. However, it seems like the vector is not added if I check via `.has_index_for`.

#### Steps/code/corpus to reproduce

```
>>> from gensim.models import fasttext
>>> import numpy as np
>>> ft_model =  fasttext.load_facebook_vectors(""fastText/cc.en.300.bin"")
>>> ft_model.has_index_for(""testtest"")
False
>>> ft_model.add_vector(""testtest"", np.zeros((300,)))
2000000
>>> ft_model.has_index_for(""testtest"")
False
>>> ft_model.index_to_key[2000000]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
IndexError: list index out of range
```

#### Versions

```
Windows-10-10.0.19041-SP0
Python 3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]
Bits 64
NumPy 1.20.3
SciPy 1.6.2
gensim 4.0.1
FAST_VERSION 1
```
"
929,https://github.com/RaRe-Technologies/gensim/issues/3225,3225,[],open,2021-08-31 16:22:30+00:00,,AttributeError: 'dict' object has no attribute '__NUMPY_SETUP__',"Building gensim from source on Python 3.9 I consistently get this error:
```
  File ""setup.py"", line 108, in finalize_options
    __builtins__.__NUMPY_SETUP__ = False
AttributeError: 'dict' object has no attribute '__NUMPY_SETUP__'
```

My current workaround is this:
https://github.com/RaRe-Technologies/gensim/blob/919b4154a5696a544b87f792992f25f5e4d59d3e/setup.py#L109

```
        try:
            __builtins__.__NUMPY_SETUP__ = False
        except AttributeError:
            print(""Cannot set '__builtins__.__NUMPY_SETUP__ = False' This is not needed if numpy is already installed."")
```
"
930,https://github.com/RaRe-Technologies/gensim/issues/3226,3226,[],closed,2021-09-01 09:09:12+00:00,,numpy 1.19.2 incompatible with gensim 4.1.0,"#### Problem description

When importing gensim I get the following error

```python
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/mbertoni/software/miniconda3/envs/test/lib/python3.7/site-packages/gensim/__init__.py"", line 11, in <module>
    from gensim import parsing, corpora, matutils, interfaces, models, similarities, utils  # noqa:F401
  File ""/home/mbertoni/software/miniconda3/envs/test/lib/python3.7/site-packages/gensim/corpora/__init__.py"", line 6, in <module>
    from .indexedcorpus import IndexedCorpus  # noqa:F401 must appear before the other classes
  File ""/home/mbertoni/software/miniconda3/envs/test/lib/python3.7/site-packages/gensim/corpora/indexedcorpus.py"", line 14, in <module>
    from gensim import interfaces, utils
  File ""/home/mbertoni/software/miniconda3/envs/test/lib/python3.7/site-packages/gensim/interfaces.py"", line 19, in <module>
    from gensim import utils, matutils
  File ""/home/mbertoni/software/miniconda3/envs/test/lib/python3.7/site-packages/gensim/matutils.py"", line 1024, in <module>
    from gensim._matutils import logsumexp, mean_absolute_difference, dirichlet_expectation
  File ""gensim/_matutils.pyx"", line 1, in init gensim._matutils
ValueError: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject
```

#### Steps/code/corpus to reproduce
```
conda create --name=test python=3.7 -y
conda install -y numpy==1.19.2
pip install gensim
```

#### Versions

Linux-5.11.0-25-generic-x86_64-with-debian-bullseye-sid
Python 3.7.11 (default, Jul 27 2021, 14:32:16) 
[GCC 7.5.0]
Bits 64
NumPy 1.19.2
SciPy 1.7.1"
931,https://github.com/RaRe-Technologies/gensim/issues/3228,3228,[],open,2021-09-08 15:44:39+00:00,,get_latest_training_loss returns 0,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

It seems that the `get_latest_training_loss` function in `fasttext` returns only 0. Both gensim **4.1.0** and **4.0.0** do not work.

```
from gensim.models.callbacks import CallbackAny2Vec
from pprint import pprint as print
from gensim.models.fasttext import FastText
from gensim.test.utils import datapath

class callback(CallbackAny2Vec):
    '''Callback to print loss after each epoch.'''

    def __init__(self):
        self.epoch = 0

    def on_epoch_end(self, model):
        loss = model.get_latest_training_loss()
        print('Loss after epoch {}: {}'.format(self.epoch, loss))
        self.epoch += 1

# Set file names for train and test data
corpus_file = datapath('lee_background.cor')

model = FastText(vector_size=100, callbacks=[callback()])

# build the vocabulary
model.build_vocab(corpus_file=corpus_file)

# train the model
model.train(
    corpus_file=corpus_file, epochs=model.epochs,
    total_examples=model.corpus_count, total_words=model.corpus_total_words,
    callbacks=model.callbacks, compute_loss=True,
)

print(model)
```


```
'Loss after epoch 0: 0.0'
'Loss after epoch 1: 0.0'
'Loss after epoch 2: 0.0'
'Loss after epoch 3: 0.0'
'Loss after epoch 4: 0.0'
```

**If currently FastText does not support `get_latest_training_loss`, the documentation here needs to be removed:** 

https://radimrehurek.com/gensim/models/fasttext.html#gensim.models.fasttext.FastText.get_latest_training_loss

#### Versions

I have tried this in three different environments and neither of them works.

**First environment:** 

```Python 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:39:48)
[GCC 9.3.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import platform; print(platform.platform())
Linux-3.10.0-1160.36.2.el7.x86_64-x86_64-with-glibc2.17
>>> import sys; print(""Python"", sys.version)
Python 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:39:48)
[GCC 9.3.0]
>>> import struct; print(""Bits"", 8 * struct.calcsize(""P""))
Bits 64
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.21.2
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.7.1
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 4.1.0
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 0
```

**Second environment:** 

```
Python 3.9.5 (default, May 18 2021, 12:31:01)
[Clang 10.0.0 ] :: Anaconda, Inc. on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import platform; print(platform.platform())
macOS-10.16-x86_64-i386-64bit
>>> import sys; print(""Python"", sys.version)
Python 3.9.5 (default, May 18 2021, 12:31:01)
[Clang 10.0.0 ]
>>> import struct; print(""Bits"", 8 * struct.calcsize(""P""))
Bits 64
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.20.3
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.7.1
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 4.1.0
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 0
```

**Third environment:** 

```
Python 3.9.5 (default, May 18 2021, 12:31:01)
[Clang 10.0.0 ] :: Anaconda, Inc. on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import platform; print(platform.platform())
macOS-10.16-x86_64-i386-64bit
>>> import sys; print(""Python"", sys.version)
Python 3.9.5 (default, May 18 2021, 12:31:01)
[Clang 10.0.0 ]
>>> import struct; print(""Bits"", 8 * struct.calcsize(""P""))
Bits 64
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.20.3
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.7.1
>>> import gensim; print(""gensim"", gensim.__version__)
/Users/jinhuawang/miniconda3/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.
  warnings.warn(msg)
gensim 4.0.0
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 0
```

"
932,https://github.com/RaRe-Technologies/gensim/issues/3229,3229,[],closed,2021-09-09 04:02:40+00:00,,Word2Vec model callbacks property not accessible,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

It seems that the callbacks property in the Word2Vec model is not callable: 

#### Steps/code/corpus to reproduce

```python
from gensim.models.callbacks import CallbackAny2Vec
from pprint import pprint as print
from gensim.models.word2vec import Word2Vec
from gensim.test.utils import datapath

class callback(CallbackAny2Vec):
    '''Callback to print loss after each epoch.'''

    def __init__(self):
        self.epoch = 0

    def on_epoch_end(self, model):
        loss = model.get_latest_training_loss()
        print('Loss after epoch {}: {}'.format(self.epoch, loss))
        self.epoch += 1

# Set file names for train and test data
corpus_file = datapath('lee_background.cor')

model = Word2Vec(vector_size=100, callbacks=[callback()])

# build the vocabulary
model.build_vocab(corpus_file=corpus_file)

# train the model
model.train(
    corpus_file=corpus_file, epochs=model.epochs,
    total_examples=model.corpus_count, total_words=model.corpus_total_words,
    callbacks=model.callbacks, compute_loss=True,
)

print(model)
```

> 
> AttributeError                            Traceback (most recent call last)
> <ipython-input-1-4a4736964107> in <module>
>      27     corpus_file=corpus_file, epochs=model.epochs,
>      28     total_examples=model.corpus_count, total_words=model.corpus_total_words,
> ---> 29     callbacks=model.callbacks, compute_loss=True,
>      30 )
>      31 
> 
> AttributeError: 'Word2Vec' object has no attribute 'callbacks'
> 
> 
> 

#### Versions

```>>> import platform; print(platform.platform())
macOS-10.16-x86_64-i386-64bit
>>> import sys; print(""Python"", sys.version)
Python 3.9.5 (default, May 18 2021, 12:31:01)
[Clang 10.0.0 ]
>>> import struct; print(""Bits"", 8 * struct.calcsize(""P""))
Bits 64
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.20.3
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.7.1
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 4.1.0
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 0
```
"
933,https://github.com/RaRe-Technologies/gensim/issues/3232,3232,"[{'id': 175641, 'node_id': 'MDU6TGFiZWwxNzU2NDE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/bug', 'name': 'bug', 'color': 'e10c02', 'default': True, 'description': 'Issue described a bug'}, {'id': 233081, 'node_id': 'MDU6TGFiZWwyMzMwODE=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/difficulty%20easy', 'name': 'difficulty easy', 'color': '00ff00', 'default': False, 'description': 'Easy issue: required small fix'}, {'id': 721000065, 'node_id': 'MDU6TGFiZWw3MjEwMDAwNjU=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/good%20first%20issue', 'name': 'good first issue', 'color': '7057ff', 'default': True, 'description': 'Issue for new contributors (not required gensim understanding + very simple)'}, {'id': 1602257032, 'node_id': 'MDU6TGFiZWwxNjAyMjU3MDMy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20HIGH', 'name': 'impact HIGH', 'color': 'b60205', 'default': False, 'description': 'Show-stopper for affected users'}, {'id': 1602340302, 'node_id': 'MDU6TGFiZWwxNjAyMzQwMzAy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/reach%20LOW', 'name': 'reach LOW', 'color': '5abc21', 'default': False, 'description': 'Affects only niche use-case users'}]",closed,2021-09-13 16:12:11+00:00,,Negative exponent with value -1 (minus one) raises error when loading Doc2Vec model,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

I try to vary the value of the negative exponent parameter. When I use a value of -1, training works fine, saving the model too, but when I try to load the model afterwards with Doc2Vec.load() it raises the error ""ValueError: Integers to negative integer powers are not allowed.""

This is due to the following line: https://github.com/RaRe-Technologies/gensim/blob/266a01455ade51a93a08dba5950e87b4d98e0724/gensim/models/word2vec.py#L836

Here, numpy does not raise an integer by the power of another, but negative integer.

I guess this could be solved by converting the exponent to a float in this case?


"
934,https://github.com/RaRe-Technologies/gensim/issues/3233,3233,"[{'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",closed,2021-09-14 12:49:47+00:00,,Ask travis-ci.com for more credits,"Sounds like RaReTech ran out of Travis credits again:

https://app.travis-ci.com/github/RaRe-Technologies/gensim/requests

>  Owner RaRe-Technologies does not have enough credits.

Can you please ask them for more? It's not urgent, we only need travis for aarch64 wheel builds, and we can deal with them later, but it'd be good to have that working soon."
935,https://github.com/RaRe-Technologies/gensim/issues/3234,3234,"[{'id': 175643, 'node_id': 'MDU6TGFiZWwxNzU2NDM=', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/documentation', 'name': 'documentation', 'color': '02d7e1', 'default': True, 'description': 'Current issue related to documentation'}, {'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",open,2021-09-14 13:45:07+00:00,,Update release instructions,"https://github.com/RaRe-Technologies/gensim/wiki/Maintainer-page is out of date

- We don't use gensim-wheels repo anymore - everything happens in the main gensim repo
- Wheel building is less of a pain now - GHA takes care of most things
- Some release scripts appear out of date, e.g. prepare.sh
- A general description of what we're doing and why wrt to the wheel builds (interplay between manylinux, multibuild, etc) would be helpful"
936,https://github.com/RaRe-Technologies/gensim/issues/3237,3237,"[{'id': 1602257032, 'node_id': 'MDU6TGFiZWwxNjAyMjU3MDMy', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/impact%20HIGH', 'name': 'impact HIGH', 'color': 'b60205', 'default': False, 'description': 'Show-stopper for affected users'}, {'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",closed,2021-09-17 00:28:13+00:00,,Clean up gensim project on PyPI,"We've hit the 10GB limit for projects on PyPI. This is preventing some of the 4.1.2 wheels from being uploaded.

https://pypi.org/help/#project-size-limit

We need to clean up the project area before we can upload new wheels."
937,https://github.com/RaRe-Technologies/gensim/issues/3238,3238,"[{'id': 2020756897, 'node_id': 'MDU6TGFiZWwyMDIwNzU2ODk3', 'url': 'https://api.github.com/repos/RaRe-Technologies/gensim/labels/housekeeping', 'name': 'housekeeping', 'color': 'd863b1', 'default': False, 'description': 'internal tasks and processes'}]",closed,2021-09-17 09:23:11+00:00,,Investigate wheel filesize,"We build wheels for 4 platforms x 4 Python versions = 16 wheels per release. Each wheel is 25 MB (why so large?), so that's > 400 MB per release! I can see 10 GB disappearing quickly.

How do other projects with extensive wheel support (scikit-learn?) solve this?

_Originally posted by @piskvorky in https://github.com/RaRe-Technologies/gensim/issues/3237#issuecomment-921580397_"
938,https://github.com/RaRe-Technologies/gensim/issues/3239,3239,[],closed,2021-09-17 10:16:45+00:00,,ImportError: cannot import name 'lemmatize' from 'gensim.utils',"Hi! 

I'm having this issue:  **ImportError: cannot import name 'lemmatize' from 'gensim.utils'**
Could it be that you changed the name and it's not possible to import it as 'lemmatize'? Needed to post it here since I didn't find any information in the internet. Some people mentioned incompatibility with numpy though.
Thank you in advance for your response!

**What I use**:
macOS
Python 3.8.2 
[Clang 6.0 (clang-600.0.57)]
Bits 64
NumPy 1.21.1
SciPy 1.7.1
gensim 4.1.0
FAST_VERSION 1

"
939,https://github.com/RaRe-Technologies/gensim/issues/3240,3240,[],closed,2021-09-19 10:30:18+00:00,,Trying to get in touch regarding a security issue,"Hey there!

I'd like to report a security issue but cannot find contact instructions on your repository.

If not a hassle, might you kindly add a `SECURITY.md` file with an email, or another contact method? GitHub [recommends](https://docs.github.com/en/code-security/getting-started/adding-a-security-policy-to-your-repository) this best practice to ensure security issues are responsibly disclosed, and it would serve as a simple instruction for security researchers in the future.

Thank you for your consideration, and I look forward to hearing from you!

(cc @huntr-helper)"
940,https://github.com/RaRe-Technologies/gensim/issues/3241,3241,[],closed,2021-09-28 21:12:26+00:00,,I cannot import remove_stopword_tokens,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description
Following the [documentation ](https://radimrehurek.com/gensim/parsing/preprocessing.html) I attempt to import in Colab as follows: 
`from gensim.parsing.preprocessing import remove_stopword_tokens
`
#### Steps/code/corpus to reproduce

```
from gensim.parsing.preprocessing import remove_stopword_tokens

ImportError Traceback (most recent call last)
<ipython-input-16-dbd838c83237> in <module>()
----> 1 from gensim.parsing.preprocessing import remove_stopword_tokens

ImportError: cannot import name 'remove_stopword_tokens' from 'gensim.parsing.preprocessing' (/usr/local/lib/python3.7/dist-packages/gensim/parsing/preprocessing.py)
```
I observe also the same problem with `remove_short_tokens` for which also no example is provided in the docs.

#### Versions

```python
Linux-5.4.104+-x86_64-with-Ubuntu-18.04-bionic
Python 3.7.12 (default, Sep 10 2021, 00:21:48) 
[GCC 7.5.0]
Bits 64
NumPy 1.19.5
SciPy 1.4.1
gensim 4.0.0
FAST_VERSION 1
```
"
941,https://github.com/RaRe-Technologies/gensim/issues/3242,3242,[],open,2021-10-01 08:21:04+00:00,,Computing WmdSimilarity each-with-each,"Right now I am working on a model, where for a given dataset of sentences I need to compute WmdSimilarity between each of them. Thus the result is a (n x n) matrix, that is **symmetric**. Right now the only way is to compute similarity for each sentence with each sentence in the dataset. But half of the steps is reduntant, because the matrix is symmetric, so we only need to compute the _lower triangular portion_.

The only need is to create a method that computes this matrix and then sets the upper triangular portion according to the lower one (I believe this is easily done with numpy). This way the computing time can be reduced by 50%."
942,https://github.com/RaRe-Technologies/gensim/issues/3243,3243,[],closed,2021-10-05 07:54:03+00:00,,default estimation method of gensim's word2vec skipgram?,"I am now trying to use word2vec by estimating skipgram embeddings via NCE (noise contrastive estimation) rather than conventional negative sampling method, as a recent paper did (https://asistdl.onlinelibrary.wiley.com/doi/full/10.1002/asi.24421?casa_token=uCHp2XQZVV8AAAAA%3Ac7ETNVxnpqe7u9nhLzX7pIDjw5Fuq560ihU3K5tYVDcgQEOJGgXEakRudGwEQaomXnQPVRulw8gF9XeO). The paper has a replication github repository (https://github.com/sandeepsoni/semantic-progressiveness), and it mainly relied on gensim for implementing word2vec, but the repository is not well organized and in a mess, so I have no clue about how the authors implemented NCE estimation via gensim's word2vec.

The authors just used gensim's word2vec as a default status without including any options, so my question is what is the default estimation method for gensim's word2vec under skipgram embeddings. NCE? According to your manual, it just says there is an option for negative sampling, and if set to 0, then no negative sampling is used. But then what estimation method is used? negative (int, optional) – If > 0, negative sampling will be used, the int for negative specifies how many “noise words” should be drawn (usually between 5-20). If set to 0, no negative sampling is used.

Thanks you in advance, and look forward to hearing from you soon!
"
943,https://github.com/RaRe-Technologies/gensim/issues/3244,3244,[],open,2021-10-05 23:00:33+00:00,,Self provided normalization function is not used.,"https://github.com/RaRe-Technologies/gensim/blob/5bec27767ad40712e8912d53a896cb2282c33880/gensim/models/tfidfmodel.py#L525

`self.normalize = matutils.unitvec` does not allow users to use self-defined normalization function. "
944,https://github.com/RaRe-Technologies/gensim/issues/3245,3245,[],closed,2021-10-05 23:12:51+00:00,,Log level control,"https://github.com/RaRe-Technologies/gensim/blob/5bec27767ad40712e8912d53a896cb2282c33880/gensim/models/tfidfmodel.py#L447

I think it a good idea to control this logger output (give an option to disable) to avoid spamming the terminal."
945,https://github.com/RaRe-Technologies/gensim/issues/3246,3246,[],open,2021-10-09 11:31:27+00:00,,Partial support of compressed corpora in FastText model,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

Seems that vocab part of the FastText model are totally fine with compressed files. I.e you can pass bzipped file to `build_vocab` method and be perfectly fine. Until you try to train the model on the same file. It seems that `train_epoch_sg`/`train_epoch_cbow` (or more precisely, `CythonLineSentence`) doesn't support the same logic and only can accept text files.

Nevertheless you can pass bzip file to train method and it won't object at all. It'll even train on it. But as you can imagine, results are peculiar

This is a bit misleading. While I understand why it happens it took me sometime to debug why my vectors are rubbish.

#### Steps/code/corpus to reproduce

```python
    model = FastText()
    model.build_vocab(corpus_file=""/my/corpus.txt.bz2"")

    model.train(
        corpus_file=""/my/corpus.txt.bz2"",
        total_words=model.corpus_total_words,
        total_examples=model.corpus_count,
    )
```

#### Versions

Please provide the output of:

```python
macOS-11.5.2-x86_64-i386-64bit
Python 3.8.12 (default, Aug 31 2021, 04:09:21)
[Clang 12.0.5 (clang-1205.0.22.9)]
Bits 64
NumPy 1.21.2
SciPy 1.7.1
gensim 4.1.2
FAST_VERSION 0
```
"
946,https://github.com/RaRe-Technologies/gensim/issues/3248,3248,[],closed,2021-10-13 05:40:13+00:00,,LdaMallet error returned non-zero exit status 1.,"
I'm using LdaMallet to my project. It'd worked well until I used it with some corpus(Thai language).but it kinda confusing cause with other Thai,English corpora it can work.

The Error is:
CalledProcessError: Command '/content/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex ""\S+"" --input /tmp/6d3068_corpus.txt --output /tmp/6d3068_corpus.mallet' returned non-zero exit status 1. 

<img width=""1059"" alt=""Screen Shot 2021-10-13 at 11 54 41 AM"" src=""https://user-images.githubusercontent.com/69430817/137073559-ecca32ac-8739-4b79-a45c-930e1944a3de.png"">



I have tried:
- update environment -> os.environ.update({'MALLET_HOME': r'/content/mymallet/mallet-2.0.8/'})
- changed path to mallet.bat and edit mallet.bat follow this reply(https://stackoverflow.com/questions/55288724/gensim-mallet-calledprocesserror-returned-non-zero-exit-status)

#### Versions

<img width=""795"" alt=""Screen Shot 2021-10-13 at 12 21 50 PM"" src=""https://user-images.githubusercontent.com/69430817/137072043-fb11f1c5-da62-4b5e-92c6-9e77ac2f591c.png"">
"
947,https://github.com/RaRe-Technologies/gensim/issues/3249,3249,[],closed,2021-10-20 12:37:34+00:00,,Installing older version of Gensim gives a newer version,"
I tried installing an older versions from gensim due to the older version being able to run a LDA Mallet topic model using ""gensim.models.wrappers.LdaMallet"". I used the following:

```
! pip install gensim==3.8.3
```
However, when I test the version by using:

```
print(gensim.__version__)
```
I receive version: 4.1.2. I already tried uninstalling gensim and re-installing, but I still receive the newer version. 
"
948,https://github.com/RaRe-Technologies/gensim/issues/3256,3256,[],open,2021-10-26 03:19:14+00:00,,FastTextKeyedVectors.load_word2vec_format() does not initialize correctly.,"<!--
**IMPORTANT**:

- Use the [Gensim mailing list](https://groups.google.com/forum/#!forum/gensim) to ask general or usage questions. Github issues are only for bug reports.
- Check [Recipes&FAQ](https://github.com/RaRe-Technologies/gensim/wiki/Recipes-&-FAQ) first for common answers.

Github bug reports that do not include relevant information and context will be closed without an answer. Thanks!
-->

#### Problem description

What are you trying to achieve? What is the expected result? What are you seeing instead?
I have been trying to load my own trained FastText vectors into a FastTextKeyedVectors model (trained in Gensim).  The expected result is to load the saved vectors without flaw.  Instead, the error below occurs at initialization of the instance.

I investigated, and this occurs because `FastTextKeyedVectors` (FTKV) *require* the `max_n` and `bucket` parameters, whereas normal `KeyedVectors` do not.  FTKV does not have a constructor specific to its parameters, and so fails.

#### Steps/code/corpus to reproduce

Include full tracebacks, logs and datasets if necessary. Please keep the examples minimal (""minimal reproducible example"").

MWE: 
```
from gensim.models.fasttext import FastTextKeyedVectors
from gensim.models import KeyedVectors


kv = KeyedVectors.load_word2vec_format('path_to_ft.txt', binary=False)
ftkv = FastTextKeyedVectors.load_word2vec_format('path_to_ft.txt', binary=False)
```

```
Traceback (most recent call last):
  File ""fasttext_test.py"", line 6, in <module>
    ftkv = FastTextKeyedVectors.load_word2vec_format('data/local_election2020_temporal_medium_ft.txt', binary=False)
  File ""/home/rob/.env/topics/lib/python3.6/site-packages/gensim/models/keyedvectors.py"", line 1632, in load_word2vec_format
    limit=limit, datatype=datatype, no_header=no_header,
  File ""/home/rob/.env/topics/lib/python3.6/site-packages/gensim/models/keyedvectors.py"", line 1906, in _load_word2vec_format
    kv = cls(vector_size, vocab_size, dtype=datatype)
TypeError: __init__() missing 2 required positional arguments: 'max_n' and 'bucket'
```

For full reproducability, I used embeddings trained on the Twenty Newsgroups data set, as well as a few larger social media data sets.  I found this bug while investigating another bug having to do with the saving of FastText (and possibly W2V) vectors in the w2v text format.  On some lines when saving vectors, two words are written to the beginning of the line. I will post separately about this bug once I have convinced myself that it is not user error.

I'm not sure if lifecycle events works in this case because it's pre-initialization.

If your problem is with a specific Gensim model (word2vec, lsimodel, doc2vec, fasttext, ldamodel etc), include the following:

```python
print(my_model.lifecycle_events)
```

#### Versions

Please provide the output of:

```python
import platform; print(platform.platform())
import sys; print(""Python"", sys.version)
import struct; print(""Bits"", 8 * struct.calcsize(""P""))
import numpy; print(""NumPy"", numpy.__version__)
import scipy; print(""SciPy"", scipy.__version__)
import gensim; print(""gensim"", gensim.__version__)
from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
```

```
>>> import platform; print(platform.platform())
Linux-5.4.0-1055-gcp-x86_64-with-Ubuntu-18.04-bionic
>>> import sys; print(""Python"", sys.version)
Python 3.6.9 (default, Jan 26 2021, 15:33:00) 
[GCC 8.4.0]
>>> import struct; print(""Bits"", 8 * struct.calcsize(""P""))
Bits 64
>>> import numpy; print(""NumPy"", numpy.__version__)
NumPy 1.19.5
>>> import scipy; print(""SciPy"", scipy.__version__)
SciPy 1.5.4
>>> import gensim; print(""gensim"", gensim.__version__)
gensim 4.0.1
>>> from gensim.models import word2vec;print(""FAST_VERSION"", word2vec.FAST_VERSION)
FAST_VERSION 1
```
"
949,https://github.com/RaRe-Technologies/gensim/issues/3260,3260,[],open,2021-10-27 15:34:27+00:00,,Documentation should explain how to run tests,"The [Testing Gensim](https://radimrehurek.com/gensim/#testing) section of the documentation doesn't explain how to run tests.

Running ```python -m pytest``` fails:
```
============================= test session starts ==============================
platform freebsd13 -- Python 3.8.12, pytest-4.6.11, py-1.9.0, pluggy-0.13.1
rootdir: /disk-samsung/freebsd-ports/textproc/py-gensim/work-py38/gensim-4.1.2
plugins: forked-1.0.2, cov-2.9.0, rerunfailures-10.1, timeout-1.4.2, xdist-1.32.0, mock-1.10.4, hypothesis-6.23.1, asyncio-0.10.0, localserver-0.5.0
collected 0 items / 44 errors

==================================== ERRORS ====================================
_______________ ERROR collecting gensim/test/test_aggregation.py _______________
gensim/matutils.py:1346: in <module>
    from gensim.corpora._mmreader import MmReader  # noqa: F401
E   ModuleNotFoundError: No module named 'gensim.corpora._mmreader'

During handling of the above exception, another exception occurred:
/usr/local/lib/python3.8/site-packages/py/_path/local.py:704: in pyimport
    __import__(modname)
gensim/__init__.py:11: in <module>
    from gensim import parsing, corpora, matutils, interfaces, models, similarities, utils  # noqa:F401
gensim/corpora/__init__.py:6: in <module>
    from .indexedcorpus import IndexedCorpus  # noqa:F401 must appear before the other classes
gensim/corpora/indexedcorpus.py:14: in <module>
    from gensim import interfaces, utils
gensim/interfaces.py:19: in <module>
    from gensim import utils, matutils
gensim/matutils.py:1348: in <module>
    raise utils.NO_CYTHON
E   RuntimeError: Compiled extensions are unavailable. If you've installed from a package, ask the package maintainer to include compiled extensions. If you're building Gensim from source yourself, install Cython and a C compiler, and then run `python setup.py build_ext --inplace` to retry.
___________________ ERROR collecting gensim/test/test_api.py ___________________
gensim/matutils.py:1346: in <module>
    from gensim.corpora._mmreader import MmReader  # noqa: F401
E   ModuleNotFoundError: No module named 'gensim.corpora._mmreader'

During handling of the above exception, another exception occurred:
/usr/local/lib/python3.8/site-packages/py/_path/local.py:704: in pyimport
    __import__(modname)
gensim/__init__.py:11: in <module>
    from gensim import parsing, corpora, matutils, interfaces, models, similarities, utils  # noqa:F401
gensim/corpora/__init__.py:6: in <module>
    from .indexedcorpus import IndexedCorpus  # noqa:F401 must appear before the other classes
gensim/corpora/indexedcorpus.py:14: in <module>
    from gensim import interfaces, utils
gensim/interfaces.py:19: in <module>
    from gensim import utils, matutils
gensim/matutils.py:1348: in <module>
    raise utils.NO_CYTHON
```"
950,https://github.com/RaRe-Technologies/gensim/issues/3261,3261,[],open,2021-10-28 08:16:24+00:00,,Add `CITATTION.cff` file to repository,"Github has a built-in support for citation. Can you please consider adding CITATTION.cff file to your repository so we can easy cite your work?

Info:
https://citation-file-format.github.io/
https://twitter.com/natfriedman/status/1420122675813441540?lang=en"
951,https://github.com/RaRe-Technologies/gensim/issues/3262,3262,[],open,2021-10-29 07:06:06+00:00,,Adding new tags in doctag_vectors in ,"Hello! 

I am training a doc2vec model on a tagged docset.
I need to update it on new sets that contain new tags. Is there a way to update docvectors in gensim.doc2vec? How can I do it?

There is an old issue https://github.com/RaRe-Technologies/gensim/issues/1019 on the same topic, but it didn't help me as there were many changes in gensim. Maybe there is another way?
"
